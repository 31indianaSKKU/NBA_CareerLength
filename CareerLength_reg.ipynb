{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8feacd78",
   "metadata": {},
   "source": [
    "<h1>1.전처리 및 데이터 병합<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "ef14c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14822ff1",
   "metadata": {},
   "source": [
    "<h3>NCAA_STAT<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "d962e5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24596\\1487458159.py:19: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_data = pd.read_csv(file_path, encoding='latin1')  # 데이터 로드, 인코딩을 'latin1'으로 설정\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24596\\1487458159.py:19: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_data = pd.read_csv(file_path, encoding='latin1')  # 데이터 로드, 인코딩을 'latin1'으로 설정\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24596\\1487458159.py:19: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_data = pd.read_csv(file_path, encoding='latin1')  # 데이터 로드, 인코딩을 'latin1'으로 설정\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24596\\1487458159.py:19: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_data = pd.read_csv(file_path, encoding='latin1')  # 데이터 로드, 인코딩을 'latin1'으로 설정\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24596\\1487458159.py:19: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_data = pd.read_csv(file_path, encoding='latin1')  # 데이터 로드, 인코딩을 'latin1'으로 설정\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24596\\1487458159.py:19: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_data = pd.read_csv(file_path, encoding='latin1')  # 데이터 로드, 인코딩을 'latin1'으로 설정\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Season          School          Player Class Pos Height  \\\n",
      "0  1985-86  north-carolina  Brad Daugherty    SR   C    7-0   \n",
      "1  1985-86  north-carolina     Kenny Smith    JR   G    6-3   \n",
      "2  1985-86  north-carolina      Steve Hale    SR   G    6-4   \n",
      "3  1985-86  north-carolina        Joe Wolf    JR   F   6-11   \n",
      "4  1985-86  north-carolina       Jeff Lebo    FR   G    6-2   \n",
      "\n",
      "                      Summary  Rk_per_game  G_per_game  GS_per_game  \\\n",
      "0  20.2 Pts, 9.0 Reb, 1.8 Ast            1        34.0         34.0   \n",
      "1  12.0 Pts, 2.2 Reb, 6.2 Ast            2        34.0         34.0   \n",
      "2  11.3 Pts, 3.2 Reb, 4.9 Ast            3        31.0         31.0   \n",
      "3  10.0 Pts, 6.6 Reb, 2.1 Ast            4        34.0         34.0   \n",
      "4   9.2 Pts, 2.5 Reb, 4.0 Ast            5        34.0         10.0   \n",
      "\n",
      "   MP_per_game  FG_per_game  FGA_per_game  FG%_per_game  2P_per_game  \\\n",
      "0         32.0          8.4          12.9         0.648          NaN   \n",
      "1         32.6          4.8           9.4         0.516          NaN   \n",
      "2         29.0          4.3           8.0         0.532          NaN   \n",
      "3         25.1          4.4           8.2         0.532          NaN   \n",
      "4         26.3          3.8           7.4         0.514          NaN   \n",
      "\n",
      "   2PA_per_game  2P%_per_game  3P_per_game  3PA_per_game  3P%_per_game  \\\n",
      "0           NaN           NaN          NaN           NaN           NaN   \n",
      "1           NaN           NaN          NaN           NaN           NaN   \n",
      "2           NaN           NaN          NaN           NaN           NaN   \n",
      "3           NaN           NaN          NaN           NaN           NaN   \n",
      "4           NaN           NaN          NaN           NaN           NaN   \n",
      "\n",
      "   FT_per_game  FTA_per_game  FT%_per_game  TRB_per_game  AST_per_game  \\\n",
      "0          3.5           5.1         0.684           9.0           1.8   \n",
      "1          2.4           2.9         0.808           2.2           6.2   \n",
      "2          2.7           3.3         0.825           3.2           4.9   \n",
      "3          1.2           1.7         0.712           6.6           2.1   \n",
      "4          1.6           2.1         0.740           2.5           4.0   \n",
      "\n",
      "   STL_per_game  BLK_per_game  TOV_per_game  PF_per_game  PTS_per_game  \\\n",
      "0           1.0           1.1           2.3          2.7          20.2   \n",
      "1           1.5           0.1           2.8          1.4          12.0   \n",
      "2           1.8           0.1           2.0          2.5          11.3   \n",
      "3           0.5           0.3           2.1          2.4          10.0   \n",
      "4           1.2           0.0           1.4          2.1           9.2   \n",
      "\n",
      "   Rk_totals  G_totals  GS_totals  MP_totals  FG_totals  FGA_totals  \\\n",
      "0          1      34.0       34.0     1087.0      284.0       438.0   \n",
      "1          2      34.0       34.0     1109.0      164.0       318.0   \n",
      "2          3      31.0       31.0      900.0      132.0       248.0   \n",
      "3          4      34.0       34.0      854.0      149.0       280.0   \n",
      "4          5      34.0       10.0      893.0      130.0       253.0   \n",
      "\n",
      "   FG%_totals  2P_totals  2PA_totals  2P%_totals  3P_totals  3PA_totals  \\\n",
      "0       0.648        NaN         NaN         NaN        NaN         NaN   \n",
      "1       0.516        NaN         NaN         NaN        NaN         NaN   \n",
      "2       0.532        NaN         NaN         NaN        NaN         NaN   \n",
      "3       0.532        NaN         NaN         NaN        NaN         NaN   \n",
      "4       0.514        NaN         NaN         NaN        NaN         NaN   \n",
      "\n",
      "   3P%_totals  FT_totals  FTA_totals  FT%_totals  TRB_totals  AST_totals  \\\n",
      "0         NaN      119.0       174.0       0.684       306.0        61.0   \n",
      "1         NaN       80.0        99.0       0.808        75.0       210.0   \n",
      "2         NaN       85.0       103.0       0.825        99.0       152.0   \n",
      "3         NaN       42.0        59.0       0.712       224.0        72.0   \n",
      "4         NaN       54.0        73.0       0.740        84.0       137.0   \n",
      "\n",
      "   STL_totals  BLK_totals  TOV_totals  PF_totals  PTS_totals  Rk_per_min  \\\n",
      "0        35.0        36.0        79.0       92.0       687.0         2.0   \n",
      "1        52.0         2.0        96.0       49.0       408.0         9.0   \n",
      "2        55.0         2.0        63.0       77.0       349.0         8.0   \n",
      "3        17.0        11.0        71.0       83.0       340.0         5.0   \n",
      "4        40.0         1.0        46.0       70.0       314.0        10.0   \n",
      "\n",
      "   G_per_min  GS_per_min  MP_per_min  FG_per_min  FGA_per_min  FG%_per_min  \\\n",
      "0       34.0        34.0      1087.0        10.5         16.1        0.648   \n",
      "1       34.0        34.0      1109.0         5.9         11.5        0.516   \n",
      "2       31.0        31.0       900.0         5.9         11.0        0.532   \n",
      "3       34.0        34.0       854.0         7.0         13.1        0.532   \n",
      "4       34.0        10.0       893.0         5.8         11.3        0.514   \n",
      "\n",
      "   2P_per_min  2PA_per_min  2P%_per_min  3P_per_min  3PA_per_min  3P%_per_min  \\\n",
      "0         NaN          NaN          NaN         NaN          NaN          NaN   \n",
      "1         NaN          NaN          NaN         NaN          NaN          NaN   \n",
      "2         NaN          NaN          NaN         NaN          NaN          NaN   \n",
      "3         NaN          NaN          NaN         NaN          NaN          NaN   \n",
      "4         NaN          NaN          NaN         NaN          NaN          NaN   \n",
      "\n",
      "   FT_per_min  FTA_per_min  FT%_per_min  TRB_per_min  AST_per_min  \\\n",
      "0         4.4          6.4        0.684         11.3          2.2   \n",
      "1         2.9          3.6        0.808          2.7          7.6   \n",
      "2         3.8          4.6        0.825          4.4          6.8   \n",
      "3         2.0          2.8        0.712         10.5          3.4   \n",
      "4         2.4          3.3        0.740          3.8          6.1   \n",
      "\n",
      "   STL_per_min  BLK_per_min  TOV_per_min  PF_per_min  PTS_per_min  \\\n",
      "0          1.3          1.3          2.9         3.4         25.3   \n",
      "1          1.9          0.1          3.5         1.8         14.7   \n",
      "2          2.4          0.1          2.8         3.4         15.5   \n",
      "3          0.8          0.5          3.3         3.9         15.9   \n",
      "4          1.8          0.0          2.1         3.1         14.1   \n",
      "\n",
      "   ORB_per_game  DRB_per_game  ORB_totals  DRB_totals  Rk_advanced  \\\n",
      "0           NaN           NaN         NaN         NaN          NaN   \n",
      "1           NaN           NaN         NaN         NaN          NaN   \n",
      "2           NaN           NaN         NaN         NaN          NaN   \n",
      "3           NaN           NaN         NaN         NaN          NaN   \n",
      "4           NaN           NaN         NaN         NaN          NaN   \n",
      "\n",
      "   G_advanced  GS_advanced  MP_advanced  TS%_advanced  eFG%_advanced  \\\n",
      "0         NaN          NaN          NaN           NaN            NaN   \n",
      "1         NaN          NaN          NaN           NaN            NaN   \n",
      "2         NaN          NaN          NaN           NaN            NaN   \n",
      "3         NaN          NaN          NaN           NaN            NaN   \n",
      "4         NaN          NaN          NaN           NaN            NaN   \n",
      "\n",
      "   3PAr_advanced  FTr_advanced  PProd_advanced  ORB%_advanced  DRB%_advanced  \\\n",
      "0            NaN           NaN             NaN            NaN            NaN   \n",
      "1            NaN           NaN             NaN            NaN            NaN   \n",
      "2            NaN           NaN             NaN            NaN            NaN   \n",
      "3            NaN           NaN             NaN            NaN            NaN   \n",
      "4            NaN           NaN             NaN            NaN            NaN   \n",
      "\n",
      "   TRB%_advanced  AST%_advanced  STL%_advanced  BLK%_advanced  TOV%_advanced  \\\n",
      "0            NaN            NaN            NaN            NaN            NaN   \n",
      "1            NaN            NaN            NaN            NaN            NaN   \n",
      "2            NaN            NaN            NaN            NaN            NaN   \n",
      "3            NaN            NaN            NaN            NaN            NaN   \n",
      "4            NaN            NaN            NaN            NaN            NaN   \n",
      "\n",
      "   USG%_advanced  _advanced  OWS_advanced  DWS_advanced  WS_advanced  \\\n",
      "0            NaN        NaN           NaN           NaN          NaN   \n",
      "1            NaN        NaN           NaN           NaN          NaN   \n",
      "2            NaN        NaN           NaN           NaN          NaN   \n",
      "3            NaN        NaN           NaN           NaN          NaN   \n",
      "4            NaN        NaN           NaN           NaN          NaN   \n",
      "\n",
      "   WS/40_advanced RSCI Top 100  Rk_per_poss  G_per_poss  GS_per_poss  \\\n",
      "0             NaN          NaN          NaN         NaN          NaN   \n",
      "1             NaN          NaN          NaN         NaN          NaN   \n",
      "2             NaN          NaN          NaN         NaN          NaN   \n",
      "3             NaN          NaN          NaN         NaN          NaN   \n",
      "4             NaN          NaN          NaN         NaN          NaN   \n",
      "\n",
      "   MP_per_poss  FG_per_poss  FGA_per_poss  FG%_per_poss  2P_per_poss  \\\n",
      "0          NaN          NaN           NaN           NaN          NaN   \n",
      "1          NaN          NaN           NaN           NaN          NaN   \n",
      "2          NaN          NaN           NaN           NaN          NaN   \n",
      "3          NaN          NaN           NaN           NaN          NaN   \n",
      "4          NaN          NaN           NaN           NaN          NaN   \n",
      "\n",
      "   2PA_per_poss  2P%_per_poss  3P_per_poss  3PA_per_poss  3P%_per_poss  \\\n",
      "0           NaN           NaN          NaN           NaN           NaN   \n",
      "1           NaN           NaN          NaN           NaN           NaN   \n",
      "2           NaN           NaN          NaN           NaN           NaN   \n",
      "3           NaN           NaN          NaN           NaN           NaN   \n",
      "4           NaN           NaN          NaN           NaN           NaN   \n",
      "\n",
      "   FT_per_poss  FTA_per_poss  FT%_per_poss  TRB_per_poss  AST_per_poss  \\\n",
      "0          NaN           NaN           NaN           NaN           NaN   \n",
      "1          NaN           NaN           NaN           NaN           NaN   \n",
      "2          NaN           NaN           NaN           NaN           NaN   \n",
      "3          NaN           NaN           NaN           NaN           NaN   \n",
      "4          NaN           NaN           NaN           NaN           NaN   \n",
      "\n",
      "   STL_per_poss  BLK_per_poss  TOV_per_poss  PF_per_poss  PTS_per_poss  \\\n",
      "0           NaN           NaN           NaN          NaN           NaN   \n",
      "1           NaN           NaN           NaN          NaN           NaN   \n",
      "2           NaN           NaN           NaN          NaN           NaN   \n",
      "3           NaN           NaN           NaN          NaN           NaN   \n",
      "4           NaN           NaN           NaN          NaN           NaN   \n",
      "\n",
      "   _per_poss  ORtg_per_poss  DRtg_per_poss   #  Weight Hometown  PER_advanced  \\\n",
      "0        NaN            NaN            NaN NaN     NaN      NaN           NaN   \n",
      "1        NaN            NaN            NaN NaN     NaN      NaN           NaN   \n",
      "2        NaN            NaN            NaN NaN     NaN      NaN           NaN   \n",
      "3        NaN            NaN            NaN NaN     NaN      NaN           NaN   \n",
      "4        NaN            NaN            NaN NaN     NaN      NaN           NaN   \n",
      "\n",
      "   OBPM_advanced  DBPM_advanced  BPM_advanced High School  \n",
      "0            NaN            NaN           NaN         NaN  \n",
      "1            NaN            NaN           NaN         NaN  \n",
      "2            NaN            NaN           NaN         NaN  \n",
      "3            NaN            NaN           NaN         NaN  \n",
      "4            NaN            NaN           NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "#NLoad DATA: NCAA_stat \n",
    "\n",
    "# import os\n",
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "folder_path_ncaa = r\"C:\\Users\\31ind\\Desktop\\데이터사이언티스트로가는길\\성균관대SIS대학원\\재영논문자료\\데이터수집_크롤링\\NCAA_stat\"\n",
    "\n",
    "# 해당 폴더에 있는 모든 파일의 이름을 리스트에 저장\n",
    "file_list_ncaa = os.listdir(folder_path_ncaa)\n",
    "\n",
    "# 각 파일을 각각 읽어들여 병합\n",
    "data_frames = []  # 각 파일에서 읽은 데이터프레임을 저장할 리스트\n",
    "for file in file_list_ncaa:\n",
    "    if file.endswith('.csv'):  # CSV 파일만 읽어오기\n",
    "        file_path = os.path.join(folder_path_ncaa, file)\n",
    "        try:\n",
    "            temp_data = pd.read_csv(file_path, encoding='latin1')  # 데이터 로드, 인코딩을 'latin1'으로 설정\n",
    "            data_frames.append(temp_data)  # 읽은 데이터프레임을 리스트에 추가\n",
    "        except Exception as e:\n",
    "            print(f'Error occurred while processing {file}: {e}')\n",
    "            continue\n",
    "\n",
    "# 모든 데이터프레임을 병합\n",
    "ncaa_stat = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# 병합 결과 확인\n",
    "print(ncaa_stat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "78aa3621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Season School        Hometown                High School  \\\n",
      "160572  2021-22  iupui  Prattville, AL           Robert E. Lee HS   \n",
      "160573  2021-22  iupui     Wichita, KS         Wichita North (KS)   \n",
      "160574  2021-22  iupui  Lewisville, TX  Sunrise Christian Academy   \n",
      "160575  2021-22  iupui             NaN     The Skill Factory (GA)   \n",
      "160576  2021-22  iupui     Chicago, IL             Hillcrest (IL)   \n",
      "\n",
      "                Player     # Class Pos Height  Weight  \\\n",
      "160572    Azariah Seay  12.0    SR   G    6-4   195.0   \n",
      "160573  Jonah Carrasco  24.0    SR   F    6-9   220.0   \n",
      "160574       KJ Pruitt   1.0    FR   G    6-4   203.0   \n",
      "160575  Dimitar Pandev  33.0    SR   F   6-10   225.0   \n",
      "160576    Bobby Harvey   2.0    SR   G    6-3   200.0   \n",
      "\n",
      "                          Summary RSCI Top 100  Rk_per_game  G_per_game  \\\n",
      "160572  6.4 Pts, 2.9 Reb, 0.7 Ast          NaN            5        17.0   \n",
      "160573  4.4 Pts, 3.8 Reb, 0.4 Ast          NaN            9        19.0   \n",
      "160574  5.0 Pts, 3.1 Reb, 1.8 Ast          NaN            7        10.0   \n",
      "160575  2.6 Pts, 1.8 Reb, 0.4 Ast          NaN           11        16.0   \n",
      "160576  4.2 Pts, 2.6 Reb, 0.8 Ast          NaN           10         9.0   \n",
      "\n",
      "        GS_per_game  MP_per_game  FG_per_game  FGA_per_game  FG%_per_game  \\\n",
      "160572          4.0         18.2          2.5           6.8         0.371   \n",
      "160573         16.0         19.4          1.6           3.4         0.484   \n",
      "160574         10.0         27.0          1.9           4.6         0.413   \n",
      "160575          0.0          8.0          0.9           2.0         0.469   \n",
      "160576          1.0         19.3          1.4           5.3         0.271   \n",
      "\n",
      "        2P_per_game  2PA_per_game  2P%_per_game  3P_per_game  3PA_per_game  \\\n",
      "160572          2.1           4.3         0.479          0.5           2.5   \n",
      "160573          1.6           3.4         0.484          0.0           0.0   \n",
      "160574          1.5           3.2         0.469          0.4           1.4   \n",
      "160575          0.7           1.3         0.550          0.3           0.8   \n",
      "160576          0.3           1.9         0.176          1.1           3.4   \n",
      "\n",
      "        3P%_per_game  FT_per_game  FTA_per_game  FT%_per_game  TRB_per_game  \\\n",
      "160572         0.186          0.9           1.1         0.789           2.9   \n",
      "160573           NaN          1.2           2.3         0.500           3.8   \n",
      "160574         0.286          0.8           1.3         0.615           3.1   \n",
      "160575         0.333          0.5           0.8         0.615           1.8   \n",
      "160576         0.323          0.2           0.3         0.667           2.6   \n",
      "\n",
      "        AST_per_game  STL_per_game  BLK_per_game  TOV_per_game  PF_per_game  \\\n",
      "160572           0.7           0.6           0.1           1.5          2.1   \n",
      "160573           0.4           0.3           1.1           1.2          2.3   \n",
      "160574           1.8           1.0           0.4           3.1          1.9   \n",
      "160575           0.4           0.1           0.1           0.6          0.6   \n",
      "160576           0.8           0.3           0.1           0.8          2.0   \n",
      "\n",
      "        PTS_per_game  Rk_totals  G_totals  GS_totals  MP_totals  FG_totals  \\\n",
      "160572           6.4          7      17.0        4.0      310.0       43.0   \n",
      "160573           4.4          8      19.0       16.0      369.0       31.0   \n",
      "160574           5.0          9      10.0       10.0      270.0       19.0   \n",
      "160575           2.6         10      16.0        0.0      128.0       15.0   \n",
      "160576           4.2         11       9.0        1.0      174.0       13.0   \n",
      "\n",
      "        FGA_totals  FG%_totals  2P_totals  2PA_totals  2P%_totals  3P_totals  \\\n",
      "160572       116.0       0.371       35.0        73.0       0.479        8.0   \n",
      "160573        64.0       0.484       31.0        64.0       0.484        0.0   \n",
      "160574        46.0       0.413       15.0        32.0       0.469        4.0   \n",
      "160575        32.0       0.469       11.0        20.0       0.550        4.0   \n",
      "160576        48.0       0.271        3.0        17.0       0.176       10.0   \n",
      "\n",
      "        3PA_totals  3P%_totals  FT_totals  FTA_totals  FT%_totals  TRB_totals  \\\n",
      "160572        43.0       0.186       15.0        19.0       0.789        49.0   \n",
      "160573         0.0         NaN       22.0        44.0       0.500        72.0   \n",
      "160574        14.0       0.286        8.0        13.0       0.615        31.0   \n",
      "160575        12.0       0.333        8.0        13.0       0.615        28.0   \n",
      "160576        31.0       0.323        2.0         3.0       0.667        23.0   \n",
      "\n",
      "        AST_totals  STL_totals  BLK_totals  TOV_totals  PF_totals  PTS_totals  \\\n",
      "160572        12.0        10.0         1.0        25.0       35.0       109.0   \n",
      "160573         7.0         5.0        21.0        23.0       44.0        84.0   \n",
      "160574        18.0        10.0         4.0        31.0       19.0        50.0   \n",
      "160575         6.0         1.0         1.0        10.0       10.0        42.0   \n",
      "160576         7.0         3.0         1.0         7.0       18.0        38.0   \n",
      "\n",
      "        Rk_per_min  G_per_min  GS_per_min  MP_per_min  FG_per_min  \\\n",
      "160572         2.0       17.0         4.0       310.0         5.5   \n",
      "160573         6.0       19.0        16.0       369.0         3.4   \n",
      "160574        11.0       10.0        10.0       270.0         2.8   \n",
      "160575         3.0       16.0         0.0       128.0         4.7   \n",
      "160576         7.0        9.0         1.0       174.0         3.0   \n",
      "\n",
      "        FGA_per_min  FG%_per_min  2P_per_min  2PA_per_min  2P%_per_min  \\\n",
      "160572         15.0        0.371         4.5          9.4        0.479   \n",
      "160573          6.9        0.484         3.4          6.9        0.484   \n",
      "160574          6.8        0.413         2.2          4.7        0.469   \n",
      "160575         10.0        0.469         3.4          6.3        0.550   \n",
      "160576         11.0        0.271         0.7          3.9        0.176   \n",
      "\n",
      "        3P_per_min  3PA_per_min  3P%_per_min  FT_per_min  FTA_per_min  \\\n",
      "160572         1.0          5.5        0.186         1.9          2.5   \n",
      "160573         0.0          0.0          NaN         2.4          4.8   \n",
      "160574         0.6          2.1        0.286         1.2          1.9   \n",
      "160575         1.3          3.8        0.333         2.5          4.1   \n",
      "160576         2.3          7.1        0.323         0.5          0.7   \n",
      "\n",
      "        FT%_per_min  TRB_per_min  AST_per_min  STL_per_min  BLK_per_min  \\\n",
      "160572        0.789          6.3          1.5          1.3          0.1   \n",
      "160573        0.500          7.8          0.8          0.5          2.3   \n",
      "160574        0.615          4.6          2.7          1.5          0.6   \n",
      "160575        0.615          8.8          1.9          0.3          0.3   \n",
      "160576        0.667          5.3          1.6          0.7          0.2   \n",
      "\n",
      "        TOV_per_min  PF_per_min  PTS_per_min  ORB_per_game  DRB_per_game  \\\n",
      "160572          3.2         4.5         14.1           1.1           1.8   \n",
      "160573          2.5         4.8          9.1           1.6           2.2   \n",
      "160574          4.6         2.8          7.4           0.8           2.3   \n",
      "160575          3.1         3.1         13.1           0.6           1.2   \n",
      "160576          1.6         4.1          8.7           0.4           2.1   \n",
      "\n",
      "        ORB_totals  DRB_totals  Rk_advanced  G_advanced  GS_advanced  \\\n",
      "160572        18.0        31.0          8.0        17.0          4.0   \n",
      "160573        31.0        41.0          5.0        19.0         16.0   \n",
      "160574         8.0        23.0          9.0        10.0         10.0   \n",
      "160575         9.0        19.0          6.0        16.0          0.0   \n",
      "160576         4.0        19.0          7.0         9.0          1.0   \n",
      "\n",
      "        MP_advanced  TS%_advanced  eFG%_advanced  3PAr_advanced  FTr_advanced  \\\n",
      "160572        310.0         0.436          0.405          0.371         0.164   \n",
      "160573        369.0         0.495          0.484          0.000         0.688   \n",
      "160574        270.0         0.479          0.457          0.304         0.283   \n",
      "160575        128.0         0.550          0.531          0.375         0.406   \n",
      "160576        174.0         0.384          0.375          0.646         0.063   \n",
      "\n",
      "        PProd_advanced  ORB%_advanced  DRB%_advanced  TRB%_advanced  \\\n",
      "160572           102.0            7.0           12.9            9.8   \n",
      "160573            84.0           10.1           14.4           12.1   \n",
      "160574            53.0            3.6           11.0            7.1   \n",
      "160575            40.0            8.4           19.2           13.6   \n",
      "160576            36.0            2.8           14.1            8.2   \n",
      "\n",
      "        AST%_advanced  STL%_advanced  BLK%_advanced  TOV%_advanced  \\\n",
      "160572           11.3            2.0            0.4           16.7   \n",
      "160573            4.8            0.9            7.5           21.3   \n",
      "160574           16.3            2.3            2.0           37.3   \n",
      "160575           12.9            0.5            1.0           20.8   \n",
      "160576            9.9            1.1            0.8           12.4   \n",
      "\n",
      "        USG%_advanced  _advanced  OWS_advanced  DWS_advanced  WS_advanced  \\\n",
      "160572           26.3        NaN          -0.2           0.2          0.0   \n",
      "160573           15.9        NaN           0.0           0.3          0.4   \n",
      "160574           16.8        NaN          -0.4           0.2         -0.2   \n",
      "160575           20.5        NaN           0.1           0.1          0.2   \n",
      "160576           17.6        NaN          -0.1           0.1          0.0   \n",
      "\n",
      "        WS/40_advanced  Rk_per_poss  G_per_poss  GS_per_poss  MP_per_poss  \\\n",
      "160572           0.004          2.0        17.0          4.0        310.0   \n",
      "160573           0.038          6.0        19.0         16.0        369.0   \n",
      "160574          -0.030         11.0        10.0         10.0        270.0   \n",
      "160575           0.061          3.0        16.0          0.0        128.0   \n",
      "160576           0.001          7.0         9.0          1.0        174.0   \n",
      "\n",
      "        FG_per_poss  FGA_per_poss  FG%_per_poss  2P_per_poss  2PA_per_poss  \\\n",
      "160572          8.7          23.6         0.371          7.1          14.9   \n",
      "160573          5.3          10.9         0.484          5.3          10.9   \n",
      "160574          4.4          10.7         0.413          3.5           7.5   \n",
      "160575          7.4          15.8         0.469          5.4           9.9   \n",
      "160576          4.7          17.4         0.271          1.1           6.2   \n",
      "\n",
      "        2P%_per_poss  3P_per_poss  3PA_per_poss  3P%_per_poss  FT_per_poss  \\\n",
      "160572         0.479          1.6           8.7         0.186          3.1   \n",
      "160573         0.484          0.0           0.0           NaN          3.8   \n",
      "160574         0.469          0.9           3.3         0.286          1.9   \n",
      "160575         0.550          2.0           5.9         0.333          3.9   \n",
      "160576         0.176          3.6          11.2         0.323          0.7   \n",
      "\n",
      "        FTA_per_poss  FT%_per_poss  TRB_per_poss  AST_per_poss  STL_per_poss  \\\n",
      "160572           3.9         0.789          10.0           2.4           2.0   \n",
      "160573           7.5         0.500          12.3           1.2           0.9   \n",
      "160574           3.0         0.615           7.2           4.2           2.3   \n",
      "160575           6.4         0.615          13.8           3.0           0.5   \n",
      "160576           1.1         0.667           8.3           2.5           1.1   \n",
      "\n",
      "        BLK_per_poss  TOV_per_poss  PF_per_poss  PTS_per_poss  _per_poss  \\\n",
      "160572           0.2           5.1          7.1          22.2        NaN   \n",
      "160573           3.6           3.9          7.5          14.4        NaN   \n",
      "160574           0.9           7.2          4.4          11.7        NaN   \n",
      "160575           0.5           4.9          4.9          20.7        NaN   \n",
      "160576           0.4           2.5          6.5          13.8        NaN   \n",
      "\n",
      "        ORtg_per_poss  DRtg_per_poss  PER_advanced  OBPM_advanced  \\\n",
      "160572           84.3          107.4           9.1           -5.1   \n",
      "160573           90.6          106.3          11.2           -6.8   \n",
      "160574           71.2          107.0           5.2           -7.4   \n",
      "160575           98.4          108.3          13.5           -2.0   \n",
      "160576           82.0          109.0           4.3           -5.8   \n",
      "\n",
      "        DBPM_advanced  BPM_advanced  \n",
      "160572           -3.2          -8.3  \n",
      "160573           -2.3          -9.1  \n",
      "160574           -0.9          -8.4  \n",
      "160575           -3.3          -5.3  \n",
      "160576           -2.3          -8.1  \n"
     ]
    }
   ],
   "source": [
    "#ncaa_stat 복사본 생성\n",
    "ncaa_stat_new = ncaa_stat.copy()\n",
    "# 원래의 컬럼 순서를 복사\n",
    "new_order = ncaa_stat_new.columns.tolist()\n",
    "\n",
    "# 각 컬럼 위치 변경\n",
    "new_order.insert(new_order.index('Player') + 1, new_order.pop(new_order.index('#')))\n",
    "new_order.insert(new_order.index('Height') + 1, new_order.pop(new_order.index('Weight')))\n",
    "new_order.insert(new_order.index('School') + 1, new_order.pop(new_order.index('Hometown')))\n",
    "new_order.insert(new_order.index('Hometown') + 1, new_order.pop(new_order.index('High School')))\n",
    "new_order.insert(new_order.index('Summary') + 1, new_order.pop(new_order.index('RSCI Top 100')))\n",
    "\n",
    "# 새로운 컬럼 순서를 데이터프레임에 적용\n",
    "ncaa_stat_new = ncaa_stat_new[new_order]\n",
    "\n",
    "# 결과 확인\n",
    "print(ncaa_stat_new.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "75d9b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "9518aaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season              0.000000\n",
      "School              0.000000\n",
      "Hometown           43.475716\n",
      "High School        70.293380\n",
      "Player              0.000000\n",
      "#                  40.144604\n",
      "Class               0.675688\n",
      "Pos                 1.183233\n",
      "Height              0.868119\n",
      "Weight             39.957155\n",
      "Summary             0.260311\n",
      "RSCI Top 100       95.691164\n",
      "Rk_per_game         0.000000\n",
      "G_per_game          0.239760\n",
      "GS_per_game        12.452593\n",
      "MP_per_game        12.061503\n",
      "FG_per_game         0.267784\n",
      "FGA_per_game        0.269653\n",
      "FG%_per_game        2.679089\n",
      "2P_per_game         2.555783\n",
      "2PA_per_game        2.565747\n",
      "2P%_per_game        6.576284\n",
      "3P_per_game         2.548933\n",
      "3PA_per_game        2.558897\n",
      "3P%_per_game       24.558312\n",
      "FT_per_game         0.279617\n",
      "FTA_per_game        0.282108\n",
      "FT%_per_game        8.993193\n",
      "TRB_per_game        0.271521\n",
      "AST_per_game        0.278994\n",
      "STL_per_game        0.305772\n",
      "BLK_per_game        0.315114\n",
      "TOV_per_game       13.295179\n",
      "PF_per_game        11.468641\n",
      "PTS_per_game        0.260934\n",
      "Rk_totals           0.000000\n",
      "G_totals            0.239760\n",
      "GS_totals          12.452593\n",
      "MP_totals          12.035970\n",
      "FG_totals           0.240383\n",
      "FGA_totals          0.242874\n",
      "FG%_totals          2.679089\n",
      "2P_totals           2.529628\n",
      "2PA_totals          2.538969\n",
      "2P%_totals          6.576284\n",
      "3P_totals           2.522154\n",
      "3PA_totals          2.532119\n",
      "3P%_totals         24.558312\n",
      "FT_totals           0.252215\n",
      "FTA_totals          0.255952\n",
      "FT%_totals          8.993193\n",
      "TRB_totals          0.242874\n",
      "AST_totals          0.249724\n",
      "STL_totals          0.276503\n",
      "BLK_totals          0.285844\n",
      "TOV_totals         13.270892\n",
      "PF_totals          11.443731\n",
      "PTS_totals          0.227305\n",
      "Rk_per_min          6.427446\n",
      "G_per_min           6.556979\n",
      "GS_per_min         14.830268\n",
      "MP_per_min         12.035970\n",
      "FG_per_min         12.224042\n",
      "FGA_per_min        12.227156\n",
      "FG%_per_min         8.922822\n",
      "2P_per_min         13.781550\n",
      "2PA_per_min        13.789646\n",
      "2P%_per_min        12.416473\n",
      "3P_per_min         13.780305\n",
      "3PA_per_min        13.788401\n",
      "3P%_per_min        29.012872\n",
      "FT_per_min         12.227156\n",
      "FTA_per_min        12.232761\n",
      "FT%_per_min        14.987825\n",
      "TRB_per_min        12.230270\n",
      "AST_per_min        12.235252\n",
      "STL_per_min        12.252689\n",
      "BLK_per_min        12.260162\n",
      "TOV_per_min        15.233813\n",
      "PF_per_min         14.543801\n",
      "PTS_per_min        12.219060\n",
      "ORB_per_game       37.207695\n",
      "DRB_per_game       37.207695\n",
      "ORB_totals         37.190258\n",
      "DRB_totals         37.190258\n",
      "Rk_advanced        24.185282\n",
      "G_advanced         24.262503\n",
      "GS_advanced        28.976753\n",
      "MP_advanced        29.798788\n",
      "TS%_advanced       25.953904\n",
      "eFG%_advanced      26.288323\n",
      "3PAr_advanced      26.285209\n",
      "FTr_advanced       26.289568\n",
      "PProd_advanced     61.472066\n",
      "ORB%_advanced      61.472066\n",
      "DRB%_advanced      61.529360\n",
      "TRB%_advanced      48.690037\n",
      "AST%_advanced      48.686923\n",
      "STL%_advanced      61.342533\n",
      "BLK%_advanced      48.690037\n",
      "TOV%_advanced      37.141683\n",
      "USG%_advanced      48.725534\n",
      "_advanced         100.000000\n",
      "OWS_advanced       24.280563\n",
      "DWS_advanced       24.280563\n",
      "WS_advanced        24.280563\n",
      "WS/40_advanced     30.037303\n",
      "Rk_per_poss        61.289599\n",
      "G_per_poss         61.289599\n",
      "GS_per_poss        61.295204\n",
      "MP_per_poss        61.290845\n",
      "FG_per_poss        61.511923\n",
      "FGA_per_poss       61.511923\n",
      "FG%_per_poss       62.474078\n",
      "2P_per_poss        61.511923\n",
      "2PA_per_poss       61.511923\n",
      "2P%_per_poss       63.383922\n",
      "3P_per_poss        61.511923\n",
      "3PA_per_poss       61.511923\n",
      "3P%_per_poss       68.761404\n",
      "FT_per_poss        61.511923\n",
      "FTA_per_poss       61.511923\n",
      "FT%_per_poss       65.481358\n",
      "TRB_per_poss       61.511923\n",
      "AST_per_poss       61.511923\n",
      "STL_per_poss       61.511923\n",
      "BLK_per_poss       61.511923\n",
      "TOV_per_poss       61.512545\n",
      "PF_per_poss        61.512545\n",
      "PTS_per_poss       61.511923\n",
      "_per_poss         100.000000\n",
      "ORtg_per_poss      61.472066\n",
      "DRtg_per_poss      61.529360\n",
      "PER_advanced       64.344209\n",
      "OBPM_advanced      64.262628\n",
      "DBPM_advanced      64.262628\n",
      "BPM_advanced       64.262628\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#컬럼 별 결측치 check\n",
    "\n",
    "missing_counts = ncaa_stat_new.isnull().sum()\n",
    "missing_ratios = (missing_counts / len(ncaa_stat_new)) * 100\n",
    "print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "5464e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불필요한 컬럼 삭제처리: 중복되는 값, 크롤링 과정에서의 불필요한 정보 등\n",
    "\n",
    "ncaa_stat_new = ncaa_stat_new.drop([\"Rk_per_game\", \"Rk_totals\", \"Rk_per_min\", \"Rk_per_poss\", \"RSCI Top 100\",\n",
    "                                    \"Rk_advanced\", \"High School\", \"Hometown\", \"#\", \"Summary\", 'GS_totals',\n",
    "                                    'G_per_game', 'GS_per_game', 'MP_per_game', 'FG_per_game', 'FGA_per_game', \n",
    "                                    'FG%_per_game', '2P_per_game', '2PA_per_game', '2P%_per_game', '3P_per_game', \n",
    "                                    '3PA_per_game', '3P%_per_game', 'FT_per_game', 'FTA_per_game', 'FT%_per_game', \n",
    "                                    'ORB_per_game', 'DRB_per_game','TRB_per_game', 'AST_per_game', 'STL_per_game', \n",
    "                                    'BLK_per_game', 'TOV_per_game', 'PF_per_game', 'PTS_per_game', \"G_per_min\", \n",
    "                                    \"GS_per_min\", 'MP_per_min', 'FG%_per_min', '2P%_per_min', '3P%_per_min', 'FT%_per_min',\n",
    "                                    \"G_advanced\", \"GS_advanced\",'MP_advanced', \"_advanced\", \"G_per_poss\", \"GS_per_poss\", \n",
    "                                    'MP_per_poss', \"_per_poss\", 'FG%_per_poss', '2P%_per_poss', '3P%_per_poss','FT%_per_poss'], axis=1)\n",
    "\n",
    "\n",
    "#학교명 형식 수정.\n",
    "ncaa_stat_new['School'] = ncaa_stat_new['School'].str.replace('-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "3316709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#선수별 ID생성: 선수이름+학교\n",
    "\n",
    "ncaa_stat_new['Player_ID'] = ncaa_stat_new['Player'] + '_' + ncaa_stat_new['School']\n",
    "ncaa_stat_new['Player_ID'] = ncaa_stat_new.apply(lambda row: row['Player_ID'] + ' _None' if pd.isna(row['School']) else row['Player_ID'], axis=1)\n",
    "player_id_col = ncaa_stat_new.pop('Player_ID')\n",
    "ncaa_stat_new.insert(0, 'Player_ID', player_id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "5228ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3P%_totals 결측치 0 대체(3점슛을 한 번도 시도하지 않은 선수가 결측치로 되어 있음)\n",
    "ncaa_stat_new['3P%_totals'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "57e5efa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Height  Height_inch\n",
      "0    7-0         84.0\n",
      "1    6-3         75.0\n",
      "2    6-4         76.0\n",
      "3   6-11         83.0\n",
      "4    6-2         74.0\n"
     ]
    }
   ],
   "source": [
    "#'Height'컬럼 '피트-인치' --> '인치'로 변환\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# \"Height\" 컬럼을 문자열로 변환\n",
    "ncaa_stat_new['Height'] = ncaa_stat_new['Height'].astype(str)\n",
    "\n",
    "# \"0-0\" 또는 \"00-00\" 값을 결측값으로 처리\n",
    "ncaa_stat_new['Height'] = ncaa_stat_new['Height'].apply(lambda x: None if x in ['0-0', '00-00'] else x)\n",
    "\n",
    "# 피트와 인치를 인치 단위로 변환하는 함수\n",
    "def height_to_inches(height_str):\n",
    "    # 이미 숫자로 표현된 경우 그대로 반환\n",
    "     if re.match(r'^\\d+(\\.\\d+)?$', height_str):\n",
    "        return float(height_str)\n",
    "    \n",
    "# 피트와 인치를 추출\n",
    "     match = re.match(r'(\\d+)[-](\\d+)', height_str)\n",
    "     if match:\n",
    "        feet = float(match.group(1))\n",
    "        inches = float(match.group(2))\n",
    "        if len(match.group(1)) == 1:  # 피트가 한 자릿수인 경우 '0'을 추가하여 두 자릿수로 변환\n",
    "            feet = float('0' + match.group(1))\n",
    "        return feet * 12 + inches\n",
    "    \n",
    "    # 매칭되지 않는 경우 NaN 반환\n",
    "     return float('9999999999999')\n",
    "\n",
    "# \"Height_inch\" 컬럼에 변환 결과 저장\n",
    "ncaa_stat_new['Height_inch'] = ncaa_stat_new['Height'].apply(height_to_inches)\n",
    "\n",
    "# \"Height_inch\" 컬럼을 \"Height\" 컬럼 다음에 위치시킴\n",
    "ncaa_stat_new = ncaa_stat_new[['Height'] + [col for col in ncaa_stat_new.columns if col != 'Height']]\n",
    "\n",
    "# 결과 확인\n",
    "print(ncaa_stat_new[['Height', 'Height_inch']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "5c74fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height             0.000000\n",
      "Player_ID          0.000000\n",
      "Season             0.000000\n",
      "School             0.000000\n",
      "Player             0.000000\n",
      "Class              0.675688\n",
      "Pos                1.183233\n",
      "Weight            39.957155\n",
      "G_totals           0.239760\n",
      "MP_totals         12.035970\n",
      "FG_totals          0.240383\n",
      "FGA_totals         0.242874\n",
      "FG%_totals         2.679089\n",
      "2P_totals          2.529628\n",
      "2PA_totals         2.538969\n",
      "2P%_totals         6.576284\n",
      "3P_totals          2.522154\n",
      "3PA_totals         2.532119\n",
      "3P%_totals         0.000000\n",
      "FT_totals          0.252215\n",
      "FTA_totals         0.255952\n",
      "FT%_totals         8.993193\n",
      "TRB_totals         0.242874\n",
      "AST_totals         0.249724\n",
      "STL_totals         0.276503\n",
      "BLK_totals         0.285844\n",
      "TOV_totals        13.270892\n",
      "PF_totals         11.443731\n",
      "PTS_totals         0.227305\n",
      "FG_per_min        12.224042\n",
      "FGA_per_min       12.227156\n",
      "2P_per_min        13.781550\n",
      "2PA_per_min       13.789646\n",
      "3P_per_min        13.780305\n",
      "3PA_per_min       13.788401\n",
      "FT_per_min        12.227156\n",
      "FTA_per_min       12.232761\n",
      "TRB_per_min       12.230270\n",
      "AST_per_min       12.235252\n",
      "STL_per_min       12.252689\n",
      "BLK_per_min       12.260162\n",
      "TOV_per_min       15.233813\n",
      "PF_per_min        14.543801\n",
      "PTS_per_min       12.219060\n",
      "ORB_totals        37.190258\n",
      "DRB_totals        37.190258\n",
      "TS%_advanced      25.953904\n",
      "eFG%_advanced     26.288323\n",
      "3PAr_advanced     26.285209\n",
      "FTr_advanced      26.289568\n",
      "PProd_advanced    61.472066\n",
      "ORB%_advanced     61.472066\n",
      "DRB%_advanced     61.529360\n",
      "TRB%_advanced     48.690037\n",
      "AST%_advanced     48.686923\n",
      "STL%_advanced     61.342533\n",
      "BLK%_advanced     48.690037\n",
      "TOV%_advanced     37.141683\n",
      "USG%_advanced     48.725534\n",
      "OWS_advanced      24.280563\n",
      "DWS_advanced      24.280563\n",
      "WS_advanced       24.280563\n",
      "WS/40_advanced    30.037303\n",
      "FG_per_poss       61.511923\n",
      "FGA_per_poss      61.511923\n",
      "2P_per_poss       61.511923\n",
      "2PA_per_poss      61.511923\n",
      "3P_per_poss       61.511923\n",
      "3PA_per_poss      61.511923\n",
      "FT_per_poss       61.511923\n",
      "FTA_per_poss      61.511923\n",
      "TRB_per_poss      61.511923\n",
      "AST_per_poss      61.511923\n",
      "STL_per_poss      61.511923\n",
      "BLK_per_poss      61.511923\n",
      "TOV_per_poss      61.512545\n",
      "PF_per_poss       61.512545\n",
      "PTS_per_poss      61.511923\n",
      "ORtg_per_poss     61.472066\n",
      "DRtg_per_poss     61.529360\n",
      "PER_advanced      64.344209\n",
      "OBPM_advanced     64.262628\n",
      "DBPM_advanced     64.262628\n",
      "BPM_advanced      64.262628\n",
      "Height_inch        0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#컬럼 별 결측치 재확인\n",
    "\n",
    "missing_counts = ncaa_stat_new.isnull().sum()\n",
    "missing_ratios = (missing_counts / len(ncaa_stat_new)) * 100\n",
    "print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "4cfd337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#화면 출력 옵션_reset\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "193e9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불필요한 컬럼 삭제처리 및 컬럼 순서 변경처리\n",
    "\n",
    "ncaa_stat_new = ncaa_stat_new.drop(['Height'], axis=1)\n",
    "\n",
    "new_order = ['Player_ID', 'Season', 'School', 'Player', 'Class', 'Pos', 'Height_inch', 'Weight',\n",
    "              'G_totals', 'MP_totals', 'FG_totals', 'FGA_totals', 'FG%_totals', '2P_totals', \n",
    "              '2PA_totals', '2P%_totals', '3P_totals', '3PA_totals', '3P%_totals', 'FT_totals', 'FTA_totals', \n",
    "              'FT%_totals', 'ORB_totals', 'DRB_totals','TRB_totals', 'AST_totals', 'STL_totals', 'BLK_totals', \n",
    "              'TOV_totals', 'PF_totals', 'PTS_totals', \n",
    "              'FG_per_min', 'FGA_per_min',  '2P_per_min', '2PA_per_min',  \n",
    "              '3P_per_min', '3PA_per_min',  'FT_per_min', 'FTA_per_min',  \n",
    "              'TRB_per_min', 'AST_per_min', 'STL_per_min', 'BLK_per_min', 'TOV_per_min', 'PF_per_min', \n",
    "              'PTS_per_min', \n",
    "              'TS%_advanced', 'eFG%_advanced', '3PAr_advanced', 'FTr_advanced', 'PProd_advanced', \n",
    "              'ORB%_advanced', 'DRB%_advanced', 'TRB%_advanced', 'AST%_advanced', 'OBPM_advanced', \n",
    "              'DBPM_advanced', 'BPM_advanced', 'STL%_advanced', 'BLK%_advanced', 'TOV%_advanced', \n",
    "              'USG%_advanced',  'OWS_advanced', 'DWS_advanced', 'WS_advanced', 'WS/40_advanced', 'PER_advanced',\n",
    "               'FG_per_poss', 'FGA_per_poss', '2P_per_poss', '2PA_per_poss', \n",
    "              '3P_per_poss', '3PA_per_poss', 'FT_per_poss', 'FTA_per_poss',  \n",
    "              'TRB_per_poss', 'AST_per_poss', 'STL_per_poss', 'BLK_per_poss', 'TOV_per_poss', 'PF_per_poss', \n",
    "              'PTS_per_poss', 'ORtg_per_poss', 'DRtg_per_poss'\n",
    "              ]  # 변경하고 싶은 순서대로 컬럼명을 리스트에 저장\n",
    "ncaa_stat_new = ncaa_stat_new[new_order]  # 데이터프레임의 컬럼 순서를 변경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "dd117b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data as a file\n",
    "\n",
    "# ncaa_stat_new.to_excel(\"ncaa_stat_new.xlsx\", index=False)\n",
    "# ncaa_stat_new.to_csv(\"ncaa_stat_new.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "00817c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ncaa_stat_new데이터 파일 분할 저장\n",
    "\n",
    "# # import pandas as pd\n",
    "\n",
    "# # 1단계: Excel 파일을 CSV 파일로 변환하는 함수\n",
    "# def convert_excel_to_csv(file_path, output_csv_path, sheet_name=0):\n",
    "#     df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "#     df.to_csv(output_csv_path, index=False)\n",
    "#     print(f\"Excel to CSV conversion complete: {output_csv_path}\")\n",
    "\n",
    "# # 2단계: CSV 파일을 분할하는 함수\n",
    "# def split_csv_file(file_path, output_folder, chunk_size=10000):\n",
    "#     iterator = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "#     for i, chunk in enumerate(iterator):\n",
    "#         output_file = f\"{output_folder}/chunk_{i}.csv\"\n",
    "#         chunk.to_csv(output_file, index=False)\n",
    "#         print(f\"Chunk {i} saved as {output_file}\")\n",
    "\n",
    "# # 함수 사용 예시\n",
    "# excel_file_path = \"C:\\\\Users\\\\31ind\\\\ncaa_stat_new.xlsx\"\n",
    "# temp_csv_path = \"C:\\\\Users\\\\31ind\\\\ncaa_stat_new.csv\"\n",
    "# output_folder_path = \"C:\\\\Users\\\\31ind\\\\ncaa_stat_new_split\"\n",
    "\n",
    "# # Excel 파일을 CSV로 변환\n",
    "# convert_excel_to_csv(excel_file_path, temp_csv_path)\n",
    "\n",
    "# # CSV 파일을 분할\n",
    "# split_csv_file(temp_csv_path, output_folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f6a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09c71ea5",
   "metadata": {},
   "source": [
    "<h3>COLLEGE MAPPING<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "b510d9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  NBA draft           NCAA   비고\n",
      "0                   Alabama        alabama  NaN\n",
      "1  Alabama State University  alabama_state  NaN\n",
      "2                   Arizona        arizona  NaN\n",
      "3             Arizona State  arizona_state  NaN\n",
      "4                  Arkansas       arkansas  NaN\n"
     ]
    }
   ],
   "source": [
    "#Load DATA\n",
    "\n",
    "# import os\n",
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "file_path = \"C:\\\\Users\\\\31ind\\\\Desktop\\\\데이터사이언티스트로가는길\\\\성균관대SIS대학원\\\\재영논문자료\\\\데이터수집_크롤링\\\\college_mapping.xlsx\"\n",
    "\n",
    "# 엑셀 파일 읽어오기\n",
    "college_mapping = pd.read_excel(file_path)\n",
    "\n",
    "# 데이터프레임의 처음 몇 행을 출력하여 확인\n",
    "print(college_mapping.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "8d55212a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NBA</th>\n",
       "      <th>NCAA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>alabama_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona State</td>\n",
       "      <td>arizona_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Meridian Community College</td>\n",
       "      <td>not_NCAA_Division_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Midland College</td>\n",
       "      <td>not_NCAA_Division_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Globe Tech Junior College</td>\n",
       "      <td>not_NCAA_Division_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Siena College</td>\n",
       "      <td>siena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Northern Illinois</td>\n",
       "      <td>northern_illinois</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            NBA                 NCAA\n",
       "0                       Alabama              alabama\n",
       "1      Alabama State University        alabama_state\n",
       "2                       Arizona              arizona\n",
       "3                 Arizona State        arizona_state\n",
       "4                      Arkansas             arkansas\n",
       "..                          ...                  ...\n",
       "237  Meridian Community College  not_NCAA_Division_1\n",
       "238             Midland College  not_NCAA_Division_1\n",
       "239   Globe Tech Junior College  not_NCAA_Division_1\n",
       "240               Siena College                siena\n",
       "241           Northern Illinois    northern_illinois\n",
       "\n",
       "[242 rows x 2 columns]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_mapping = college_mapping.rename(columns={\"NBA draft\": \"NBA\"})\n",
    "college_mapping = college_mapping.drop(college_mapping.columns[2], axis=1)\n",
    "college_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd48d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c66b188",
   "metadata": {},
   "source": [
    "<h3>Career Length (target variable포함)<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "4be344be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Name                            Twitter Instagram  \\\n",
      "0     Derrick Coleman    https://twitter.com/44TheLegend       NaN   \n",
      "1         Gary Payton     https://twitter.com/GaryPayton       NaN   \n",
      "2  Mahmoud Abdul-Rauf                                NaN       NaN   \n",
      "3        Dennis Scott  https://twitter.com/dennis3dscott       NaN   \n",
      "4        Kendall Gill     https://twitter.com/kendallg13       NaN   \n",
      "\n",
      "                           Position Shoots Height_inch Weight_lb Height_cm  \\\n",
      "0          Power Forward and Center   Left     06월 10일     230lb     208cm   \n",
      "1                       Point Guard  Right     06월 04일     180lb     193cm   \n",
      "2                       Point Guard  Right     06월 01일     162lb     185cm   \n",
      "3  Small Forward and Shooting Guard  Right     06월 08일     229lb     203cm   \n",
      "4  Shooting Guard and Small Forward  Right     06월 05일     195lb     196cm   \n",
      "\n",
      "  Weight_kg                                           Born  ... College_2  \\\n",
      "0     104kg           June 21, 1967  in Mobile, Alabama us  ...       NaN   \n",
      "1      81kg       July 23, 1968  in Oakland, California us  ...       NaN   \n",
      "2      73kg     March 9, 1969  in Gulfport, Mississippi us  ...       NaN   \n",
      "3     103kg  September 5, 1968  in Hagerstown, Maryland us  ...       NaN   \n",
      "4      88kg          May 25, 1968  in Chicago, Illinois us  ...       NaN   \n",
      "\n",
      "  College_3 College_4                               High School  \\\n",
      "0       NaN       NaN             Northern in Detroit, Michigan   \n",
      "1       NaN       NaN            Skyline in Oakland, California   \n",
      "2       NaN       NaN         Gulfport in Gulfport, Mississippi   \n",
      "3       NaN       NaN            Flint Hill in Oakton, Virginia   \n",
      "4       NaN       NaN  Rich Central in Olympia Fields, Illinois   \n",
      "\n",
      "  Recruiting Rank           Draft_team                          Draft_num  \\\n",
      "0             NaN      New Jersey Nets  1st round (1st pick, 1st overall)   \n",
      "1             NaN  Seattle SuperSonics  1st round (2nd pick, 2nd overall)   \n",
      "2             NaN       Denver Nuggets  1st round (3rd pick, 3rd overall)   \n",
      "3             NaN        Orlando Magic  1st round (4th pick, 4th overall)   \n",
      "4             NaN    Charlotte Hornets  1st round (5th pick, 5th overall)   \n",
      "\n",
      "  Draft_year  NBA Debut  Experience  \n",
      "0       1990  02-Nov-90    15 years  \n",
      "1       1990  03-Nov-90    17 years  \n",
      "2       1990  10-Nov-90     9 years  \n",
      "3       1990  02-Nov-90    10 years  \n",
      "4       1990  02-Nov-90    15 years  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load DATA\n",
    "\n",
    "# import os\n",
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "file_path = \"C:\\\\Users\\\\31ind\\\\Desktop\\\\데이터사이언티스트로가는길\\\\성균관대SIS대학원\\\\재영논문자료\\\\데이터수집_크롤링\\\\NBA_Player_CareerLength_1990_2021_Inactive_modified.csv\"\n",
    "\n",
    "# 엑셀 파일 읽어오기\n",
    "CareerLength = pd.read_csv(file_path, encoding='CP949')\n",
    "\n",
    "# 데이터프레임의 처음 몇 행을 출력하여 확인\n",
    "print(CareerLength.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "6d1e7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불필요한 컬럼 삭제 처리.\n",
    "\n",
    "CareerLength = CareerLength.drop([\"Height_inch\", \"Twitter\", \"Instagram\", \"Shoots\", \"Weight_lb\", \n",
    "                                  \"Born\", \"Age\", \"High School\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "d1c04f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #특정컬럼 형식 수정\n",
    "\n",
    "# CareerLength['Height_inch'] = CareerLength['Height_inch'].str.replace(' ', '-')\n",
    "# CareerLength['Height_inch'] = CareerLength['Height_inch'].str.replace(r'[월일]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "738ccdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                0.000000\n",
      "Position            0.215983\n",
      "Height_cm           0.143988\n",
      "Weight_kg           0.143988\n",
      "College_1          17.782577\n",
      "College_2          91.000720\n",
      "College_3          99.856012\n",
      "College_4          99.928006\n",
      "Recruiting Rank    72.498200\n",
      "Draft_team          0.000000\n",
      "Draft_num           0.000000\n",
      "Draft_year          0.000000\n",
      "NBA Debut          14.182865\n",
      "Experience          0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#컬럼 별 결측치 비율 확인\n",
    "\n",
    "missing_counts = CareerLength.isnull().sum()\n",
    "missing_ratios = (missing_counts / len(CareerLength)) * 100\n",
    "print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "0fa1ec5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1389, 14)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추출한 샘플의 행과 열 수 카운트\n",
    "row_count, column_count = CareerLength.shape\n",
    "row_count, column_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "0bfa19c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##college변수에 값이 복수일 경우 split(college1,2,3,4) 및 ncaa기준으로 학교mapping\n",
    "#학교이름 맵핑(nba-ncaa)\n",
    "\n",
    "CareerLength.insert(5, 'College_ncaa_1', CareerLength['College_1'].map(college_mapping.set_index('NBA')['NCAA']))\n",
    "CareerLength.insert(7, 'College_ncaa_2', CareerLength['College_2'].map(college_mapping.set_index('NBA')['NCAA']))\n",
    "CareerLength.insert(9, 'College_ncaa_3', CareerLength['College_3'].map(college_mapping.set_index('NBA')['NCAA']))\n",
    "CareerLength.insert(17, 'College_ncaa_4', CareerLength['College_4'].map(college_mapping.set_index('NBA')['NCAA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "56b8b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable 형식 수정.\n",
    "\n",
    "CareerLength['Experience'] = CareerLength['Experience'].str.replace(' years', '').str.replace(' year', '')\n",
    "CareerLength['Experience'] = CareerLength['Experience'].str.replace('Rookie', '0')\n",
    "CareerLength['Experience'] = CareerLength['Experience'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "53424e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Draft_overall\n",
      "0                1\n",
      "1                2\n",
      "2                3\n",
      "3                4\n",
      "4                5\n",
      "...            ...\n",
      "1384            39\n",
      "1385            40\n",
      "1386            55\n",
      "1387            56\n",
      "1388            60\n",
      "\n",
      "[1389 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# \"Draft_num\" 컬럼에서 숫자 추출하여 새로운 컬럼 생성\n",
    "\n",
    "# career_length['Draft_pick'] = career_length['Draft_num'].str.extract(r'(\\d+)\\w+ pick')[0]\n",
    "CareerLength['Draft_overall'] = CareerLength['Draft_num'].str.extract(r'(\\d+)\\w+ overall')[0]\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(CareerLength[['Draft_overall']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "44a0a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불필요한 컬럼 삭제 처리.\n",
    "\n",
    "CareerLength = CareerLength.drop([\"Draft_num\"], axis=1)\n",
    "\n",
    "#단위 삭제 처리.\n",
    "\n",
    "# 'Weight_kg' 컬럼에서 'kg'를 제거합니다.\n",
    "CareerLength['Weight_kg'] = CareerLength['Weight_kg'].str.replace('kg', '').astype(float)\n",
    "# 'Height_cm' 컬럼에서 'cm'를 제거합니다.\n",
    "CareerLength['Height_cm'] = CareerLength['Height_cm'].str.replace('cm', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "0893557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터병합(ncaa_stat+nba_draft)과정에서 발견된 선수누락에 대한 처리\n",
    "\n",
    "##School_ncaa_1 확인 결과 및 처리\n",
    "# 1. Frank Mason III(Kansas): Frank Mason(NCAA)-->Frank Mason으로 맞춰 줌\n",
    "CareerLength['Name'].replace({'Frank Mason III': 'Frank Mason'}, inplace=True)\n",
    "\n",
    "# 2. Glen Rice Jr.(georgia-tech): Glen Rice (NCAA) --> Glen Rice로 맞춰 줌\n",
    "CareerLength['Name'].replace({'Glen Rice Jr.': 'Glen Rice'}, inplace=True)\n",
    "\n",
    "# 3. God Shammgod(providence): nba와 ncaa모두 이상없는데 왜 누락됐지?? 추후 확인!!!!!!!\n",
    "\n",
    "# 4. James Ennis III(long-beach-state): James Ennis(NCAA) -->James Ennis로 맞춰 줌\n",
    "CareerLength['Name'].replace({'James Ennis III': 'James Ennis'}, inplace=True)\n",
    "\n",
    "# 5. Jeff Taylor(Vanderbilt): Jeffery Taylor(NCAA) --> Jeffery Tylor로 맞춰 줌\n",
    "CareerLength['Name'].replace({'Jeff Taylor': 'Jeffery Taylor'}, inplace=True)\n",
    "\n",
    "# 6. Maurice Taylor(louisiana-tech): nba쪽 데이터에는 LSU가 있지만 실제로는 미시간 데이터만 존재. 추후 미시간 데이터 잘 가져왔는지 확인!!!!!!!!\n",
    "\n",
    "# 7. Michael McDonald(utah-valley): Utah-valley의 경우 현재는 Division1이나 당시에는 division1아님. 추후 다른 뉴올리언스 데이터 잘 가져왔는지 확인!!\n",
    "\n",
    "# 8. Travis Hansen(utah-valley): Utah-valley의 경우 현재는 Division1이나 당시에는 division1아님. 추후 브리검영 데이터 잘 가져왔는지 확인!!!\n",
    "\n",
    "# 9. Glenn Robinson lll(michigan): Glenn Robinson(ncaa) --> Glenn Robinson으로 맞춰 줌.\n",
    "CareerLength['Name'].replace({'Glenn Robinson III': 'Glenn Robinson'}, inplace=True)\n",
    "#Glenn Robinson(perdue)도 있음. Glenn Robinson III(michigan)의 아빠\n",
    "\n",
    "##School_ncaa_2 전수조사 결과 및 처리\n",
    "#1. David Young --> Dave Young:ncaa에서의 표기법으로 맞춰 줌.\n",
    "# ' David Young(nba)'를 'Dave Young(ncaa)'로 변경\n",
    "CareerLength['Name'].replace({'David Young': 'Dave Young'}, inplace=True)\n",
    "\n",
    "#2. Kebu Stewart: 이 선수의 소속대학이었던 cal-state-bakersfeild가 현재는 division1이지만 이 선수가 소속되었던 당시에는 division1이 아니었음-->nba_draft데이터에서 두 번째 학교를 Not_division1으로 수정.\n",
    "# Kebu Stewart는 Nevada-Las Vegas (UNLV)와 cal-state-bakersfield 소속이었으나\n",
    "#cal-state-bakersfield의 경우 현재는 division1이라 전처리된 데이터에서는 division1으로 처리되었지만 해당 선수가 뛰었던 시기에는 division2였고 \n",
    "#이에 따라 ncaa 데이터에는 UNLV시절 데이터만 있음. \n",
    "#데이터에 별도로 Not_division1으로 처리!!\n",
    "CareerLength.loc[(CareerLength['Name'] == 'Kebu Stewart') & (CareerLength['College_ncaa_2'] == 'cal-state-bakersfield'), 'College_ncaa_2'] = 'not_NCAA_Division1'\n",
    "\n",
    "#3. Patrick Ewing --> Pat Ewing:ncaa에서의 표기법으로 맞춰 줌.\n",
    "# 'Patrick Ewing(nba)'를 'Pat Ewing(ncaa)'으로 변경\n",
    "CareerLength['Name'].replace({'Patrick Ewing': 'Pat Ewing'}, inplace=True)\n",
    "\n",
    "#4. Wesley Johnson --> Wes Johnson:ncaa에서의 표기법으로 맞춰 줌.\n",
    "# 'Wesley Johnson(nba)'을 'Wes Johnson(ncaa)'으로 변경\n",
    "CareerLength['Name'].replace({'Wesley Johnson': 'Wes Johnson'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "fb0aebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#특정컬럼 형식 수정\n",
    "CareerLength['Name'] = CareerLength['Name'].astype(str)  # 'Name'을 문자열로 변환\n",
    "CareerLength['College_ncaa_1'] = CareerLength['College_ncaa_1'].astype(str)  # 'School'을 문자열로 변환\n",
    "CareerLength['College_ncaa_2'] = CareerLength['College_ncaa_2'].astype(str)  # 'School'을 문자열로 변환\n",
    "CareerLength['College_ncaa_3'] = CareerLength['College_ncaa_3'].astype(str)  # 'School'을 문자열로 변환\n",
    "CareerLength['College_ncaa_4'] = CareerLength['College_ncaa_4'].astype(str)  # 'School'을 문자열로 변환\n",
    "\n",
    "\n",
    "#값 형태 수정\n",
    "CareerLength['College_ncaa_1'] = CareerLength['College_ncaa_1'].str.replace('-', '_')\n",
    "CareerLength['College_ncaa_2'] = CareerLength['College_ncaa_2'].str.replace('-', '_')\n",
    "CareerLength['College_ncaa_3'] = CareerLength['College_ncaa_3'].str.replace('-', '_')\n",
    "CareerLength['College_ncaa_4'] = CareerLength['College_ncaa_4'].str.replace('-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "7a725e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#선수id생성: 선수이름+학교명(복수의 학교에 소속되었던 선수들은 각각의 학교별로 id생성)\n",
    "\n",
    "CareerLength['Player_ID_1'] = CareerLength['Name'] + '_' + CareerLength['College_ncaa_1']\n",
    "CareerLength['Player_ID_1'] = CareerLength.apply(lambda row: row['Player_ID_1'] + ' _None' if pd.isna(row['College_ncaa_1']) else row['Player_ID_1'], axis=1)\n",
    "player_id_col = CareerLength.pop('Player_ID_1')\n",
    "CareerLength.insert(0, 'Player_ID_1', player_id_col)\n",
    "\n",
    "\n",
    "CareerLength['Player_ID_2'] = CareerLength['Name'] + '_' + CareerLength['College_ncaa_2']\n",
    "CareerLength['Player_ID_2'] = CareerLength.apply(lambda row: row['Player_ID_2'] + ' _None' if pd.isna(row['College_ncaa_2']) else row['Player_ID_2'], axis=1)\n",
    "player_id_col = CareerLength.pop('Player_ID_2')\n",
    "CareerLength.insert(1, 'Player_ID_2', player_id_col)\n",
    "\n",
    "\n",
    "CareerLength['Player_ID_3'] = CareerLength['Name'] + '_' + CareerLength['College_ncaa_3']\n",
    "CareerLength['Player_ID_3'] = CareerLength.apply(lambda row: row['Player_ID_3'] + ' _None' if pd.isna(row['College_ncaa_3']) else row['Player_ID_3'], axis=1)\n",
    "player_id_col = CareerLength.pop('Player_ID_3')\n",
    "CareerLength.insert(2, 'Player_ID_3', player_id_col)\n",
    "\n",
    "\n",
    "\n",
    "CareerLength['Player_ID_4'] = CareerLength['Name'] + '_' + CareerLength['College_ncaa_4']\n",
    "CareerLength['Player_ID_4'] = CareerLength.apply(lambda row: row['Player_ID_4'] + ' _None' if pd.isna(row['College_ncaa_4']) else row['Player_ID_4'], axis=1)\n",
    "player_id_col = CareerLength.pop('Player_ID_4')\n",
    "CareerLength.insert(3, 'Player_ID_4', player_id_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "e09254d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ncaa_stat_new + Careerlength 데이터셋을 선수id와 학교명을 key값으로 병합. \n",
    "\n",
    "\n",
    "# Career length의 \"Name\"과 \"College_ncaa_1\"의 값을 기준으로 Ncaa_stat의 \"Player\", \"School\"이 일치하는 데이터만 추출\n",
    "merged_data_1 = pd.merge(ncaa_stat_new, CareerLength, left_on=[\"Player_ID\", \"School\"], right_on=[\"Player_ID_1\", \"College_ncaa_1\"], how='inner')\n",
    "\n",
    "# Career length의 \"Name\"과 \"College_ncaa_1\"의 값을 기준으로 Ncaa_stat의 \"Player\", \"School\"이 일치하는 데이터만 추출\n",
    "merged_data_2 = pd.merge(ncaa_stat_new, CareerLength, left_on=[\"Player_ID\", \"School\"], right_on=[\"Player_ID_2\", \"College_ncaa_2\"], how='inner')\n",
    "\n",
    "# Career length의 \"Name\"과 \"College_ncaa_1\"의 값을 기준으로 Ncaa_stat의 \"Player\", \"School\"이 일치하는 데이터만 추출\n",
    "merged_data_3 = pd.merge(ncaa_stat_new, CareerLength, left_on=[\"Player_ID\", \"School\"], right_on=[\"Player_ID_3\", \"College_ncaa_3\"], how='inner')\n",
    "\n",
    "# Career length의 \"Name\"과 \"College_ncaa_1\"의 값을 기준으로 Ncaa_stat의 \"Player\", \"School\"이 일치하는 데이터만 추출\n",
    "merged_data_4 = pd.merge(ncaa_stat_new, CareerLength, left_on=[\"Player_ID\", \"School\"], right_on=[\"Player_ID_4\", \"College_ncaa_4\"], how='inner')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "eeb77005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data as a file\n",
    "\n",
    "# CareerLength.to_excel(\"CareerLength.xlsx\", index=False)\n",
    "# CareerLength.to_csv(\"CareerLength.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a584c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "701ccd9f",
   "metadata": {},
   "source": [
    "<h3>데이터 병합: ncaa_stat_new + CareerLength<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "263947e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all = pd.concat([merged_data_1, merged_data_2, merged_data_3], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "84b69942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불필요한 컬럼 삭제처리\n",
    "\n",
    "merged_all = merged_all.drop([\"Player_ID_1\", \"Player_ID_2\", \"Player_ID_3\", \"Player_ID_4\", \n",
    "                              \"Player\",\"Position\", \"Recruiting Rank\",  \"NBA Debut\",\n",
    "                              \"College_1\",\"College_ncaa_1\", \"College_2\", \"College_ncaa_2\", \n",
    "                              \"College_3\", \"College_ncaa_3\", \"College_4\", \"College_ncaa_4\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "1408eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 형식 변경\n",
    "\n",
    "# merged_all['Draft_year'] = merged_all['Draft_year'].astype(float)\n",
    "merged_all['Experience'] = merged_all['Experience'].astype(float)\n",
    "merged_all['Draft_year'] = merged_all['Draft_year'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "fda64987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼 위치 조정\n",
    "\n",
    "new_order = [\"Player_ID\", \"Season\", \"Draft_year\", \"School\", \"Name\", \"Class\", \"Pos\", 'Height_cm','Weight_kg', \n",
    "              \"Draft_team\", \"Draft_overall\",'G_totals', 'MP_totals', 'FG_totals', 'FGA_totals', 'FG%_totals', '2P_totals', \n",
    "              '2PA_totals', '2P%_totals', '3P_totals', '3PA_totals', '3P%_totals', 'FT_totals', 'FTA_totals', \n",
    "              'FT%_totals', 'ORB_totals', 'DRB_totals','TRB_totals', 'AST_totals', 'STL_totals', 'BLK_totals', \n",
    "              'TOV_totals', 'PF_totals', 'PTS_totals', \n",
    "              'FG_per_min', 'FGA_per_min', '2P_per_min', '2PA_per_min', \n",
    "              '3P_per_min', '3PA_per_min',  'FT_per_min', 'FTA_per_min', \n",
    "              'TRB_per_min', 'AST_per_min', 'STL_per_min', 'BLK_per_min', 'TOV_per_min', 'PF_per_min', \n",
    "              'PTS_per_min', \n",
    "              'TS%_advanced', 'eFG%_advanced', '3PAr_advanced', 'FTr_advanced', 'PProd_advanced', \n",
    "              'ORB%_advanced', 'DRB%_advanced', 'TRB%_advanced', 'AST%_advanced', 'OBPM_advanced', \n",
    "              'DBPM_advanced', 'BPM_advanced', 'STL%_advanced', 'BLK%_advanced', 'TOV%_advanced', \n",
    "              'USG%_advanced',  'OWS_advanced', 'DWS_advanced', 'WS_advanced', 'WS/40_advanced', 'PER_advanced',\n",
    "               'FG_per_poss', 'FGA_per_poss', '2P_per_poss', '2PA_per_poss','3P_per_poss', '3PA_per_poss', \n",
    "             'FT_per_poss', 'FTA_per_poss', 'TRB_per_poss', 'AST_per_poss', 'STL_per_poss', 'BLK_per_poss', 'TOV_per_poss', \n",
    "             'PF_per_poss', 'PTS_per_poss', 'ORtg_per_poss', 'DRtg_per_poss', \"Experience\"]  # 변경하고 싶은 순서대로 컬럼명을 리스트에 저장\n",
    "merged_all = merged_all[new_order]  # 데이터프레임의 컬럼 순서를 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "29e4a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "c22ab3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player_ID          0.000000\n",
      "Season             0.000000\n",
      "Draft_year         0.000000\n",
      "School             0.000000\n",
      "Name               0.000000\n",
      "Class              0.000000\n",
      "Pos                0.027801\n",
      "Height_cm          0.000000\n",
      "Weight_kg          0.000000\n",
      "Draft_team         0.000000\n",
      "Draft_overall      0.000000\n",
      "G_totals           0.000000\n",
      "MP_totals          0.083403\n",
      "FG_totals          0.000000\n",
      "FGA_totals         0.000000\n",
      "FG%_totals         0.027801\n",
      "2P_totals          0.139005\n",
      "2PA_totals         0.166806\n",
      "2P%_totals         0.222408\n",
      "3P_totals          0.139005\n",
      "3PA_totals         0.166806\n",
      "3P%_totals         0.000000\n",
      "FT_totals          0.000000\n",
      "FTA_totals         0.000000\n",
      "FT%_totals         0.194607\n",
      "ORB_totals        52.571587\n",
      "DRB_totals        52.571587\n",
      "TRB_totals         0.000000\n",
      "AST_totals         0.000000\n",
      "STL_totals         0.000000\n",
      "BLK_totals         0.000000\n",
      "TOV_totals         0.250209\n",
      "PF_totals          0.166806\n",
      "PTS_totals         0.000000\n",
      "FG_per_min         0.083403\n",
      "FGA_per_min        0.083403\n",
      "2P_per_min         0.222408\n",
      "2PA_per_min        0.250209\n",
      "3P_per_min         0.222408\n",
      "3PA_per_min        0.250209\n",
      "FT_per_min         0.083403\n",
      "FTA_per_min        0.083403\n",
      "TRB_per_min        0.083403\n",
      "AST_per_min        0.083403\n",
      "STL_per_min        0.083403\n",
      "BLK_per_min        0.083403\n",
      "TOV_per_min        0.333611\n",
      "PF_per_min         0.250209\n",
      "PTS_per_min        0.083403\n",
      "TS%_advanced      36.057826\n",
      "eFG%_advanced     36.057826\n",
      "3PAr_advanced     36.057826\n",
      "FTr_advanced      36.057826\n",
      "PProd_advanced    85.765916\n",
      "ORB%_advanced     85.765916\n",
      "DRB%_advanced     85.793717\n",
      "TRB%_advanced     67.556297\n",
      "AST%_advanced     67.556297\n",
      "OBPM_advanced     88.990826\n",
      "DBPM_advanced     88.990826\n",
      "BPM_advanced      88.990826\n",
      "STL%_advanced     85.265499\n",
      "BLK%_advanced     67.556297\n",
      "TOV%_advanced     41.896024\n",
      "USG%_advanced     67.584098\n",
      "OWS_advanced      36.030025\n",
      "DWS_advanced      36.030025\n",
      "WS_advanced       36.030025\n",
      "WS/40_advanced    36.085627\n",
      "PER_advanced      88.990826\n",
      "FG_per_poss       85.765916\n",
      "FGA_per_poss      85.765916\n",
      "2P_per_poss       85.765916\n",
      "2PA_per_poss      85.765916\n",
      "3P_per_poss       85.765916\n",
      "3PA_per_poss      85.765916\n",
      "FT_per_poss       85.765916\n",
      "FTA_per_poss      85.765916\n",
      "TRB_per_poss      85.765916\n",
      "AST_per_poss      85.765916\n",
      "STL_per_poss      85.765916\n",
      "BLK_per_poss      85.765916\n",
      "TOV_per_poss      85.765916\n",
      "PF_per_poss       85.765916\n",
      "PTS_per_poss      85.765916\n",
      "ORtg_per_poss     85.765916\n",
      "DRtg_per_poss     85.793717\n",
      "Experience         0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#컬럼 별 결측치 비율 확인\n",
    "\n",
    "missing_counts = merged_all.isnull().sum()\n",
    "missing_ratios = (missing_counts / len(merged_all)) * 100\n",
    "print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "418e26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "c510cc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Draft_year</th>\n",
       "      <th>School</th>\n",
       "      <th>Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Draft_team</th>\n",
       "      <th>...</th>\n",
       "      <th>TRB_per_poss</th>\n",
       "      <th>AST_per_poss</th>\n",
       "      <th>STL_per_poss</th>\n",
       "      <th>BLK_per_poss</th>\n",
       "      <th>TOV_per_poss</th>\n",
       "      <th>PF_per_poss</th>\n",
       "      <th>PTS_per_poss</th>\n",
       "      <th>ORtg_per_poss</th>\n",
       "      <th>DRtg_per_poss</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tony Massenburg_maryland</td>\n",
       "      <td>1985-86</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>FR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tony Massenburg_maryland</td>\n",
       "      <td>1987-88</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>SO</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tony Massenburg_maryland</td>\n",
       "      <td>1988-89</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>JR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tony Massenburg_maryland</td>\n",
       "      <td>1989-90</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>SR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lance Blanks_virginia</td>\n",
       "      <td>1985-86</td>\n",
       "      <td>1990</td>\n",
       "      <td>virginia</td>\n",
       "      <td>Lance Blanks</td>\n",
       "      <td>FR</td>\n",
       "      <td>G</td>\n",
       "      <td>193.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Abdel Nader_iowa_state</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>iowa_state</td>\n",
       "      <td>Abdel Nader</td>\n",
       "      <td>SR</td>\n",
       "      <td>F</td>\n",
       "      <td>196.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>105.4</td>\n",
       "      <td>104.3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Damyean Dotson_houston</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>2017</td>\n",
       "      <td>houston</td>\n",
       "      <td>Damyean Dotson</td>\n",
       "      <td>JR</td>\n",
       "      <td>G</td>\n",
       "      <td>196.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>27.1</td>\n",
       "      <td>132.1</td>\n",
       "      <td>103.1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Damyean Dotson_houston</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>2017</td>\n",
       "      <td>houston</td>\n",
       "      <td>Damyean Dotson</td>\n",
       "      <td>SR</td>\n",
       "      <td>G</td>\n",
       "      <td>196.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>30.8</td>\n",
       "      <td>127.0</td>\n",
       "      <td>98.3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Semi Ojeleye_southern_methodist</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>2017</td>\n",
       "      <td>southern_methodist</td>\n",
       "      <td>Semi Ojeleye</td>\n",
       "      <td>JR</td>\n",
       "      <td>F</td>\n",
       "      <td>198.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>...</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>34.9</td>\n",
       "      <td>131.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaylon Nickerson_kansas_state</td>\n",
       "      <td>1991-92</td>\n",
       "      <td>1994</td>\n",
       "      <td>kansas_state</td>\n",
       "      <td>Gaylon Nickerson</td>\n",
       "      <td>JR</td>\n",
       "      <td>G</td>\n",
       "      <td>190.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3597 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Player_ID   Season  Draft_year              School  \\\n",
       "0           Tony Massenburg_maryland  1985-86        1990            maryland   \n",
       "1           Tony Massenburg_maryland  1987-88        1990            maryland   \n",
       "2           Tony Massenburg_maryland  1988-89        1990            maryland   \n",
       "3           Tony Massenburg_maryland  1989-90        1990            maryland   \n",
       "4              Lance Blanks_virginia  1985-86        1990            virginia   \n",
       "..                               ...      ...         ...                 ...   \n",
       "234           Abdel Nader_iowa_state  2015-16        2016          iowa_state   \n",
       "235           Damyean Dotson_houston  2015-16        2017             houston   \n",
       "236           Damyean Dotson_houston  2016-17        2017             houston   \n",
       "237  Semi Ojeleye_southern_methodist  2016-17        2017  southern_methodist   \n",
       "0      Gaylon Nickerson_kansas_state  1991-92        1994        kansas_state   \n",
       "\n",
       "                 Name Class Pos  Height_cm  Weight_kg         Draft_team  ...  \\\n",
       "0     Tony Massenburg    FR   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "1     Tony Massenburg    SO   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "2     Tony Massenburg    JR   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "3     Tony Massenburg    SR   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "4        Lance Blanks    FR   G      193.0       86.0    Detroit Pistons  ...   \n",
       "..                ...   ...  ..        ...        ...                ...  ...   \n",
       "234       Abdel Nader    SR   F      196.0      102.0     Boston Celtics  ...   \n",
       "235    Damyean Dotson    JR   G      196.0       95.0    New York Knicks  ...   \n",
       "236    Damyean Dotson    SR   G      196.0       95.0    New York Knicks  ...   \n",
       "237      Semi Ojeleye    JR   F      198.0      108.0     Boston Celtics  ...   \n",
       "0    Gaylon Nickerson    JR   G      190.0       86.0      Atlanta Hawks  ...   \n",
       "\n",
       "    TRB_per_poss  AST_per_poss  STL_per_poss  BLK_per_poss  TOV_per_poss  \\\n",
       "0            NaN           NaN           NaN           NaN           NaN   \n",
       "1            NaN           NaN           NaN           NaN           NaN   \n",
       "2            NaN           NaN           NaN           NaN           NaN   \n",
       "3            NaN           NaN           NaN           NaN           NaN   \n",
       "4            NaN           NaN           NaN           NaN           NaN   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "234          8.9           2.8           1.9           1.2           4.1   \n",
       "235         13.2           2.4           1.3           0.4           2.0   \n",
       "236         12.3           2.0           1.6           0.3           1.8   \n",
       "237         12.6           2.8           0.8           0.7           2.6   \n",
       "0            NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "     PF_per_poss  PTS_per_poss  ORtg_per_poss  DRtg_per_poss  Experience  \n",
       "0            NaN           NaN            NaN            NaN        13.0  \n",
       "1            NaN           NaN            NaN            NaN        13.0  \n",
       "2            NaN           NaN            NaN            NaN        13.0  \n",
       "3            NaN           NaN            NaN            NaN        13.0  \n",
       "4            NaN           NaN            NaN            NaN         3.0  \n",
       "..           ...           ...            ...            ...         ...  \n",
       "234          5.0          23.2          105.4          104.3         5.0  \n",
       "235          3.7          27.1          132.1          103.1         5.0  \n",
       "236          2.9          30.8          127.0           98.3         5.0  \n",
       "237          3.3          34.9          131.8           98.0         5.0  \n",
       "0            NaN           NaN            NaN            NaN         1.0  \n",
       "\n",
       "[3597 rows x 88 columns]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "f4680be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data as a file\n",
    "\n",
    "# merged_all.to_excel(\"merged_all.xlsx\", index=False)\n",
    "# merged_all.to_csv(\"merged_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d7e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52c0c4b2",
   "metadata": {},
   "source": [
    "<h3>데이터 병합: merged_all + Draft_combine <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "52879069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draft_combine 데이터셋 id생성(merged_data_all과 병합위한 처리)\n",
    "\n",
    "merged_all['Draft_year'] = merged_all['Draft_year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "da2ed798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draft_combine 데이터셋 id생성(merged_data_all과 병합위한 처리)\n",
    "merged_all['Player_ID'] = merged_all['Draft_year'] + '_' + merged_all['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "df9f7c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Draft_year</th>\n",
       "      <th>School</th>\n",
       "      <th>Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Draft_team</th>\n",
       "      <th>...</th>\n",
       "      <th>TRB_per_poss</th>\n",
       "      <th>AST_per_poss</th>\n",
       "      <th>STL_per_poss</th>\n",
       "      <th>BLK_per_poss</th>\n",
       "      <th>TOV_per_poss</th>\n",
       "      <th>PF_per_poss</th>\n",
       "      <th>PTS_per_poss</th>\n",
       "      <th>ORtg_per_poss</th>\n",
       "      <th>DRtg_per_poss</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990_Tony Massenburg</td>\n",
       "      <td>1985-86</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>FR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990_Tony Massenburg</td>\n",
       "      <td>1987-88</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>SO</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990_Tony Massenburg</td>\n",
       "      <td>1988-89</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>JR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990_Tony Massenburg</td>\n",
       "      <td>1989-90</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>SR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990_Lance Blanks</td>\n",
       "      <td>1985-86</td>\n",
       "      <td>1990</td>\n",
       "      <td>virginia</td>\n",
       "      <td>Lance Blanks</td>\n",
       "      <td>FR</td>\n",
       "      <td>G</td>\n",
       "      <td>193.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2016_Abdel Nader</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>iowa_state</td>\n",
       "      <td>Abdel Nader</td>\n",
       "      <td>SR</td>\n",
       "      <td>F</td>\n",
       "      <td>196.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>105.4</td>\n",
       "      <td>104.3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2017_Damyean Dotson</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>2017</td>\n",
       "      <td>houston</td>\n",
       "      <td>Damyean Dotson</td>\n",
       "      <td>JR</td>\n",
       "      <td>G</td>\n",
       "      <td>196.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>27.1</td>\n",
       "      <td>132.1</td>\n",
       "      <td>103.1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2017_Damyean Dotson</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>2017</td>\n",
       "      <td>houston</td>\n",
       "      <td>Damyean Dotson</td>\n",
       "      <td>SR</td>\n",
       "      <td>G</td>\n",
       "      <td>196.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>30.8</td>\n",
       "      <td>127.0</td>\n",
       "      <td>98.3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2017_Semi Ojeleye</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>2017</td>\n",
       "      <td>southern_methodist</td>\n",
       "      <td>Semi Ojeleye</td>\n",
       "      <td>JR</td>\n",
       "      <td>F</td>\n",
       "      <td>198.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>...</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>34.9</td>\n",
       "      <td>131.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994_Gaylon Nickerson</td>\n",
       "      <td>1991-92</td>\n",
       "      <td>1994</td>\n",
       "      <td>kansas_state</td>\n",
       "      <td>Gaylon Nickerson</td>\n",
       "      <td>JR</td>\n",
       "      <td>G</td>\n",
       "      <td>190.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3597 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Player_ID   Season Draft_year              School  \\\n",
       "0     1990_Tony Massenburg  1985-86       1990            maryland   \n",
       "1     1990_Tony Massenburg  1987-88       1990            maryland   \n",
       "2     1990_Tony Massenburg  1988-89       1990            maryland   \n",
       "3     1990_Tony Massenburg  1989-90       1990            maryland   \n",
       "4        1990_Lance Blanks  1985-86       1990            virginia   \n",
       "..                     ...      ...        ...                 ...   \n",
       "234       2016_Abdel Nader  2015-16       2016          iowa_state   \n",
       "235    2017_Damyean Dotson  2015-16       2017             houston   \n",
       "236    2017_Damyean Dotson  2016-17       2017             houston   \n",
       "237      2017_Semi Ojeleye  2016-17       2017  southern_methodist   \n",
       "0    1994_Gaylon Nickerson  1991-92       1994        kansas_state   \n",
       "\n",
       "                 Name Class Pos  Height_cm  Weight_kg         Draft_team  ...  \\\n",
       "0     Tony Massenburg    FR   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "1     Tony Massenburg    SO   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "2     Tony Massenburg    JR   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "3     Tony Massenburg    SR   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "4        Lance Blanks    FR   G      193.0       86.0    Detroit Pistons  ...   \n",
       "..                ...   ...  ..        ...        ...                ...  ...   \n",
       "234       Abdel Nader    SR   F      196.0      102.0     Boston Celtics  ...   \n",
       "235    Damyean Dotson    JR   G      196.0       95.0    New York Knicks  ...   \n",
       "236    Damyean Dotson    SR   G      196.0       95.0    New York Knicks  ...   \n",
       "237      Semi Ojeleye    JR   F      198.0      108.0     Boston Celtics  ...   \n",
       "0    Gaylon Nickerson    JR   G      190.0       86.0      Atlanta Hawks  ...   \n",
       "\n",
       "    TRB_per_poss  AST_per_poss  STL_per_poss  BLK_per_poss  TOV_per_poss  \\\n",
       "0            NaN           NaN           NaN           NaN           NaN   \n",
       "1            NaN           NaN           NaN           NaN           NaN   \n",
       "2            NaN           NaN           NaN           NaN           NaN   \n",
       "3            NaN           NaN           NaN           NaN           NaN   \n",
       "4            NaN           NaN           NaN           NaN           NaN   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "234          8.9           2.8           1.9           1.2           4.1   \n",
       "235         13.2           2.4           1.3           0.4           2.0   \n",
       "236         12.3           2.0           1.6           0.3           1.8   \n",
       "237         12.6           2.8           0.8           0.7           2.6   \n",
       "0            NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "     PF_per_poss  PTS_per_poss  ORtg_per_poss  DRtg_per_poss  Experience  \n",
       "0            NaN           NaN            NaN            NaN        13.0  \n",
       "1            NaN           NaN            NaN            NaN        13.0  \n",
       "2            NaN           NaN            NaN            NaN        13.0  \n",
       "3            NaN           NaN            NaN            NaN        13.0  \n",
       "4            NaN           NaN            NaN            NaN         3.0  \n",
       "..           ...           ...            ...            ...         ...  \n",
       "234          5.0          23.2          105.4          104.3         5.0  \n",
       "235          3.7          27.1          132.1          103.1         5.0  \n",
       "236          2.9          30.8          127.0           98.3         5.0  \n",
       "237          3.3          34.9          131.8           98.0         5.0  \n",
       "0            NaN           NaN            NaN            NaN         1.0  \n",
       "\n",
       "[3597 rows x 88 columns]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "c120352b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season              Name    Pos LANE_AGILITY_sec SHUTTLE_RUN_sec  \\\n",
      "0  Jan-00       Malik Allen   PF-C            11.83               -   \n",
      "1  Jan-00  Harold Arceneaux  SG-SF             13.8               -   \n",
      "2  Jan-00     Lamont Barnes   PF-C             12.3               -   \n",
      "3  Jan-00       Mario Bland     PF            13.04               -   \n",
      "4  Jan-00     Primoz Brezec      C            11.53               -   \n",
      "\n",
      "  THREE_QUATER_SPRINT STANDING_VERTICAL_LEAP_inch MAX_VERTICAL_LEAP_inch  \\\n",
      "0                3.38                        25.5                     29   \n",
      "1                   -                           -                     29   \n",
      "2                 3.4                          28                   29.5   \n",
      "3                3.47                          27                     31   \n",
      "4                3.55                          26                   29.5   \n",
      "\n",
      "  MAX_BENCH_PRESS Body_fat_pct  ... COLLEGE_BREAK_left_pct  \\\n",
      "0              13           -%  ...                      -   \n",
      "1               -           -%  ...                      -   \n",
      "2              10           -%  ...                      -   \n",
      "3              15           -%  ...                      -   \n",
      "4               -           -%  ...                      -   \n",
      "\n",
      "  COLLEGE_BREAK_right_pct COLLEGE_CORNER_left_pct COLLEGE_CORNER_right_pct  \\\n",
      "0                       -                       -                        -   \n",
      "1                       -                       -                        -   \n",
      "2                       -                       -                        -   \n",
      "3                       -                       -                        -   \n",
      "4                       -                       -                        -   \n",
      "\n",
      "  COLLEGE_TOP_KEY_pct FIFTEEN_BREAK_left_pct FIFTEEN_BREAK_right_pct  \\\n",
      "0                   -                      -                       -   \n",
      "1                   -                      -                       -   \n",
      "2                   -                      -                       -   \n",
      "3                   -                      -                       -   \n",
      "4                   -                      -                       -   \n",
      "\n",
      "  FIFTEEN_CORNER_left_pct FIFTEEN_CORNER_right_pct FIFTEEN_TOP_KEY_pct  \n",
      "0                       -                        -                   -  \n",
      "1                       -                        -                   -  \n",
      "2                       -                        -                   -  \n",
      "3                       -                        -                   -  \n",
      "4                       -                        -                   -  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "#Draft combine results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "folder_path_draft_combine = r\"C:\\Users\\31ind\\Desktop\\데이터사이언티스트로가는길\\성균관대SIS대학원\\재영논문자료\\데이터수집_크롤링\\draft_combine\"\n",
    "\n",
    "# 해당 폴더에 있는 모든 파일의 이름을 리스트에 저장\n",
    "file_list_draft_combine = os.listdir(folder_path_draft_combine)\n",
    "\n",
    "# 각 파일을 각각 읽어들여 병합\n",
    "data_frames = []  # 각 파일에서 읽은 데이터프레임을 저장할 리스트\n",
    "for file in file_list_draft_combine:\n",
    "    if file.endswith('.csv'):  # CSV 파일만 읽어오기\n",
    "        file_path = os.path.join(folder_path_draft_combine, file)\n",
    "        try:\n",
    "            temp_data = pd.read_csv(file_path, encoding='latin1')  # 데이터 로드, 인코딩을 'latin1'으로 설정\n",
    "            data_frames.append(temp_data)  # 읽은 데이터프레임을 리스트에 추가\n",
    "        except Exception as e:\n",
    "            print(f'Error occurred while processing {file}: {e}')\n",
    "            continue\n",
    "\n",
    "# 모든 데이터프레임을 병합\n",
    "draft_combine = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# 병합 결과 확인\n",
    "print(draft_combine.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "04d8a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Season 표기형식 수정(일부)\n",
    "\n",
    "draft_combine.loc[draft_combine['Season'] == 'Jan-00', 'Season'] = '2000-01'\n",
    "draft_combine.loc[draft_combine['Season'] == 'Feb-01', 'Season'] = '2001-02'\n",
    "draft_combine.loc[draft_combine['Season'] == 'Mar-02', 'Season'] = '2002-03'\n",
    "draft_combine.loc[draft_combine['Season'] == 'Apr-03', 'Season'] = '2003-04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "27aec307",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_combine['Draft_year'] = draft_combine['Season'].apply(lambda x: x.split('-')[0])  # 연도 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "d44a303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 컬럼 값 형태 수정\n",
    "# 'Body_fat_pct' 컬럼에서 '%'를 제거.\n",
    "\n",
    "draft_combine['Body_fat_pct'] = draft_combine['Body_fat_pct'].str.replace('%', '').astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "0f2df740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 컬럼에 대해 '-'(값 존재x)를 NaN으로 대체.\n",
    "\n",
    "for column in draft_combine.columns:\n",
    "    draft_combine[column] = draft_combine[column].replace('-', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "3e70a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#특정 컬럼 '피트-인치' --> '피트'로 변환 처리.\n",
    "\n",
    "import re\n",
    "\n",
    "# 데이터프레임의 컬럼을 문자열로 변환\n",
    "for col in ['Wingspan_inch', 'Standing_Reach_inch', 'Height_wo_Shoes', 'Height_w_Shoes']:\n",
    "    draft_combine[col] = draft_combine[col].astype(str)\n",
    "\n",
    "# 피트와 인치를 인치 단위로 변환하는 함수\n",
    "def height_to_inches(height_str):\n",
    "    # 이미 숫자인 경우 그대로 반환\n",
    "    if re.match(r'^\\d+(\\.\\d+)?$', height_str):\n",
    "        return float(height_str)\n",
    "    \n",
    "    # 피트와 인치를 추출\n",
    "    match = re.match(r'(\\d+)[\\'\"]\\s*(\\d+(\\.\\d+)?)[\"]?', height_str)\n",
    "    if match:\n",
    "        feet = float(match.group(1))\n",
    "        inches = float(match.group(2))\n",
    "        return feet * 12 + inches\n",
    "    \n",
    "    # 매칭되지 않는 경우 NaN 반환\n",
    "    return float('NaN')\n",
    "\n",
    "# 변환 함수를 데이터프레임의 해당 컬럼에 적용\n",
    "for col in ['Wingspan_inch', 'Standing_Reach_inch', 'Height_wo_Shoes', 'Height_w_Shoes']:\n",
    "    draft_combine[col] = draft_combine[col].apply(height_to_inches)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "d17802c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불필요한 컬럼 삭제처리\n",
    "\n",
    "draft_combine = draft_combine.drop(['Pos', 'Season', 'OFF_DRIBBLE_COELLEGE_BREAK_left_pct', 'OFF_DRIBBLE_COELLEGE_BREAK_right_pct',\n",
    "                                        'OFF_DRIBBLE_COELLEGE_TOP_KEY_pct','OFF_DRIBBLE_FIFTEEN_BREAK_left_pct', \n",
    "                                        'OFF_DRIBBLE_FIFTEEN_BREAK_right_pct', 'OFF_DRIBBLE_FIFTEEN_TOP_KEY_pct',\n",
    "                                        'ON_THE_MOVE_COLLEGE_pct','ON_THE_MOVE_FIFTEEN_pct','NBA_BREAK_left_pct',\n",
    "                                        'NBA_BREAK_right_pct', 'NBA_CORNER_left_pct', 'NBA_CORNER_right_pct',\n",
    "                                        'NBA_TOP_KEY_pct', 'COLLEGE_BREAK_left_pct','COLLEGE_BREAK_right_pct',\n",
    "                                        'COLLEGE_CORNER_left_pct','COLLEGE_CORNER_right_pct','COLLEGE_TOP_KEY_pct',\n",
    "                                        'FIFTEEN_BREAK_left_pct','FIFTEEN_BREAK_right_pct','FIFTEEN_CORNER_left_pct',\n",
    "                                        'FIFTEEN_CORNER_right_pct','FIFTEEN_TOP_KEY_pct','FIFTEEN_TOP_KEY_pct'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "a7b32d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 컬럼 데이터 타입 변경.('Season', 'Name', 'Pos'를 제외한 모든 컬럼을 float으로)\n",
    "\n",
    "cols_to_convert = [col for col in draft_combine.columns if col not in ['Player_ID','Season', 'Name', 'Pos', 'Draft_year']]\n",
    "draft_combine[cols_to_convert] = draft_combine[cols_to_convert].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "90ca5992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                            object\n",
      "LANE_AGILITY_sec               float64\n",
      "SHUTTLE_RUN_sec                float64\n",
      "THREE_QUATER_SPRINT            float64\n",
      "STANDING_VERTICAL_LEAP_inch    float64\n",
      "MAX_VERTICAL_LEAP_inch         float64\n",
      "MAX_BENCH_PRESS                float64\n",
      "Body_fat_pct                   float64\n",
      "Hand_Length_inch               float64\n",
      "Hand_width_inch                float64\n",
      "Height_wo_Shoes                float64\n",
      "Height_w_Shoes                 float64\n",
      "Standing_Reach_inch            float64\n",
      "Weight_lbs                     float64\n",
      "Wingspan_inch                  float64\n",
      "Draft_year                      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#컬럼 별 데이터타입 확인\n",
    "\n",
    "data_types = draft_combine.dtypes\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "a2a44b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draft_combine 데이터셋 id생성(merged_data_all과 병합위한 처리)\n",
    "\n",
    "draft_combine['Player_ID'] = draft_combine['Draft_year'] + '_' + draft_combine['Name']\n",
    "# draft_combine['Player_ID'] = draft_combine.apply(lambda row: row['Player_ID_1'] + ' _None' if pd.isna(row['College_ncaa_1']) else row['Player_ID_1'], axis=1)\n",
    "# player_id_col = draft_combine.pop('Player_ID')\n",
    "# draft_combine.insert(0, 'Player_ID', player_id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "0ce8c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #컬럼 순서 변경\n",
    "\n",
    "# columns = draft_combine.columns.tolist()  # 현재 열 순서를 리스트로 얻습니다.\n",
    "# columns = columns[:-1] + [columns[-1]] + [columns[-2]]  # 순서를 조정함\n",
    "# draft_combine = draft_combine[columns]  # 변경된 순서대로 데이터프레임을 재구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "b34f9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = [ 'Player_ID', 'Draft_year', 'Name', 'Body_fat_pct',\n",
    "       'Hand_Length_inch', 'Hand_width_inch', 'Height_wo_Shoes',\n",
    "       'Height_w_Shoes', 'Standing_Reach_inch', 'Weight_lbs', 'Wingspan_inch', \n",
    "             'LANE_AGILITY_sec', 'SHUTTLE_RUN_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch',\n",
    "       'MAX_VERTICAL_LEAP_inch', 'MAX_BENCH_PRESS']  # 변경하고 싶은 순서대로 컬럼명을 리스트에 저장\n",
    "draft_combine = draft_combine[new_order]  # 데이터프레임의 컬럼 순서를 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "e039fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불필요한 컬럼 삭제처리\n",
    "draft_combine = draft_combine.drop(['Draft_year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "e2d783f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Body_fat_pct</th>\n",
       "      <th>Hand_Length_inch</th>\n",
       "      <th>Hand_width_inch</th>\n",
       "      <th>Height_wo_Shoes</th>\n",
       "      <th>Height_w_Shoes</th>\n",
       "      <th>Standing_Reach_inch</th>\n",
       "      <th>Weight_lbs</th>\n",
       "      <th>Wingspan_inch</th>\n",
       "      <th>LANE_AGILITY_sec</th>\n",
       "      <th>SHUTTLE_RUN_sec</th>\n",
       "      <th>THREE_QUATER_SPRINT</th>\n",
       "      <th>STANDING_VERTICAL_LEAP_inch</th>\n",
       "      <th>MAX_VERTICAL_LEAP_inch</th>\n",
       "      <th>MAX_BENCH_PRESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000_Malik Allen</td>\n",
       "      <td>Malik Allen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>86.50</td>\n",
       "      <td>11.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.38</td>\n",
       "      <td>25.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000_Harold Arceneaux</td>\n",
       "      <td>Harold Arceneaux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>80.50</td>\n",
       "      <td>13.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000_Lamont Barnes</td>\n",
       "      <td>Lamont Barnes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "      <td>235.5</td>\n",
       "      <td>87.50</td>\n",
       "      <td>12.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.40</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000_Mario Bland</td>\n",
       "      <td>Mario Bland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>13.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.47</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000_Primoz Brezec</td>\n",
       "      <td>Primoz Brezec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>11.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.55</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>2021_Aaron Wiggins</td>\n",
       "      <td>Aaron Wiggins</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.50</td>\n",
       "      <td>76.50</td>\n",
       "      <td>77.00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>81.75</td>\n",
       "      <td>11.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>29.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>2021_Ziaire Williams</td>\n",
       "      <td>Ziaire Williams</td>\n",
       "      <td>4.4</td>\n",
       "      <td>9.00</td>\n",
       "      <td>8.75</td>\n",
       "      <td>80.25</td>\n",
       "      <td>81.75</td>\n",
       "      <td>106.5</td>\n",
       "      <td>188.4</td>\n",
       "      <td>82.25</td>\n",
       "      <td>10.69</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.12</td>\n",
       "      <td>34.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>2021_Moses Wright</td>\n",
       "      <td>Moses Wright</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.50</td>\n",
       "      <td>79.75</td>\n",
       "      <td>81.00</td>\n",
       "      <td>107.0</td>\n",
       "      <td>225.8</td>\n",
       "      <td>84.75</td>\n",
       "      <td>11.20</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.15</td>\n",
       "      <td>31.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>2021_McKinley Wright IV</td>\n",
       "      <td>McKinley Wright IV</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.50</td>\n",
       "      <td>9.00</td>\n",
       "      <td>71.25</td>\n",
       "      <td>72.25</td>\n",
       "      <td>94.0</td>\n",
       "      <td>192.2</td>\n",
       "      <td>77.25</td>\n",
       "      <td>10.76</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.08</td>\n",
       "      <td>31.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>2021_Marcus Zegarowski</td>\n",
       "      <td>Marcus Zegarowski</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.50</td>\n",
       "      <td>72.75</td>\n",
       "      <td>74.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>180.8</td>\n",
       "      <td>74.75</td>\n",
       "      <td>11.47</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.11</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1469 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Player_ID                Name  Body_fat_pct  \\\n",
       "0            2000_Malik Allen         Malik Allen           NaN   \n",
       "1       2000_Harold Arceneaux    Harold Arceneaux           NaN   \n",
       "2          2000_Lamont Barnes       Lamont Barnes           NaN   \n",
       "3            2000_Mario Bland         Mario Bland           NaN   \n",
       "4          2000_Primoz Brezec       Primoz Brezec           NaN   \n",
       "...                       ...                 ...           ...   \n",
       "1464       2021_Aaron Wiggins       Aaron Wiggins           5.0   \n",
       "1465     2021_Ziaire Williams     Ziaire Williams           4.4   \n",
       "1466        2021_Moses Wright        Moses Wright           5.6   \n",
       "1467  2021_McKinley Wright IV  McKinley Wright IV           6.7   \n",
       "1468   2021_Marcus Zegarowski   Marcus Zegarowski           7.2   \n",
       "\n",
       "      Hand_Length_inch  Hand_width_inch  Height_wo_Shoes  Height_w_Shoes  \\\n",
       "0                  NaN              NaN            80.25             NaN   \n",
       "1                  NaN              NaN            76.50             NaN   \n",
       "2                  NaN              NaN            80.50             NaN   \n",
       "3                  NaN              NaN            77.50             NaN   \n",
       "4                  NaN              NaN            84.75             NaN   \n",
       "...                ...              ...              ...             ...   \n",
       "1464              8.75             8.50            76.50           77.00   \n",
       "1465              9.00             8.75            80.25           81.75   \n",
       "1466              9.00             9.50            79.75           81.00   \n",
       "1467              8.50             9.00            71.25           72.25   \n",
       "1468              8.00             9.50            72.75           74.00   \n",
       "\n",
       "      Standing_Reach_inch  Weight_lbs  Wingspan_inch  LANE_AGILITY_sec  \\\n",
       "0                   109.0       271.0          86.50             11.83   \n",
       "1                   103.0       219.0          80.50             13.80   \n",
       "2                   108.0       235.5          87.50             12.30   \n",
       "3                   103.0       287.0          84.00             13.04   \n",
       "4                   110.0       243.0          86.00             11.53   \n",
       "...                   ...         ...            ...               ...   \n",
       "1464                103.0       190.0          81.75             11.20   \n",
       "1465                106.5       188.4          82.25             10.69   \n",
       "1466                107.0       225.8          84.75             11.20   \n",
       "1467                 94.0       192.2          77.25             10.76   \n",
       "1468                 96.0       180.8          74.75             11.47   \n",
       "\n",
       "      SHUTTLE_RUN_sec  THREE_QUATER_SPRINT  STANDING_VERTICAL_LEAP_inch  \\\n",
       "0                 NaN                 3.38                         25.5   \n",
       "1                 NaN                  NaN                          NaN   \n",
       "2                 NaN                 3.40                         28.0   \n",
       "3                 NaN                 3.47                         27.0   \n",
       "4                 NaN                 3.55                         26.0   \n",
       "...               ...                  ...                          ...   \n",
       "1464             3.00                 3.04                         29.5   \n",
       "1465             3.04                 3.12                         34.0   \n",
       "1466             3.42                 3.15                         31.5   \n",
       "1467             3.12                 3.08                         31.5   \n",
       "1468             3.26                 3.11                         30.0   \n",
       "\n",
       "      MAX_VERTICAL_LEAP_inch  MAX_BENCH_PRESS  \n",
       "0                       29.0             13.0  \n",
       "1                       29.0              NaN  \n",
       "2                       29.5             10.0  \n",
       "3                       31.0             15.0  \n",
       "4                       29.5              NaN  \n",
       "...                      ...              ...  \n",
       "1464                    36.0              NaN  \n",
       "1465                    39.5              NaN  \n",
       "1466                    38.0              NaN  \n",
       "1467                    38.0              NaN  \n",
       "1468                    35.5              NaN  \n",
       "\n",
       "[1469 rows x 16 columns]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draft_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "1353cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player_ID                       0.000000\n",
      "Name                            0.000000\n",
      "Body_fat_pct                   17.290674\n",
      "Hand_Length_inch               51.599728\n",
      "Hand_width_inch                51.599728\n",
      "Height_wo_Shoes                 1.497617\n",
      "Height_w_Shoes                 22.123894\n",
      "Standing_Reach_inch             1.633764\n",
      "Weight_lbs                      1.633764\n",
      "Wingspan_inch                   1.429544\n",
      "LANE_AGILITY_sec               12.933969\n",
      "SHUTTLE_RUN_sec                70.047651\n",
      "THREE_QUATER_SPRINT            12.865895\n",
      "STANDING_VERTICAL_LEAP_inch    12.321307\n",
      "MAX_VERTICAL_LEAP_inch         12.321307\n",
      "MAX_BENCH_PRESS                28.182437\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#컬럼별 결측치 비율 확인\n",
    "missing_counts = draft_combine.isnull().sum()\n",
    "missing_ratios = (missing_counts / len(draft_combine)) * 100\n",
    "print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "692ba925",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_combine.to_csv(\"draft_combine.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "5d52314a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Draft_year</th>\n",
       "      <th>School</th>\n",
       "      <th>Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Draft_team</th>\n",
       "      <th>...</th>\n",
       "      <th>TRB_per_poss</th>\n",
       "      <th>AST_per_poss</th>\n",
       "      <th>STL_per_poss</th>\n",
       "      <th>BLK_per_poss</th>\n",
       "      <th>TOV_per_poss</th>\n",
       "      <th>PF_per_poss</th>\n",
       "      <th>PTS_per_poss</th>\n",
       "      <th>ORtg_per_poss</th>\n",
       "      <th>DRtg_per_poss</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990_Tony Massenburg</td>\n",
       "      <td>1985-86</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>FR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990_Tony Massenburg</td>\n",
       "      <td>1987-88</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>SO</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990_Tony Massenburg</td>\n",
       "      <td>1988-89</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>JR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990_Tony Massenburg</td>\n",
       "      <td>1989-90</td>\n",
       "      <td>1990</td>\n",
       "      <td>maryland</td>\n",
       "      <td>Tony Massenburg</td>\n",
       "      <td>SR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990_Lance Blanks</td>\n",
       "      <td>1985-86</td>\n",
       "      <td>1990</td>\n",
       "      <td>virginia</td>\n",
       "      <td>Lance Blanks</td>\n",
       "      <td>FR</td>\n",
       "      <td>G</td>\n",
       "      <td>193.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2016_Abdel Nader</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>iowa_state</td>\n",
       "      <td>Abdel Nader</td>\n",
       "      <td>SR</td>\n",
       "      <td>F</td>\n",
       "      <td>196.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>105.4</td>\n",
       "      <td>104.3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2017_Damyean Dotson</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>2017</td>\n",
       "      <td>houston</td>\n",
       "      <td>Damyean Dotson</td>\n",
       "      <td>JR</td>\n",
       "      <td>G</td>\n",
       "      <td>196.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>27.1</td>\n",
       "      <td>132.1</td>\n",
       "      <td>103.1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2017_Damyean Dotson</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>2017</td>\n",
       "      <td>houston</td>\n",
       "      <td>Damyean Dotson</td>\n",
       "      <td>SR</td>\n",
       "      <td>G</td>\n",
       "      <td>196.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>30.8</td>\n",
       "      <td>127.0</td>\n",
       "      <td>98.3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2017_Semi Ojeleye</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>2017</td>\n",
       "      <td>southern_methodist</td>\n",
       "      <td>Semi Ojeleye</td>\n",
       "      <td>JR</td>\n",
       "      <td>F</td>\n",
       "      <td>198.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>...</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>34.9</td>\n",
       "      <td>131.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994_Gaylon Nickerson</td>\n",
       "      <td>1991-92</td>\n",
       "      <td>1994</td>\n",
       "      <td>kansas_state</td>\n",
       "      <td>Gaylon Nickerson</td>\n",
       "      <td>JR</td>\n",
       "      <td>G</td>\n",
       "      <td>190.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3597 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Player_ID   Season Draft_year              School  \\\n",
       "0     1990_Tony Massenburg  1985-86       1990            maryland   \n",
       "1     1990_Tony Massenburg  1987-88       1990            maryland   \n",
       "2     1990_Tony Massenburg  1988-89       1990            maryland   \n",
       "3     1990_Tony Massenburg  1989-90       1990            maryland   \n",
       "4        1990_Lance Blanks  1985-86       1990            virginia   \n",
       "..                     ...      ...        ...                 ...   \n",
       "234       2016_Abdel Nader  2015-16       2016          iowa_state   \n",
       "235    2017_Damyean Dotson  2015-16       2017             houston   \n",
       "236    2017_Damyean Dotson  2016-17       2017             houston   \n",
       "237      2017_Semi Ojeleye  2016-17       2017  southern_methodist   \n",
       "0    1994_Gaylon Nickerson  1991-92       1994        kansas_state   \n",
       "\n",
       "                 Name Class Pos  Height_cm  Weight_kg         Draft_team  ...  \\\n",
       "0     Tony Massenburg    FR   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "1     Tony Massenburg    SO   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "2     Tony Massenburg    JR   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "3     Tony Massenburg    SR   F      206.0       99.0  San Antonio Spurs  ...   \n",
       "4        Lance Blanks    FR   G      193.0       86.0    Detroit Pistons  ...   \n",
       "..                ...   ...  ..        ...        ...                ...  ...   \n",
       "234       Abdel Nader    SR   F      196.0      102.0     Boston Celtics  ...   \n",
       "235    Damyean Dotson    JR   G      196.0       95.0    New York Knicks  ...   \n",
       "236    Damyean Dotson    SR   G      196.0       95.0    New York Knicks  ...   \n",
       "237      Semi Ojeleye    JR   F      198.0      108.0     Boston Celtics  ...   \n",
       "0    Gaylon Nickerson    JR   G      190.0       86.0      Atlanta Hawks  ...   \n",
       "\n",
       "    TRB_per_poss  AST_per_poss  STL_per_poss  BLK_per_poss  TOV_per_poss  \\\n",
       "0            NaN           NaN           NaN           NaN           NaN   \n",
       "1            NaN           NaN           NaN           NaN           NaN   \n",
       "2            NaN           NaN           NaN           NaN           NaN   \n",
       "3            NaN           NaN           NaN           NaN           NaN   \n",
       "4            NaN           NaN           NaN           NaN           NaN   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "234          8.9           2.8           1.9           1.2           4.1   \n",
       "235         13.2           2.4           1.3           0.4           2.0   \n",
       "236         12.3           2.0           1.6           0.3           1.8   \n",
       "237         12.6           2.8           0.8           0.7           2.6   \n",
       "0            NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "     PF_per_poss  PTS_per_poss  ORtg_per_poss  DRtg_per_poss  Experience  \n",
       "0            NaN           NaN            NaN            NaN        13.0  \n",
       "1            NaN           NaN            NaN            NaN        13.0  \n",
       "2            NaN           NaN            NaN            NaN        13.0  \n",
       "3            NaN           NaN            NaN            NaN        13.0  \n",
       "4            NaN           NaN            NaN            NaN         3.0  \n",
       "..           ...           ...            ...            ...         ...  \n",
       "234          5.0          23.2          105.4          104.3         5.0  \n",
       "235          3.7          27.1          132.1          103.1         5.0  \n",
       "236          2.9          30.8          127.0           98.3         5.0  \n",
       "237          3.3          34.9          131.8           98.0         5.0  \n",
       "0            NaN           NaN            NaN            NaN         1.0  \n",
       "\n",
       "[3597 rows x 88 columns]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "4755bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data as a file\n",
    "\n",
    "# draft_combine.to_excel(\"draft_combine2.xlsx\", index=False)\n",
    "# draft_combine.to_csv(\"draft_combine2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "d161c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge data\n",
    "\n",
    "merged_all_comb = pd.merge(merged_all, draft_combine, on='Player_ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "0619d85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Draft_year</th>\n",
       "      <th>School</th>\n",
       "      <th>Name_x</th>\n",
       "      <th>Class</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Draft_team</th>\n",
       "      <th>...</th>\n",
       "      <th>Height_w_Shoes</th>\n",
       "      <th>Standing_Reach_inch</th>\n",
       "      <th>Weight_lbs</th>\n",
       "      <th>Wingspan_inch</th>\n",
       "      <th>LANE_AGILITY_sec</th>\n",
       "      <th>SHUTTLE_RUN_sec</th>\n",
       "      <th>THREE_QUATER_SPRINT</th>\n",
       "      <th>STANDING_VERTICAL_LEAP_inch</th>\n",
       "      <th>MAX_VERTICAL_LEAP_inch</th>\n",
       "      <th>MAX_BENCH_PRESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001_Loren Woods</td>\n",
       "      <td>1996-97</td>\n",
       "      <td>2001</td>\n",
       "      <td>wake_forest</td>\n",
       "      <td>Loren Woods</td>\n",
       "      <td>FR</td>\n",
       "      <td>C</td>\n",
       "      <td>216.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>11.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>24.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001_Loren Woods</td>\n",
       "      <td>1997-98</td>\n",
       "      <td>2001</td>\n",
       "      <td>wake_forest</td>\n",
       "      <td>Loren Woods</td>\n",
       "      <td>SO</td>\n",
       "      <td>C</td>\n",
       "      <td>216.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>11.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>24.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001_Loren Woods</td>\n",
       "      <td>1999-00</td>\n",
       "      <td>2001</td>\n",
       "      <td>arizona</td>\n",
       "      <td>Loren Woods</td>\n",
       "      <td>JR</td>\n",
       "      <td>C</td>\n",
       "      <td>216.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>11.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>24.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001_Loren Woods</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>arizona</td>\n",
       "      <td>Loren Woods</td>\n",
       "      <td>SR</td>\n",
       "      <td>C</td>\n",
       "      <td>216.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>11.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>24.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000_Mark Madsen</td>\n",
       "      <td>1996-97</td>\n",
       "      <td>2000</td>\n",
       "      <td>stanford</td>\n",
       "      <td>Mark Madsen</td>\n",
       "      <td>FR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.5</td>\n",
       "      <td>236.5</td>\n",
       "      <td>84.5</td>\n",
       "      <td>12.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.46</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>2004_Tony Allen</td>\n",
       "      <td>2003-04</td>\n",
       "      <td>2004</td>\n",
       "      <td>oklahoma_state</td>\n",
       "      <td>Tony Allen</td>\n",
       "      <td>SR</td>\n",
       "      <td>G</td>\n",
       "      <td>193.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>...</td>\n",
       "      <td>76.25</td>\n",
       "      <td>102.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.19</td>\n",
       "      <td>31.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>2005_Robert Whaley</td>\n",
       "      <td>2003-04</td>\n",
       "      <td>2005</td>\n",
       "      <td>cincinnati</td>\n",
       "      <td>Robert Whaley</td>\n",
       "      <td>JR</td>\n",
       "      <td>C</td>\n",
       "      <td>208.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>...</td>\n",
       "      <td>81.00</td>\n",
       "      <td>108.0</td>\n",
       "      <td>269.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>12.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.25</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>2007_Carl Landry</td>\n",
       "      <td>2004-05</td>\n",
       "      <td>2007</td>\n",
       "      <td>purdue</td>\n",
       "      <td>Carl Landry</td>\n",
       "      <td>JR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Seattle SuperSonics</td>\n",
       "      <td>...</td>\n",
       "      <td>80.50</td>\n",
       "      <td>102.5</td>\n",
       "      <td>248.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>11.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.29</td>\n",
       "      <td>31.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>2007_Carl Landry</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>2007</td>\n",
       "      <td>purdue</td>\n",
       "      <td>Carl Landry</td>\n",
       "      <td>SR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Seattle SuperSonics</td>\n",
       "      <td>...</td>\n",
       "      <td>80.50</td>\n",
       "      <td>102.5</td>\n",
       "      <td>248.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>11.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.29</td>\n",
       "      <td>31.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>2007_Carl Landry</td>\n",
       "      <td>2006-07</td>\n",
       "      <td>2007</td>\n",
       "      <td>purdue</td>\n",
       "      <td>Carl Landry</td>\n",
       "      <td>SR</td>\n",
       "      <td>F</td>\n",
       "      <td>206.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Seattle SuperSonics</td>\n",
       "      <td>...</td>\n",
       "      <td>80.50</td>\n",
       "      <td>102.5</td>\n",
       "      <td>248.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>11.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.29</td>\n",
       "      <td>31.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1375 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Player_ID   Season Draft_year          School         Name_x  \\\n",
       "0       2001_Loren Woods  1996-97       2001     wake_forest    Loren Woods   \n",
       "1       2001_Loren Woods  1997-98       2001     wake_forest    Loren Woods   \n",
       "2       2001_Loren Woods  1999-00       2001         arizona    Loren Woods   \n",
       "3       2001_Loren Woods  2000-01       2001         arizona    Loren Woods   \n",
       "4       2000_Mark Madsen  1996-97       2000        stanford    Mark Madsen   \n",
       "...                  ...      ...        ...             ...            ...   \n",
       "1370     2004_Tony Allen  2003-04       2004  oklahoma_state     Tony Allen   \n",
       "1371  2005_Robert Whaley  2003-04       2005      cincinnati  Robert Whaley   \n",
       "1372    2007_Carl Landry  2004-05       2007          purdue    Carl Landry   \n",
       "1373    2007_Carl Landry  2005-06       2007          purdue    Carl Landry   \n",
       "1374    2007_Carl Landry  2006-07       2007          purdue    Carl Landry   \n",
       "\n",
       "     Class Pos  Height_cm  Weight_kg              Draft_team  ...  \\\n",
       "0       FR   C      216.0      111.0  Minnesota Timberwolves  ...   \n",
       "1       SO   C      216.0      111.0  Minnesota Timberwolves  ...   \n",
       "2       JR   C      216.0      111.0  Minnesota Timberwolves  ...   \n",
       "3       SR   C      216.0      111.0  Minnesota Timberwolves  ...   \n",
       "4       FR   F      206.0      108.0      Los Angeles Lakers  ...   \n",
       "...    ...  ..        ...        ...                     ...  ...   \n",
       "1370    SR   G      193.0       96.0          Boston Celtics  ...   \n",
       "1371    JR   C      208.0      117.0               Utah Jazz  ...   \n",
       "1372    JR   F      206.0      112.0     Seattle SuperSonics  ...   \n",
       "1373    SR   F      206.0      112.0     Seattle SuperSonics  ...   \n",
       "1374    SR   F      206.0      112.0     Seattle SuperSonics  ...   \n",
       "\n",
       "     Height_w_Shoes  Standing_Reach_inch  Weight_lbs  Wingspan_inch  \\\n",
       "0               NaN                113.0       246.0           89.5   \n",
       "1               NaN                113.0       246.0           89.5   \n",
       "2               NaN                113.0       246.0           89.5   \n",
       "3               NaN                113.0       246.0           89.5   \n",
       "4               NaN                104.5       236.5           84.5   \n",
       "...             ...                  ...         ...            ...   \n",
       "1370          76.25                102.0       214.0           81.0   \n",
       "1371          81.00                108.0       269.4           86.0   \n",
       "1372          80.50                102.5       248.0           83.0   \n",
       "1373          80.50                102.5       248.0           83.0   \n",
       "1374          80.50                102.5       248.0           83.0   \n",
       "\n",
       "      LANE_AGILITY_sec  SHUTTLE_RUN_sec  THREE_QUATER_SPRINT  \\\n",
       "0                11.83              NaN                 3.48   \n",
       "1                11.83              NaN                 3.48   \n",
       "2                11.83              NaN                 3.48   \n",
       "3                11.83              NaN                 3.48   \n",
       "4                12.12              NaN                 3.46   \n",
       "...                ...              ...                  ...   \n",
       "1370             10.70              NaN                 3.19   \n",
       "1371             12.11              NaN                 3.25   \n",
       "1372             11.35              NaN                 3.29   \n",
       "1373             11.35              NaN                 3.29   \n",
       "1374             11.35              NaN                 3.29   \n",
       "\n",
       "      STANDING_VERTICAL_LEAP_inch  MAX_VERTICAL_LEAP_inch  MAX_BENCH_PRESS  \n",
       "0                            24.5                    28.0             10.0  \n",
       "1                            24.5                    28.0             10.0  \n",
       "2                            24.5                    28.0             10.0  \n",
       "3                            24.5                    28.0             10.0  \n",
       "4                            30.5                    33.5             13.0  \n",
       "...                           ...                     ...              ...  \n",
       "1370                         31.5                    36.5             17.0  \n",
       "1371                         28.5                    33.5             15.0  \n",
       "1372                         31.5                    36.5             21.0  \n",
       "1373                         31.5                    36.5             21.0  \n",
       "1374                         31.5                    36.5             21.0  \n",
       "\n",
       "[1375 rows x 103 columns]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_all_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "12c022d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "108bbbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼 별 결측치 비율 확인\n",
    "\n",
    "# missing_counts = merged_all_comb.isnull().sum()\n",
    "# missing_ratios = (missing_counts / len(merged_all_comb)) * 100\n",
    "# print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "26434f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼명 변경.\n",
    "\n",
    "merged_all_comb.rename(columns = {'Name_x':'Name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "4ccd9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID생성\n",
    "\n",
    "merged_all_comb['Player_ID'] = merged_all_comb['Draft_year'] + '_' + merged_all_comb['Name'] + '_' + merged_all_comb['School']+ '_' + merged_all_comb['Draft_team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "01efc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼 별 결측치 비율 확인\n",
    "\n",
    "# missing_counts = merged_all_comb.isnull().sum()\n",
    "# missing_ratios = (missing_counts / len(merged_all_comb)) * 100\n",
    "# print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "c67b49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#화면 출력 옵션_reset\n",
    "\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "64340ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1375, 103)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추출한 샘플의 행과 열 수 카운트\n",
    "row_count, column_count = merged_all_comb.shape\n",
    "row_count, column_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "96b4b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 복사본 생성\n",
    "\n",
    "merged_all_comb_copy = merged_all_comb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "17fd0ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_all_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "ed474b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼 별 데이터타입 확인\n",
    "\n",
    "# data_types = merged_all_comb_copy.dtypes\n",
    "# print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "64b93acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #불필요한 컬럼 삭제처리\n",
    "merged_all_comb_copy = merged_all_comb_copy.drop(['ORB_totals','DRB_totals', \"Weight_lbs\"], axis=1)\n",
    "# #컬럼 삭제 처리: ORB, DRB(공격 및 수비리바운드는 결측치 비율이 높으므로 총 리바운드 피처만 사용할 것)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "9c426fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_all_comb 컬럼순서 조정\n",
    "\n",
    "new_order = [\"Player_ID\", \"Season\", \"Draft_year\", \"School\", \"Name\",\n",
    "             \"Class\", \"Pos\", \"Height_cm\", \"Weight_kg\",\"Draft_team\", \"Draft_overall\",\n",
    "             \n",
    "             \n",
    "              \"Body_fat_pct\", \"Hand_Length_inch\", \"Hand_width_inch\",\n",
    "             \"Height_wo_Shoes\", \"Height_w_Shoes\", \"Standing_Reach_inch\", \"Wingspan_inch\",\"LANE_AGILITY_sec\", \"SHUTTLE_RUN_sec\", \"THREE_QUATER_SPRINT\", \"STANDING_VERTICAL_LEAP_inch\",\n",
    "             \"MAX_VERTICAL_LEAP_inch\", \"MAX_BENCH_PRESS\", \n",
    "             \n",
    "             \n",
    "             \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\",\n",
    "             \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "             \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\",\n",
    "             \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",\n",
    "             \"FG_per_min\", \"FGA_per_min\", \"2P_per_min\", \"2PA_per_min\", \"3P_per_min\", \"3PA_per_min\",\n",
    "             \"FT_per_min\", \"FTA_per_min\", \"TRB_per_min\", \"AST_per_min\", \"STL_per_min\", \"BLK_per_min\",\n",
    "             \"TOV_per_min\", \"PF_per_min\", \"PTS_per_min\",\n",
    "             \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",\n",
    "             \"ORB%_advanced\", \"DRB%_advanced\", \"TRB%_advanced\", \"AST%_advanced\", \"OBPM_advanced\",\n",
    "             \"DBPM_advanced\", \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\",\n",
    "             \"USG%_advanced\", \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\",\n",
    "             \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\",\n",
    "             \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \"STL_per_poss\",\n",
    "             \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \"ORtg_per_poss\", \"DRtg_per_poss\",\n",
    "            \n",
    "             \"Experience\"]  # 변경하고 싶은 순서대로 컬럼명을 리스트에 저장\n",
    "merged_all_comb_copy = merged_all_comb_copy[new_order]  # 데이터프레임의 컬럼 순서를 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "2b4bbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "# 'Class' 및 'Pos' 컬럼 전처리\n",
    "\n",
    "class_mapping = {'FR': 1, 'SO': 2, 'JR': 3, 'SR': 4}\n",
    "pos_mapping = {'G': 1, 'F': 3, 'C': 5}\n",
    "merged_all_comb_copy['Class'] = merged_all_comb_copy['Class'].map(class_mapping)\n",
    "merged_all_comb_copy['Pos'] = merged_all_comb_copy['Pos'].map(pos_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "d2fcdf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "bcbf2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼 별 결측치 비율 확인\n",
    "\n",
    "# missing_counts = merged_all_comb_copy.isnull().sum()\n",
    "# missing_ratios = (missing_counts / len(merged_all_comb_copy)) * 100\n",
    "# print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "c42e72a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#화면 출력 옵션_reset\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81fc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbdc99aa",
   "metadata": {},
   "source": [
    "<h1>2. 결측치 추정<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8018ee",
   "metadata": {},
   "source": [
    "<h3>2-1. 데이터 학습<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "5c04d78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Target: TS%_advanced - MSE: 0.00019414524389037302, MAPE: inf, R2: 0.9806928823623583\n",
      "Model for Target: eFG%_advanced - MSE: 3.0150003957653122e-05, MAPE: 0.5473006623846647, R2: 0.997811823355645\n",
      "Model for Target: 3PAr_advanced - MSE: 1.137097951914514e-05, MAPE: 0.7079406360469278, R2: 0.9998204346004902\n",
      "Model for Target: FTr_advanced - MSE: 0.0003121630652023351, MAPE: 1.1976608705501368, R2: 0.9971446646979981\n",
      "Model for Target: PProd_advanced - MSE: 46.04661224893638, MAPE: inf, R2: 0.9979888373429454\n",
      "Model for Target: ORB%_advanced - MSE: 6.25513022657564, MAPE: inf, R2: 0.6758228144450511\n",
      "Model for Target: DRB%_advanced - MSE: 6.967802859404374, MAPE: inf, R2: 0.7765284450099824\n",
      "Model for Target: TRB%_advanced - MSE: 0.6266109231225884, MAPE: inf, R2: 0.9661903778843308\n",
      "Model for Target: AST%_advanced - MSE: 2.255697526466805, MAPE: 8.461687887952806, R2: 0.9638900144287446\n",
      "Model for Target: OBPM_advanced - MSE: 7.555860344315822, MAPE: inf, R2: 0.6364667690244594\n",
      "Model for Target: DBPM_advanced - MSE: 3.8560768378351633, MAPE: inf, R2: 0.3633754076347525\n",
      "Model for Target: BPM_advanced - MSE: 16.530802651627585, MAPE: inf, R2: 0.5476723795870458\n",
      "Model for Target: STL%_advanced - MSE: 0.020243405560502616, MAPE: 4.545802335007514, R2: 0.9840129889355155\n",
      "Model for Target: BLK%_advanced - MSE: 0.1534704660136539, MAPE: inf, R2: 0.9770480738165197\n",
      "Model for Target: TOV%_advanced - MSE: 0.28537396853665775, MAPE: 1.7024270293116774, R2: 0.9950390559905894\n",
      "Model for Target: USG%_advanced - MSE: 2.384341001286237, MAPE: 5.445440006703773, R2: 0.929684086171529\n",
      "Model for Target: OWS_advanced - MSE: 0.058678688037993476, MAPE: inf, R2: 0.9386378330340491\n",
      "Model for Target: DWS_advanced - MSE: 0.08561473236370831, MAPE: inf, R2: 0.7376581758216267\n",
      "Model for Target: WS_advanced - MSE: 0.17440163253190857, MAPE: inf, R2: 0.9126331542466944\n",
      "Model for Target: WS/40_advanced - MSE: 0.0013024757346393589, MAPE: inf, R2: 0.7712516699817694\n",
      "Model for Target: PER_advanced - MSE: 7.1042894528544585, MAPE: inf, R2: 0.8573461623872284\n",
      "Model for Target: FG_per_poss - MSE: 0.23392825970032533, MAPE: inf, R2: 0.9688528435695082\n",
      "Model for Target: FGA_per_poss - MSE: 1.0706201715034194, MAPE: inf, R2: 0.9623587895136062\n",
      "Model for Target: 2P_per_poss - MSE: 0.16057070164594572, MAPE: inf, R2: 0.9796573574844892\n",
      "Model for Target: 2PA_per_poss - MSE: 0.44839207257143676, MAPE: inf, R2: 0.9806856333555029\n",
      "Model for Target: 3P_per_poss - MSE: 0.05078629274709475, MAPE: inf, R2: 0.9828107719132664\n",
      "Model for Target: 3PA_per_poss - MSE: 0.3226563567119269, MAPE: inf, R2: 0.9849400412772179\n",
      "Model for Target: FT_per_poss - MSE: 0.08123911727422994, MAPE: inf, R2: 0.9877378338041672\n",
      "Model for Target: FTA_per_poss - MSE: 0.38150191876265394, MAPE: inf, R2: 0.971960015961892\n",
      "Model for Target: TRB_per_poss - MSE: 0.38224750071302066, MAPE: inf, R2: 0.9800209698651388\n",
      "Model for Target: AST_per_poss - MSE: 0.05687879687345405, MAPE: 4.5510562430786425, R2: 0.989682102449023\n",
      "Model for Target: STL_per_poss - MSE: 0.02027728307113881, MAPE: 4.522732456950079, R2: 0.9839868317450008\n",
      "Model for Target: BLK_per_poss - MSE: 0.023812506183832984, MAPE: inf, R2: 0.9874284596970188\n",
      "Model for Target: TOV_per_poss - MSE: 0.0640560572234213, MAPE: inf, R2: 0.9808144392021158\n",
      "Model for Target: PF_per_poss - MSE: 0.49516038327633205, MAPE: inf, R2: 0.9436878898944829\n",
      "Model for Target: PTS_per_poss - MSE: 1.988388619860101, MAPE: inf, R2: 0.9639215389170975\n",
      "Model for Target: ORtg_per_poss - MSE: 32.14036447986922, MAPE: inf, R2: 0.8983188080300349\n",
      "Model for Target: DRtg_per_poss - MSE: 27.862872177697405, MAPE: 4.098676651123669, R2: 0.3307065653991921\n"
     ]
    }
   ],
   "source": [
    "#분석모판3  ############################################################################\n",
    "#ncaa raw data를 활용해 결측치 예측 후 분석모판 생성(전체연구기간)\n",
    "\n",
    "#1)기본stat으로 acvanced stat 추정##################\n",
    "\n",
    "\n",
    "\n",
    "#기본작업(아래의 grid search 시간오래 거림)\n",
    "#결측치 추정작업을 위한 ncaa_stat데이터 학습\n",
    "#Forest Regression\n",
    "#8:2데이터분할방식\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 정의된 피처와 타겟 컬럼\n",
    "feature_columns_stat = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"]\n",
    "\n",
    "# \"Height_cm\", \"Weight_kg\", \"Wingspan_inch\"\n",
    "\n",
    "target_columns = [\n",
    "    \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \"ORB%_advanced\", \n",
    "    \"DRB%_advanced\", \"TRB%_advanced\", \"AST%_advanced\", \"OBPM_advanced\", \"DBPM_advanced\", \n",
    "    \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\", \"DRtg_per_poss\"]\n",
    "\n",
    "\n",
    "# 'LANE_AGILITY_sec ', \"SHUTTLE_RUN_sec\", \"THREE_QUATER_SPRINT\",\n",
    "#     \"STANDING_VERTICAL_LEAP_inch\", \"MAX_BENCH_PRESS\", \"Body_fat_pct\", \"Hand_Length_inch\", \"Hand_width_inch\",\n",
    "#     \"Height_wo_Shoes\", \"Standing_Reach_inch\", \"Weight_lbs\", \"Wingspan_inch\"\n",
    "# 결측치가 없는 열 확인\n",
    "columns_to_check = feature_columns_stat + target_columns\n",
    "non_missing_samples = ncaa_stat_new.dropna(subset=columns_to_check)\n",
    "\n",
    "# 결과 저장을 위한 딕셔너리\n",
    "trained_models_stat = {}\n",
    "\n",
    "# 각 타겟 컬럼에 대해 모델링 및 성능 평가\n",
    "for target in target_columns:\n",
    "    # 피처와 타겟 분리\n",
    "    X = non_missing_samples[feature_columns_stat]\n",
    "    y = non_missing_samples[target]\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 생성 및 학습 (트리 개수 줄임)\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 학습된 모델 저장\n",
    "    trained_models_stat[target] = model\n",
    "    \n",
    "    # 테스트 데이터 예측 및 평가\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / (y_test))) * 100\n",
    "\n",
    "    # 모델 성능 출력\n",
    "    print(f\"Model for Target: {target} - MSE: {mse}, MAPE: {mape}, R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "2fb80dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#오래걸려서 일단 주석처리\n",
    "\n",
    "\n",
    "# #하이퍼파라미터 튜닝\n",
    "# #정규화\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np\n",
    "\n",
    "# # 정의된 피처와 타겟 컬럼\n",
    "# feature_columns_stat = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"]\n",
    "\n",
    "# # \"Height_cm\", \"Weight_kg\", \"Wingspan_inch\"\n",
    "\n",
    "# target_columns = [\n",
    "#     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \"ORB%_advanced\", \n",
    "#     \"DRB%_advanced\", \"TRB%_advanced\", \"AST%_advanced\", \"OBPM_advanced\", \"DBPM_advanced\", \n",
    "#     \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\", \"DRtg_per_poss\"]\n",
    "\n",
    "# # 결과 저장을 위한 딕셔너리\n",
    "# trained_models_stat = {}\n",
    "\n",
    "# # 데이터 스케일링 (옵션)\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# for target in target_columns:\n",
    "#     X = non_missing_samples[feature_columns_stat]\n",
    "#     y = non_missing_samples[target]\n",
    "\n",
    "#     # 데이터 분할\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # 데이터 스케일링 적용\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#     # 하이퍼파라미터 튜닝을 위한 그리드 정의\n",
    "#     param_grid = {\n",
    "#         'n_estimators': [10, 50, 100],\n",
    "#         'max_depth': [None, 10, 20],\n",
    "#         # 여기에 더 많은 하이퍼파라미터를 추가할 수 있습니다\n",
    "#     }\n",
    "\n",
    "#     # 그리드 서치 객체 생성\n",
    "#     grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "#     grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "#     # 최적의 모델 찾기\n",
    "#     best_model = grid_search.best_estimator_\n",
    "\n",
    "#     # 학습된 모델 저장\n",
    "#     trained_models_stat[target] = best_model\n",
    "\n",
    "#     # 테스트 데이터 예측 및 평가\n",
    "#     y_pred = best_model.predict(X_test_scaled)\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#     # 모델 성능 출력\n",
    "#     print(f\"Model for Target: {target} - MSE: {mse}, R2: {r2}\")\n",
    "\n",
    "# # 최적의 파라미터 출력 (예시)\n",
    "# print(\"\\nBest Model Parameters for a Target:\")\n",
    "# print(trained_models_stat[target_columns[0]].get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "495fc1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#오래걸려서 일단 주석처리\n",
    "\n",
    "\n",
    "# #하이퍼파라미터 튜닝\n",
    "# #정규화\n",
    "# #MAPE RMSE 추가\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np\n",
    "\n",
    "# # 정의된 피처와 타겟 컬럼\n",
    "# feature_columns_stat = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"]\n",
    "\n",
    "# target_columns = [\n",
    "#     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \"ORB%_advanced\", \n",
    "#     \"DRB%_advanced\", \"TRB%_advanced\", \"AST%_advanced\", \"OBPM_advanced\", \"DBPM_advanced\", \n",
    "#     \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\", \"DRtg_per_poss\"]\n",
    "\n",
    "# # 결과 저장을 위한 딕셔너리\n",
    "# trained_models_stat = {}\n",
    "\n",
    "# # 데이터 스케일링 (옵션)\n",
    "# scaler = StandardScaler()\n",
    "# # epsilon = 1e-10  # 작은 상수 epsilon 정의\n",
    "\n",
    "# for target in target_columns:\n",
    "#     X = non_missing_samples[feature_columns_stat]\n",
    "#     y = non_missing_samples[target]\n",
    "\n",
    "#     # 데이터 분할\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # 데이터 스케일링 적용\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#     # 하이퍼파라미터 튜닝을 위한 그리드 정의\n",
    "#     param_grid = {\n",
    "#         'n_estimators': [10, 50, 100],\n",
    "#         'max_depth': [None, 10, 20],\n",
    "#         # 추가 하이퍼파라미터 설정 가능\n",
    "#     }\n",
    "\n",
    "#     # 그리드 서치 객체 생성\n",
    "#     grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "#     grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "#     # 최적의 모델 찾기\n",
    "#     best_model = grid_search.best_estimator_\n",
    "\n",
    "#     # 학습된 모델 저장\n",
    "#     trained_models_stat[target] = best_model\n",
    "\n",
    "#     # 테스트 데이터 예측 및 평가\n",
    "#     y_pred = best_model.predict(X_test_scaled)\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mape = np.mean(np.abs((y_test - y_pred) / (y_test))) * 100\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#     # 모델 성능 출력\n",
    "#     print(f\"Model for Target: {target} - MSE: {mse}, RMSE: {rmse}, MAPE: {mape}, R2: {r2}\")\n",
    "\n",
    "# # 최적의 파라미터 출력 (예시)\n",
    "# print(\"\\nBest Model Parameters for a Target:\")\n",
    "# print(trained_models_stat[target_columns[0]].get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "a44f02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#오래걸려서 일단 주석처리\n",
    "\n",
    "# #결측치 추정작업을 위한 ncaa_stat데이터 학습\n",
    "# #Random Forest_Regression\n",
    "# #8:2데이터분할방식\n",
    "# #각 변수별 최적의 예측모델을 별도로 저장하는 과정 추가\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import joblib\n",
    "# # import pandas as pd\n",
    "\n",
    "# # 정의된 피처와 타겟 컬럼\n",
    "# feature_columns_stat = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"\n",
    "# ]\n",
    "\n",
    "# target_columns = [\n",
    "#     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\", \"ORB%_advanced\", \n",
    "#     \"DRB%_advanced\", \"TRB%_advanced\", \"AST%_advanced\", \"OBPM_advanced\", \"DBPM_advanced\", \n",
    "#     \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\", \"DRtg_per_poss\"\n",
    "# ]\n",
    "\n",
    "# # 결측치가 없는 열 확인\n",
    "# columns_to_check = feature_columns_stat + target_columns\n",
    "# non_missing_samples = ncaa_stat_new.dropna(subset=columns_to_check)\n",
    "\n",
    "# # 하이퍼파라미터 그리드 정의\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],  # 트리의 개수\n",
    "#     'max_depth': [None, 10, 20, 30],  # 트리의 최대 깊이\n",
    "#     'min_samples_split': [2, 5, 10],  # 노드를 분할하기 위한 최소 샘플 수\n",
    "#     'min_samples_leaf': [1, 2, 4]     # 리프 노드에 있어야 하는 최소 샘플 수\n",
    "# }\n",
    "\n",
    "# # 모델과 그리드 서치 객체 생성\n",
    "# model = RandomForestRegressor(random_state=42)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# # 각 타겟 컬럼에 대해 최적의 모델 찾기 및 저장\n",
    "# for target in target_columns:\n",
    "#     X = non_missing_samples[feature_columns_stat]\n",
    "#     y = non_missing_samples[target]\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # 그리드 서치 수행\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "#     print(f\"Best parameters for {target}: {grid_search.best_params_}\")\n",
    "#     best_model = grid_search.best_estimator_\n",
    "#     y_pred = best_model.predict(X_test)\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "#     print(f\"Optimized Model for Target: {target} - MSE: {mse}, R2: {r2}\")\n",
    "\n",
    "#     # 모델 저장\n",
    "#     save_path = f\"best_model_{target}.joblib\"\n",
    "#     joblib.dump(best_model, save_path)\n",
    "\n",
    "# # 이 코드는 각 'target'에 대해 최적화된 RandomForestRegressor 모델을 찾고 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e09bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08ea12dd",
   "metadata": {},
   "source": [
    "<h3>2-2. 결측치 대체<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "e8990889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값을 추정값으로 대체할 컬럼의 결측치가 있는 샘플 추출\n",
    "missing_samples = merged_all_comb_copy[merged_all_comb_copy[target_columns].isnull().any(axis=1)]\n",
    "\n",
    "# 'feature_columns_stat'에 정의된 컬럼들 중 결측치가 없는 행 추출\n",
    "samples_with_missing = missing_samples.dropna(subset=feature_columns_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "183125d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "cbb83de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncaa_stat_new데이터를 학습하여 생성한 모델로 결측치 추정 및 대체\n",
    "\n",
    "for target in target_columns:\n",
    "    model = trained_models_stat[target]\n",
    "    X_missing = samples_with_missing[feature_columns_stat]\n",
    "    \n",
    "    y_missing = model.predict(X_missing)\n",
    "    \n",
    "    merged_all_comb_copy.loc[samples_with_missing.index, target] = y_missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "92d8264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as a file\n",
    "\n",
    "# merged_all_comb_copy.to_csv('merged_all_comb_copy33.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "79812496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #컬럼별 결측치 비율 확인\n",
    "# missing_counts = merged_all_comb_copy.isnull().sum()\n",
    "# missing_ratios = (missing_counts / len(merged_all_comb_copy)) * 100\n",
    "# print(missing_ratios)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3418f0fc",
   "metadata": {},
   "source": [
    "<h3>NCAA재학기간 평균_학년 별 가중평균 X<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "7cdbcef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Draft_year            Name  Pos  Height_cm  Weight_kg  \\\n",
      "0       2000     A.J. Guyton    1      185.0       81.0   \n",
      "1       2000    Chris Porter    3      201.0       98.0   \n",
      "2       2000      Dan Langhi    3      211.0       99.0   \n",
      "3       2000  Dan McClintock    5      213.0      122.0   \n",
      "4       2000  Donnell Harvey    5      203.0       99.0   \n",
      "\n",
      "              Draft_team Draft_overall  Experience  Body_fat_pct  \\\n",
      "0          Chicago Bulls            32         3.0           NaN   \n",
      "1  Golden State Warriors            55         1.0           NaN   \n",
      "2       Dallas Mavericks            31         4.0           NaN   \n",
      "3         Denver Nuggets            53         1.0           NaN   \n",
      "4        New York Knicks            22         5.0           NaN   \n",
      "\n",
      "   Hand_Length_inch  ...  BLK_per_poss  TOV_per_poss  PF_per_poss  \\\n",
      "0               NaN  ...        0.7075        4.0625       2.4050   \n",
      "1               NaN  ...        0.7650        4.5350       5.1650   \n",
      "2               NaN  ...        0.5450        3.7750       3.9975   \n",
      "3               NaN  ...        5.1250        5.5800       6.8275   \n",
      "4               NaN  ...        2.4100        4.6000       7.8500   \n",
      "\n",
      "   PTS_per_poss  ORtg_per_poss  DRtg_per_poss  FG%_totals  2P%_totals  \\\n",
      "0       28.4175       112.8900       105.6975    0.454933    0.484342   \n",
      "1       30.1750       103.4000        95.5000    0.467153    0.476780   \n",
      "2       27.0350       109.9825       107.3400    0.444546    0.474692   \n",
      "3       33.9700       116.3325        96.6875    0.631702    0.632439   \n",
      "4       29.9700       103.9100        95.1800    0.507042    0.508834   \n",
      "\n",
      "   3P%_totals  FT%_totals  \n",
      "0    0.413743    0.789731  \n",
      "1    0.307692    0.650943  \n",
      "2    0.383333    0.831224  \n",
      "3    0.000000    0.651869  \n",
      "4    0.000000    0.609929  \n",
      "\n",
      "[5 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_all_comb_copy_new = merged_all_comb_copy.copy()\n",
    "\n",
    "# 데이터 로드\n",
    "# 예: merged_all_comb_copy_new = pd.read_csv('your_file.csv')\n",
    "\n",
    "# 기준이 되는 컬럼 목록\n",
    "grouping_columns = ['Draft_year', 'Name', 'Pos', 'Height_cm', 'Weight_kg', 'Draft_team', 'Draft_overall','Experience']\n",
    "\n",
    "# 숫자형 컬럼과 문자형 컬럼 분리\n",
    "numeric_columns = merged_all_comb_copy_new.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "object_columns = merged_all_comb_copy_new.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# 제외할 컬럼들\n",
    "exclude_columns = ['Player_ID', 'Season', 'School', 'Class'] + grouping_columns + ['FG%_totals', '2P%_totals', '3P%_totals', 'FT%_totals']\n",
    "\n",
    "# 그룹화 기준을 제외한 숫자형 컬럼만 선택\n",
    "numeric_columns = [col for col in numeric_columns if col not in exclude_columns]\n",
    "\n",
    "# 동일한 선수의 숫자형 컬럼에 대해 평균 계산\n",
    "merged_all_comb_copy_grouped = merged_all_comb_copy_new.groupby(grouping_columns)[numeric_columns].mean().reset_index()\n",
    "\n",
    "# 특정 컬럼에 대한 합계 계산\n",
    "sum_columns = ['FG_totals', 'FGA_totals', '2P_totals', '2PA_totals', '3P_totals', '3PA_totals', 'FT_totals', 'FTA_totals']\n",
    "sums = merged_all_comb_copy_new.groupby(grouping_columns)[sum_columns].sum().reset_index()\n",
    "\n",
    "# 성공률 계산 및 대체\n",
    "merged_all_comb_copy_grouped['FG%_totals'] = sums['FG_totals'] / sums['FGA_totals']\n",
    "merged_all_comb_copy_grouped['2P%_totals'] = sums['2P_totals'] / sums['2PA_totals']\n",
    "merged_all_comb_copy_grouped['3P%_totals'] = sums['3P_totals'] / sums['3PA_totals']\n",
    "merged_all_comb_copy_grouped['FT%_totals'] = sums['FT_totals'] / sums['FTA_totals']\n",
    "\n",
    "# NaN 값 처리 (0으로 대체)\n",
    "# merged_all_comb_copy_grouped.fillna(0, inplace=True)\n",
    "\n",
    "# 문자형 컬럼 추가 (첫 번째 값 선택)\n",
    "for col in object_columns:\n",
    "    if col not in exclude_columns:\n",
    "        merged_all_comb_copy_grouped[col] = merged_all_comb_copy_new.groupby(grouping_columns)[col].first().reset_index()[col]\n",
    "\n",
    "# 결과 확인\n",
    "print(merged_all_comb_copy_grouped.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "5935ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼 위치 조정\n",
    "\n",
    "new_order = ['Draft_year', 'Name', 'Pos', \"Height_cm\", \"Weight_kg\",\"Draft_team\", \"Draft_overall\",             \n",
    "             \"Body_fat_pct\", \"Hand_Length_inch\", \"Hand_width_inch\",\n",
    "             \"Height_wo_Shoes\", \"Height_w_Shoes\", \"Standing_Reach_inch\", \"Wingspan_inch\",\"LANE_AGILITY_sec\", \"SHUTTLE_RUN_sec\", \"THREE_QUATER_SPRINT\", \"STANDING_VERTICAL_LEAP_inch\",\n",
    "             \"MAX_VERTICAL_LEAP_inch\", \"MAX_BENCH_PRESS\", \n",
    "              \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\",\n",
    "             \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "             \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\",\n",
    "             \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",\n",
    "             \"FG_per_min\", \"FGA_per_min\", \"2P_per_min\", \"2PA_per_min\", \"3P_per_min\", \"3PA_per_min\",\n",
    "             \"FT_per_min\", \"FTA_per_min\", \"TRB_per_min\", \"AST_per_min\", \"STL_per_min\", \"BLK_per_min\",\n",
    "             \"TOV_per_min\", \"PF_per_min\", \"PTS_per_min\",\n",
    "             \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",\n",
    "             \"ORB%_advanced\", \"DRB%_advanced\", \"TRB%_advanced\", \"AST%_advanced\", \"OBPM_advanced\",\n",
    "             \"DBPM_advanced\", \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\",\n",
    "             \"USG%_advanced\", \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\",\n",
    "             \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\",\n",
    "             \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \"STL_per_poss\",\n",
    "             \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \"ORtg_per_poss\", \"DRtg_per_poss\", 'Experience'            \n",
    "      ]  # 변경하고 싶은 순서대로 컬럼명을 리스트에 저장\n",
    "merged_all_comb_copy_grouped = merged_all_comb_copy_grouped[new_order]  # 데이터프레임의 컬럼 순서를 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "d8b0b492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original missing values count: 36\n",
      "New missing values count: 0\n"
     ]
    }
   ],
   "source": [
    "# '3P%_totals' 컬럼의 결측값 개수 확인\n",
    "missing_values_count = merged_all_comb_copy_grouped['3P%_totals'].isna().sum()\n",
    "print(\"Original missing values count:\", missing_values_count)\n",
    "# 결측값을 0으로 대체\n",
    "merged_all_comb_copy_grouped['3P%_totals'].fillna(0, inplace=True)\n",
    "\n",
    "# 대체 후의 결측값 개수 확인\n",
    "new_missing_values_count = merged_all_comb_copy_grouped['3P%_totals'].isna().sum()\n",
    "print(\"New missing values count:\", new_missing_values_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "81055c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 숫자형 컬럼을 소수점 둘째자리까지 반올림\n",
    "numeric_columns = merged_all_comb_copy_grouped.select_dtypes(include=['float64', 'int']).columns\n",
    "merged_all_comb_copy_grouped[numeric_columns] = merged_all_comb_copy_grouped[numeric_columns].round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "c6b94c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft_year       0.0\n",
      "Name             0.0\n",
      "Pos              0.0\n",
      "Height_cm        0.0\n",
      "Weight_kg        0.0\n",
      "                ... \n",
      "PF_per_poss      0.0\n",
      "PTS_per_poss     0.0\n",
      "ORtg_per_poss    0.0\n",
      "DRtg_per_poss    0.0\n",
      "Experience       0.0\n",
      "Length: 95, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#컬럼별 결측치 비율 확인\n",
    "missing_counts = merged_all_comb_copy_grouped.isnull().sum()\n",
    "missing_ratios = (missing_counts / len(merged_all_comb_copy_grouped)) * 100\n",
    "print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "8518f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_all_comb_copy_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "a6a48fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the data as a file\n",
    "\n",
    "# merged_all_comb_copy_grouped.to_csv('merged_all_comb_copy_grouped31.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6990f6",
   "metadata": {},
   "source": [
    "<h3>NCAA재학기간 평균_학년 별 가중평균 <h3>\n",
    "<h4>1,2,3,4학년 모두 존재할 경우 각각 0.1, 0.2, 0.3, 0.4의 가중치 부여<h4>\n",
    "<h4>1,2,3학년만 존재할 경우 각각 0.2, 0.3, 0.5의 가중치 부여<h4>\n",
    "<h4>1,2학년만 존재할 경우 각각 0.4, 0.6의 가중치 부여<h4>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "c2065be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merged_all_comb_copy_new1 = merged_all_comb_copy.copy()\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# # 기준이 되는 컬럼 목록\n",
    "# grouping_columns = ['Draft_year', 'Name', 'Pos', 'Height_cm', 'Weight_kg', 'Draft_team', 'Draft_overall','Experience']\n",
    "\n",
    "# # 숫자형 컬럼과 문자형 컬럼 분리\n",
    "# numeric_columns = merged_all_comb_copy_new1.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "# object_columns = merged_all_comb_copy_new1.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# # 제외할 컬럼들\n",
    "# exclude_columns = ['Player_ID', 'Season', 'School', 'Class'] + grouping_columns + ['FG%_totals', '2P%_totals', '3P%_totals', 'FT%_totals']\n",
    "\n",
    "# # 그룹화 기준을 제외한 숫자형 컬럼만 선택\n",
    "# numeric_columns = [col for col in numeric_columns if col not in exclude_columns]\n",
    "\n",
    "# # 수정된 가중치 할당 함수\n",
    "# def assign_modified_weights(group):\n",
    "#     num_classes = group['Class'].nunique()\n",
    "#     sorted_classes = sorted(group['Class'].unique())\n",
    "\n",
    "#     if num_classes == 4:\n",
    "#         weights = {class_val: weight for class_val, weight in zip(sorted_classes, [0.1, 0.2, 0.3, 0.4])}\n",
    "#     elif num_classes == 3:\n",
    "#         weights = {class_val: weight for class_val, weight in zip(sorted_classes, [0.2, 0.3, 0.5])}\n",
    "#     elif num_classes == 2:\n",
    "#         weights = {class_val: weight for class_val, weight in zip(sorted_classes, [0.4, 0.6])}\n",
    "#     else:  # num_classes == 1\n",
    "#         weights = {class_val: 1.0 for class_val in sorted_classes}\n",
    "    \n",
    "#     return group['Class'].map(weights)\n",
    "\n",
    "# # 각 선수별로 수정된 가중치 적용\n",
    "# modified_weights = merged_all_comb_copy_new1.groupby(grouping_columns).apply(assign_modified_weights).reset_index(level=grouping_columns, drop=True)\n",
    "\n",
    "# # 가중평균 계산 함수\n",
    "# def safe_weighted_average(df, cols, weights):\n",
    "#     if sum(weights) == 0:\n",
    "#         return df[cols].mean()\n",
    "#     else:\n",
    "#         return pd.Series(np.average(df[cols], weights=weights, axis=0), index=cols)\n",
    "\n",
    "# # 각 선수별로 안전한 가중평균을 계산\n",
    "# def compute_weighted_average(group, weights):\n",
    "#     group_weights = weights.loc[group.index]\n",
    "#     return safe_weighted_average(group, numeric_columns, group_weights)\n",
    "\n",
    "# weighted_avg_new = merged_all_comb_copy_new1.groupby(grouping_columns).apply(lambda x: compute_weighted_average(x, modified_weights))\n",
    "\n",
    "# # 성공률 계산 (평균 사용)\n",
    "# averages = merged_all_comb_copy_new1.groupby(grouping_columns)[sum_columns].mean()\n",
    "\n",
    "# # 특정 컬럼에 대한 합계 계산\n",
    "# sums = merged_all_comb_copy_new1.groupby(grouping_columns)[['FG_totals', 'FGA_totals', '2P_totals', '2PA_totals', '3P_totals', '3PA_totals', 'FT_totals', 'FTA_totals']].sum()\n",
    "# # 성공률 계산 및 대체\n",
    "# weighted_avg_new['FG%_totals'] = sums['FG_totals'] / sums['FGA_totals']\n",
    "# weighted_avg_new['2P%_totals'] = sums['2P_totals'] / sums['2PA_totals']\n",
    "# weighted_avg_new['3P%_totals'] = sums['3P_totals'] / sums['3PA_totals']\n",
    "# weighted_avg_new['FT%_totals'] = sums['FT_totals'] / sums['FTA_totals']\n",
    "\n",
    "# # NaN 값 처리 (0으로 대체)\n",
    "# weighted_avg_new.fillna(0, inplace=True)\n",
    "\n",
    "# # 문자형 컬럼 추가 (첫 번째 값 선택)\n",
    "# for col in object_columns:\n",
    "#     if col not in exclude_columns:\n",
    "#         weighted_avg_new[col] = merged_all_comb_copy_new1.groupby(grouping_columns)[col].first().reset_index()[col]\n",
    "\n",
    "# # 데이터프레임의 다중컬럼 형식을 기본컬럼 형식으로 변경\n",
    "# weighted_avg_new.reset_index(inplace=True)\n",
    "\n",
    "# # 결과 출력\n",
    "# print(weighted_avg_new.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "79b1c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_all_comb_copy_new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "08094c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Draft_year            Name  Pos  Height_cm  Weight_kg  \\\n",
      "0       2000     A.J. Guyton    1      185.0       81.0   \n",
      "1       2000    Chris Porter    3      201.0       98.0   \n",
      "2       2000      Dan Langhi    3      211.0       99.0   \n",
      "3       2000  Dan McClintock    5      213.0      122.0   \n",
      "4       2000  Donnell Harvey    5      203.0       99.0   \n",
      "\n",
      "              Draft_team Draft_overall  Experience  Body_fat_pct  \\\n",
      "0          Chicago Bulls            32         3.0           NaN   \n",
      "1  Golden State Warriors            55         1.0           NaN   \n",
      "2       Dallas Mavericks            31         4.0           NaN   \n",
      "3         Denver Nuggets            53         1.0           NaN   \n",
      "4        New York Knicks            22         5.0           NaN   \n",
      "\n",
      "   Hand_Length_inch  ...  FTA_per_poss  TRB_per_poss  AST_per_poss  \\\n",
      "0               NaN  ...         5.809         5.743         5.059   \n",
      "1               NaN  ...        11.356        15.882         2.232   \n",
      "2               NaN  ...         9.360        11.212         1.607   \n",
      "3               NaN  ...        11.822        13.761         2.190   \n",
      "4               NaN  ...        10.810        19.750         2.910   \n",
      "\n",
      "   STL_per_poss  BLK_per_poss  TOV_per_poss  PF_per_poss  PTS_per_poss  \\\n",
      "0         1.630         0.704         4.100        2.268        29.569   \n",
      "1         3.952         0.740         4.498        5.206        30.086   \n",
      "2         1.110         0.534         3.687        3.749        30.558   \n",
      "3         1.069         5.235         5.437        6.472        34.879   \n",
      "4         2.160         2.410         4.600        7.850        29.970   \n",
      "\n",
      "   ORtg_per_poss  DRtg_per_poss  \n",
      "0        112.925        105.731  \n",
      "1        103.376         95.636  \n",
      "2        112.385        108.428  \n",
      "3        117.616         95.981  \n",
      "4        103.910         95.180  \n",
      "\n",
      "[5 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "merged_all_comb_copy_new1 = merged_all_comb_copy.copy()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 기준이 되는 컬럼 목록\n",
    "grouping_columns = ['Draft_year', 'Name', 'Pos', 'Height_cm', 'Weight_kg', 'Draft_team', 'Draft_overall', 'Experience']\n",
    "\n",
    "# 숫자형 컬럼과 문자형 컬럼 분리\n",
    "numeric_columns = merged_all_comb_copy_new1.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "object_columns = merged_all_comb_copy_new1.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# 제외할 컬럼들\n",
    "exclude_columns = ['Player_ID', 'Season', 'School', 'Class'] + grouping_columns \n",
    "\n",
    "# 그룹화 기준을 제외한 숫자형 컬럼만 선택\n",
    "numeric_columns = [col for col in numeric_columns if col not in exclude_columns]\n",
    "\n",
    "# 수정된 가중치 할당 함수\n",
    "def assign_modified_weights(group):\n",
    "    num_classes = group['Class'].nunique()\n",
    "    sorted_classes = sorted(group['Class'].unique())\n",
    "\n",
    "    if num_classes == 4:\n",
    "        weights = {class_val: weight for class_val, weight in zip(sorted_classes, [0.1, 0.2, 0.3, 0.4])}\n",
    "    elif num_classes == 3:\n",
    "        weights = {class_val: weight for class_val, weight in zip(sorted_classes, [0.2, 0.3, 0.5])}\n",
    "    elif num_classes == 2:\n",
    "        weights = {class_val: weight for class_val, weight in zip(sorted_classes, [0.4, 0.6])}\n",
    "    else:  # num_classes == 1\n",
    "        weights = {class_val: 1.0 for class_val in sorted_classes}\n",
    "    \n",
    "    return group['Class'].map(weights)\n",
    "\n",
    "# 각 선수별로 수정된 가중치 적용\n",
    "modified_weights = merged_all_comb_copy_new1.groupby(grouping_columns).apply(assign_modified_weights).reset_index(level=grouping_columns, drop=True)\n",
    "\n",
    "# 가중평균 계산 함수\n",
    "def safe_weighted_average(df, cols, weights):\n",
    "    if sum(weights) == 0:\n",
    "        return df[cols].mean()\n",
    "    else:\n",
    "        return pd.Series(np.average(df[cols], weights=weights, axis=0), index=cols)\n",
    "\n",
    "# 각 선수별로 안전한 가중평균을 계산\n",
    "def compute_weighted_average(group, weights):\n",
    "    group_weights = weights.loc[group.index]\n",
    "    return safe_weighted_average(group, numeric_columns, group_weights)\n",
    "\n",
    "weighted_avg_new = merged_all_comb_copy_new1.groupby(grouping_columns).apply(lambda x: compute_weighted_average(x, modified_weights))\n",
    "\n",
    "# sum_columns = ['FG_totals', 'FGA_totals', '2P_totals', '2PA_totals', '3P_totals', '3PA_totals', 'FT_totals', 'FTA_totals']\n",
    "\n",
    "# 성공률 계산 (평균 사용)\n",
    "# averages = merged_all_comb_copy_new1.groupby(grouping_columns)[sum_columns].mean()\n",
    "\n",
    "# 특정 컬럼에 대한 합계 계산\n",
    "# sums = merged_all_comb_copy_new1.groupby(grouping_columns)[['FG_totals', 'FGA_totals', '2P_totals', '2PA_totals', '3P_totals', '3PA_totals', 'FT_totals', 'FTA_totals']].sum()\n",
    "# 성공률 계산 및 대체\n",
    "# weighted_avg_new['FG%_totals'] = sums['FG_totals'] / sums['FGA_totals']\n",
    "# weighted_avg_new['2P%_totals'] = sums['2P_totals'] / sums['2PA_totals']\n",
    "# weighted_avg_new['3P%_totals'] = sums['3P_totals'] / sums['3PA_totals']\n",
    "# weighted_avg_new['FT%_totals'] = sums['FT_totals'] / sums['FTA_totals']\n",
    "\n",
    "# # NaN 값 처리 (0으로 대체)\n",
    "# weighted_avg_new.fillna(0, inplace=True)\n",
    "\n",
    "# 문자형 컬럼 추가 (첫 번째 값 선택)\n",
    "for col in object_columns:\n",
    "    if col not in exclude_columns:\n",
    "        weighted_avg_new[col] = merged_all_comb_copy_new1.groupby(grouping_columns)[col].first().reset_index()[col]\n",
    "\n",
    "# 데이터프레임의 다중컬럼 형식을 기본컬럼 형식으로 변경\n",
    "weighted_avg_new.reset_index(inplace=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(weighted_avg_new.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "0a652e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff912f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "207db81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_avg_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "394a9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼 위치 조정\n",
    "\n",
    "new_order = ['Draft_year', 'Name', 'Pos', \"Height_cm\", \"Weight_kg\",\"Draft_team\", \"Draft_overall\",             \n",
    "             \"Body_fat_pct\", \"Hand_Length_inch\", \"Hand_width_inch\",\n",
    "             \"Height_wo_Shoes\", \"Height_w_Shoes\", \"Standing_Reach_inch\", \"Wingspan_inch\",\"LANE_AGILITY_sec\", \"SHUTTLE_RUN_sec\", \"THREE_QUATER_SPRINT\", \"STANDING_VERTICAL_LEAP_inch\",\n",
    "             \"MAX_VERTICAL_LEAP_inch\", \"MAX_BENCH_PRESS\", \n",
    "              \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\",\n",
    "             \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "             \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\",\n",
    "             \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",\n",
    "             \"FG_per_min\", \"FGA_per_min\", \"2P_per_min\", \"2PA_per_min\", \"3P_per_min\", \"3PA_per_min\",\n",
    "             \"FT_per_min\", \"FTA_per_min\", \"TRB_per_min\", \"AST_per_min\", \"STL_per_min\", \"BLK_per_min\",\n",
    "             \"TOV_per_min\", \"PF_per_min\", \"PTS_per_min\",\n",
    "             \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",\n",
    "             \"ORB%_advanced\", \"DRB%_advanced\", \"TRB%_advanced\", \"AST%_advanced\", \"OBPM_advanced\",\n",
    "             \"DBPM_advanced\", \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\",\n",
    "             \"USG%_advanced\", \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\",\n",
    "             \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\",\n",
    "             \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \"STL_per_poss\",\n",
    "             \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \"ORtg_per_poss\", \"DRtg_per_poss\", 'Experience'            \n",
    "      ]  # 변경하고 싶은 순서대로 컬럼명을 리스트에 저장\n",
    "weighted_avg_new = weighted_avg_new[new_order]  # 데이터프레임의 컬럼 순서를 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "ee0b5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성공률 계산 및 데이터프레임에 추가\n",
    "weighted_avg_new['FG%_totals'] = weighted_avg_new['FG_totals'] / weighted_avg_new['FGA_totals']\n",
    "weighted_avg_new['2P%_totals'] = weighted_avg_new['2P_totals'] / weighted_avg_new['2PA_totals']\n",
    "weighted_avg_new['3P%_totals'] = weighted_avg_new['3P_totals'] / weighted_avg_new['3PA_totals']\n",
    "weighted_avg_new['FT%_totals'] = weighted_avg_new['FT_totals'] / weighted_avg_new['FTA_totals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "b7b27969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original missing values count: 36\n",
      "New missing values count: 0\n"
     ]
    }
   ],
   "source": [
    "# '3P%_totals' 컬럼의 결측값 개수 확인\n",
    "missing_values_count = weighted_avg_new['3P%_totals'].isna().sum()\n",
    "print(\"Original missing values count:\", missing_values_count)\n",
    "# 결측값을 0으로 대체\n",
    "weighted_avg_new['3P%_totals'].fillna(0, inplace=True)\n",
    "\n",
    "# 대체 후의 결측값 개수 확인\n",
    "new_missing_values_count = weighted_avg_new['3P%_totals'].isna().sum()\n",
    "print(\"New missing values count:\", new_missing_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "eeee8116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #데이터가 '0'인 값 결측값으로 변경 처리\n",
    "\n",
    "# # 'merged_all_comb_copy_grouped'에서 '0' 값을 NaN으로 변경\n",
    "# weighted_avg_new.replace(0, pd.NA, inplace=True)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(weighted_avg_new.head())\n",
    "\n",
    "# # #데이터가 '0'인 값 결측값으로 변경 처리\n",
    "\n",
    "# # # 'merged_all_comb_copy_grouped'에서 '0' 값을 NaN으로 변경\n",
    "# # merged_all_comb_copy_grouped.replace(0, pd.NA, inplace=True)\n",
    "\n",
    "# # # 결과 확인\n",
    "# # print(merged_all_comb_copy_grouped.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "090a8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼 별 데이터타입 확인\n",
    "\n",
    "# data_types = weighted_avg_new.dtypes\n",
    "# print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "c83320ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 463 entries, 0 to 462\n",
      "Data columns (total 95 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Draft_year                   463 non-null    int64  \n",
      " 1   Name                         463 non-null    object \n",
      " 2   Pos                          463 non-null    int64  \n",
      " 3   Height_cm                    463 non-null    float64\n",
      " 4   Weight_kg                    463 non-null    float64\n",
      " 5   Draft_team                   463 non-null    object \n",
      " 6   Draft_overall                463 non-null    int64  \n",
      " 7   Body_fat_pct                 384 non-null    float64\n",
      " 8   Hand_Length_inch             192 non-null    float64\n",
      " 9   Hand_width_inch              192 non-null    float64\n",
      " 10  Height_wo_Shoes              462 non-null    float64\n",
      " 11  Height_w_Shoes               352 non-null    float64\n",
      " 12  Standing_Reach_inch          461 non-null    float64\n",
      " 13  Wingspan_inch                462 non-null    float64\n",
      " 14  LANE_AGILITY_sec             421 non-null    float64\n",
      " 15  SHUTTLE_RUN_sec              78 non-null     float64\n",
      " 16  THREE_QUATER_SPRINT          424 non-null    float64\n",
      " 17  STANDING_VERTICAL_LEAP_inch  428 non-null    float64\n",
      " 18  MAX_VERTICAL_LEAP_inch       427 non-null    float64\n",
      " 19  MAX_BENCH_PRESS              379 non-null    float64\n",
      " 20  G_totals                     463 non-null    float64\n",
      " 21  MP_totals                    461 non-null    float64\n",
      " 22  FG_totals                    463 non-null    float64\n",
      " 23  FGA_totals                   463 non-null    float64\n",
      " 24  FG%_totals                   463 non-null    float64\n",
      " 25  2P_totals                    463 non-null    float64\n",
      " 26  2PA_totals                   463 non-null    float64\n",
      " 27  2P%_totals                   463 non-null    float64\n",
      " 28  3P_totals                    463 non-null    float64\n",
      " 29  3PA_totals                   463 non-null    float64\n",
      " 30  3P%_totals                   463 non-null    float64\n",
      " 31  FT_totals                    463 non-null    float64\n",
      " 32  FTA_totals                   463 non-null    float64\n",
      " 33  FT%_totals                   463 non-null    float64\n",
      " 34  TRB_totals                   463 non-null    float64\n",
      " 35  AST_totals                   463 non-null    float64\n",
      " 36  STL_totals                   463 non-null    float64\n",
      " 37  BLK_totals                   463 non-null    float64\n",
      " 38  TOV_totals                   463 non-null    float64\n",
      " 39  PF_totals                    462 non-null    float64\n",
      " 40  PTS_totals                   463 non-null    float64\n",
      " 41  FG_per_min                   461 non-null    float64\n",
      " 42  FGA_per_min                  461 non-null    float64\n",
      " 43  2P_per_min                   461 non-null    float64\n",
      " 44  2PA_per_min                  461 non-null    float64\n",
      " 45  3P_per_min                   461 non-null    float64\n",
      " 46  3PA_per_min                  461 non-null    float64\n",
      " 47  FT_per_min                   461 non-null    float64\n",
      " 48  FTA_per_min                  461 non-null    float64\n",
      " 49  TRB_per_min                  461 non-null    float64\n",
      " 50  AST_per_min                  461 non-null    float64\n",
      " 51  STL_per_min                  461 non-null    float64\n",
      " 52  BLK_per_min                  461 non-null    float64\n",
      " 53  TOV_per_min                  461 non-null    float64\n",
      " 54  PF_per_min                   460 non-null    float64\n",
      " 55  PTS_per_min                  461 non-null    float64\n",
      " 56  TS%_advanced                 463 non-null    float64\n",
      " 57  eFG%_advanced                463 non-null    float64\n",
      " 58  3PAr_advanced                463 non-null    float64\n",
      " 59  FTr_advanced                 463 non-null    float64\n",
      " 60  PProd_advanced               460 non-null    float64\n",
      " 61  ORB%_advanced                460 non-null    float64\n",
      " 62  DRB%_advanced                460 non-null    float64\n",
      " 63  TRB%_advanced                460 non-null    float64\n",
      " 64  AST%_advanced                460 non-null    float64\n",
      " 65  OBPM_advanced                460 non-null    float64\n",
      " 66  DBPM_advanced                460 non-null    float64\n",
      " 67  BPM_advanced                 460 non-null    float64\n",
      " 68  STL%_advanced                460 non-null    float64\n",
      " 69  BLK%_advanced                460 non-null    float64\n",
      " 70  TOV%_advanced                462 non-null    float64\n",
      " 71  USG%_advanced                460 non-null    float64\n",
      " 72  OWS_advanced                 463 non-null    float64\n",
      " 73  DWS_advanced                 463 non-null    float64\n",
      " 74  WS_advanced                  463 non-null    float64\n",
      " 75  WS/40_advanced               461 non-null    float64\n",
      " 76  PER_advanced                 460 non-null    float64\n",
      " 77  FG_per_poss                  460 non-null    float64\n",
      " 78  FGA_per_poss                 460 non-null    float64\n",
      " 79  2P_per_poss                  460 non-null    float64\n",
      " 80  2PA_per_poss                 460 non-null    float64\n",
      " 81  3P_per_poss                  460 non-null    float64\n",
      " 82  3PA_per_poss                 460 non-null    float64\n",
      " 83  FT_per_poss                  460 non-null    float64\n",
      " 84  FTA_per_poss                 460 non-null    float64\n",
      " 85  TRB_per_poss                 460 non-null    float64\n",
      " 86  AST_per_poss                 460 non-null    float64\n",
      " 87  STL_per_poss                 460 non-null    float64\n",
      " 88  BLK_per_poss                 460 non-null    float64\n",
      " 89  TOV_per_poss                 460 non-null    float64\n",
      " 90  PF_per_poss                  460 non-null    float64\n",
      " 91  PTS_per_poss                 460 non-null    float64\n",
      " 92  ORtg_per_poss                460 non-null    float64\n",
      " 93  DRtg_per_poss                460 non-null    float64\n",
      " 94  Experience                   463 non-null    float64\n",
      "dtypes: float64(90), int64(3), object(2)\n",
      "memory usage: 343.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 'Name'과 'Draft_team' 컬럼을 제외하고 나머지 컬럼을 숫자형으로 변환\n",
    "for col in weighted_avg_new.columns:\n",
    "    if col not in ['Name', 'Draft_team']:\n",
    "        weighted_avg_new[col] = pd.to_numeric(weighted_avg_new[col], errors='coerce')\n",
    "\n",
    "# 결과 확인\n",
    "print(weighted_avg_new.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "fc232438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자형 컬럼을 소수점 둘째자리까지 반올림\n",
    "numeric_columns = weighted_avg_new.select_dtypes(include=['float64', 'int']).columns\n",
    "weighted_avg_new[numeric_columns] = weighted_avg_new[numeric_columns].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "90c0223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼별 결측치 비율 확인\n",
    "# missing_counts = weighted_avg_new.isnull().sum()\n",
    "# missing_ratios = (missing_counts / len(weighted_avg_new)) * 100\n",
    "# print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "d9e00972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불필요한 컬럼 삭제처리\n",
    "weighted_avg_new = weighted_avg_new.drop([ 'Body_fat_pct', 'Hand_Length_inch', 'Hand_width_inch', \n",
    "                                          'Height_w_Shoes', 'Height_wo_Shoes', 'SHUTTLE_RUN_sec',\n",
    "                                         'MAX_BENCH_PRESS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "b1fbda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 'Experience' 컬럼의 결측값을 0으로 변경\n",
    "# weighted_avg_new['Experience'] = weighted_avg_new['Experience'].fillna(0)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(weighted_avg_new['Experience'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "2145dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#화면 출력 옵션_reset\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "64491fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the data as a file\n",
    "\n",
    "# weighted_avg_new.to_csv('weighted_avg_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e5c26",
   "metadata": {},
   "source": [
    "<h1>3. 선수 경력(Experience) 예측<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab5df6",
   "metadata": {},
   "source": [
    "<h3>3-1. Machine Learning<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "f1c724b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ccb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "ac10e081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010    36\n",
      "2001    35\n",
      "2012    34\n",
      "2002    31\n",
      "2009    29\n",
      "2007    29\n",
      "2011    28\n",
      "2005    27\n",
      "2004    26\n",
      "2006    26\n",
      "2003    25\n",
      "2008    24\n",
      "2013    24\n",
      "2014    22\n",
      "2000    19\n",
      "2016    18\n",
      "2017    16\n",
      "2015    13\n",
      "2021     1\n",
      "Name: Draft_year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 'Draft_year' 컬럼의 고유값과 그 갯수를 구하는 코드\n",
    "unique_values = data['Draft_year'].value_counts()\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "914a8af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2000\n",
       "1      2000\n",
       "2      2000\n",
       "3      2000\n",
       "4      2000\n",
       "       ... \n",
       "458    2017\n",
       "459    2017\n",
       "460    2017\n",
       "461    2017\n",
       "462    2021\n",
       "Name: Draft_year, Length: 463, dtype: object"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Draft_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "53356306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0     65\n",
      "1.0     59\n",
      "3.0     48\n",
      "4.0     45\n",
      "0.0     38\n",
      "8.0     27\n",
      "5.0     25\n",
      "6.0     25\n",
      "10.0    24\n",
      "11.0    21\n",
      "13.0    19\n",
      "9.0     16\n",
      "7.0     14\n",
      "12.0    13\n",
      "14.0    11\n",
      "15.0     5\n",
      "16.0     3\n",
      "17.0     2\n",
      "20.0     1\n",
      "18.0     1\n",
      "19.0     1\n",
      "Name: Experience, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_values = data['Experience'].value_counts()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "2d4409c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 'Experience'의 unique 값과 개수\n",
    "experience_counts = {\n",
    "    0.0: 33, 1.0: 52, 2.0: 58, 3.0: 44, 4.0: 39,\n",
    "    5.0: 20, 6.0: 25, 7.0: 13, 8.0: 24, 9.0: 16,\n",
    "    10.0: 22, 11.0: 19, 12.0: 12, 13.0: 18, 14.0: 11,\n",
    "    15.0: 5, 16.0: 3, 17.0: 2, 18.0: 1, 19.0: 1\n",
    "}\n",
    "\n",
    "# 데이터 준비\n",
    "experience = list(experience_counts.keys())\n",
    "counts = list(experience_counts.values())\n",
    "\n",
    "# 막대 그래프 생성\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(experience, counts, color='skyblue')\n",
    "plt.xlabel('Experience (years)')\n",
    "plt.ylabel('Number of Players')\n",
    "plt.title('Distribution of Players by Experience')\n",
    "plt.xticks(ticks=experience, labels=[str(int(exp)) for exp in experience])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ff67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "ab259655",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "\n",
    "\n",
    "feature_columns_1 = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "feature_columns_2 = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "2f61d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Name'과 'Draft_team' 컬럼을 제외하고 나머지 컬럼을 숫자형으로 변환\n",
    "for col in data.columns:\n",
    "    if col not in ['Name', 'Draft_team']:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d932442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "43d24395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "\n",
    "# # 정의된 피처 컬럼들\n",
    "# feature_columns_1 = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"\n",
    "# ]\n",
    "\n",
    "# feature_columns_2 = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\", \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"\n",
    "# ]\n",
    "\n",
    "# # 함수: VIF 계산\n",
    "# def calculate_vif(data, features):\n",
    "#     vif_data = pd.DataFrame()\n",
    "#     vif_data[\"feature\"] = features\n",
    "#     vif_data[\"VIF\"] = [variance_inflation_factor(data[features].values, i) for i in range(len(features))]\n",
    "#     return vif_data\n",
    "\n",
    "# # 함수: 상관관계 히트맵\n",
    "# def plot_correlation(data, features):\n",
    "#     plt.figure(figsize=(12, 10))\n",
    "#     sns.heatmap(data[features].corr(), annot=True, fmt=\".2f\")\n",
    "#     plt.title(\"Feature Correlation\")\n",
    "#     plt.show()\n",
    "\n",
    "# # 데이터 'data'에 대한 다중공선성 및 상관관계\n",
    "# print(\"Data 'data' - Feature Set 1 VIF:\")\n",
    "# print(calculate_vif(data, feature_columns_1))\n",
    "# plot_correlation(data, feature_columns_1)\n",
    "\n",
    "# print(\"\\nData 'data' - Feature Set 2 VIF:\")\n",
    "# print(calculate_vif(data, feature_columns_2))\n",
    "# plot_correlation(data, feature_columns_2)\n",
    "\n",
    "# # 데이터 'data_avg'에 대한 다중공선성 및 상관관계\n",
    "# print(\"\\nData 'data_avg' - Feature Set 1 VIF:\")\n",
    "# print(calculate_vif(data_avg, feature_columns_1))\n",
    "# plot_correlation(data_avg, feature_columns_1)\n",
    "\n",
    "# print(\"\\nData 'data_avg' - Feature Set 2 VIF:\")\n",
    "# print(calculate_vif(data_avg, feature_columns_2))\n",
    "# plot_correlation(data_avg, feature_columns_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "d11137e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "\n",
    "\n",
    "\n",
    "# # 정의된 피처 컬럼들\n",
    "# feature_columns_1 = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "# ]\n",
    "\n",
    "# feature_columns_2 = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\", \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"\n",
    "# ]\n",
    "\n",
    "# # MissingDataError 방지를 위해 NaN 및 무한값 처리\n",
    "# data = data.replace([np.inf, -np.inf], np.nan)\n",
    "# data_avg = data_avg.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# # 필요한 피처 컬럼들만 선택\n",
    "# data = data[feature_columns_2].dropna()\n",
    "# data_avg = data_avg[feature_columns_2].dropna()\n",
    "\n",
    "# # 데이터셋의 첫 번째 열(Pos)은 범주형 데이터이므로 제거\n",
    "# data = data.iloc[:, 1:]\n",
    "# data_avg = data_avg.iloc[:, 1:]\n",
    "\n",
    "# # VIF 계산 함수 정의\n",
    "# def calculate_vif(data):\n",
    "#     vif_data = pd.DataFrame()\n",
    "#     vif_data[\"feature\"] = data.columns\n",
    "#     vif_data[\"VIF\"] = [variance_inflation_factor(data.values, i) for i in range(len(data.columns))]\n",
    "#     return vif_data.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "# # 데이터 'data'에 대한 다중공선성 및 상관관계\n",
    "# print(\"Data 'data' - Feature Set 1 VIF:\")\n",
    "# print(calculate_vif(data, feature_columns_1))\n",
    "# plot_correlation(data, feature_columns_1)\n",
    "\n",
    "# print(\"\\nData 'data' - Feature Set 2 VIF:\")\n",
    "# print(calculate_vif(data, feature_columns_2))\n",
    "# plot_correlation(data, feature_columns_2)\n",
    "\n",
    "# # 데이터 'data_avg'에 대한 다중공선성 및 상관관계\n",
    "# print(\"\\nData 'data_avg' - Feature Set 1 VIF:\")\n",
    "# print(calculate_vif(data_avg, feature_columns_1))\n",
    "# plot_correlation(data_avg, feature_columns_1)\n",
    "\n",
    "# print(\"\\nData 'data_avg' - Feature Set 2 VIF:\")\n",
    "# print(calculate_vif(data_avg, feature_columns_2))\n",
    "# plot_correlation(data_avg, feature_columns_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "6d45819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 범주형 데이터 확인\n",
    "# print(data.select_dtypes(include=['object']).columns)\n",
    "\n",
    "# # 결측값 확인\n",
    "# print(data.isna().sum())\n",
    "\n",
    "# # 필요한 경우 범주형 데이터 처리 및 결측값 대체\n",
    "# # 예: data['Pos'] = pd.get_dummies(data['Pos'])\n",
    "# # 예: data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# # 데이터 타입 확인\n",
    "# print(data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "de38e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #화면 출력 옵션_전체 출력\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# #화면 출력 옵션_reset\n",
    "# # pd.reset_option('display.max_rows')\n",
    "# # pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "32ca922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # 데이터셋을 복사하여 피처 간 상관관계 분석\n",
    "# data_corr = data.copy()\n",
    "\n",
    "# # 상관관계 계산\n",
    "# corr = data_corr[feature_columns].corr()\n",
    "\n",
    "# # 상관관계 시각화\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "# plt.title('Feature Correlation')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123a49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fd5c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "391c5b66",
   "metadata": {},
   "source": [
    "<h3> 3.1.1. Random Forest<h3> <br/><br/><h4> - 데이터정규화 <br/><br/> - cross validation<h4>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7002aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d89f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "b8b6876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "MAE: 2.8801180987294677, RMSE: 3.4955938171247896\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   6.690575  2.880118  3.495594\n",
      "447     3.0   7.186291  2.880118  3.495594\n",
      "448     5.0   4.791333  2.880118  3.495594\n",
      "449     4.0   5.096242  2.880118  3.495594\n",
      "450     3.0   3.268909  2.880118  3.495594\n",
      "451     2.0   3.064989  2.880118  3.495594\n",
      "452     2.0   5.901502  2.880118  3.495594\n",
      "453     1.0   3.824734  2.880118  3.495594\n",
      "454     2.0   5.533584  2.880118  3.495594\n",
      "455     4.0   8.477713  2.880118  3.495594\n",
      "\n",
      "Overall MAE: 2.8801180987294677, Overall RMSE: 3.4955938171247896\n",
      "\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#연도별\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "\n",
    "# 'Name'과 'Draft_team' 컬럼을 제외하고 나머지 컬럼을 숫자형으로 변환\n",
    "for col in data.columns:\n",
    "    if col not in ['Name', 'Draft_team']:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "#data\n",
    "#기본stat사용\n",
    "#특정시즌 test\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의 및 그리드 서치\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 찾기 및 테스트 데이터에 대한 예측\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "# 테스트 데이터에 대한 예측\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "print(f\"MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "3cf2a68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "     Actual  Predicted      MAE      RMSE\n",
      "446     1.0   5.768667  2.78937  3.323109\n",
      "447     3.0   7.635278  2.78937  3.323109\n",
      "448     5.0   5.773333  2.78937  3.323109\n",
      "449     4.0   6.806667  2.78937  3.323109\n",
      "450     3.0   3.583333  2.78937  3.323109\n",
      "451     2.0   3.563333  2.78937  3.323109\n",
      "452     2.0   4.841146  2.78937  3.323109\n",
      "453     1.0   4.408095  2.78937  3.323109\n",
      "454     2.0   5.979697  2.78937  3.323109\n",
      "455     4.0   7.330000  2.78937  3.323109\n",
      "\n",
      "Overall MAE: 2.7893695710569366, Overall RMSE: 3.3231086674268813\n",
      "\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 20, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "#연도별\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "#data\n",
    "#data 비율 split\n",
    "#정규화 제외\n",
    "#PCA제외\n",
    "#기본 stat사용\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Feature 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 찾기\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# epsilon = 1e-10  # 작은 상수 epsilon 추가\n",
    "# mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "f810a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "     Actual  Predicted      MAE      RMSE\n",
      "448     5.0   5.279223  2.75201  3.280877\n",
      "449     4.0   5.305931  2.75201  3.280877\n",
      "450     3.0   4.039890  2.75201  3.280877\n",
      "451     2.0   3.238767  2.75201  3.280877\n",
      "452     2.0   5.479868  2.75201  3.280877\n",
      "453     1.0   3.882596  2.75201  3.280877\n",
      "454     2.0   4.875231  2.75201  3.280877\n",
      "455     4.0   9.328147  2.75201  3.280877\n",
      "456     3.0   6.008778  2.75201  3.280877\n",
      "457     1.0   6.450006  2.75201  3.280877\n",
      "\n",
      "Overall MAE: 2.752009940609174, Overall RMSE: 3.280876963234854\n",
      "\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "#data\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의 및 그리드 서치\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 찾기 및 테스트 데이터에 대한 예측\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "# 테스트 데이터에 대한 예측\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "cb60e81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "     Actual  Predicted      MAE      RMSE\n",
      "448     5.0   5.553752  2.46643  2.939376\n",
      "449     4.0   6.538955  2.46643  2.939376\n",
      "450     3.0   3.919806  2.46643  2.939376\n",
      "451     2.0   3.135650  2.46643  2.939376\n",
      "452     2.0   4.624224  2.46643  2.939376\n",
      "453     1.0   4.996004  2.46643  2.939376\n",
      "454     2.0   5.494663  2.46643  2.939376\n",
      "455     4.0   8.067131  2.46643  2.939376\n",
      "456     3.0   3.616944  2.46643  2.939376\n",
      "457     1.0   6.480056  2.46643  2.939376\n",
      "\n",
      "Overall MAE: 2.4664297670637727, Overall RMSE: 2.9393761418152633\n",
      "\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "\n",
    "\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의 및 그리드 서치\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 찾기 및 테스트 데이터에 대한 예측\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "4900624e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010    36\n",
       "2001    35\n",
       "2012    34\n",
       "2002    31\n",
       "2009    29\n",
       "2007    29\n",
       "2011    28\n",
       "2005    27\n",
       "2004    26\n",
       "2006    26\n",
       "2003    25\n",
       "2008    24\n",
       "2013    24\n",
       "2014    22\n",
       "2000    19\n",
       "2016    18\n",
       "2017    16\n",
       "2015    13\n",
       "2021     1\n",
       "Name: Draft_year, dtype: int64"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_counts = data['Draft_year'].value_counts()\n",
    "unique_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "15c8d536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for Draft Year: 2000\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2001\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2002\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2003\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2004\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2005\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2006\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2007\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2008\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2009\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2010\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2011\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2012\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2013\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2014\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2015\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2016\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2017\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2021\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    }
   ],
   "source": [
    "#4-1 \n",
    "#전체 Draft_year에 대해서 성능test\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "\n",
    "# 'Name'과 'Draft_team' 컬럼을 제외하고 나머지 컬럼을 숫자형으로 변환\n",
    "for col in data.columns:\n",
    "    if col not in ['Name', 'Draft_team']:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "        \n",
    "# 'Name'과 'Draft_team' 컬럼을 제외하고 나머지 컬럼을 숫자형으로 변환\n",
    "for col in data_avg.columns:\n",
    "    if col not in ['Name', 'Draft_team']:\n",
    "        data_avg[col] = pd.to_numeric(data_avg[col], errors='coerce')\n",
    "\n",
    "# 각 'Draft_year'별로 테스트 데이터를 설정하고 모델을 학습 및 평가하는 함수를 정의합니다.\n",
    "\n",
    "# Feature 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "\n",
    "def evaluate_model_per_draft_year(data, feature_columns, target_column, param_grid):\n",
    "    results = []\n",
    "\n",
    "    for year in sorted(data['Draft_year'].unique()):\n",
    "#         if year == 2021:  # 2021년 데이터는 제외\n",
    "#             continue\n",
    "\n",
    "        print(f\"Evaluating for Draft Year: {year}\")\n",
    "        train_data = data[data['Draft_year'] != year]\n",
    "        test_data = data[data['Draft_year'] == year]\n",
    "\n",
    "#         # 훈련 데이터 또는 테스트 데이터가 너무 적은 경우 건너뛰기\n",
    "#         if len(train_data) < 5 or len(test_data) < 5:\n",
    "#             print(f\"Skipping Draft Year {year} due to insufficient data.\")\n",
    "#             continue\n",
    "\n",
    "        X_train = train_data[feature_columns]\n",
    "        y_train = train_data[target_column]\n",
    "        X_test = test_data[feature_columns]\n",
    "        y_test = test_data[target_column]\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                                   param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred_raw = best_model.predict(X_test)\n",
    "        y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        results.append({\n",
    "            'Draft_year': year,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'Best_Params': grid_search.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의 (이전에 정의된 param_grid를 사용)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "\n",
    "yearly_results = evaluate_model_per_draft_year(data_avg, feature_columns, 'Experience', param_grid)\n",
    "\n",
    "# 함수 실행\n",
    "# 결과는 실제 데이터셋 'data_avg'와 'feature_columns' 리스트가 필요합니다.\n",
    "# yearly_results = evaluate_model_per_draft_year(data_avg, feature_columns, 'Experience', param_grid)\n",
    "\n",
    "# 주의: 위의 'yearly_results' 실행은 실제 데이터셋 'data_avg'와 'feature_columns' 리스트가 필요합니다.\n",
    "# 실제 환경에서 이 코드를 실행하려면 적절한 데이터셋과 피처 컬럼 리스트를 제공해야 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "937e602b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Draft_year</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Best_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>3.986428</td>\n",
       "      <td>4.430268</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 4, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>4.536318</td>\n",
       "      <td>5.567686</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>4.098311</td>\n",
       "      <td>4.895104</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 2, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>6.199167</td>\n",
       "      <td>6.796084</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 4, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>4.201310</td>\n",
       "      <td>4.758417</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 2, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005</td>\n",
       "      <td>4.111679</td>\n",
       "      <td>4.800989</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 4, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006</td>\n",
       "      <td>3.086389</td>\n",
       "      <td>4.014037</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 4, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007</td>\n",
       "      <td>3.681475</td>\n",
       "      <td>4.198206</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_leaf': 2, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008</td>\n",
       "      <td>3.801629</td>\n",
       "      <td>4.401904</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 2, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009</td>\n",
       "      <td>2.705025</td>\n",
       "      <td>3.249697</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 4, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010</td>\n",
       "      <td>3.368658</td>\n",
       "      <td>3.962772</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 2, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011</td>\n",
       "      <td>3.073302</td>\n",
       "      <td>3.562040</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 1, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>2.810230</td>\n",
       "      <td>3.180807</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 2, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013</td>\n",
       "      <td>2.632939</td>\n",
       "      <td>3.166864</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 2, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014</td>\n",
       "      <td>2.806838</td>\n",
       "      <td>3.158718</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 2, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015</td>\n",
       "      <td>1.850886</td>\n",
       "      <td>2.256714</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 2, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016</td>\n",
       "      <td>3.223477</td>\n",
       "      <td>3.509901</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 4, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>2.466430</td>\n",
       "      <td>2.939376</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 2, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021</td>\n",
       "      <td>2.069482</td>\n",
       "      <td>2.069482</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 4, 'min_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Draft_year       MAE      RMSE  \\\n",
       "0         2000  3.986428  4.430268   \n",
       "1         2001  4.536318  5.567686   \n",
       "2         2002  4.098311  4.895104   \n",
       "3         2003  6.199167  6.796084   \n",
       "4         2004  4.201310  4.758417   \n",
       "5         2005  4.111679  4.800989   \n",
       "6         2006  3.086389  4.014037   \n",
       "7         2007  3.681475  4.198206   \n",
       "8         2008  3.801629  4.401904   \n",
       "9         2009  2.705025  3.249697   \n",
       "10        2010  3.368658  3.962772   \n",
       "11        2011  3.073302  3.562040   \n",
       "12        2012  2.810230  3.180807   \n",
       "13        2013  2.632939  3.166864   \n",
       "14        2014  2.806838  3.158718   \n",
       "15        2015  1.850886  2.256714   \n",
       "16        2016  3.223477  3.509901   \n",
       "17        2017  2.466430  2.939376   \n",
       "18        2021  2.069482  2.069482   \n",
       "\n",
       "                                          Best_Params  \n",
       "0   {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
       "1   {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
       "2   {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
       "3   {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
       "4   {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
       "5   {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
       "6   {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
       "7   {'max_depth': 20, 'min_samples_leaf': 2, 'min_...  \n",
       "8   {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
       "9   {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
       "10  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
       "11  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...  \n",
       "12  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
       "13  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
       "14  {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
       "15  {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
       "16  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
       "17  {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
       "18  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  "
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table = pd.DataFrame(yearly_results)\n",
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "4fc9c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#화면 출력 옵션_전체 출력\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#화면 출력 옵션_reset\n",
    "# pd.reset_option('display.max_rows')\n",
    "# pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "eebdc909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft_year                       int64\n",
      "Name                            object\n",
      "Pos                              int64\n",
      "Height_cm                      float64\n",
      "Weight_kg                      float64\n",
      "Draft_team                      object\n",
      "Draft_overall                    int64\n",
      "Body_fat_pct                   float64\n",
      "Hand_Length_inch               float64\n",
      "Hand_width_inch                float64\n",
      "Height_wo_Shoes                float64\n",
      "Height_w_Shoes                 float64\n",
      "Standing_Reach_inch            float64\n",
      "Wingspan_inch                  float64\n",
      "LANE_AGILITY_sec               float64\n",
      "SHUTTLE_RUN_sec                float64\n",
      "THREE_QUATER_SPRINT            float64\n",
      "STANDING_VERTICAL_LEAP_inch    float64\n",
      "MAX_VERTICAL_LEAP_inch         float64\n",
      "MAX_BENCH_PRESS                float64\n",
      "G_totals                       float64\n",
      "MP_totals                      float64\n",
      "FG_totals                      float64\n",
      "FGA_totals                     float64\n",
      "FG%_totals                     float64\n",
      "2P_totals                      float64\n",
      "2PA_totals                     float64\n",
      "2P%_totals                     float64\n",
      "3P_totals                      float64\n",
      "3PA_totals                     float64\n",
      "3P%_totals                     float64\n",
      "FT_totals                      float64\n",
      "FTA_totals                     float64\n",
      "FT%_totals                     float64\n",
      "TRB_totals                     float64\n",
      "AST_totals                     float64\n",
      "STL_totals                     float64\n",
      "BLK_totals                     float64\n",
      "TOV_totals                     float64\n",
      "PF_totals                      float64\n",
      "PTS_totals                     float64\n",
      "FG_per_min                     float64\n",
      "FGA_per_min                    float64\n",
      "2P_per_min                     float64\n",
      "2PA_per_min                    float64\n",
      "3P_per_min                     float64\n",
      "3PA_per_min                    float64\n",
      "FT_per_min                     float64\n",
      "FTA_per_min                    float64\n",
      "TRB_per_min                    float64\n",
      "AST_per_min                    float64\n",
      "STL_per_min                    float64\n",
      "BLK_per_min                    float64\n",
      "TOV_per_min                    float64\n",
      "PF_per_min                     float64\n",
      "PTS_per_min                    float64\n",
      "TS%_advanced                   float64\n",
      "eFG%_advanced                  float64\n",
      "3PAr_advanced                  float64\n",
      "FTr_advanced                   float64\n",
      "PProd_advanced                 float64\n",
      "ORB%_advanced                  float64\n",
      "DRB%_advanced                  float64\n",
      "TRB%_advanced                  float64\n",
      "AST%_advanced                  float64\n",
      "OBPM_advanced                  float64\n",
      "DBPM_advanced                  float64\n",
      "BPM_advanced                   float64\n",
      "STL%_advanced                  float64\n",
      "BLK%_advanced                  float64\n",
      "TOV%_advanced                  float64\n",
      "USG%_advanced                  float64\n",
      "OWS_advanced                   float64\n",
      "DWS_advanced                   float64\n",
      "WS_advanced                    float64\n",
      "WS/40_advanced                 float64\n",
      "PER_advanced                   float64\n",
      "FG_per_poss                    float64\n",
      "FGA_per_poss                   float64\n",
      "2P_per_poss                    float64\n",
      "2PA_per_poss                   float64\n",
      "3P_per_poss                    float64\n",
      "3PA_per_poss                   float64\n",
      "FT_per_poss                    float64\n",
      "FTA_per_poss                   float64\n",
      "TRB_per_poss                   float64\n",
      "AST_per_poss                   float64\n",
      "STL_per_poss                   float64\n",
      "BLK_per_poss                   float64\n",
      "TOV_per_poss                   float64\n",
      "PF_per_poss                    float64\n",
      "PTS_per_poss                   float64\n",
      "ORtg_per_poss                  float64\n",
      "DRtg_per_poss                  float64\n",
      "Experience                     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#컬럼별 데이터 타입 확인\n",
    "data_types = data.dtypes\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "edf82206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for Draft Year: 2000, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2000, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2000, Position: 5\n",
      "Skipping Draft Year 2000, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2001, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2001, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2001, Position: 5\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2002, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2002, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2002, Position: 5\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2003, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2003, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2003, Position: 5\n",
      "Skipping Draft Year 2003, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2004, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2004, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2004, Position: 5\n",
      "Skipping Draft Year 2004, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2005, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2005, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2005, Position: 5\n",
      "Skipping Draft Year 2005, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2006, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2006, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2006, Position: 5\n",
      "Skipping Draft Year 2006, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2007, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2007, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2007, Position: 5\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2008, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2008, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2008, Position: 5\n",
      "Skipping Draft Year 2008, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2009, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2009, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2009, Position: 5\n",
      "Skipping Draft Year 2009, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2010, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2010, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2010, Position: 5\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2011, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2011, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2011, Position: 5\n",
      "Skipping Draft Year 2011, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2012, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2012, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2012, Position: 5\n",
      "Skipping Draft Year 2012, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2013, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2013, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2013, Position: 5\n",
      "Skipping Draft Year 2013, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2014, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2014, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2014, Position: 5\n",
      "Skipping Draft Year 2014, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2015, Position: 1\n",
      "Skipping Draft Year 2015, Position 1 due to insufficient data.\n",
      "Evaluating for Draft Year: 2015, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2015, Position: 5\n",
      "Skipping Draft Year 2015, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2016, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2016, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2016, Position: 5\n",
      "Skipping Draft Year 2016, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2017, Position: 1\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2017, Position: 3\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Evaluating for Draft Year: 2017, Position: 5\n",
      "Skipping Draft Year 2017, Position 5 due to insufficient data.\n",
      "Evaluating for Draft Year: 2021, Position: 1\n",
      "Skipping Draft Year 2021, Position 1 due to insufficient data.\n",
      "Evaluating for Draft Year: 2021, Position: 3\n",
      "Skipping Draft Year 2021, Position 3 due to insufficient data.\n",
      "Evaluating for Draft Year: 2021, Position: 5\n",
      "Skipping Draft Year 2021, Position 5 due to insufficient data.\n"
     ]
    }
   ],
   "source": [
    "#4-2\n",
    "#POS별 Draft year별\n",
    "\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "target_column = 'Experience'\n",
    "\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "# 'Draft_year'와 'Pos'를 기준으로 모델을 학습 및 평가하는 함수를 정의합니다.\n",
    "\n",
    "def evaluate_model_per_draft_year_and_position(data, feature_columns, target_column, param_grid):\n",
    "    results = []\n",
    "\n",
    "    for year in sorted(data['Draft_year'].unique()):\n",
    "        for position in data['Pos'].unique():\n",
    "            print(f\"Evaluating for Draft Year: {year}, Position: {position}\")\n",
    "            train_data = data[(data['Draft_year'] != year) & (data['Pos'] != position)]\n",
    "            test_data = data[(data['Draft_year'] == year) & (data['Pos'] == position)]\n",
    "\n",
    "            # 훈련 데이터 또는 테스트 데이터가 너무 적은 경우 건너뛰기\n",
    "            if len(train_data) < 5 or len(test_data) < 5:\n",
    "                print(f\"Skipping Draft Year {year}, Position {position} due to insufficient data.\")\n",
    "                continue\n",
    "\n",
    "            X_train = train_data[feature_columns]\n",
    "            y_train = train_data[target_column]\n",
    "            X_test = test_data[feature_columns]\n",
    "            y_test = test_data[target_column]\n",
    "\n",
    "            grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                                       param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_pred_raw = best_model.predict(X_test)\n",
    "            y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "            results.append({\n",
    "                'Draft_year': year,\n",
    "                'Position': position,\n",
    "                'MAE': mae,\n",
    "                'RMSE': rmse,\n",
    "                'Best_Params': grid_search.best_params_\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 함수 실행\n",
    "# 결과는 실제 데이터셋 'data_avg'와 'feature_columns' 리스트가 필요합니다.\n",
    "# draft_year_pos_results = evaluate_model_per_draft_year_and_position(data_avg, feature_columns, 'Experience', param_grid)\n",
    "\n",
    "# 주의: 위의 'draft_year_pos_results' 실행은 실제 데이터셋 'data_avg'와 'feature_columns' 리스트가 필요합니다.\n",
    "# 실제 환경에서 이 코드를 실행하려면 적절한 데이터셋과 피처 컬럼 리스트를 제공해야 합니다.\n",
    "yearly_pos_results = evaluate_model_per_draft_year_and_position(data_avg, feature_columns, 'Experience', param_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "3ddcd71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by Position:\n",
      "    Draft_year  Position       MAE      RMSE  \\\n",
      "0         2000         1  4.888303  5.464769   \n",
      "2         2001         1  4.978192  5.557705   \n",
      "5         2002         1  4.797788  5.057211   \n",
      "8         2003         1  5.077193  5.448760   \n",
      "10        2004         1  4.726274  5.173223   \n",
      "12        2005         1  4.673661  4.963986   \n",
      "14        2006         1  3.138679  3.515335   \n",
      "16        2007         1  3.592284  4.319423   \n",
      "19        2008         1  4.402719  4.695219   \n",
      "21        2009         1  3.141066  3.993032   \n",
      "23        2010         1  4.967418  5.589347   \n",
      "26        2011         1  3.681223  4.521380   \n",
      "28        2012         1  4.446775  4.849013   \n",
      "30        2013         1  2.911007  3.397338   \n",
      "32        2014         1  4.604191  5.112079   \n",
      "35        2016         1  5.489839  5.780279   \n",
      "37        2017         1  4.708165  5.367464   \n",
      "1         2000         3  3.591905  4.374690   \n",
      "3         2001         3  5.780383  7.157117   \n",
      "6         2002         3  4.895819  5.753031   \n",
      "9         2003         3  7.032872  7.717935   \n",
      "11        2004         3  4.356956  4.914125   \n",
      "13        2005         3  4.201110  4.524967   \n",
      "15        2006         3  3.482240  4.707515   \n",
      "17        2007         3  3.731061  4.098651   \n",
      "20        2008         3  3.850551  4.370148   \n",
      "22        2009         3  1.565933  1.947964   \n",
      "24        2010         3  3.479412  4.053990   \n",
      "27        2011         3  3.356459  3.913143   \n",
      "29        2012         3  2.276944  2.613805   \n",
      "31        2013         3  3.215100  3.482287   \n",
      "33        2014         3  3.851511  3.974744   \n",
      "34        2015         3  3.185209  3.575249   \n",
      "36        2016         3  3.688006  3.990153   \n",
      "38        2017         3  2.675178  3.425700   \n",
      "4         2001         5  3.434958  4.073324   \n",
      "7         2002         5  4.006989  4.519109   \n",
      "18        2007         5  2.991784  3.323504   \n",
      "25        2010         5  2.722420  2.908854   \n",
      "\n",
      "                                          Best_Params  \n",
      "0   {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "2   {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "5   {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "8   {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
      "10  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "12  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "14  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "16  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "19  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "21  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "23  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "26  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...  \n",
      "28  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...  \n",
      "30  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "32  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "35  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "37  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "1   {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
      "3   {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "6   {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
      "9   {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
      "11  {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
      "13  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...  \n",
      "15  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "17  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "20  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "22  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "24  {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
      "27  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "29  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "31  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "33  {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
      "34  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...  \n",
      "36  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "38  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "4   {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "7   {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "18  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "25  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "\n",
      "Sorted by Draft Year:\n",
      "    Draft_year  Position       MAE      RMSE  \\\n",
      "0         2000         1  4.888303  5.464769   \n",
      "1         2000         3  3.591905  4.374690   \n",
      "2         2001         1  4.978192  5.557705   \n",
      "3         2001         3  5.780383  7.157117   \n",
      "4         2001         5  3.434958  4.073324   \n",
      "5         2002         1  4.797788  5.057211   \n",
      "6         2002         3  4.895819  5.753031   \n",
      "7         2002         5  4.006989  4.519109   \n",
      "8         2003         1  5.077193  5.448760   \n",
      "9         2003         3  7.032872  7.717935   \n",
      "10        2004         1  4.726274  5.173223   \n",
      "11        2004         3  4.356956  4.914125   \n",
      "12        2005         1  4.673661  4.963986   \n",
      "13        2005         3  4.201110  4.524967   \n",
      "14        2006         1  3.138679  3.515335   \n",
      "15        2006         3  3.482240  4.707515   \n",
      "16        2007         1  3.592284  4.319423   \n",
      "17        2007         3  3.731061  4.098651   \n",
      "18        2007         5  2.991784  3.323504   \n",
      "19        2008         1  4.402719  4.695219   \n",
      "20        2008         3  3.850551  4.370148   \n",
      "21        2009         1  3.141066  3.993032   \n",
      "22        2009         3  1.565933  1.947964   \n",
      "23        2010         1  4.967418  5.589347   \n",
      "24        2010         3  3.479412  4.053990   \n",
      "25        2010         5  2.722420  2.908854   \n",
      "26        2011         1  3.681223  4.521380   \n",
      "27        2011         3  3.356459  3.913143   \n",
      "28        2012         1  4.446775  4.849013   \n",
      "29        2012         3  2.276944  2.613805   \n",
      "30        2013         1  2.911007  3.397338   \n",
      "31        2013         3  3.215100  3.482287   \n",
      "32        2014         1  4.604191  5.112079   \n",
      "33        2014         3  3.851511  3.974744   \n",
      "34        2015         3  3.185209  3.575249   \n",
      "35        2016         1  5.489839  5.780279   \n",
      "36        2016         3  3.688006  3.990153   \n",
      "37        2017         1  4.708165  5.367464   \n",
      "38        2017         3  2.675178  3.425700   \n",
      "\n",
      "                                          Best_Params  \n",
      "0   {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "1   {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
      "2   {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "3   {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "4   {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "5   {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "6   {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
      "7   {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "8   {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
      "9   {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
      "10  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "11  {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
      "12  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "13  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...  \n",
      "14  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "15  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "16  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "17  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "18  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "19  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "20  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "21  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "22  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "23  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "24  {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
      "25  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "26  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...  \n",
      "27  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "28  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...  \n",
      "29  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "30  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "31  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "32  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
      "33  {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
      "34  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...  \n",
      "35  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "36  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n",
      "37  {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
      "38  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...  \n"
     ]
    }
   ],
   "source": [
    "result_table_year_pos = pd.DataFrame(yearly_pos_results)\n",
    "result_table_year_pos\n",
    "# 'Position'별로 정렬\n",
    "sorted_by_position = result_table_year_pos.sort_values(by=['Position', 'Draft_year'])\n",
    "print(\"Sorted by Position:\")\n",
    "print(sorted_by_position)\n",
    "\n",
    "# 'Draft_year'별로 정렬\n",
    "sorted_by_draft_year = result_table_year_pos.sort_values(by=['Draft_year', 'Position'])\n",
    "print(\"\\nSorted by Draft Year:\")\n",
    "print(sorted_by_draft_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf90659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "d1837696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "225     2.0   4.859581  3.719685  4.484989\n",
      "30     11.0   5.629251  3.719685  4.484989\n",
      "39      2.0   6.886758  3.719685  4.484989\n",
      "222     0.0   3.511169  3.719685  4.484989\n",
      "124     1.0   5.243808  3.719685  4.484989\n",
      "203     0.0   5.719042  3.719685  4.484989\n",
      "310     2.0   7.356826  3.719685  4.484989\n",
      "211    11.0   4.447465  3.719685  4.484989\n",
      "457     1.0   5.941614  3.719685  4.484989\n",
      "77     13.0   4.560470  3.719685  4.484989\n",
      "\n",
      "Overall MAE: 3.7196853266825296, Overall RMSE: 4.484989456311125\n",
      "\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "#split\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "#data\n",
    "#data 비율 split\n",
    "#정규화 제외\n",
    "#PCA제외\n",
    "#기본 stat사용\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Feature 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 찾기\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# epsilon = 1e-10  # 작은 상수 epsilon 추가\n",
    "# mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975fd9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "fc1f958f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "126    15.0   7.647635  3.505418  4.238074\n",
      "30     11.0   7.228840  3.505418  4.238074\n",
      "202    14.0   5.184803  3.505418  4.238074\n",
      "442     1.0   3.945223  3.505418  4.238074\n",
      "157    14.0   5.772581  3.505418  4.238074\n",
      "228     2.0   4.101564  3.505418  4.238074\n",
      "409     2.0   2.905023  3.505418  4.238074\n",
      "299     8.0   6.946510  3.505418  4.238074\n",
      "225     2.0   4.231557  3.505418  4.238074\n",
      "76      1.0   5.216778  3.505418  4.238074\n",
      "\n",
      "Overall MAE: 3.505418240722974, Overall RMSE: 4.238073559117305\n",
      "\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "#split\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "#data\n",
    "#data 비율 split\n",
    "#정규화 제외\n",
    "#PCA제외\n",
    "#기본 stat사용\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Feature 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 찾기\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# epsilon = 1e-10  # 작은 상수 epsilon 추가\n",
    "# mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "70fa288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "     Actual  Predicted      MAE      RMSE\n",
      "350     1.0   4.467937  3.39839  4.323303\n",
      "354     3.0   6.716595  3.39839  4.323303\n",
      "428     1.0   4.278524  3.39839  4.323303\n",
      "60      4.0   8.322953  3.39839  4.323303\n",
      "169     0.0   3.040410  3.39839  4.323303\n",
      "33     13.0   3.692595  3.39839  4.323303\n",
      "76      1.0   3.192291  3.39839  4.323303\n",
      "88     13.0   6.496448  3.39839  4.323303\n",
      "278     3.0   2.693441  3.39839  4.323303\n",
      "461     2.0   6.065965  3.39839  4.323303\n",
      "\n",
      "Overall MAE: 3.3983902937912767, Overall RMSE: 4.32330332140628\n",
      "\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "#split\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "#data\n",
    "#결측치 추정 단계에서 R스퀘어값 낮은 피처 제외 후 모델링.\n",
    "#data 비율 split\n",
    "#정규화 제외\n",
    "#PCA제외\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Feature 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 찾기\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# epsilon = 1e-10  # 작은 상수 epsilon 추가\n",
    "# mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "752beb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "170     6.0   2.011546  3.967639  4.903975\n",
      "322     1.0   4.581543  3.967639  4.903975\n",
      "457     1.0   6.328131  3.967639  4.903975\n",
      "104    14.0  10.573595  3.967639  4.903975\n",
      "75     15.0   6.755562  3.967639  4.903975\n",
      "441     1.0   4.533201  3.967639  4.903975\n",
      "408     1.0   4.990076  3.967639  4.903975\n",
      "239     0.0   5.049932  3.967639  4.903975\n",
      "42      5.0   6.816328  3.967639  4.903975\n",
      "60      4.0   7.169798  3.967639  4.903975\n",
      "\n",
      "Overall MAE: 3.9676387619827502, Overall RMSE: 4.903975432136278\n",
      "\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "#split\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data_avg\n",
    "#data split\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의 및 그리드 서치\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 찾기 및 테스트 데이터에 대한 예측\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d1abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9872f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5aff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d91bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3bdbfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "609e1c21",
   "metadata": {},
   "source": [
    "<h3> 3.1.2. Gradient Boost<h3> <br/><br/><h4>- PCA <br/><br/>- 데이터정규화 <br/><br/> - cross validation<h4>    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "a0416197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   6.767761  3.131658  3.549776\n",
      "447     3.0   6.299173  3.131658  3.549776\n",
      "448     5.0   4.150061  3.131658  3.549776\n",
      "449     4.0   4.808570  3.131658  3.549776\n",
      "450     3.0   3.439428  3.131658  3.549776\n",
      "451     2.0   3.545795  3.131658  3.549776\n",
      "452     2.0   5.686055  3.131658  3.549776\n",
      "453     1.0   4.716389  3.131658  3.549776\n",
      "454     2.0   5.199558  3.131658  3.549776\n",
      "455     4.0   8.685596  3.131658  3.549776\n",
      "\n",
      "Overall MAE: 3.1316583703665652, Overall RMSE: 3.5497762294671666\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#연도별\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "#data split\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 데이터셋의 차원 확인\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "e5b349c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   5.056314  2.712864  3.067227\n",
      "447     3.0   5.945631  2.712864  3.067227\n",
      "448     5.0   4.916207  2.712864  3.067227\n",
      "449     4.0   7.080534  2.712864  3.067227\n",
      "450     3.0   3.568061  2.712864  3.067227\n",
      "451     2.0   3.534549  2.712864  3.067227\n",
      "452     2.0   5.517064  2.712864  3.067227\n",
      "453     1.0   4.891457  2.712864  3.067227\n",
      "454     2.0   5.167052  2.712864  3.067227\n",
      "455     4.0   6.825622  2.712864  3.067227\n",
      "\n",
      "Overall MAE: 2.7128636631641263, Overall RMSE: 3.067227399228591\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "#연도별\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "#data split\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 데이터셋의 차원 확인\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "0f1ca55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   4.763319  2.595597  3.004365\n",
      "449     4.0   4.830111  2.595597  3.004365\n",
      "450     3.0   3.879097  2.595597  3.004365\n",
      "451     2.0   4.008366  2.595597  3.004365\n",
      "452     2.0   5.997807  2.595597  3.004365\n",
      "453     1.0   5.661284  2.595597  3.004365\n",
      "454     2.0   5.081228  2.595597  3.004365\n",
      "455     4.0   7.600468  2.595597  3.004365\n",
      "456     3.0   6.092454  2.595597  3.004365\n",
      "457     1.0   5.579257  2.595597  3.004365\n",
      "\n",
      "Overall MAE: 2.5955968060214016, Overall RMSE: 3.004365321763257\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 데이터셋의 차원 확인\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "caccac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   5.222365  2.355419  2.755597\n",
      "449     4.0   6.705676  2.355419  2.755597\n",
      "450     3.0   3.646608  2.355419  2.755597\n",
      "451     2.0   3.180530  2.355419  2.755597\n",
      "452     2.0   5.261253  2.355419  2.755597\n",
      "453     1.0   5.542012  2.355419  2.755597\n",
      "454     2.0   4.771082  2.355419  2.755597\n",
      "455     4.0   5.991701  2.355419  2.755597\n",
      "456     3.0   3.895044  2.355419  2.755597\n",
      "457     1.0   6.382266  2.355419  2.755597\n",
      "\n",
      "Overall MAE: 2.355419362658389, Overall RMSE: 2.75559714072074\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data_avg\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 데이터셋의 차원 확인\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "ae859dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE    RMSE\n",
      "225     2.0   5.305701  3.768937  4.5559\n",
      "30     11.0   5.043341  3.768937  4.5559\n",
      "39      2.0   6.019449  3.768937  4.5559\n",
      "222     0.0   3.856896  3.768937  4.5559\n",
      "124     1.0   5.216108  3.768937  4.5559\n",
      "203     0.0   5.543990  3.768937  4.5559\n",
      "310     2.0   6.193486  3.768937  4.5559\n",
      "211    11.0   3.723249  3.768937  4.5559\n",
      "457     1.0   5.504907  3.768937  4.5559\n",
      "77     13.0   4.551873  3.768937  4.5559\n",
      "\n",
      "Overall MAE: 3.7689369637260954, Overall RMSE: 4.555900389129614\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "#split\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "#data split\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 데이터셋의 차원 확인\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "3596a8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE     RMSE\n",
      "126    15.0   5.786586  3.562116  4.29132\n",
      "30     11.0   5.742704  3.562116  4.29132\n",
      "202    14.0   5.693003  3.562116  4.29132\n",
      "442     1.0   4.741764  3.562116  4.29132\n",
      "157    14.0   5.139366  3.562116  4.29132\n",
      "228     2.0   4.865829  3.562116  4.29132\n",
      "409     2.0   4.116851  3.562116  4.29132\n",
      "299     8.0   5.651759  3.562116  4.29132\n",
      "225     2.0   5.303702  3.562116  4.29132\n",
      "76      1.0   5.489688  3.562116  4.29132\n",
      "\n",
      "Overall MAE: 3.5621156311767392, Overall RMSE: 4.291320262702613\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "#split\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "#data split\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 데이터셋의 차원 확인\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "e9f303ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "350     1.0   4.685847  3.469147  4.318615\n",
      "354     3.0   5.741736  3.469147  4.318615\n",
      "428     1.0   5.851238  3.469147  4.318615\n",
      "60      4.0   9.678966  3.469147  4.318615\n",
      "169     0.0   4.285009  3.469147  4.318615\n",
      "33     13.0   3.509102  3.469147  4.318615\n",
      "76      1.0   3.543311  3.469147  4.318615\n",
      "88     13.0   6.395060  3.469147  4.318615\n",
      "278     3.0   3.550281  3.469147  4.318615\n",
      "461     2.0   4.864415  3.469147  4.318615\n",
      "\n",
      "Overall MAE: 3.4691468057655634, Overall RMSE: 4.318614712146205\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "#split\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "#data split\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 데이터셋의 차원 확인\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "f64830d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted      MAE      RMSE\n",
      "170     6.0   2.551943  3.88861  4.851982\n",
      "322     1.0   4.528696  3.88861  4.851982\n",
      "457     1.0   5.845526  3.88861  4.851982\n",
      "104    14.0  11.872702  3.88861  4.851982\n",
      "75     15.0   6.593727  3.88861  4.851982\n",
      "441     1.0   4.710870  3.88861  4.851982\n",
      "408     1.0   5.385159  3.88861  4.851982\n",
      "239     0.0   4.668304  3.88861  4.851982\n",
      "42      5.0   5.468139  3.88861  4.851982\n",
      "60      4.0   4.734231  3.88861  4.851982\n",
      "\n",
      "Overall MAE: 3.888609668913516, Overall RMSE: 4.851982397299222\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "#split\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#data_avg\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "#data split\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 데이터셋의 차원 확인\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d8cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fe0e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd72c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc7644c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa162c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe68770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0383440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e596c62e",
   "metadata": {},
   "source": [
    "<h3> 3.1.3. XGBoost <h3> <br/><br/><h4>- PCA <br/><br/>- 데이터정규화 <br/><br/> - cross validation<h4>    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "3dc002f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\jupyter\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\jupyter\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\jupyter\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "6fe712aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   5.899260  2.811238  3.111227\n",
      "447     3.0   5.688596  2.811238  3.111227\n",
      "448     5.0   4.649080  2.811238  3.111227\n",
      "449     4.0   5.118979  2.811238  3.111227\n",
      "450     3.0   4.051440  2.811238  3.111227\n",
      "451     2.0   4.195941  2.811238  3.111227\n",
      "452     2.0   5.459537  2.811238  3.111227\n",
      "453     1.0   4.824791  2.811238  3.111227\n",
      "454     2.0   5.045118  2.811238  3.111227\n",
      "455     4.0   7.818213  2.811238  3.111227\n",
      "\n",
      "Overall MAE: 2.811237543821335, Overall RMSE: 3.1112273387442366\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.01, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#연도별\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "#data split\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "f164c9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   5.897915  2.651572  3.167813\n",
      "447     3.0   6.477106  2.651572  3.167813\n",
      "448     5.0   4.723784  2.651572  3.167813\n",
      "449     4.0   6.224149  2.651572  3.167813\n",
      "450     3.0   3.284983  2.651572  3.167813\n",
      "451     2.0   3.284983  2.651572  3.167813\n",
      "452     2.0   5.301277  2.651572  3.167813\n",
      "453     1.0   5.151687  2.651572  3.167813\n",
      "454     2.0   5.071522  2.651572  3.167813\n",
      "455     4.0   6.425967  2.651572  3.167813\n",
      "\n",
      "Overall MAE: 2.6515719145536423, Overall RMSE: 3.167813130877639\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.01, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "#연도별\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "#data_avg\n",
    "#PCA제외\n",
    "#정규화제외\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "b8620772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   5.558907  2.551884  2.943606\n",
      "449     4.0   4.682265  2.551884  2.943606\n",
      "450     3.0   4.146018  2.551884  2.943606\n",
      "451     2.0   4.284941  2.551884  2.943606\n",
      "452     2.0   6.022764  2.551884  2.943606\n",
      "453     1.0   5.639886  2.551884  2.943606\n",
      "454     2.0   5.342758  2.551884  2.943606\n",
      "455     4.0   6.577963  2.551884  2.943606\n",
      "456     3.0   6.281938  2.551884  2.943606\n",
      "457     1.0   5.405420  2.551884  2.943606\n",
      "\n",
      "Overall MAE: 2.551884174346924, Overall RMSE: 2.9436055563413936\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.01, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "c1d161d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted      MAE      RMSE\n",
      "448     5.0   5.585737  2.47186  2.790748\n",
      "449     4.0   6.541820  2.47186  2.790748\n",
      "450     3.0   4.479160  2.47186  2.790748\n",
      "451     2.0   3.991735  2.47186  2.790748\n",
      "452     2.0   5.781312  2.47186  2.790748\n",
      "453     1.0   5.294400  2.47186  2.790748\n",
      "454     2.0   5.239945  2.47186  2.790748\n",
      "455     4.0   5.876357  2.47186  2.790748\n",
      "456     3.0   4.641928  2.47186  2.790748\n",
      "457     1.0   6.171567  2.47186  2.790748\n",
      "\n",
      "Overall MAE: 2.4718602555138722, Overall RMSE: 2.7907482584222314\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.01, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "#data_avg\n",
    "#PCA제외\n",
    "#정규화제외\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "599970aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "225     2.0   5.240109  3.794318  4.570817\n",
      "30     11.0   5.160679  3.794318  4.570817\n",
      "39      2.0   5.980672  3.794318  4.570817\n",
      "222     0.0   3.800009  3.794318  4.570817\n",
      "124     1.0   5.321174  3.794318  4.570817\n",
      "203     0.0   5.595422  3.794318  4.570817\n",
      "310     2.0   6.262986  3.794318  4.570817\n",
      "211    11.0   3.729994  3.794318  4.570817\n",
      "457     1.0   5.515543  3.794318  4.570817\n",
      "77     13.0   4.548246  3.794318  4.570817\n",
      "\n",
      "Overall MAE: 3.7943178069206978, Overall RMSE: 4.570817094353502\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.01, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "#split\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "#data split\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "40131778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "126    15.0   5.730171  3.579531  4.304844\n",
      "30     11.0   5.657172  3.579531  4.304844\n",
      "202    14.0   5.728386  3.579531  4.304844\n",
      "442     1.0   5.165690  3.579531  4.304844\n",
      "157    14.0   5.070110  3.579531  4.304844\n",
      "228     2.0   4.938879  3.579531  4.304844\n",
      "409     2.0   4.178058  3.579531  4.304844\n",
      "299     8.0   5.626859  3.579531  4.304844\n",
      "225     2.0   5.354475  3.579531  4.304844\n",
      "76      1.0   5.356330  3.579531  4.304844\n",
      "\n",
      "Overall MAE: 3.5795307548149773, Overall RMSE: 4.304844467031281\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.01, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "#split\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "#data_avg\n",
    "#PCA제외\n",
    "#정규화제외\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "dd2686a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted      MAE      RMSE\n",
      "350     1.0   5.031853  3.47597  4.371625\n",
      "354     3.0   5.520224  3.47597  4.371625\n",
      "428     1.0   6.033310  3.47597  4.371625\n",
      "60      4.0   8.973329  3.47597  4.371625\n",
      "169     0.0   4.500467  3.47597  4.371625\n",
      "33     13.0   3.652467  3.47597  4.371625\n",
      "76      1.0   3.650558  3.47597  4.371625\n",
      "88     13.0   6.591516  3.47597  4.371625\n",
      "278     3.0   3.360404  3.47597  4.371625\n",
      "461     2.0   4.914188  3.47597  4.371625\n",
      "\n",
      "Overall MAE: 3.4759696977479115, Overall RMSE: 4.371624582891765\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.01, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "#split\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#PCA 제외\n",
    "#정규화 제외\n",
    "#data split\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "cf6e1b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "170     6.0   2.368622  4.015883  4.991471\n",
      "322     1.0   4.096123  4.015883  4.991471\n",
      "457     1.0   5.946548  4.015883  4.991471\n",
      "104    14.0  11.602270  4.015883  4.991471\n",
      "75     15.0   6.694699  4.015883  4.991471\n",
      "441     1.0   5.203858  4.015883  4.991471\n",
      "408     1.0   5.460289  4.015883  4.991471\n",
      "239     0.0   4.391591  4.015883  4.991471\n",
      "42      5.0   5.633595  4.015883  4.991471\n",
      "60      4.0   4.437467  4.015883  4.991471\n",
      "\n",
      "Overall MAE: 4.01588267371768, Overall RMSE: 4.991470885930016\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.01, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "#split\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "#data_avg\n",
    "#data split\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train)\n",
    "# X_test_scaled = pca.transform(X_test)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-폴드 교차 검증\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9c91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2262d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b0a353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77129e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ab8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12610260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3252e1c",
   "metadata": {},
   "source": [
    "<h3> 3.1.4. LightGBM <h3> <br/><br/><h4>- PCA <br/><br/>- 데이터정규화 <br/><br/> - cross validation<h4>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "bdc8a866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\jupyter\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy in c:\\jupyter\\anaconda3\\lib\\site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\jupyter\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "ec2dad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2378\n",
      "[LightGBM] [Info] Number of data points in the train set: 447, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 5.463087\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   5.628367  2.780878  3.121525\n",
      "447     3.0   5.966186  2.780878  3.121525\n",
      "448     5.0   4.565647  2.780878  3.121525\n",
      "449     4.0   5.028018  2.780878  3.121525\n",
      "450     3.0   4.184070  2.780878  3.121525\n",
      "451     2.0   3.903715  2.780878  3.121525\n",
      "452     2.0   5.722923  2.780878  3.121525\n",
      "453     1.0   4.957584  2.780878  3.121525\n",
      "454     2.0   5.538105  2.780878  3.121525\n",
      "455     4.0   7.835816  2.780878  3.121525\n",
      "\n",
      "Overall MAE: 2.780877514468173, Overall RMSE: 3.121525494670908\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'num_leaves': 31}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.01, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "# #1\n",
    "# #연도별\n",
    "# #1차\n",
    "# #data\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data\n",
    "# #특정시즌 test\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from lightgbm import LGBMRegressor\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # merged_all_comb_copy_model = ...\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "#      ]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data = data.dropna(subset=feature_columns + [target_column])\n",
    "# X = data[feature_columns]\n",
    "# y = data[target_column]\n",
    "\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# test_data = data[data['Draft_year'] == 2017]\n",
    "# train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# # 하이퍼파라미터 그리드 정의\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'num_leaves': [31, 62, 127]  # LightGBM 특정 파라미터\n",
    "# }\n",
    "\n",
    "# # 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=LGBMRegressor(random_state=42), \n",
    "#     param_grid=param_grid, \n",
    "#     cv=5,  # 5-폴드 교차 검증\n",
    "#     n_jobs=-1, \n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "2e63b5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2517\n",
      "[LightGBM] [Info] Number of data points in the train set: 444, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 5.497748\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   6.181879  2.617384  3.073607\n",
      "447     3.0   5.918021  2.617384  3.073607\n",
      "448     5.0   5.244698  2.617384  3.073607\n",
      "449     4.0   5.668006  2.617384  3.073607\n",
      "450     3.0   4.014716  2.617384  3.073607\n",
      "451     2.0   3.816081  2.617384  3.073607\n",
      "452     2.0   5.691585  2.617384  3.073607\n",
      "453     1.0   5.084695  2.617384  3.073607\n",
      "454     2.0   6.086533  2.617384  3.073607\n",
      "455     4.0   5.738393  2.617384  3.073607\n",
      "\n",
      "Overall MAE: 2.617383807040697, Overall RMSE: 3.073606683200658\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'num_leaves': 31}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.01, 'max_depth': 7, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "# #2\n",
    "# #연도별\n",
    "# #1차\n",
    "# #data_avg\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data_avg\n",
    "# #data_split\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from lightgbm import LGBMRegressor\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # merged_all_comb_copy_model = ...\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "#      ]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "# X = data_avg[feature_columns]\n",
    "# y = data_avg[target_column]\n",
    "\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # 하이퍼파라미터 그리드 정의\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'num_leaves': [31, 62, 127]  # LightGBM 특정 파라미터\n",
    "# }\n",
    "\n",
    "# # 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=LGBMRegressor(random_state=42), \n",
    "#     param_grid=param_grid, \n",
    "#     cv=5,  # 5-폴드 교차 검증\n",
    "#     n_jobs=-1, \n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "32c6521f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5928\n",
      "[LightGBM] [Info] Number of data points in the train set: 404, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score 5.559406\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "     Actual  Predicted       MAE     RMSE\n",
      "448     5.0   4.723697  2.707417  3.10392\n",
      "449     4.0   4.517573  2.707417  3.10392\n",
      "450     3.0   4.303761  2.707417  3.10392\n",
      "451     2.0   3.989177  2.707417  3.10392\n",
      "452     2.0   5.955343  2.707417  3.10392\n",
      "453     1.0   4.536834  2.707417  3.10392\n",
      "454     2.0   5.721662  2.707417  3.10392\n",
      "455     4.0   8.151918  2.707417  3.10392\n",
      "456     3.0   6.608427  2.707417  3.10392\n",
      "457     1.0   5.141392  2.707417  3.10392\n",
      "\n",
      "Overall MAE: 2.7074171367951756, Overall RMSE: 3.1039195053309854\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'num_leaves': 31}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.01, 'max_depth': 5, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "# #3\n",
    "# #연도별\n",
    "# #1차+2차\n",
    "# #data\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data\n",
    "# #특정시즌 test\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from lightgbm import LGBMRegressor\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # merged_all_comb_copy_model = ...\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#      \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#      \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data = data.dropna(subset=feature_columns + [target_column])\n",
    "# X = data[feature_columns]\n",
    "# y = data[target_column]\n",
    "\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# test_data = data[data['Draft_year'] == 2017]\n",
    "# train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# # 하이퍼파라미터 그리드 정의\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'num_leaves': [31, 62, 127]  # LightGBM 특정 파라미터\n",
    "# }\n",
    "\n",
    "# # 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=LGBMRegressor(random_state=42), \n",
    "#     param_grid=param_grid, \n",
    "#     cv=5,  # 5-폴드 교차 검증\n",
    "#     n_jobs=-1, \n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "a43e35d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6098\n",
      "[LightGBM] [Info] Number of data points in the train set: 402, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score 5.584577\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   5.531184  2.260106  2.707846\n",
      "449     4.0   5.533414  2.260106  2.707846\n",
      "450     3.0   3.079563  2.260106  2.707846\n",
      "451     2.0   3.163591  2.260106  2.707846\n",
      "452     2.0   5.524929  2.260106  2.707846\n",
      "453     1.0   5.217379  2.260106  2.707846\n",
      "454     2.0   4.311038  2.260106  2.707846\n",
      "455     4.0   6.603813  2.260106  2.707846\n",
      "456     3.0   4.736295  2.260106  2.707846\n",
      "457     1.0   6.498744  2.260106  2.707846\n",
      "\n",
      "Overall MAE: 2.260105529395537, Overall RMSE: 2.707846365211822\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'num_leaves': 31}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.01, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 200, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "# #4\n",
    "# #연도별\n",
    "# #1차+2차\n",
    "# #data_avg\n",
    "\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data_avg\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from lightgbm import LGBMRegressor\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # merged_all_comb_copy_model = ...\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#      \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#      \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "# X = data_avg[feature_columns]\n",
    "# y = data_avg[target_column]\n",
    "\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # 하이퍼파라미터 그리드 정의\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'num_leaves': [31, 62, 127]  # LightGBM 특정 파라미터\n",
    "# }\n",
    "\n",
    "# # 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=LGBMRegressor(random_state=42), \n",
    "#     param_grid=param_grid, \n",
    "#     cv=5,  # 5-폴드 교차 검증\n",
    "#     n_jobs=-1, \n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "5c0d9ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1980\n",
      "[LightGBM] [Info] Number of data points in the train set: 370, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 5.345946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "225     2.0   4.875887  3.748326  4.566108\n",
      "30     11.0   4.789470  3.748326  4.566108\n",
      "39      2.0   5.819208  3.748326  4.566108\n",
      "222     0.0   3.706767  3.748326  4.566108\n",
      "124     1.0   5.145517  3.748326  4.566108\n",
      "203     0.0   5.955804  3.748326  4.566108\n",
      "310     2.0   6.812552  3.748326  4.566108\n",
      "211    11.0   2.434392  3.748326  4.566108\n",
      "457     1.0   5.856797  3.748326  4.566108\n",
      "77     13.0   4.870910  3.748326  4.566108\n",
      "\n",
      "Overall MAE: 3.748326241755217, Overall RMSE: 4.566108310533195\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'num_leaves': 31}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.01, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 200, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "# #5\n",
    "# #split\n",
    "# #1차\n",
    "# #data\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data\n",
    "# #data split\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from lightgbm import LGBMRegressor\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # merged_all_comb_copy_model = ...\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "#      ]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data = data.dropna(subset=feature_columns + [target_column])\n",
    "# X = data[feature_columns]\n",
    "# y = data[target_column]\n",
    "\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# # data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# # test_data = data[data['Draft_year'] == 2017]\n",
    "# # train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# # 하이퍼파라미터 그리드 정의\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'num_leaves': [31, 62, 127]  # LightGBM 특정 파라미터\n",
    "# }\n",
    "\n",
    "# # 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=LGBMRegressor(random_state=42), \n",
    "#     param_grid=param_grid, \n",
    "#     cv=5,  # 5-폴드 교차 검증\n",
    "#     n_jobs=-1, \n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "58b2e846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2080\n",
      "[LightGBM] [Info] Number of data points in the train set: 368, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 5.453804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "126    15.0   6.348290  3.554386  4.256769\n",
      "30     11.0   4.935478  3.554386  4.256769\n",
      "202    14.0   6.027752  3.554386  4.256769\n",
      "442     1.0   4.574813  3.554386  4.256769\n",
      "157    14.0   4.767747  3.554386  4.256769\n",
      "228     2.0   5.116306  3.554386  4.256769\n",
      "409     2.0   4.857753  3.554386  4.256769\n",
      "299     8.0   5.977375  3.554386  4.256769\n",
      "225     2.0   5.192389  3.554386  4.256769\n",
      "76      1.0   5.545273  3.554386  4.256769\n",
      "\n",
      "Overall MAE: 3.5543863088333616, Overall RMSE: 4.256768576826404\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'num_leaves': 31}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.01, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "# #6\n",
    "# #split\n",
    "# #1차\n",
    "# #data_avg\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data_avg\n",
    "# #data_split\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from lightgbm import LGBMRegressor\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # merged_all_comb_copy_model = ...\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "#      ]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "# X = data_avg[feature_columns]\n",
    "# y = data_avg[target_column]\n",
    "\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# # data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "# # X_train = train_data[feature_columns]\n",
    "# # y_train = train_data[target_column]\n",
    "# # X_test = test_data[feature_columns]\n",
    "# # y_test = test_data[target_column]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # 하이퍼파라미터 그리드 정의\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'num_leaves': [31, 62, 127]  # LightGBM 특정 파라미터\n",
    "# }\n",
    "\n",
    "# # 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=LGBMRegressor(random_state=42), \n",
    "#     param_grid=param_grid, \n",
    "#     cv=5,  # 5-폴드 교차 검증\n",
    "#     n_jobs=-1, \n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "d32cbce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5005\n",
      "[LightGBM] [Info] Number of data points in the train set: 334, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score 5.559880\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "     Actual  Predicted      MAE      RMSE\n",
      "350     1.0   5.141696  3.48452  4.361318\n",
      "354     3.0   5.742629  3.48452  4.361318\n",
      "428     1.0   5.931318  3.48452  4.361318\n",
      "60      4.0   7.380825  3.48452  4.361318\n",
      "169     0.0   4.189540  3.48452  4.361318\n",
      "33     13.0   3.197548  3.48452  4.361318\n",
      "76      1.0   2.930850  3.48452  4.361318\n",
      "88     13.0   6.750336  3.48452  4.361318\n",
      "278     3.0   3.358649  3.48452  4.361318\n",
      "461     2.0   5.008075  3.48452  4.361318\n",
      "\n",
      "Overall MAE: 3.4845195125549373, Overall RMSE: 4.361317553847619\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'num_leaves': 31}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.01, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 200, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "# #7\n",
    "# #split\n",
    "# #1차+2차\n",
    "# #data\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data\n",
    "# #data split\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from lightgbm import LGBMRegressor\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # merged_all_comb_copy_model = ...\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#      \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#      \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data = data.dropna(subset=feature_columns + [target_column])\n",
    "# X = data[feature_columns]\n",
    "# y = data[target_column]\n",
    "\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# # test_data = data[data['Draft_year'] == 2017]\n",
    "# # train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# # 하이퍼파라미터 그리드 정의\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'num_leaves': [31, 62, 127]  # LightGBM 특정 파라미터\n",
    "# }\n",
    "\n",
    "# # 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=LGBMRegressor(random_state=42), \n",
    "#     param_grid=param_grid, \n",
    "#     cv=5,  # 5-폴드 교차 검증\n",
    "#     n_jobs=-1, \n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "a9c20c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5079\n",
      "[LightGBM] [Info] Number of data points in the train set: 332, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score 5.246988\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "170     6.0   3.116806  4.098245  4.979245\n",
      "322     1.0   4.278425  4.098245  4.979245\n",
      "457     1.0   5.953000  4.098245  4.979245\n",
      "104    14.0   8.142148  4.098245  4.979245\n",
      "75     15.0   6.168776  4.098245  4.979245\n",
      "441     1.0   4.377966  4.098245  4.979245\n",
      "408     1.0   5.913341  4.098245  4.979245\n",
      "239     0.0   4.173166  4.098245  4.979245\n",
      "42      5.0   6.015360  4.098245  4.979245\n",
      "60      4.0   6.494066  4.098245  4.979245\n",
      "\n",
      "Overall MAE: 4.098245381733229, Overall RMSE: 4.979245224072992\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'num_leaves': 31}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.01, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "# #8\n",
    "# #split\n",
    "# #1차+2차\n",
    "# #data_avg\n",
    "\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data_avg\n",
    "# #data_split\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from lightgbm import LGBMRegressor\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # merged_all_comb_copy_model = ...\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#      \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#      \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "# X = data_avg[feature_columns]\n",
    "# y = data_avg[target_column]\n",
    "\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "# # X_train = train_data[feature_columns]\n",
    "# # y_train = train_data[target_column]\n",
    "# # X_test = test_data[feature_columns]\n",
    "# # y_test = test_data[target_column]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# # 하이퍼파라미터 그리드 정의\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'num_leaves': [31, 62, 127]  # LightGBM 특정 파라미터\n",
    "# }\n",
    "\n",
    "# # 그리드 서치 객체 생성 및 교차 검증 설정\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=LGBMRegressor(random_state=42), \n",
    "#     param_grid=param_grid, \n",
    "#     cv=5,  # 5-폴드 교차 검증\n",
    "#     n_jobs=-1, \n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638707c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a92fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b5fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00553110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2903d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc48ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6d0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf2e0c9e",
   "metadata": {},
   "source": [
    "<h3> 3.1.5. Catboost <h3> <br/><br/><h4>- 데이터 split <br/><br/>- 데이터정규화 <br/><br/> - cross validation<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "cc2ec703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\jupyter\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: graphviz in c:\\jupyter\\anaconda3\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\jupyter\\anaconda3\\lib\\site-packages (from catboost) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\jupyter\\anaconda3\\lib\\site-packages (from catboost) (1.4.4)\n",
      "Requirement already satisfied: scipy in c:\\jupyter\\anaconda3\\lib\\site-packages (from catboost) (1.9.1)\n",
      "Requirement already satisfied: plotly in c:\\jupyter\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\jupyter\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\jupyter\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\jupyter\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\jupyter\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\jupyter\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\jupyter\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "f10a89b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "0:\tlearn: 3.6118559\ttotal: 63.6ms\tremaining: 6.3s\n",
      "99:\tlearn: 2.3159364\ttotal: 224ms\tremaining: 0us\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   6.878657  2.797376  3.572588\n",
      "447     3.0   7.142223  2.797376  3.572588\n",
      "448     5.0   3.913178  2.797376  3.572588\n",
      "449     4.0   5.149682  2.797376  3.572588\n",
      "450     3.0   2.862459  2.797376  3.572588\n",
      "451     2.0   3.141702  2.797376  3.572588\n",
      "452     2.0   4.875449  2.797376  3.572588\n",
      "453     1.0   3.876478  2.797376  3.572588\n",
      "454     2.0   4.393258  2.797376  3.572588\n",
      "455     4.0   7.350993  2.797376  3.572588\n",
      "\n",
      "Overall MAE: 2.7973757691157455, Overall RMSE: 3.572587781623997\n",
      "\n",
      "Best Parameters: {'depth': 4, 'iterations': 100, 'learning_rate': 0.1}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'iterations': 100, 'learning_rate': 0.1, 'depth': 4, 'loss_function': 'MAE', 'verbose': 200, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "# #1\n",
    "# #연도별\n",
    "# #1차\n",
    "# #data\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data  ##학습시간 길다\n",
    "\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# # Feature 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "#      ]\n",
    "\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data = data.dropna(subset=feature_columns + [target_column])\n",
    "# X = data[feature_columns]\n",
    "# y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# test_data = data[data['Draft_year'] == 2017]\n",
    "# train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # X_train_scaled = scaler.fit_transform(X_train)\n",
    "# # X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 하이퍼파라미터 그리드 설정\n",
    "# param_grid = {\n",
    "#     'iterations': [100, 500],  # 트리의 수 감소\n",
    "#     'depth': [4, 6],          # 트리 깊이 감소\n",
    "#     'learning_rate': [0.1]    # 학습률 증가\n",
    "# }\n",
    "\n",
    "# # CatBoost 모델 생성 및 그리드 서치 설정\n",
    "# model = CatBoostRegressor(loss_function='MAE', verbose=200, random_state = 42)\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "e298804b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "0:\tlearn: 3.6118559\ttotal: 1.68ms\tremaining: 166ms\n",
      "99:\tlearn: 2.3159364\ttotal: 132ms\tremaining: 0us\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   6.878657  2.797376  3.572588\n",
      "447     3.0   7.142223  2.797376  3.572588\n",
      "448     5.0   3.913178  2.797376  3.572588\n",
      "449     4.0   5.149682  2.797376  3.572588\n",
      "450     3.0   2.862459  2.797376  3.572588\n",
      "451     2.0   3.141702  2.797376  3.572588\n",
      "452     2.0   4.875449  2.797376  3.572588\n",
      "453     1.0   3.876478  2.797376  3.572588\n",
      "454     2.0   4.393258  2.797376  3.572588\n",
      "455     4.0   7.350993  2.797376  3.572588\n",
      "\n",
      "Overall MAE: 2.7973757691157455, Overall RMSE: 3.572587781623997\n",
      "\n",
      "Best Parameters: {'depth': 4, 'iterations': 100, 'learning_rate': 0.1}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'iterations': 100, 'learning_rate': 0.1, 'depth': 4, 'loss_function': 'MAE', 'verbose': 200, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "# #2\n",
    "# #연도별\n",
    "# #1차\n",
    "# #data_avg\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data_avg\n",
    "# # data split\n",
    "\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "#      ]\n",
    "\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "# X = data_avg[feature_columns]\n",
    "# y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # X_train_scaled = scaler.fit_transform(X_train)\n",
    "# # X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 하이퍼파라미터 그리드 설정\n",
    "# param_grid = {\n",
    "#     'iterations': [100, 500],  # 트리의 수 감소\n",
    "#     'depth': [4, 6],          # 트리 깊이 감소\n",
    "#     'learning_rate': [0.1]    # 학습률 증가\n",
    "# }\n",
    "\n",
    "# # CatBoost 모델 생성 및 그리드 서치 설정\n",
    "# model = CatBoostRegressor(loss_function='MAE', verbose=200, random_state = 42)\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "c7f694eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "0:\tlearn: 3.6581674\ttotal: 3.76ms\tremaining: 372ms\n",
      "99:\tlearn: 2.2004995\ttotal: 276ms\tremaining: 0us\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   3.912322  2.424357  2.974414\n",
      "449     4.0   4.834629  2.424357  2.974414\n",
      "450     3.0   2.369437  2.424357  2.974414\n",
      "451     2.0   2.480650  2.424357  2.974414\n",
      "452     2.0   6.706491  2.424357  2.974414\n",
      "453     1.0   4.170909  2.424357  2.974414\n",
      "454     2.0   4.879879  2.424357  2.974414\n",
      "455     4.0   8.658239  2.424357  2.974414\n",
      "456     3.0   3.188072  2.424357  2.974414\n",
      "457     1.0   6.918483  2.424357  2.974414\n",
      "\n",
      "Overall MAE: 2.4243566789686404, Overall RMSE: 2.9744139178551183\n",
      "\n",
      "Best Parameters: {'depth': 4, 'iterations': 100, 'learning_rate': 0.1}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'iterations': 100, 'learning_rate': 0.1, 'depth': 4, 'loss_function': 'MAE', 'verbose': 200, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "# #3\n",
    "# #연도별\n",
    "# #1차+2차\n",
    "# #data\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data  ##학습시간 길다\n",
    "\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#      \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#      \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data = data.dropna(subset=feature_columns + [target_column])\n",
    "# X = data[feature_columns]\n",
    "# y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# test_data = data[data['Draft_year'] == 2017]\n",
    "# train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # X_train_scaled = scaler.fit_transform(X_train)\n",
    "# # X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 하이퍼파라미터 그리드 설정\n",
    "# param_grid = {\n",
    "#     'iterations': [100, 500],  # 트리의 수 감소\n",
    "#     'depth': [4, 6],          # 트리 깊이 감소\n",
    "#     'learning_rate': [0.1]    # 학습률 증가\n",
    "# }\n",
    "\n",
    "# # CatBoost 모델 생성 및 그리드 서치 설정\n",
    "# model = CatBoostRegressor(loss_function='MAE', verbose=200, random_state = 42)\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "4bca2634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "0:\tlearn: 3.6589543\ttotal: 3.41ms\tremaining: 337ms\n",
      "99:\tlearn: 2.1742753\ttotal: 291ms\tremaining: 0us\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   3.737075  2.180616  2.745831\n",
      "449     4.0   5.125733  2.180616  2.745831\n",
      "450     3.0   1.527999  2.180616  2.745831\n",
      "451     2.0   2.841688  2.180616  2.745831\n",
      "452     2.0   4.389925  2.180616  2.745831\n",
      "453     1.0   6.801820  2.180616  2.745831\n",
      "454     2.0   4.946518  2.180616  2.745831\n",
      "455     4.0   5.546045  2.180616  2.745831\n",
      "456     3.0   3.329803  2.180616  2.745831\n",
      "457     1.0   6.664461  2.180616  2.745831\n",
      "\n",
      "Overall MAE: 2.1806155727733647, Overall RMSE: 2.7458307493607306\n",
      "\n",
      "Best Parameters: {'depth': 4, 'iterations': 100, 'learning_rate': 0.1}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'iterations': 100, 'learning_rate': 0.1, 'depth': 4, 'loss_function': 'MAE', 'verbose': 200, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "# #4\n",
    "# #연도별\n",
    "# #1차+2차\n",
    "# #data_avg\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data_avg\n",
    "\n",
    "\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#      \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#      \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "# X = data_avg[feature_columns]\n",
    "# y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # X_train_scaled = scaler.fit_transform(X_train)\n",
    "# # X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 하이퍼파라미터 그리드 설정\n",
    "# param_grid = {\n",
    "#     'iterations': [100, 500],  # 트리의 수 감소\n",
    "#     'depth': [4, 6],          # 트리 깊이 감소\n",
    "#     'learning_rate': [0.1]    # 학습률 증가\n",
    "# }\n",
    "\n",
    "# # CatBoost 모델 생성 및 그리드 서치 설정\n",
    "# model = CatBoostRegressor(loss_function='MAE', verbose=200, random_state = 42)\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "55bd09ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "0:\tlearn: 3.4735125\ttotal: 3.55ms\tremaining: 352ms\n",
      "99:\tlearn: 2.1129137\ttotal: 164ms\tremaining: 0us\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "225     2.0   4.324145  3.559709  4.474455\n",
      "30     11.0   3.931140  3.559709  4.474455\n",
      "39      2.0   6.046237  3.559709  4.474455\n",
      "222     0.0   2.028235  3.559709  4.474455\n",
      "124     1.0   4.243196  3.559709  4.474455\n",
      "203     0.0   5.900696  3.559709  4.474455\n",
      "310     2.0   6.273754  3.559709  4.474455\n",
      "211    11.0   3.601812  3.559709  4.474455\n",
      "457     1.0   6.458272  3.559709  4.474455\n",
      "77     13.0   3.170267  3.559709  4.474455\n",
      "\n",
      "Overall MAE: 3.5597094216979617, Overall RMSE: 4.474454892952302\n",
      "\n",
      "Best Parameters: {'depth': 4, 'iterations': 100, 'learning_rate': 0.1}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'iterations': 100, 'learning_rate': 0.1, 'depth': 4, 'loss_function': 'MAE', 'verbose': 200, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "# #5\n",
    "# #split\n",
    "# #1차\n",
    "# #data\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data  ##학습시간 길다\n",
    "\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# # Feature 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "#      ]\n",
    "\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data = data.dropna(subset=feature_columns + [target_column])\n",
    "# X = data[feature_columns]\n",
    "# y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # X_train_scaled = scaler.fit_transform(X_train)\n",
    "# # X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 하이퍼파라미터 그리드 설정\n",
    "# param_grid = {\n",
    "#     'iterations': [100, 500],  # 트리의 수 감소\n",
    "#     'depth': [4, 6],          # 트리 깊이 감소\n",
    "#     'learning_rate': [0.1]    # 학습률 증가\n",
    "# }\n",
    "\n",
    "# # CatBoost 모델 생성 및 그리드 서치 설정\n",
    "# model = CatBoostRegressor(loss_function='MAE', verbose=200, random_state = 42)\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "e48638ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "0:\tlearn: 3.6019012\ttotal: 1.58ms\tremaining: 156ms\n",
      "99:\tlearn: 2.2545522\ttotal: 137ms\tremaining: 0us\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "126    15.0   8.043566  3.064637  4.013532\n",
      "30     11.0   4.634004  3.064637  4.013532\n",
      "202    14.0   4.219516  3.064637  4.013532\n",
      "442     1.0   3.846647  3.064637  4.013532\n",
      "157    14.0   6.166433  3.064637  4.013532\n",
      "228     2.0   3.386517  3.064637  4.013532\n",
      "409     2.0   1.570370  3.064637  4.013532\n",
      "299     8.0   5.762051  3.064637  4.013532\n",
      "225     2.0   3.965874  3.064637  4.013532\n",
      "76      1.0   4.557986  3.064637  4.013532\n",
      "\n",
      "Overall MAE: 3.064636718708186, Overall RMSE: 4.013532278117885\n",
      "\n",
      "Best Parameters: {'depth': 4, 'iterations': 100, 'learning_rate': 0.1}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'iterations': 100, 'learning_rate': 0.1, 'depth': 4, 'loss_function': 'MAE', 'verbose': 200, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "# #6\n",
    "# #split\n",
    "# #1차\n",
    "# #data_avg\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data_avg\n",
    "# # data split\n",
    "\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "#      ]\n",
    "\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "# X = data_avg[feature_columns]\n",
    "# y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # X_train_scaled = scaler.fit_transform(X_train)\n",
    "# # X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 하이퍼파라미터 그리드 설정\n",
    "# param_grid = {\n",
    "#     'iterations': [100, 500],  # 트리의 수 감소\n",
    "#     'depth': [4, 6],          # 트리 깊이 감소\n",
    "#     'learning_rate': [0.1]    # 학습률 증가\n",
    "# }\n",
    "\n",
    "# # CatBoost 모델 생성 및 그리드 서치 설정\n",
    "# model = CatBoostRegressor(loss_function='MAE', verbose=200, random_state = 42)\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "d51ea942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "0:\tlearn: 3.6733522\ttotal: 8.95ms\tremaining: 886ms\n",
      "99:\tlearn: 1.2072353\ttotal: 654ms\tremaining: 0us\n",
      "     Actual  Predicted       MAE     RMSE\n",
      "350     1.0   3.525141  3.273222  4.40133\n",
      "354     3.0   3.421332  3.273222  4.40133\n",
      "428     1.0   4.685147  3.273222  4.40133\n",
      "60      4.0   7.233484  3.273222  4.40133\n",
      "169     0.0   3.921433  3.273222  4.40133\n",
      "33     13.0   4.501333  3.273222  4.40133\n",
      "76      1.0   2.351089  3.273222  4.40133\n",
      "88     13.0   6.315841  3.273222  4.40133\n",
      "278     3.0   2.676144  3.273222  4.40133\n",
      "461     2.0   4.441070  3.273222  4.40133\n",
      "\n",
      "Overall MAE: 3.2732222434971048, Overall RMSE: 4.401330015092511\n",
      "\n",
      "Best Parameters: {'depth': 6, 'iterations': 100, 'learning_rate': 0.1}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'iterations': 100, 'learning_rate': 0.1, 'depth': 6, 'loss_function': 'MAE', 'verbose': 200, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "# #7\n",
    "# #split\n",
    "# #1차+2차\n",
    "# #data\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data  ##학습시간 길다\n",
    "\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#      \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#      \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data = data.dropna(subset=feature_columns + [target_column])\n",
    "# X = data[feature_columns]\n",
    "# y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # X_train_scaled = scaler.fit_transform(X_train)\n",
    "# # X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 하이퍼파라미터 그리드 설정\n",
    "# param_grid = {\n",
    "#     'iterations': [100, 500],  # 트리의 수 감소\n",
    "#     'depth': [4, 6],          # 트리 깊이 감소\n",
    "#     'learning_rate': [0.1]    # 학습률 증가\n",
    "# }\n",
    "\n",
    "# # CatBoost 모델 생성 및 그리드 서치 설정\n",
    "# model = CatBoostRegressor(loss_function='MAE', verbose=200, random_state = 42)\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "50ca83f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "0:\tlearn: 3.3677701\ttotal: 7.09ms\tremaining: 702ms\n",
      "99:\tlearn: 1.2475440\ttotal: 632ms\tremaining: 0us\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "170     6.0   1.270398  4.103893  5.206609\n",
      "322     1.0   5.359826  4.103893  5.206609\n",
      "457     1.0   7.067576  4.103893  5.206609\n",
      "104    14.0   8.747393  4.103893  5.206609\n",
      "75     15.0   5.723969  4.103893  5.206609\n",
      "441     1.0   6.479990  4.103893  5.206609\n",
      "408     1.0   5.938920  4.103893  5.206609\n",
      "239     0.0   4.418492  4.103893  5.206609\n",
      "42      5.0   6.641130  4.103893  5.206609\n",
      "60      4.0   3.901857  4.103893  5.206609\n",
      "\n",
      "Overall MAE: 4.103892821111486, Overall RMSE: 5.206609055036199\n",
      "\n",
      "Best Parameters: {'depth': 6, 'iterations': 100, 'learning_rate': 0.1}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'iterations': 100, 'learning_rate': 0.1, 'depth': 6, 'loss_function': 'MAE', 'verbose': 200, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "# #8\n",
    "# #split\n",
    "# #1차+2차\n",
    "# #data_avg\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# #data_avg\n",
    "# # data split\n",
    "\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#      \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#      \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "# X = data_avg[feature_columns]\n",
    "# y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# # 훈련 데이터와 테스트 데이터 분할\n",
    "# # train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# # test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # X_train_scaled = scaler.fit_transform(X_train)\n",
    "# # X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 하이퍼파라미터 그리드 설정\n",
    "# param_grid = {\n",
    "#     'iterations': [100, 500],  # 트리의 수 감소\n",
    "#     'depth': [4, 6],          # 트리 깊이 감소\n",
    "#     'learning_rate': [0.1]    # 학습률 증가\n",
    "# }\n",
    "\n",
    "# # CatBoost 모델 생성 및 그리드 서치 설정\n",
    "# model = CatBoostRegressor(loss_function='MAE', verbose=200, random_state = 42)\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# # y_pred = model.predict(X_test)\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# # 예측값에서 음수 제거\n",
    "# y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "# # 평가 지표 계산 및 출력\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # r2 = r2_score(y_test, y_pred)\n",
    "# # 결과를 데이터프레임으로 출력\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred,\n",
    "#     'MAE': mae,\n",
    "#     'RMSE': rmse\n",
    "# })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# # 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e2b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b924406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf9355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909078a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09082ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203491ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3528b5c",
   "metadata": {},
   "source": [
    "<h3> 3.1.6. SVM <h3> <br/><br/><h4>- PCA <br/><br/>- 데이터정규화 <br/><br/> - cross validation<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "5b159d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   5.141772  2.274464  2.662737\n",
      "447     3.0   6.063973  2.274464  2.662737\n",
      "448     5.0   3.616222  2.274464  2.662737\n",
      "449     4.0   4.583937  2.274464  2.662737\n",
      "450     3.0   3.037750  2.274464  2.662737\n",
      "451     2.0   3.240921  2.274464  2.662737\n",
      "452     2.0   5.650890  2.274464  2.662737\n",
      "453     1.0   4.453931  2.274464  2.662737\n",
      "454     2.0   4.366874  2.274464  2.662737\n",
      "455     4.0   6.327625  2.274464  2.662737\n",
      "\n",
      "Overall MAE: 2.2744641722011383, Overall RMSE: 2.6627370301318583\n",
      "\n",
      "Best Parameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 0.1, 'kernel': 'sigmoid', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#연도별\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#data split\n",
    "################################################################################\n",
    "################################################################################\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# 표준화를 위한 스케일러 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터 표준화\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "# X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['sigmoid']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "1e5eb01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   4.940673  2.070551  2.487606\n",
      "447     3.0   5.866053  2.070551  2.487606\n",
      "448     5.0   3.729749  2.070551  2.487606\n",
      "449     4.0   4.370881  2.070551  2.487606\n",
      "450     3.0   2.682011  2.070551  2.487606\n",
      "451     2.0   2.867241  2.070551  2.487606\n",
      "452     2.0   4.904233  2.070551  2.487606\n",
      "453     1.0   4.816908  2.070551  2.487606\n",
      "454     2.0   4.364930  2.070551  2.487606\n",
      "455     4.0   5.683060  2.070551  2.487606\n",
      "\n",
      "Overall MAE: 2.070550679604219, Overall RMSE: 2.487606313602033\n",
      "\n",
      "Best Parameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 0.1, 'kernel': 'sigmoid', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "#연도별\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data_avg\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 표준화를 위한 스케일러 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터 표준화\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "# X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['sigmoid']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# print(f\"MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "# 실제 값과 예측 값 출력\n",
    "# results_df = pd.DataFrame({'Actual Experience': y_test, 'Predicted Experience': y_pred})\n",
    "# print(results_df)\n",
    "\n",
    "# # 최적의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "f6e6b651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   3.607005  2.252598  2.678678\n",
      "449     4.0   4.274886  2.252598  2.678678\n",
      "450     3.0   1.955382  2.252598  2.678678\n",
      "451     2.0   0.853874  2.252598  2.678678\n",
      "452     2.0   5.003744  2.252598  2.678678\n",
      "453     1.0   3.926336  2.252598  2.678678\n",
      "454     2.0   5.649834  2.252598  2.678678\n",
      "455     4.0   7.029483  2.252598  2.678678\n",
      "456     3.0   3.742512  2.252598  2.678678\n",
      "457     1.0   6.157492  2.252598  2.678678\n",
      "\n",
      "Overall MAE: 2.252597706801159, Overall RMSE: 2.6786778392144073\n",
      "\n",
      "Best Parameters: {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "################################################################################\n",
    "################################################################################\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 표준화를 위한 스케일러 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터 표준화\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA 설정 및 적용\n",
    "n_components = 50\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "48e6259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   3.657463  2.245537  2.629096\n",
      "449     4.0   3.769043  2.245537  2.629096\n",
      "450     3.0   1.098435  2.245537  2.629096\n",
      "451     2.0   0.059392  2.245537  2.629096\n",
      "452     2.0   4.093910  2.245537  2.629096\n",
      "453     1.0   4.283498  2.245537  2.629096\n",
      "454     2.0   5.479484  2.245537  2.629096\n",
      "455     4.0   6.875126  2.245537  2.629096\n",
      "456     3.0   3.477718  2.245537  2.629096\n",
      "457     1.0   6.307124  2.245537  2.629096\n",
      "\n",
      "Overall MAE: 2.2455365702330243, Overall RMSE: 2.6290964050589705\n",
      "\n",
      "Best Parameters: {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data_avg\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 표준화를 위한 스케일러 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터 표준화\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA 설정 및 적용\n",
    "n_components = 50\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['sigmoid']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# print(f\"MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "# 실제 값과 예측 값 출력\n",
    "# results_df = pd.DataFrame({'Actual Experience': y_test, 'Predicted Experience': y_pred})\n",
    "# print(results_df)\n",
    "\n",
    "# # 최적의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "e26c27a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "225     2.0   3.838496  3.621867  4.688405\n",
      "30     11.0   4.840403  3.621867  4.688405\n",
      "39      2.0   4.140163  3.621867  4.688405\n",
      "222     0.0   2.171904  3.621867  4.688405\n",
      "124     1.0   4.567871  3.621867  4.688405\n",
      "203     0.0   4.205582  3.621867  4.688405\n",
      "310     2.0   5.517905  3.621867  4.688405\n",
      "211    11.0   3.375172  3.621867  4.688405\n",
      "457     1.0   5.236075  3.621867  4.688405\n",
      "77     13.0   4.022104  3.621867  4.688405\n",
      "\n",
      "Overall MAE: 3.621867167305605, Overall RMSE: 4.688405111885664\n",
      "\n",
      "Best Parameters: {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "#split\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#data split\n",
    "################################################################################\n",
    "################################################################################\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 표준화를 위한 스케일러 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터 표준화\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 21\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "# X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['sigmoid']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "008372db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "126    15.0   5.488452  3.209438  4.250015\n",
      "30     11.0   4.471625  3.209438  4.250015\n",
      "202    14.0   5.171582  3.209438  4.250015\n",
      "442     1.0   3.585158  3.209438  4.250015\n",
      "157    14.0   4.243268  3.209438  4.250015\n",
      "228     2.0   4.190369  3.209438  4.250015\n",
      "409     2.0   2.877868  3.209438  4.250015\n",
      "299     8.0   6.083530  3.209438  4.250015\n",
      "225     2.0   3.989927  3.209438  4.250015\n",
      "76      1.0   4.510163  3.209438  4.250015\n",
      "\n",
      "Overall MAE: 3.209437578335778, Overall RMSE: 4.250014739280565\n",
      "\n",
      "Best Parameters: {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "#split\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data_avg\n",
    "#data split\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 표준화를 위한 스케일러 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터 표준화\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "# X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['sigmoid']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# print(f\"MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "# 실제 값과 예측 값 출력\n",
    "# results_df = pd.DataFrame({'Actual Experience': y_test, 'Predicted Experience': y_pred})\n",
    "# print(results_df)\n",
    "\n",
    "# # 최적의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "59214098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "     Actual  Predicted      MAE     RMSE\n",
      "350     1.0   3.185843  3.12408  4.21245\n",
      "354     3.0   4.303166  3.12408  4.21245\n",
      "428     1.0   3.870553  3.12408  4.21245\n",
      "60      4.0   5.393552  3.12408  4.21245\n",
      "169     0.0   2.650146  3.12408  4.21245\n",
      "33     13.0   1.234618  3.12408  4.21245\n",
      "76      1.0   3.937742  3.12408  4.21245\n",
      "88     13.0   6.733173  3.12408  4.21245\n",
      "278     3.0   1.997386  3.12408  4.21245\n",
      "461     2.0   4.464290  3.12408  4.21245\n",
      "\n",
      "Overall MAE: 3.124079678362683, Overall RMSE: 4.2124500338558954\n",
      "\n",
      "Best Parameters: {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "#split\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#data split\n",
    "################################################################################\n",
    "################################################################################\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 표준화를 위한 스케일러 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터 표준화\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA 설정 및 적용\n",
    "n_components = 50\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "3da5b019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "     Actual  Predicted      MAE      RMSE\n",
      "170     6.0   1.427029  4.13003  5.256187\n",
      "322     1.0   3.238001  4.13003  5.256187\n",
      "457     1.0   6.216087  4.13003  5.256187\n",
      "104    14.0   6.829443  4.13003  5.256187\n",
      "75     15.0   5.354185  4.13003  5.256187\n",
      "441     1.0   3.902789  4.13003  5.256187\n",
      "408     1.0   3.927846  4.13003  5.256187\n",
      "239     0.0   3.929256  4.13003  5.256187\n",
      "42      5.0   6.413546  4.13003  5.256187\n",
      "60      4.0   4.943727  4.13003  5.256187\n",
      "\n",
      "Overall MAE: 4.13002962335266, Overall RMSE: 5.25618706585262\n",
      "\n",
      "Best Parameters: {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "#split\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data_avg\n",
    "#data split\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 표준화를 위한 스케일러 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터 표준화\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA 설정 및 적용\n",
    "n_components = 50\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['sigmoid']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# print(f\"MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "# 실제 값과 예측 값 출력\n",
    "# results_df = pd.DataFrame({'Actual Experience': y_test, 'Predicted Experience': y_pred})\n",
    "# print(results_df)\n",
    "\n",
    "# # 최적의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8ac08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a739e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d18f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2c55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b419332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe36d170",
   "metadata": {},
   "source": [
    "<h2>SVM - 2 <h2>\n",
    "<h4>결측치 포지션별 평균으로 대체<h4>\n",
    "<h4>평가지표 MAPE 추가<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "283a37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avg = weighted_avg_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "245a0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avg.to_csv(\"data_avg_missing.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "1aa21a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft_year                     0.000000\n",
      "Name                           0.000000\n",
      "Pos                            0.000000\n",
      "Height_cm                      0.000000\n",
      "Weight_kg                      0.000000\n",
      "Draft_team                     0.000000\n",
      "Draft_overall                  0.000000\n",
      "Standing_Reach_inch            0.431965\n",
      "Wingspan_inch                  0.215983\n",
      "LANE_AGILITY_sec               9.071274\n",
      "THREE_QUATER_SPRINT            8.423326\n",
      "STANDING_VERTICAL_LEAP_inch    7.559395\n",
      "MAX_VERTICAL_LEAP_inch         7.775378\n",
      "G_totals                       0.000000\n",
      "MP_totals                      0.431965\n",
      "FG_totals                      0.000000\n",
      "FGA_totals                     0.000000\n",
      "FG%_totals                     0.000000\n",
      "2P_totals                      0.000000\n",
      "2PA_totals                     0.000000\n",
      "2P%_totals                     0.000000\n",
      "3P_totals                      0.000000\n",
      "3PA_totals                     0.000000\n",
      "3P%_totals                     0.000000\n",
      "FT_totals                      0.000000\n",
      "FTA_totals                     0.000000\n",
      "FT%_totals                     0.000000\n",
      "TRB_totals                     0.000000\n",
      "AST_totals                     0.000000\n",
      "STL_totals                     0.000000\n",
      "BLK_totals                     0.000000\n",
      "TOV_totals                     0.000000\n",
      "PF_totals                      0.215983\n",
      "PTS_totals                     0.000000\n",
      "FG_per_min                     0.431965\n",
      "FGA_per_min                    0.431965\n",
      "2P_per_min                     0.431965\n",
      "2PA_per_min                    0.431965\n",
      "3P_per_min                     0.431965\n",
      "3PA_per_min                    0.431965\n",
      "FT_per_min                     0.431965\n",
      "FTA_per_min                    0.431965\n",
      "TRB_per_min                    0.431965\n",
      "AST_per_min                    0.431965\n",
      "STL_per_min                    0.431965\n",
      "BLK_per_min                    0.431965\n",
      "TOV_per_min                    0.431965\n",
      "PF_per_min                     0.647948\n",
      "PTS_per_min                    0.431965\n",
      "TS%_advanced                   0.000000\n",
      "eFG%_advanced                  0.000000\n",
      "3PAr_advanced                  0.000000\n",
      "FTr_advanced                   0.000000\n",
      "PProd_advanced                 0.647948\n",
      "ORB%_advanced                  0.647948\n",
      "DRB%_advanced                  0.647948\n",
      "TRB%_advanced                  0.647948\n",
      "AST%_advanced                  0.647948\n",
      "OBPM_advanced                  0.647948\n",
      "DBPM_advanced                  0.647948\n",
      "BPM_advanced                   0.647948\n",
      "STL%_advanced                  0.647948\n",
      "BLK%_advanced                  0.647948\n",
      "TOV%_advanced                  0.215983\n",
      "USG%_advanced                  0.647948\n",
      "OWS_advanced                   0.000000\n",
      "DWS_advanced                   0.000000\n",
      "WS_advanced                    0.000000\n",
      "WS/40_advanced                 0.431965\n",
      "PER_advanced                   0.647948\n",
      "FG_per_poss                    0.647948\n",
      "FGA_per_poss                   0.647948\n",
      "2P_per_poss                    0.647948\n",
      "2PA_per_poss                   0.647948\n",
      "3P_per_poss                    0.647948\n",
      "3PA_per_poss                   0.647948\n",
      "FT_per_poss                    0.647948\n",
      "FTA_per_poss                   0.647948\n",
      "TRB_per_poss                   0.647948\n",
      "AST_per_poss                   0.647948\n",
      "STL_per_poss                   0.647948\n",
      "BLK_per_poss                   0.647948\n",
      "TOV_per_poss                   0.647948\n",
      "PF_per_poss                    0.647948\n",
      "PTS_per_poss                   0.647948\n",
      "ORtg_per_poss                  0.647948\n",
      "DRtg_per_poss                  0.647948\n",
      "Experience                     0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#컬럼별 결측치 비율 확인\n",
    "missing_counts = data_avg.isnull().sum()\n",
    "missing_ratios = (missing_counts / len(data_avg)) * 100\n",
    "print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "1a72a5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft_year                     0.0\n",
      "Name                           0.0\n",
      "Pos                            0.0\n",
      "Height_cm                      0.0\n",
      "Weight_kg                      0.0\n",
      "Draft_team                     0.0\n",
      "Draft_overall                  0.0\n",
      "Standing_Reach_inch            0.0\n",
      "Wingspan_inch                  0.0\n",
      "LANE_AGILITY_sec               0.0\n",
      "THREE_QUATER_SPRINT            0.0\n",
      "STANDING_VERTICAL_LEAP_inch    0.0\n",
      "MAX_VERTICAL_LEAP_inch         0.0\n",
      "G_totals                       0.0\n",
      "MP_totals                      0.0\n",
      "FG_totals                      0.0\n",
      "FGA_totals                     0.0\n",
      "FG%_totals                     0.0\n",
      "2P_totals                      0.0\n",
      "2PA_totals                     0.0\n",
      "2P%_totals                     0.0\n",
      "3P_totals                      0.0\n",
      "3PA_totals                     0.0\n",
      "3P%_totals                     0.0\n",
      "FT_totals                      0.0\n",
      "FTA_totals                     0.0\n",
      "FT%_totals                     0.0\n",
      "TRB_totals                     0.0\n",
      "AST_totals                     0.0\n",
      "STL_totals                     0.0\n",
      "BLK_totals                     0.0\n",
      "TOV_totals                     0.0\n",
      "PF_totals                      0.0\n",
      "PTS_totals                     0.0\n",
      "FG_per_min                     0.0\n",
      "FGA_per_min                    0.0\n",
      "2P_per_min                     0.0\n",
      "2PA_per_min                    0.0\n",
      "3P_per_min                     0.0\n",
      "3PA_per_min                    0.0\n",
      "FT_per_min                     0.0\n",
      "FTA_per_min                    0.0\n",
      "TRB_per_min                    0.0\n",
      "AST_per_min                    0.0\n",
      "STL_per_min                    0.0\n",
      "BLK_per_min                    0.0\n",
      "TOV_per_min                    0.0\n",
      "PF_per_min                     0.0\n",
      "PTS_per_min                    0.0\n",
      "TS%_advanced                   0.0\n",
      "eFG%_advanced                  0.0\n",
      "3PAr_advanced                  0.0\n",
      "FTr_advanced                   0.0\n",
      "PProd_advanced                 0.0\n",
      "ORB%_advanced                  0.0\n",
      "DRB%_advanced                  0.0\n",
      "TRB%_advanced                  0.0\n",
      "AST%_advanced                  0.0\n",
      "OBPM_advanced                  0.0\n",
      "DBPM_advanced                  0.0\n",
      "BPM_advanced                   0.0\n",
      "STL%_advanced                  0.0\n",
      "BLK%_advanced                  0.0\n",
      "TOV%_advanced                  0.0\n",
      "USG%_advanced                  0.0\n",
      "OWS_advanced                   0.0\n",
      "DWS_advanced                   0.0\n",
      "WS_advanced                    0.0\n",
      "WS/40_advanced                 0.0\n",
      "PER_advanced                   0.0\n",
      "FG_per_poss                    0.0\n",
      "FGA_per_poss                   0.0\n",
      "2P_per_poss                    0.0\n",
      "2PA_per_poss                   0.0\n",
      "3P_per_poss                    0.0\n",
      "3PA_per_poss                   0.0\n",
      "FT_per_poss                    0.0\n",
      "FTA_per_poss                   0.0\n",
      "TRB_per_poss                   0.0\n",
      "AST_per_poss                   0.0\n",
      "STL_per_poss                   0.0\n",
      "BLK_per_poss                   0.0\n",
      "TOV_per_poss                   0.0\n",
      "PF_per_poss                    0.0\n",
      "PTS_per_poss                   0.0\n",
      "ORtg_per_poss                  0.0\n",
      "DRtg_per_poss                  0.0\n",
      "Experience                     0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#컬럼별 결측치 비율 확인\n",
    "missing_counts = data_avg.isnull().sum()\n",
    "missing_ratios = (missing_counts / len(data_avg)) * 100\n",
    "print(missing_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "60322f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avg.to_csv(\"data_avg_missing_avg11.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "e04c6408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   5.685723  2.396077  2.776345\n",
      "447     3.0   6.330139  2.396077  2.776345\n",
      "448     5.0   3.542589  2.396077  2.776345\n",
      "449     4.0   3.726965  2.396077  2.776345\n",
      "450     3.0   1.675497  2.396077  2.776345\n",
      "451     2.0   0.763077  2.396077  2.776345\n",
      "452     2.0   4.196525  2.396077  2.776345\n",
      "453     1.0   4.265501  2.396077  2.776345\n",
      "454     2.0   4.859876  2.396077  2.776345\n",
      "455     4.0   7.243961  2.396077  2.776345\n",
      "\n",
      "Overall MAE: 2.3960772870045273, Overall RMSE: 2.7763450854514384\n",
      "\n",
      "Best Parameters: {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data_avg\n",
    "#data_avg 결측치를 포지션별 평균값으로 대체(2차 스탯은 제외->기존대로 결측치 샘플 제거 후 모델링 수행)\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data_avg\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 'Pos' 컬럼을 제외한 나머지 컬럼의 'Pos'별 평균값으로 결측치 대체\n",
    "# for col in data_avg.columns:\n",
    "#     if col not in ['Draft_year','Name', 'Draft_team','Draft_overall', 'Pos', 'Height_cm', 'Weight_kg', target_column]:\n",
    "#         data_avg[col] = data_avg.groupby('Pos')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "        \n",
    "exclude_suffixes = ['_totals', '_min', '_advanced', '_poss']\n",
    "for col in data_avg.columns:\n",
    "    if col not in ['Draft_year', 'Name', 'Draft_team', 'Draft_overall', 'Pos', 'Height_cm', 'Weight_kg', target_column] and not any(suffix in col for suffix in exclude_suffixes):\n",
    "        data_avg[col] = data_avg.groupby('Pos')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# 숫자형 컬럼을 소수점 둘째자리에서 반올림\n",
    "numeric_columns = data_avg.select_dtypes(include=['float64', 'int']).columns\n",
    "data_avg[numeric_columns] = data_avg[numeric_columns].round(2)\n",
    "\n",
    "#결측치 샘플 제거(위에서 결측치 평균대체는 combine에 대해서만 진행)\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "        \n",
    "        \n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 표준화를 위한 스케일러 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터 표준화\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA 설정 및 적용\n",
    "n_components = 50\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['sigmoid']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# print(f\"MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "# 실제 값과 예측 값 출력\n",
    "# results_df = pd.DataFrame({'Actual Experience': y_test, 'Predicted Experience': y_pred})\n",
    "# print(results_df)\n",
    "\n",
    "# # 최적의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n",
    "\n",
    "# # 결과 출력\n",
    "# print(results_df.head(10))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "# print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "e35acbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced Samples:\n",
      "Empty DataFrame\n",
      "Columns: [Draft_year, Name, Pos, Height_cm, Weight_kg, Draft_team, Draft_overall, Standing_Reach_inch, Wingspan_inch, LANE_AGILITY_sec, THREE_QUATER_SPRINT, STANDING_VERTICAL_LEAP_inch, MAX_VERTICAL_LEAP_inch, G_totals, MP_totals, FG_totals, FGA_totals, FG%_totals, 2P_totals, 2PA_totals, 2P%_totals, 3P_totals, 3PA_totals, 3P%_totals, FT_totals, FTA_totals, FT%_totals, TRB_totals, AST_totals, STL_totals, BLK_totals, TOV_totals, PF_totals, PTS_totals, FG_per_min, FGA_per_min, 2P_per_min, 2PA_per_min, 3P_per_min, 3PA_per_min, FT_per_min, FTA_per_min, TRB_per_min, AST_per_min, STL_per_min, BLK_per_min, TOV_per_min, PF_per_min, PTS_per_min, TS%_advanced, eFG%_advanced, 3PAr_advanced, FTr_advanced, PProd_advanced, ORB%_advanced, DRB%_advanced, TRB%_advanced, AST%_advanced, OBPM_advanced, DBPM_advanced, BPM_advanced, STL%_advanced, BLK%_advanced, TOV%_advanced, USG%_advanced, OWS_advanced, DWS_advanced, WS_advanced, WS/40_advanced, PER_advanced, FG_per_poss, FGA_per_poss, 2P_per_poss, 2PA_per_poss, 3P_per_poss, 3PA_per_poss, FT_per_poss, FTA_per_poss, TRB_per_poss, AST_per_poss, STL_per_poss, BLK_per_poss, TOV_per_poss, PF_per_poss, PTS_per_poss, ORtg_per_poss, DRtg_per_poss, Experience]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 결측치 대체 이후의 샘플 출력\n",
    "replaced_samples = data_avg[data_avg.isnull().any(axis=1)]\n",
    "print(\"Replaced Samples:\")\n",
    "print(replaced_samples.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "32ab5ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "     Actual  Predicted       MAE      RMSE        MAPE\n",
      "446     1.0   5.685723  2.396077  2.776345  136.613426\n",
      "447     3.0   6.330139  2.396077  2.776345  136.613426\n",
      "448     5.0   3.542589  2.396077  2.776345  136.613426\n",
      "449     4.0   3.726965  2.396077  2.776345  136.613426\n",
      "450     3.0   1.675497  2.396077  2.776345  136.613426\n",
      "451     2.0   0.763077  2.396077  2.776345  136.613426\n",
      "452     2.0   4.196525  2.396077  2.776345  136.613426\n",
      "453     1.0   4.265501  2.396077  2.776345  136.613426\n",
      "454     2.0   4.859876  2.396077  2.776345  136.613426\n",
      "455     4.0   7.243961  2.396077  2.776345  136.613426\n",
      "\n",
      "Overall MAE: 2.3960772870045273, Overall RMSE: 2.7763450854514384\n",
      "\n",
      "Best Parameters: {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "\n",
      "Best Model Parameters:\n",
      "{'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data_avg\n",
    "#data_avg 결측치를 포지션별 평균값으로 대체(2차 스탯은 제외->기존대로 결측치 샘플 제거 후 모델링 수행)\n",
    "#MAPE 추가(y_pred 또는 y_test의 값이 0인 경우는 계산에서 제외)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#4\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data_avg\n",
    "#data_avg 결측치를 포지션별 평균값으로 대체(2차 스탯은 제외->기존대로 결측치 샘플 제거 후 모델링 수행)\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data_avg\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 'Pos' 컬럼을 제외한 나머지 컬럼의 'Pos'별 평균값으로 결측치 대체\n",
    "# for col in data_avg.columns:\n",
    "#     if col not in ['Draft_year','Name', 'Draft_team','Draft_overall', 'Pos', 'Height_cm', 'Weight_kg', target_column]:\n",
    "#         data_avg[col] = data_avg.groupby('Pos')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "        \n",
    "exclude_suffixes = ['_totals', '_min', '_advanced', '_poss']\n",
    "for col in data_avg.columns:\n",
    "    if col not in ['Draft_year', 'Name', 'Draft_team', 'Draft_overall', 'Pos', 'Height_cm', 'Weight_kg', target_column] and not any(suffix in col for suffix in exclude_suffixes):\n",
    "        data_avg[col] = data_avg.groupby('Pos')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# 숫자형 컬럼을 소수점 둘째자리에서 반올림\n",
    "numeric_columns = data_avg.select_dtypes(include=['float64', 'int']).columns\n",
    "data_avg[numeric_columns] = data_avg[numeric_columns].round(2)\n",
    "\n",
    "#결측치 샘플 제거(위에서 결측치 평균대체는 combine에 대해서만 진행)\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "        \n",
    "        \n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# train_data = data_avg[(data_avg['Draft_year'] >= 2000) & (data_avg['Draft_year'] <= 2016)]\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# # 'Draft_year'가 '2017'인 샘플을 테스트 데이터로 설정\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 표준화를 위한 스케일러 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터 표준화\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA 설정 및 적용\n",
    "n_components = 50\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['sigmoid']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "def calculate_mape(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    # 실제 값(y_test)이 0인 경우만 제외하고 MAPE 계산\n",
    "    nonzero_mask = (y_test != 0)\n",
    "    y_test_nonzero = y_test[nonzero_mask]\n",
    "#     y_pred_nonzero = y_pred[nonzero_mask]\n",
    "    if len(y_test_nonzero) == 0:\n",
    "        return np.nan  # Avoid division by zero\n",
    "    mape = np.mean(np.abs((y_test_nonzero - y_pred) / y_test_nonzero)) * 100\n",
    "    return mape\n",
    "\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = calculate_mape(y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'MAPE': mape\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8af8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdfe876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87afca59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7ec9fae",
   "metadata": {},
   "source": [
    "<h3> 3.1.7. Linear regression <h3> <br/><br/><h4>- PCA <br/><br/>- 데이터정규화 <br/><br/> - cross validation<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "d4139f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   7.448961  3.482541  4.280313\n",
      "447     3.0   7.692308  3.482541  4.280313\n",
      "448     5.0   5.172698  3.482541  4.280313\n",
      "449     4.0   4.463425  3.482541  4.280313\n",
      "450     3.0   1.831409  3.482541  4.280313\n",
      "451     2.0   1.639307  3.482541  4.280313\n",
      "452     2.0   6.676081  3.482541  4.280313\n",
      "453     1.0   4.655792  3.482541  4.280313\n",
      "454     2.0   6.638099  3.482541  4.280313\n",
      "455     4.0  10.381140  3.482541  4.280313\n",
      "\n",
      "Best Parameters: {'alpha': 1}\n",
      "\n",
      "Overall MAE: 3.4825414806776696, Overall RMSE: 4.280312977223901\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#연도별\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#split\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "e1cd3b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   7.239370  3.318656  4.001784\n",
      "447     3.0   7.875713  3.318656  4.001784\n",
      "448     5.0   5.330681  3.318656  4.001784\n",
      "449     4.0   4.270037  3.318656  4.001784\n",
      "450     3.0   1.629565  3.318656  4.001784\n",
      "451     2.0   1.377944  3.318656  4.001784\n",
      "452     2.0   5.796173  3.318656  4.001784\n",
      "453     1.0   4.877080  3.318656  4.001784\n",
      "454     2.0   6.542524  3.318656  4.001784\n",
      "455     4.0   9.575531  3.318656  4.001784\n",
      "\n",
      "Best Parameters: {'alpha': 1}\n",
      "\n",
      "Overall MAE: 3.318655749294333, Overall RMSE: 4.00178439082303\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "#연도별\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data_avg\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "41953b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   4.437483  2.991061  3.911318\n",
      "449     4.0   4.618038  2.991061  3.911318\n",
      "450     3.0   1.502061  2.991061  3.911318\n",
      "451     2.0   1.613565  2.991061  3.911318\n",
      "452     2.0   4.764300  2.991061  3.911318\n",
      "453     1.0   4.128509  2.991061  3.911318\n",
      "454     2.0   5.855105  2.991061  3.911318\n",
      "455     4.0  11.036757  2.991061  3.911318\n",
      "456     3.0   4.996570  2.991061  3.911318\n",
      "457     1.0   7.511339  2.991061  3.911318\n",
      "\n",
      "Best Parameters: {'alpha': 100}\n",
      "\n",
      "Overall MAE: 2.991060781706743, Overall RMSE: 3.911317955995524\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 100, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "59d64a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   4.034923  2.716932  3.403572\n",
      "449     4.0   4.198594  2.716932  3.403572\n",
      "450     3.0   0.675498  2.716932  3.403572\n",
      "451     2.0   0.638081  2.716932  3.403572\n",
      "452     2.0   3.902261  2.716932  3.403572\n",
      "453     1.0   4.515602  2.716932  3.403572\n",
      "454     2.0   6.106285  2.716932  3.403572\n",
      "455     4.0   9.423127  2.716932  3.403572\n",
      "456     3.0   4.081349  2.716932  3.403572\n",
      "457     1.0   7.283517  2.716932  3.403572\n",
      "\n",
      "Best Parameters: {'alpha': 100}\n",
      "\n",
      "Overall MAE: 2.7169321588700797, Overall RMSE: 3.403572493419074\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 100, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data_avg\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "dfb09d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "225     2.0   4.711144  3.638843  4.447356\n",
      "30     11.0   6.987490  3.638843  4.447356\n",
      "39      2.0   5.173437  3.638843  4.447356\n",
      "222     0.0   2.711202  3.638843  4.447356\n",
      "124     1.0   6.192890  3.638843  4.447356\n",
      "203     0.0   5.586003  3.638843  4.447356\n",
      "310     2.0   7.718123  3.638843  4.447356\n",
      "211    11.0   4.328525  3.638843  4.447356\n",
      "457     1.0   7.085597  3.638843  4.447356\n",
      "77     13.0   4.796551  3.638843  4.447356\n",
      "\n",
      "Best Parameters: {'alpha': 10}\n",
      "\n",
      "Overall MAE: 3.6388427904365126, Overall RMSE: 4.447355529680433\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 10, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "#split\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#split\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "4a59dd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "126    15.0   6.988268  3.394308  4.045652\n",
      "30     11.0   7.078773  3.394308  4.045652\n",
      "202    14.0   6.041275  3.394308  4.045652\n",
      "442     1.0   4.930753  3.394308  4.045652\n",
      "157    14.0   7.128141  3.394308  4.045652\n",
      "228     2.0   4.709101  3.394308  4.045652\n",
      "409     2.0   2.812399  3.394308  4.045652\n",
      "299     8.0   7.867650  3.394308  4.045652\n",
      "225     2.0   4.884282  3.394308  4.045652\n",
      "76      1.0   5.422032  3.394308  4.045652\n",
      "\n",
      "Best Parameters: {'alpha': 1}\n",
      "\n",
      "Overall MAE: 3.394307609844381, Overall RMSE: 4.045652324386302\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "#split\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data_avg\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\"  \n",
    "     ]\n",
    "\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "cc0d79e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "350     1.0   5.423903  3.592428  4.438397\n",
      "354     3.0   5.234446  3.592428  4.438397\n",
      "428     1.0   5.128390  3.592428  4.438397\n",
      "60      4.0   0.000000  3.592428  4.438397\n",
      "169     0.0   4.173939  3.592428  4.438397\n",
      "33     13.0   7.166958  3.592428  4.438397\n",
      "76      1.0   4.156388  3.592428  4.438397\n",
      "88     13.0   6.606153  3.592428  4.438397\n",
      "278     3.0   2.982612  3.592428  4.438397\n",
      "461     2.0   5.458017  3.592428  4.438397\n",
      "\n",
      "Best Parameters: {'alpha': 10}\n",
      "\n",
      "Overall MAE: 3.592427855331624, Overall RMSE: 4.438396628309247\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 10, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "#split\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# test_data = data[data['Draft_year'] == 2017]\n",
    "# train_data = data[data['Draft_year'] != 2017]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = best_model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "1654b5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "170     6.0   3.015997  3.698735  4.551384\n",
      "322     1.0   3.176501  3.698735  4.551384\n",
      "457     1.0   7.085818  3.698735  4.551384\n",
      "104    14.0   8.929570  3.698735  4.551384\n",
      "75     15.0   7.712775  3.698735  4.551384\n",
      "441     1.0   4.068844  3.698735  4.551384\n",
      "408     1.0   5.074516  3.698735  4.551384\n",
      "239     0.0   6.196944  3.698735  4.551384\n",
      "42      5.0   7.120245  3.698735  4.551384\n",
      "60      4.0   2.378043  3.698735  4.551384\n",
      "\n",
      "Best Parameters: {'alpha': 100}\n",
      "\n",
      "Overall MAE: 3.698734902192089, Overall RMSE: 4.551384203187508\n",
      "\n",
      "Best Model Parameters:\n",
      "{'alpha': 100, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "#split\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data_avg\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "# train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "# # 표준화를 위한 스케일러 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 훈련 데이터 표준화\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 표준화 (훈련 데이터로 fit된 스케일러 사용)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA 설정 및 적용\n",
    "# n_components = 50\n",
    "# pca = PCA(n_components=n_components, random_state=42)\n",
    "# X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "# X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7800cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb971e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7ee3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9193285e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a109c317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a921e4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f690c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "598c68a0",
   "metadata": {},
   "source": [
    "<h2>Baseline model<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "0eacd38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted      MAE      RMSE\n",
      "446     1.0   7.527114  3.60042  4.332112\n",
      "447     3.0   7.894531  3.60042  4.332112\n",
      "448     5.0   5.445305  3.60042  4.332112\n",
      "449     4.0   4.497922  3.60042  4.332112\n",
      "450     3.0   1.129600  3.60042  4.332112\n",
      "451     2.0   1.002314  3.60042  4.332112\n",
      "452     2.0   6.963720  3.60042  4.332112\n",
      "453     1.0   4.693085  3.60042  4.332112\n",
      "454     2.0   6.852538  3.60042  4.332112\n",
      "455     4.0   9.967621  3.60042  4.332112\n",
      "\n",
      "Overall MAE: 3.600419888209938, Overall RMSE: 4.332111795196711\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#연도별\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#기본 Linear Regression\n",
    "#특정시즌 test\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "9fce0f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   7.139238  3.417135  4.023266\n",
      "447     3.0   7.903143  3.417135  4.023266\n",
      "448     5.0   5.670432  3.417135  4.023266\n",
      "449     4.0   4.295189  3.417135  4.023266\n",
      "450     3.0   0.874833  3.417135  4.023266\n",
      "451     2.0   0.740010  3.417135  4.023266\n",
      "452     2.0   6.023588  3.417135  4.023266\n",
      "453     1.0   4.914994  3.417135  4.023266\n",
      "454     2.0   6.706448  3.417135  4.023266\n",
      "455     4.0   9.111064  3.417135  4.023266\n",
      "\n",
      "Overall MAE: 3.4171354696021665, Overall RMSE: 4.023265999248833\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "#연도별\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#기본 Linear Regression\n",
    "#특정시즌 test\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "e4e58a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   3.817969  2.694128  3.483883\n",
      "449     4.0   4.277793  2.694128  3.483883\n",
      "450     3.0   2.124100  2.694128  3.483883\n",
      "451     2.0   3.066270  2.694128  3.483883\n",
      "452     2.0   3.508461  2.694128  3.483883\n",
      "453     1.0   2.837378  2.694128  3.483883\n",
      "454     2.0   6.355486  2.694128  3.483883\n",
      "455     4.0  11.269201  2.694128  3.483883\n",
      "456     3.0   6.211723  2.694128  3.483883\n",
      "457     1.0   7.157983  2.694128  3.483883\n",
      "\n",
      "Overall MAE: 2.6941281030010775, Overall RMSE: 3.4838830576007283\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#기본 Linear Regression\n",
    "#특정시즌 test\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "cb341bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   3.388136  2.662368  3.347304\n",
      "449     4.0   4.381663  2.662368  3.347304\n",
      "450     3.0   2.533166  2.662368  3.347304\n",
      "451     2.0   3.754366  2.662368  3.347304\n",
      "452     2.0   2.317393  2.662368  3.347304\n",
      "453     1.0   3.205529  2.662368  3.347304\n",
      "454     2.0   8.593732  2.662368  3.347304\n",
      "455     4.0   9.672792  2.662368  3.347304\n",
      "456     3.0   5.784742  2.662368  3.347304\n",
      "457     1.0   6.753985  2.662368  3.347304\n",
      "\n",
      "Overall MAE: 2.662367653707239, Overall RMSE: 3.3473043316424507\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#기본 Linear Regression\n",
    "#특정시즌 test\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "b3a41f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted       MAE      RMSE\n",
      "225     2.0   4.250493  3.688707  4.442199\n",
      "30     11.0   7.135530  3.688707  4.442199\n",
      "39      2.0   5.272018  3.688707  4.442199\n",
      "222     0.0   2.028962  3.688707  4.442199\n",
      "124     1.0   5.994123  3.688707  4.442199\n",
      "203     0.0   5.616639  3.688707  4.442199\n",
      "310     2.0   7.590469  3.688707  4.442199\n",
      "211    11.0   4.300346  3.688707  4.442199\n",
      "457     1.0   7.611642  3.688707  4.442199\n",
      "77     13.0   5.033142  3.688707  4.442199\n",
      "454     2.0   7.140177  3.688707  4.442199\n",
      "398     2.0   3.610289  3.688707  4.442199\n",
      "76      1.0   4.282822  3.688707  4.442199\n",
      "386     3.0   6.030628  3.688707  4.442199\n",
      "278     3.0   0.622692  3.688707  4.442199\n",
      "271    11.0   5.486001  3.688707  4.442199\n",
      "70      4.0   6.925527  3.688707  4.442199\n",
      "93     16.0  10.212520  3.688707  4.442199\n",
      "157    14.0   7.067534  3.688707  4.442199\n",
      "0       3.0   6.287042  3.688707  4.442199\n",
      "388     5.0   3.763846  3.688707  4.442199\n",
      "82      3.0   5.596231  3.688707  4.442199\n",
      "368     2.0   5.728452  3.688707  4.442199\n",
      "357     7.0   4.328194  3.688707  4.442199\n",
      "420     4.0   5.347800  3.688707  4.442199\n",
      "307     3.0   7.802904  3.688707  4.442199\n",
      "172    10.0   4.934890  3.688707  4.442199\n",
      "176     4.0   3.570886  3.688707  4.442199\n",
      "18      7.0   8.155143  3.688707  4.442199\n",
      "9       0.0   4.760047  3.688707  4.442199\n",
      "428     1.0   3.713066  3.688707  4.442199\n",
      "448     5.0   5.321540  3.688707  4.442199\n",
      "73     14.0   2.967267  3.688707  4.442199\n",
      "234     1.0   3.880765  3.688707  4.442199\n",
      "287    10.0   8.564912  3.688707  4.442199\n",
      "408     1.0   2.992305  3.688707  4.442199\n",
      "55     14.0   8.078322  3.688707  4.442199\n",
      "90     13.0   4.889536  3.688707  4.442199\n",
      "364     6.0   5.775040  3.688707  4.442199\n",
      "79      0.0   3.569037  3.688707  4.442199\n",
      "325     1.0   6.481079  3.688707  4.442199\n",
      "450     3.0   0.713336  3.688707  4.442199\n",
      "209     4.0   6.540413  3.688707  4.442199\n",
      "173    16.0   6.044862  3.688707  4.442199\n",
      "185     8.0   4.794344  3.688707  4.442199\n",
      "72      0.0   3.731675  3.688707  4.442199\n",
      "148     8.0   6.349225  3.688707  4.442199\n",
      "78      2.0   2.911310  3.688707  4.442199\n",
      "126    15.0   7.190134  3.688707  4.442199\n",
      "132     0.0   9.059914  3.688707  4.442199\n",
      "\n",
      "Overall MAE: 3.6887072506799545, Overall RMSE: 4.442199379036166\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "#split\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#기본 Linear Regression\n",
    "#data split test\n",
    "#기본 stat으로 예측\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# test_data = data[data['Draft_year'] == 2017]\n",
    "# train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred_raw = model.predict(X_test)\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(50))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "5e690f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted       MAE      RMSE\n",
      "126    15.0   7.051950  3.433688  4.052011\n",
      "30     11.0   7.329318  3.433688  4.052011\n",
      "202    14.0   6.050596  3.433688  4.052011\n",
      "442     1.0   4.805163  3.433688  4.052011\n",
      "157    14.0   7.015959  3.433688  4.052011\n",
      "228     2.0   5.031053  3.433688  4.052011\n",
      "409     2.0   2.946042  3.433688  4.052011\n",
      "299     8.0   7.604630  3.433688  4.052011\n",
      "225     2.0   4.735302  3.433688  4.052011\n",
      "76      1.0   5.483253  3.433688  4.052011\n",
      "454     2.0   7.364045  3.433688  4.052011\n",
      "345     5.0   7.578211  3.433688  4.052011\n",
      "79      0.0   3.728335  3.433688  4.052011\n",
      "335     5.0   8.008406  3.433688  4.052011\n",
      "248    11.0   7.894988  3.433688  4.052011\n",
      "420     4.0   5.414508  3.433688  4.052011\n",
      "213    10.0   8.064289  3.433688  4.052011\n",
      "251     3.0   6.161848  3.433688  4.052011\n",
      "450     3.0   1.255537  3.433688  4.052011\n",
      "0       3.0   5.581230  3.433688  4.052011\n",
      "71      4.0   4.686431  3.433688  4.052011\n",
      "265     4.0   4.389953  3.433688  4.052011\n",
      "439     2.0   7.315464  3.433688  4.052011\n",
      "39      2.0   5.151953  3.433688  4.052011\n",
      "211    11.0   4.668043  3.433688  4.052011\n",
      "308     9.0   4.324023  3.433688  4.052011\n",
      "73     14.0   4.370906  3.433688  4.052011\n",
      "83      1.0   5.549699  3.433688  4.052011\n",
      "128     2.0   3.402970  3.433688  4.052011\n",
      "9       0.0   4.980589  3.433688  4.052011\n",
      "55     14.0   8.556430  3.433688  4.052011\n",
      "234     1.0   3.855992  3.433688  4.052011\n",
      "457     1.0   7.403317  3.433688  4.052011\n",
      "297     6.0   5.569298  3.433688  4.052011\n",
      "383     3.0   6.500154  3.433688  4.052011\n",
      "324     3.0   5.837756  3.433688  4.052011\n",
      "412     1.0   5.356930  3.433688  4.052011\n",
      "252     6.0   5.052206  3.433688  4.052011\n",
      "78      2.0   3.633698  3.433688  4.052011\n",
      "326     6.0   4.849254  3.433688  4.052011\n",
      "432     2.0   4.752040  3.433688  4.052011\n",
      "393     4.0   6.059744  3.433688  4.052011\n",
      "171     2.0   6.735415  3.433688  4.052011\n",
      "80      3.0   6.166167  3.433688  4.052011\n",
      "277     4.0   6.371868  3.433688  4.052011\n",
      "440     3.0   0.870793  3.433688  4.052011\n",
      "77     13.0   5.104304  3.433688  4.052011\n",
      "240     4.0   6.973535  3.433688  4.052011\n",
      "428     1.0   4.130352  3.433688  4.052011\n",
      "74      9.0   7.561269  3.433688  4.052011\n",
      "\n",
      "Overall MAE: 3.433688009298206, Overall RMSE: 4.052011081227479\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "#split\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#기본 Linear Regression\n",
    "#data split test\n",
    "#기본 stat으로 예측\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# test_data = data[data['Draft_year'] == 2017]\n",
    "# train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred_raw = model.predict(X_test)\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(50))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "f1863fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted       MAE      RMSE\n",
      "350     1.0   6.596690  3.614092  4.391249\n",
      "354     3.0   4.826316  3.614092  4.391249\n",
      "428     1.0   4.647080  3.614092  4.391249\n",
      "60      4.0   1.428869  3.614092  4.391249\n",
      "169     0.0   4.172857  3.614092  4.391249\n",
      "33     13.0   9.977597  3.614092  4.391249\n",
      "76      1.0   4.753724  3.614092  4.391249\n",
      "88     13.0   7.404892  3.614092  4.391249\n",
      "278     3.0   2.370962  3.614092  4.391249\n",
      "461     2.0   4.346350  3.614092  4.391249\n",
      "11      1.0   8.109353  3.614092  4.391249\n",
      "431     2.0   2.564500  3.614092  4.391249\n",
      "116     8.0   4.484538  3.614092  4.391249\n",
      "459     4.0   3.244430  3.614092  4.391249\n",
      "458     5.0   3.142249  3.614092  4.391249\n",
      "42      5.0   8.147803  3.614092  4.391249\n",
      "457     1.0   8.116703  3.614092  4.391249\n",
      "416     3.0   3.651804  3.614092  4.391249\n",
      "59      2.0   4.937544  3.614092  4.391249\n",
      "451     2.0   3.822525  3.614092  4.391249\n",
      "427     5.0   6.957465  3.614092  4.391249\n",
      "265     4.0   6.864161  3.614092  4.391249\n",
      "454     2.0   6.557370  3.614092  4.391249\n",
      "196    13.0   6.345899  3.614092  4.391249\n",
      "243     6.0   6.530198  3.614092  4.391249\n",
      "125     4.0  11.168003  3.614092  4.391249\n",
      "402     3.0   4.196143  3.614092  4.391249\n",
      "164     2.0   4.719568  3.614092  4.391249\n",
      "368     2.0   5.843843  3.614092  4.391249\n",
      "84      1.0   5.132361  3.614092  4.391249\n",
      "227    11.0   4.950820  3.614092  4.391249\n",
      "405     3.0   0.000000  3.614092  4.391249\n",
      "157    14.0   6.820979  3.614092  4.391249\n",
      "100    12.0   4.834097  3.614092  4.391249\n",
      "240     4.0   9.380735  3.614092  4.391249\n",
      "220     3.0   4.862261  3.614092  4.391249\n",
      "85      2.0   7.222444  3.614092  4.391249\n",
      "327     3.0   0.480910  3.614092  4.391249\n",
      "268     7.0  12.392627  3.614092  4.391249\n",
      "80      3.0   4.166387  3.614092  4.391249\n",
      "74      9.0   8.628368  3.614092  4.391249\n",
      "36     18.0   5.681972  3.614092  4.391249\n",
      "122     4.0   2.385608  3.614092  4.391249\n",
      "316    10.0   7.335639  3.614092  4.391249\n",
      "77     13.0   4.300800  3.614092  4.391249\n",
      "281     3.0   7.273984  3.614092  4.391249\n",
      "403     2.0   8.118998  3.614092  4.391249\n",
      "17      0.0   0.000000  3.614092  4.391249\n",
      "83      1.0   6.391423  3.614092  4.391249\n",
      "310     2.0  10.245435  3.614092  4.391249\n",
      "\n",
      "Overall MAE: 3.6140915578097847, Overall RMSE: 4.391249216664792\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "#split\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#기본 Linear Regression\n",
    "#data split test\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# test_data = data[data['Draft_year'] == 2017]\n",
    "# train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# # 최적화된 모델로 데이터 예측 및 평가\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(50))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "96d0243d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted       MAE      RMSE\n",
      "170     6.0   6.070215  3.698103  4.598474\n",
      "322     1.0   2.002734  3.698103  4.598474\n",
      "457     1.0   6.379592  3.698103  4.598474\n",
      "104    14.0   9.254940  3.698103  4.598474\n",
      "75     15.0   8.559182  3.698103  4.598474\n",
      "441     1.0   2.770581  3.698103  4.598474\n",
      "408     1.0   5.443841  3.698103  4.598474\n",
      "239     0.0   5.761568  3.698103  4.598474\n",
      "42      5.0   8.979293  3.698103  4.598474\n",
      "60      4.0   3.221525  3.698103  4.598474\n",
      "280     1.0   0.000000  3.698103  4.598474\n",
      "461     2.0   3.748335  3.698103  4.598474\n",
      "327     3.0   0.000000  3.698103  4.598474\n",
      "33     13.0  11.200595  3.698103  4.598474\n",
      "449     4.0   4.086064  3.698103  4.598474\n",
      "314     7.0   8.453506  3.698103  4.598474\n",
      "123    13.0   8.962848  3.698103  4.598474\n",
      "242     6.0   2.563151  3.698103  4.598474\n",
      "354     3.0   4.746077  3.698103  4.598474\n",
      "77     13.0   6.522691  3.698103  4.598474\n",
      "91     15.0   7.499916  3.698103  4.598474\n",
      "438     2.0   6.902008  3.698103  4.598474\n",
      "433     3.0   6.419165  3.698103  4.598474\n",
      "357     7.0   0.000000  3.698103  4.598474\n",
      "339     6.0   3.291413  3.698103  4.598474\n",
      "98     13.0   7.524854  3.698103  4.598474\n",
      "11      1.0   6.222978  3.698103  4.598474\n",
      "117    15.0   7.247644  3.698103  4.598474\n",
      "382     5.0   6.667013  3.698103  4.598474\n",
      "83      1.0   5.951449  3.698103  4.598474\n",
      "202    14.0   7.122259  3.698103  4.598474\n",
      "84      1.0   5.175720  3.698103  4.598474\n",
      "61      8.0   7.114554  3.698103  4.598474\n",
      "229     1.0   1.603137  3.698103  4.598474\n",
      "454     2.0   8.328833  3.698103  4.598474\n",
      "381     5.0   6.280150  3.698103  4.598474\n",
      "78      2.0   3.244481  3.698103  4.598474\n",
      "267     9.0   9.842115  3.698103  4.598474\n",
      "36     18.0   6.755635  3.698103  4.598474\n",
      "459     4.0   2.385105  3.698103  4.598474\n",
      "343     3.0   2.796630  3.698103  4.598474\n",
      "458     5.0   3.465900  3.698103  4.598474\n",
      "247    10.0   6.810281  3.698103  4.598474\n",
      "416     3.0   0.000000  3.698103  4.598474\n",
      "17      0.0   0.000000  3.698103  4.598474\n",
      "141    11.0   4.609882  3.698103  4.598474\n",
      "126    15.0   4.625741  3.698103  4.598474\n",
      "0       3.0   5.215816  3.698103  4.598474\n",
      "21     10.0   5.125440  3.698103  4.598474\n",
      "291    10.0   3.248024  3.698103  4.598474\n",
      "\n",
      "Overall MAE: 3.698102578312594, Overall RMSE: 4.598474426083374\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "#split\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "################################################################################\n",
    "################################################################################\n",
    "#data\n",
    "#기본 Linear Regression\n",
    "#data split test\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "## Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# test_data = data[data['Draft_year'] == 2017]\n",
    "# train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "# X_train = train_data[feature_columns]\n",
    "# y_train = train_data[target_column]\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# # 최적화된 모델로 데이터 예측 및 평가\n",
    "# y_pred = model.predict(X_test)\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_raw = model.predict(X_test)\n",
    "\n",
    "# 예측값에서 음수 제거\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(50))\n",
    "# print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06b188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e46dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e55e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60081aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00feb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931fa57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d80bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06c41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90df877d",
   "metadata": {},
   "source": [
    "<h3> 3.1.8. K-NN <h3> <br/><br/><h4><br/><br/>- 데이터정규화 <br/><br/> - cross validation<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "a8a74d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   6.545455  2.727273  3.303517\n",
      "447     3.0   7.636364  2.727273  3.303517\n",
      "448     5.0   4.818182  2.727273  3.303517\n",
      "449     4.0   6.818182  2.727273  3.303517\n",
      "450     3.0   2.363636  2.727273  3.303517\n",
      "451     2.0   2.454545  2.727273  3.303517\n",
      "452     2.0   4.363636  2.727273  3.303517\n",
      "453     1.0   5.909091  2.727273  3.303517\n",
      "454     2.0   5.000000  2.727273  3.303517\n",
      "455     4.0   6.181818  2.727273  3.303517\n",
      "\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "\n",
      "Overall MAE: 2.7272727272727275, Overall RMSE: 3.303516783746659\n",
      "\n",
      "Best Model Parameters:\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'manhattan', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 11, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#연도별\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "ede3281a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   4.680665  2.654173  3.125253\n",
      "447     3.0   6.812546  2.654173  3.125253\n",
      "448     5.0   4.098719  2.654173  3.125253\n",
      "449     4.0   7.014418  2.654173  3.125253\n",
      "450     3.0   2.769542  2.654173  3.125253\n",
      "451     2.0   2.558649  2.654173  3.125253\n",
      "452     2.0   5.375803  2.654173  3.125253\n",
      "453     1.0   6.509286  2.654173  3.125253\n",
      "454     2.0   5.889141  2.654173  3.125253\n",
      "455     4.0   6.667670  2.654173  3.125253\n",
      "\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "\n",
      "Overall MAE: 2.654172929368716, Overall RMSE: 3.125253248842662\n",
      "\n",
      "Best Model Parameters:\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'manhattan', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 11, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "#연도별\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data_avg\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# 데이터 분할 및 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "49fd1d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "     Actual  Predicted      MAE      RMSE\n",
      "448     5.0   4.090909  2.87013  3.380792\n",
      "449     4.0   6.727273  2.87013  3.380792\n",
      "450     3.0   2.636364  2.87013  3.380792\n",
      "451     2.0   2.727273  2.87013  3.380792\n",
      "452     2.0   5.545455  2.87013  3.380792\n",
      "453     1.0   5.454545  2.87013  3.380792\n",
      "454     2.0   5.454545  2.87013  3.380792\n",
      "455     4.0   7.363636  2.87013  3.380792\n",
      "456     3.0   5.272727  2.87013  3.380792\n",
      "457     1.0   6.181818  2.87013  3.380792\n",
      "\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "\n",
      "Overall MAE: 2.87012987012987, Overall RMSE: 3.3807916330521914\n",
      "\n",
      "Best Model Parameters:\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'manhattan', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 11, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "43417aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   5.091655  2.540566  3.123092\n",
      "449     4.0   7.158543  2.540566  3.123092\n",
      "450     3.0   3.128278  2.540566  3.123092\n",
      "451     2.0   2.711433  2.540566  3.123092\n",
      "452     2.0   3.916791  2.540566  3.123092\n",
      "453     1.0   6.143957  2.540566  3.123092\n",
      "454     2.0   6.709053  2.540566  3.123092\n",
      "455     4.0   7.656984  2.540566  3.123092\n",
      "456     3.0   4.727487  2.540566  3.123092\n",
      "457     1.0   5.800101  2.540566  3.123092\n",
      "\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "\n",
      "Overall MAE: 2.54056566500379, Overall RMSE: 3.1230922069965015\n",
      "\n",
      "Best Model Parameters:\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'manhattan', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 11, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data_avg\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "# 데이터 분할 및 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "8e4dcf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "225     2.0   4.909091  3.941349  4.703678\n",
      "30     11.0   6.909091  3.941349  4.703678\n",
      "39      2.0   6.818182  3.941349  4.703678\n",
      "222     0.0   3.636364  3.941349  4.703678\n",
      "124     1.0   4.181818  3.941349  4.703678\n",
      "203     0.0   4.636364  3.941349  4.703678\n",
      "310     2.0   6.636364  3.941349  4.703678\n",
      "211    11.0   2.000000  3.941349  4.703678\n",
      "457     1.0   6.545455  3.941349  4.703678\n",
      "77     13.0   4.363636  3.941349  4.703678\n",
      "\n",
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "\n",
      "Overall MAE: 3.941348973607039, Overall RMSE: 4.703678241386127\n",
      "\n",
      "Best Model Parameters:\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'euclidean', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 11, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "#split\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "90b160e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "     Actual  Predicted       MAE     RMSE\n",
      "126    15.0   8.772854  3.576887  4.29062\n",
      "30     11.0   7.265157  3.576887  4.29062\n",
      "202    14.0   5.169343  3.576887  4.29062\n",
      "442     1.0   4.030757  3.576887  4.29062\n",
      "157    14.0   8.120354  3.576887  4.29062\n",
      "228     2.0   4.458872  3.576887  4.29062\n",
      "409     2.0   4.888055  3.576887  4.29062\n",
      "299     8.0   5.574516  3.576887  4.29062\n",
      "225     2.0   3.617620  3.576887  4.29062\n",
      "76      1.0   4.300526  3.576887  4.29062\n",
      "\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "\n",
      "Overall MAE: 3.576887134566391, Overall RMSE: 4.290619758302228\n",
      "\n",
      "Best Model Parameters:\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'manhattan', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 11, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "#split\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data_avg\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 데이터 분할 및 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "af84c3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "350     1.0   4.533156  3.414733  4.236103\n",
      "354     3.0   5.256760  3.414733  4.236103\n",
      "428     1.0   4.760931  3.414733  4.236103\n",
      "60      4.0   9.149178  3.414733  4.236103\n",
      "169     0.0   3.426815  3.414733  4.236103\n",
      "33     13.0   3.944506  3.414733  4.236103\n",
      "76      1.0   5.355401  3.414733  4.236103\n",
      "88     13.0   6.481805  3.414733  4.236103\n",
      "278     3.0   2.166031  3.414733  4.236103\n",
      "461     2.0   6.911217  3.414733  4.236103\n",
      "\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "\n",
      "Overall MAE: 3.4147331554356466, Overall RMSE: 4.236103231517045\n",
      "\n",
      "Best Model Parameters:\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'manhattan', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 11, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "#split\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "b971854f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "170     6.0   1.571429  4.129252  5.058453\n",
      "322     1.0   4.000000  4.129252  5.058453\n",
      "457     1.0   4.142857  4.129252  5.058453\n",
      "104    14.0   8.000000  4.129252  5.058453\n",
      "75     15.0   7.000000  4.129252  5.058453\n",
      "441     1.0   4.571429  4.129252  5.058453\n",
      "408     1.0   4.285714  4.129252  5.058453\n",
      "239     0.0   5.000000  4.129252  5.058453\n",
      "42      5.0   8.285714  4.129252  5.058453\n",
      "60      4.0   4.571429  4.129252  5.058453\n",
      "\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "\n",
      "Overall MAE: 4.129251700680272, Overall RMSE: 5.05845326809495\n",
      "\n",
      "Best Model Parameters:\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'manhattan', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "#split\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data_avg\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 예: data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 데이터 분할 및 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 그에 해당하는 모델의 성능 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred_raw = best_model.predict(X_test_scaled)\n",
    "y_pred = np.maximum(y_pred_raw, 0)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(results_df.head(10))\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"\\nOverall MAE: {mae}, Overall RMSE: {rmse}\")\n",
    "\n",
    "# 모델의 파라미터 출력\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28cc821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a96d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b19c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad9721a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca21bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ca85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dabc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8ceed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae2495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599bf78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bcf7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2c803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ce062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ddfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec7eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7da1acea",
   "metadata": {},
   "source": [
    "<h3>3-2. Deep Learning<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab60ad6d",
   "metadata": {},
   "source": [
    "<h3> 3.2.1. MLP <h3> <br/><br/><h4> <br/><br/>- 데이터정규화 <br/><br/> - cross validation<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "46efccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\jupyter\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.30.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\jupyter\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\jupyter\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\jupyter\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\jupyter\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\jupyter\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\jupyter\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\jupyter\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\jupyter\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\jupyter\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\jupyter\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "fbb7e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         # 현재 프로세스에 필요한 만큼의 GPU 메모리만 할당\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     except RuntimeError as e:\n",
    "#         # 메모리 증가가 GPU를 초기화한 후에 설정되어야 하므로 예외 발생\n",
    "#         print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "dc764b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "aabcaf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 463 entries, 0 to 462\n",
      "Data columns (total 95 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Draft_year                   463 non-null    int64  \n",
      " 1   Name                         463 non-null    object \n",
      " 2   Pos                          463 non-null    int64  \n",
      " 3   Height_cm                    463 non-null    float64\n",
      " 4   Weight_kg                    463 non-null    float64\n",
      " 5   Draft_team                   463 non-null    object \n",
      " 6   Draft_overall                463 non-null    int64  \n",
      " 7   Body_fat_pct                 384 non-null    float64\n",
      " 8   Hand_Length_inch             192 non-null    float64\n",
      " 9   Hand_width_inch              192 non-null    float64\n",
      " 10  Height_wo_Shoes              462 non-null    float64\n",
      " 11  Height_w_Shoes               352 non-null    float64\n",
      " 12  Standing_Reach_inch          461 non-null    float64\n",
      " 13  Wingspan_inch                462 non-null    float64\n",
      " 14  LANE_AGILITY_sec             421 non-null    float64\n",
      " 15  SHUTTLE_RUN_sec              78 non-null     float64\n",
      " 16  THREE_QUATER_SPRINT          424 non-null    float64\n",
      " 17  STANDING_VERTICAL_LEAP_inch  428 non-null    float64\n",
      " 18  MAX_VERTICAL_LEAP_inch       427 non-null    float64\n",
      " 19  MAX_BENCH_PRESS              379 non-null    float64\n",
      " 20  G_totals                     463 non-null    float64\n",
      " 21  MP_totals                    463 non-null    float64\n",
      " 22  FG_totals                    463 non-null    float64\n",
      " 23  FGA_totals                   463 non-null    float64\n",
      " 24  FG%_totals                   463 non-null    float64\n",
      " 25  2P_totals                    463 non-null    float64\n",
      " 26  2PA_totals                   463 non-null    float64\n",
      " 27  2P%_totals                   463 non-null    float64\n",
      " 28  3P_totals                    463 non-null    float64\n",
      " 29  3PA_totals                   463 non-null    float64\n",
      " 30  3P%_totals                   463 non-null    float64\n",
      " 31  FT_totals                    463 non-null    float64\n",
      " 32  FTA_totals                   463 non-null    float64\n",
      " 33  FT%_totals                   463 non-null    float64\n",
      " 34  TRB_totals                   463 non-null    float64\n",
      " 35  AST_totals                   463 non-null    float64\n",
      " 36  STL_totals                   463 non-null    float64\n",
      " 37  BLK_totals                   463 non-null    float64\n",
      " 38  TOV_totals                   463 non-null    float64\n",
      " 39  PF_totals                    463 non-null    float64\n",
      " 40  PTS_totals                   463 non-null    float64\n",
      " 41  FG_per_min                   463 non-null    float64\n",
      " 42  FGA_per_min                  463 non-null    float64\n",
      " 43  2P_per_min                   463 non-null    float64\n",
      " 44  2PA_per_min                  463 non-null    float64\n",
      " 45  3P_per_min                   463 non-null    float64\n",
      " 46  3PA_per_min                  463 non-null    float64\n",
      " 47  FT_per_min                   463 non-null    float64\n",
      " 48  FTA_per_min                  463 non-null    float64\n",
      " 49  TRB_per_min                  463 non-null    float64\n",
      " 50  AST_per_min                  463 non-null    float64\n",
      " 51  STL_per_min                  463 non-null    float64\n",
      " 52  BLK_per_min                  463 non-null    float64\n",
      " 53  TOV_per_min                  463 non-null    float64\n",
      " 54  PF_per_min                   463 non-null    float64\n",
      " 55  PTS_per_min                  463 non-null    float64\n",
      " 56  TS%_advanced                 463 non-null    float64\n",
      " 57  eFG%_advanced                463 non-null    float64\n",
      " 58  3PAr_advanced                463 non-null    float64\n",
      " 59  FTr_advanced                 463 non-null    float64\n",
      " 60  PProd_advanced               463 non-null    float64\n",
      " 61  ORB%_advanced                463 non-null    float64\n",
      " 62  DRB%_advanced                463 non-null    float64\n",
      " 63  TRB%_advanced                463 non-null    float64\n",
      " 64  AST%_advanced                463 non-null    float64\n",
      " 65  OBPM_advanced                463 non-null    float64\n",
      " 66  DBPM_advanced                463 non-null    float64\n",
      " 67  BPM_advanced                 463 non-null    float64\n",
      " 68  STL%_advanced                463 non-null    float64\n",
      " 69  BLK%_advanced                463 non-null    float64\n",
      " 70  TOV%_advanced                463 non-null    float64\n",
      " 71  USG%_advanced                463 non-null    float64\n",
      " 72  OWS_advanced                 463 non-null    float64\n",
      " 73  DWS_advanced                 463 non-null    float64\n",
      " 74  WS_advanced                  463 non-null    float64\n",
      " 75  WS/40_advanced               463 non-null    float64\n",
      " 76  PER_advanced                 463 non-null    float64\n",
      " 77  FG_per_poss                  463 non-null    float64\n",
      " 78  FGA_per_poss                 463 non-null    float64\n",
      " 79  2P_per_poss                  463 non-null    float64\n",
      " 80  2PA_per_poss                 463 non-null    float64\n",
      " 81  3P_per_poss                  463 non-null    float64\n",
      " 82  3PA_per_poss                 463 non-null    float64\n",
      " 83  FT_per_poss                  463 non-null    float64\n",
      " 84  FTA_per_poss                 463 non-null    float64\n",
      " 85  TRB_per_poss                 463 non-null    float64\n",
      " 86  AST_per_poss                 463 non-null    float64\n",
      " 87  STL_per_poss                 463 non-null    float64\n",
      " 88  BLK_per_poss                 463 non-null    float64\n",
      " 89  TOV_per_poss                 463 non-null    float64\n",
      " 90  PF_per_poss                  463 non-null    float64\n",
      " 91  PTS_per_poss                 463 non-null    float64\n",
      " 92  ORtg_per_poss                463 non-null    float64\n",
      " 93  DRtg_per_poss                463 non-null    float64\n",
      " 94  Experience                   463 non-null    float64\n",
      "dtypes: float64(90), int64(3), object(2)\n",
      "memory usage: 343.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 변경할 컬럼 리스트\n",
    "columns_to_convert = [\"Draft_year\", \"Draft_overall\", \"Body_fat_pct\", \"Hand_Length_inch\", \"Hand_width_inch\",\"Height_wo_Shoes\", \n",
    "                      \"Height_w_Shoes\", \"Standing_Reach_inch\", \"Wingspan_inch\",\"LANE_AGILITY_sec\", \"SHUTTLE_RUN_sec\", \n",
    "                      \"THREE_QUATER_SPRINT\", \"STANDING_VERTICAL_LEAP_inch\",\"MAX_VERTICAL_LEAP_inch\", \"MAX_BENCH_PRESS\", \n",
    "                      '3P_totals', '3PA_totals', '3P%_totals',\"3P_per_poss\",\"3PA_per_poss\", \"3P_per_min\", \"3PA_per_min\",\"BLK_per_min\", \"3PAr_advanced\",\"Experience\"]  \n",
    "\n",
    "# 컬럼 타입 변경\n",
    "for col in columns_to_convert:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')  # 숫자로 변환할 수 없는 값은 NaN으로 변환됩니다.\n",
    "\n",
    "# 결과 확인\n",
    "print(data.info())\n",
    "\n",
    "# 결과 저장\n",
    "# df.to_csv('path_to_save_modified_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "a4b4e396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Best Model Results:\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   7.425490  3.417172  4.358996\n",
      "447     3.0   7.054049  3.417172  4.358996\n",
      "448     5.0   4.649758  3.417172  4.358996\n",
      "449     4.0   3.777207  3.417172  4.358996\n",
      "450     3.0   2.073951  3.417172  4.358996\n",
      "451     2.0   1.487485  3.417172  4.358996\n",
      "452     2.0   5.228990  3.417172  4.358996\n",
      "453     1.0   2.550966  3.417172  4.358996\n",
      "454     2.0   4.736276  3.417172  4.358996\n",
      "455     4.0  10.041553  3.417172  4.358996\n",
      "456     3.0   4.375559  3.417172  4.358996\n",
      "457     1.0   7.501055  3.417172  4.358996\n",
      "458     5.0   7.080001  3.417172  4.358996\n",
      "459     4.0   1.667209  3.417172  4.358996\n",
      "460     4.0  12.806901  3.417172  4.358996\n",
      "461     2.0   9.529521  3.417172  4.358996\n",
      "446     1.0   7.479333  3.080529  3.700738\n",
      "447     3.0   7.568107  3.080529  3.700738\n",
      "448     5.0   4.165999  3.080529  3.700738\n",
      "449     4.0   3.923634  3.080529  3.700738\n",
      "450     3.0   1.169019  3.080529  3.700738\n",
      "451     2.0   1.123139  3.080529  3.700738\n",
      "452     2.0   6.571291  3.080529  3.700738\n",
      "453     1.0   3.690398  3.080529  3.700738\n",
      "454     2.0   4.943955  3.080529  3.700738\n",
      "455     4.0   6.878789  3.080529  3.700738\n",
      "456     3.0   5.791596  3.080529  3.700738\n",
      "457     1.0   6.374339  3.080529  3.700738\n",
      "458     5.0   4.240369  3.080529  3.700738\n",
      "459     4.0   3.026085  3.080529  3.700738\n",
      "460     4.0   9.354737  3.080529  3.700738\n",
      "461     2.0   8.284160  3.080529  3.700738\n",
      "446     1.0   6.059021  3.133442  4.011886\n",
      "447     3.0   6.484924  3.133442  4.011886\n",
      "448     5.0   4.982220  3.133442  4.011886\n",
      "449     4.0   2.828085  3.133442  4.011886\n",
      "450     3.0   2.056084  3.133442  4.011886\n",
      "451     2.0   1.655108  3.133442  4.011886\n",
      "452     2.0   4.556678  3.133442  4.011886\n",
      "453     1.0   2.836242  3.133442  4.011886\n",
      "454     2.0   4.581644  3.133442  4.011886\n",
      "455     4.0  10.633663  3.133442  4.011886\n",
      "456     3.0   3.443613  3.133442  4.011886\n",
      "457     1.0   7.206295  3.133442  4.011886\n",
      "458     5.0   6.661558  3.133442  4.011886\n",
      "459     4.0   1.575914  3.133442  4.011886\n",
      "460     4.0  11.838049  3.133442  4.011886\n",
      "461     2.0   8.930799  3.133442  4.011886\n",
      "446     1.0   6.564927  3.021301  3.436579\n",
      "447     3.0   6.491815  3.021301  3.436579\n",
      "448     5.0   4.111483  3.021301  3.436579\n",
      "449     4.0   4.494610  3.021301  3.436579\n",
      "450     3.0   0.802654  3.021301  3.436579\n",
      "451     2.0   0.901838  3.021301  3.436579\n",
      "452     2.0   6.303522  3.021301  3.436579\n",
      "453     1.0   3.963410  3.021301  3.436579\n",
      "454     2.0   5.715495  3.021301  3.436579\n",
      "455     4.0   7.103589  3.021301  3.436579\n",
      "456     3.0   5.378522  3.021301  3.436579\n",
      "457     1.0   6.494069  3.021301  3.436579\n",
      "458     5.0   1.258788  3.021301  3.436579\n",
      "459     4.0   3.814906  3.021301  3.436579\n",
      "460     4.0   8.141707  3.021301  3.436579\n",
      "461     2.0   6.578815  3.021301  3.436579\n",
      "446     1.0   3.308104  2.728705  4.144809\n",
      "447     3.0   3.800979  2.728705  4.144809\n",
      "448     5.0   2.084769  2.728705  4.144809\n",
      "449     4.0   3.439035  2.728705  4.144809\n",
      "450     3.0   2.504396  2.728705  4.144809\n",
      "451     2.0   3.878433  2.728705  4.144809\n",
      "452     2.0   2.235155  2.728705  4.144809\n",
      "453     1.0   2.828413  2.728705  4.144809\n",
      "454     2.0   5.450882  2.728705  4.144809\n",
      "455     4.0   5.170414  2.728705  4.144809\n",
      "456     3.0   5.201970  2.728705  4.144809\n",
      "457     1.0   4.379727  2.728705  4.144809\n",
      "458     5.0   6.693916  2.728705  4.144809\n",
      "459     4.0   1.838361  2.728705  4.144809\n",
      "460     4.0   8.638304  2.728705  4.144809\n",
      "461     2.0  15.939543  2.728705  4.144809\n",
      "446     1.0   5.828669  3.156060  3.914437\n",
      "447     3.0   8.596394  3.156060  3.914437\n",
      "448     5.0   2.019135  3.156060  3.914437\n",
      "449     4.0   5.202462  3.156060  3.914437\n",
      "450     3.0   1.722385  3.156060  3.914437\n",
      "451     2.0   1.575634  3.156060  3.914437\n",
      "452     2.0   4.888547  3.156060  3.914437\n",
      "453     1.0   2.918471  3.156060  3.914437\n",
      "454     2.0   3.147902  3.156060  3.914437\n",
      "455     4.0   6.317025  3.156060  3.914437\n",
      "456     3.0   6.090332  3.156060  3.914437\n",
      "457     1.0   8.647585  3.156060  3.914437\n",
      "458     5.0   3.743222  3.156060  3.914437\n",
      "459     4.0   3.473691  3.156060  3.914437\n",
      "460     4.0  10.906558  3.156060  3.914437\n",
      "461     2.0   8.487082  3.156060  3.914437\n",
      "446     1.0   6.233987  3.272647  4.555057\n",
      "447     3.0   6.015339  3.272647  4.555057\n",
      "448     5.0   4.609845  3.272647  4.555057\n",
      "449     4.0   3.835310  3.272647  4.555057\n",
      "450     3.0   2.681512  3.272647  4.555057\n",
      "451     2.0   2.700867  3.272647  4.555057\n",
      "452     2.0   3.104617  3.272647  4.555057\n",
      "453     1.0   3.487268  3.272647  4.555057\n",
      "454     2.0   5.762427  3.272647  4.555057\n",
      "455     4.0  10.630421  3.272647  4.555057\n",
      "456     3.0   5.288205  3.272647  4.555057\n",
      "457     1.0   5.229644  3.272647  4.555057\n",
      "458     5.0   6.042861  3.272647  4.555057\n",
      "459     4.0   2.547851  3.272647  4.555057\n",
      "460     4.0  11.327175  3.272647  4.555057\n",
      "461     2.0  14.214062  3.272647  4.555057\n",
      "446     1.0   8.901597  3.437641  4.085695\n",
      "447     3.0   8.811979  3.437641  4.085695\n",
      "448     5.0   5.601874  3.437641  4.085695\n",
      "449     4.0   6.143608  3.437641  4.085695\n",
      "450     3.0   1.161151  3.437641  4.085695\n",
      "451     2.0   1.116465  3.437641  4.085695\n",
      "452     2.0   5.725288  3.437641  4.085695\n",
      "453     1.0   3.626596  3.437641  4.085695\n",
      "454     2.0   4.938089  3.437641  4.085695\n",
      "455     4.0   6.465669  3.437641  4.085695\n",
      "456     3.0   6.557796  3.437641  4.085695\n",
      "457     1.0   7.495489  3.437641  4.085695\n",
      "458     5.0   3.068436  3.437641  4.085695\n",
      "459     4.0   3.464691  3.437641  4.085695\n",
      "460     4.0   9.158602  3.437641  4.085695\n",
      "461     2.0   8.386408  3.437641  4.085695\n",
      "446     1.0   8.170863  3.825140  4.891419\n",
      "447     3.0   8.667186  3.825140  4.891419\n",
      "448     5.0   4.433388  3.825140  4.891419\n",
      "449     4.0   3.863788  3.825140  4.891419\n",
      "450     3.0   2.736854  3.825140  4.891419\n",
      "451     2.0   2.343207  3.825140  4.891419\n",
      "452     2.0   4.502583  3.825140  4.891419\n",
      "453     1.0   2.836387  3.825140  4.891419\n",
      "454     2.0   5.298595  3.825140  4.891419\n",
      "455     4.0  11.053349  3.825140  4.891419\n",
      "456     3.0   4.462703  3.825140  4.891419\n",
      "457     1.0   6.536915  3.825140  4.891419\n",
      "458     5.0   9.210617  3.825140  4.891419\n",
      "459     4.0   1.278435  3.825140  4.891419\n",
      "460     4.0  13.797990  3.825140  4.891419\n",
      "461     2.0  10.634311  3.825140  4.891419\n",
      "446     1.0   6.493512  2.992572  3.714488\n",
      "447     3.0   7.339981  2.992572  3.714488\n",
      "448     5.0   4.772141  2.992572  3.714488\n",
      "449     4.0   3.726646  2.992572  3.714488\n",
      "450     3.0   1.205177  2.992572  3.714488\n",
      "451     2.0   1.226059  2.992572  3.714488\n",
      "452     2.0   5.858226  2.992572  3.714488\n",
      "453     1.0   3.224922  2.992572  3.714488\n",
      "454     2.0   4.238229  2.992572  3.714488\n",
      "455     4.0   6.301825  2.992572  3.714488\n",
      "456     3.0   6.857185  2.992572  3.714488\n",
      "457     1.0   6.322779  2.992572  3.714488\n",
      "458     5.0   4.576444  2.992572  3.714488\n",
      "459     4.0   2.889387  2.992572  3.714488\n",
      "460     4.0  10.797359  2.992572  3.714488\n",
      "461     2.0   8.842992  2.992572  3.714488\n",
      "446     1.0   7.135769  3.764042  4.675493\n",
      "447     3.0   7.993554  3.764042  4.675493\n",
      "448     5.0   4.842137  3.764042  4.675493\n",
      "449     4.0   3.420285  3.764042  4.675493\n",
      "450     3.0   1.357075  3.764042  4.675493\n",
      "451     2.0   1.150907  3.764042  4.675493\n",
      "452     2.0   4.579758  3.764042  4.675493\n",
      "453     1.0   2.545944  3.764042  4.675493\n",
      "454     2.0   6.348722  3.764042  4.675493\n",
      "455     4.0  10.753096  3.764042  4.675493\n",
      "456     3.0   4.181339  3.764042  4.675493\n",
      "457     1.0   8.000608  3.764042  4.675493\n",
      "458     5.0   8.094599  3.764042  4.675493\n",
      "459     4.0   1.592885  3.764042  4.675493\n",
      "460     4.0  12.886507  3.764042  4.675493\n",
      "461     2.0  10.068066  3.764042  4.675493\n",
      "446     1.0   6.780523  3.139301  3.573312\n",
      "447     3.0   7.121298  3.139301  3.573312\n",
      "448     5.0   4.151917  3.139301  3.573312\n",
      "449     4.0   4.298428  3.139301  3.573312\n",
      "450     3.0   0.436734  3.139301  3.573312\n",
      "451     2.0   0.554572  3.139301  3.573312\n",
      "452     2.0   5.890774  3.139301  3.573312\n",
      "453     1.0   3.743375  3.139301  3.573312\n",
      "454     2.0   5.477834  3.139301  3.573312\n",
      "455     4.0   6.763500  3.139301  3.573312\n",
      "456     3.0   6.150879  3.139301  3.573312\n",
      "457     1.0   6.287344  3.139301  3.573312\n",
      "458     5.0   2.302588  3.139301  3.573312\n",
      "459     4.0   3.462788  3.139301  3.573312\n",
      "460     4.0   9.032973  3.139301  3.573312\n",
      "461     2.0   7.590488  3.139301  3.573312\n",
      "446     1.0   4.511662  3.349183  4.839758\n",
      "447     3.0   6.105906  3.349183  4.839758\n",
      "448     5.0   2.654179  3.349183  4.839758\n",
      "449     4.0   4.210222  3.349183  4.839758\n",
      "450     3.0   1.894835  3.349183  4.839758\n",
      "451     2.0   1.894835  3.349183  4.839758\n",
      "452     2.0   2.136186  3.349183  4.839758\n",
      "453     1.0   3.595435  3.349183  4.839758\n",
      "454     2.0   2.824231  3.349183  4.839758\n",
      "455     4.0   5.861281  3.349183  4.839758\n",
      "456     3.0   6.744961  3.349183  4.839758\n",
      "457     1.0   3.357678  3.349183  4.839758\n",
      "458     5.0  13.300439  3.349183  4.839758\n",
      "459     4.0   1.894835  3.349183  4.839758\n",
      "460     4.0  17.452597  3.349183  4.839758\n",
      "461     2.0   9.825013  3.349183  4.839758\n",
      "446     1.0   8.859596  3.763401  4.829975\n",
      "447     3.0  11.275658  3.763401  4.829975\n",
      "448     5.0   3.809209  3.763401  4.829975\n",
      "449     4.0   9.849682  3.763401  4.829975\n",
      "450     3.0   1.102435  3.763401  4.829975\n",
      "451     2.0   1.847951  3.763401  4.829975\n",
      "452     2.0   2.867540  3.763401  4.829975\n",
      "453     1.0   3.033203  3.763401  4.829975\n",
      "454     2.0   4.585932  3.763401  4.829975\n",
      "455     4.0   4.955085  3.763401  4.829975\n",
      "456     3.0   5.220180  3.763401  4.829975\n",
      "457     1.0   9.026699  3.763401  4.829975\n",
      "458     5.0   2.466318  3.763401  4.829975\n",
      "459     4.0   3.341922  3.763401  4.829975\n",
      "460     4.0  10.881067  3.763401  4.829975\n",
      "461     2.0  10.227610  3.763401  4.829975\n",
      "446     1.0   4.412034  2.602901  3.814845\n",
      "447     3.0   5.336298  2.602901  3.814845\n",
      "448     5.0   2.910808  2.602901  3.814845\n",
      "449     4.0   3.541534  2.602901  3.814845\n",
      "450     3.0   2.029131  2.602901  3.814845\n",
      "451     2.0   2.029131  2.602901  3.814845\n",
      "452     2.0   2.194855  2.602901  3.814845\n",
      "453     1.0   2.233372  2.602901  3.814845\n",
      "454     2.0   5.757041  2.602901  3.814845\n",
      "455     4.0   6.173184  2.602901  3.814845\n",
      "456     3.0   3.407834  2.602901  3.814845\n",
      "457     1.0   6.306042  2.602901  3.814845\n",
      "458     5.0   5.768443  2.602901  3.814845\n",
      "459     4.0   2.407101  2.602901  3.814845\n",
      "460     4.0   9.692844  2.602901  3.814845\n",
      "461     2.0  13.223909  2.602901  3.814845\n",
      "446     1.0   7.337527  3.258314  3.980663\n",
      "447     3.0   7.696949  3.258314  3.980663\n",
      "448     5.0   3.653488  3.258314  3.980663\n",
      "449     4.0   4.132676  3.258314  3.980663\n",
      "450     3.0   1.975563  3.258314  3.980663\n",
      "451     2.0   2.266037  3.258314  3.980663\n",
      "452     2.0   6.415055  3.258314  3.980663\n",
      "453     1.0   3.209346  3.258314  3.980663\n",
      "454     2.0   4.283876  3.258314  3.980663\n",
      "455     4.0   6.303493  3.258314  3.980663\n",
      "456     3.0   6.737835  3.258314  3.980663\n",
      "457     1.0   7.492195  3.258314  3.980663\n",
      "458     5.0   4.084601  3.258314  3.980663\n",
      "459     4.0   1.378502  3.258314  3.980663\n",
      "460     4.0  10.168019  3.258314  3.980663\n",
      "461     2.0   9.182170  3.258314  3.980663\n",
      "\n",
      "Best Model Parameters:\n",
      "{'n_units': 128, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'activation': 'relu'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.602900817990303, 3.43657907091182)"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "#연도별\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# # 데이터 준비\n",
    "# X = merged_all_comb_copy_model[feature_columns]\n",
    "# y = merged_all_comb_copy_model[target_column]\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 구축 및 컴파일 함수\n",
    "def build_model(n_units, learning_rate, dropout_rate, activation):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(n_units, activation=activation, input_shape=(X_train.shape[1],)),  # 수정: input_shape를 X_train의 특성 수에 맞게 설정\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "n_units_options = [64, 128]\n",
    "learning_rate_options = [0.001, 0.01]\n",
    "dropout_rate_options = [0.3, 0.5]\n",
    "activation_options = ['relu', 'tanh']\n",
    "\n",
    "best_model = None\n",
    "best_mae = float('inf')\n",
    "best_rmse = float('inf')\n",
    "best_model_params = None\n",
    "results_table = pd.DataFrame()\n",
    "\n",
    "# 하이퍼파라미터 실험 및 모델 평가\n",
    "for n_units in n_units_options:\n",
    "    for learning_rate in learning_rate_options:\n",
    "        for dropout_rate in dropout_rate_options:\n",
    "            for activation in activation_options:\n",
    "                model = build_model(n_units, learning_rate, dropout_rate, activation)\n",
    "                model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "                y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "                y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "                # 평가 지표 계산\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "\n",
    "                # 최적 모델 업데이트\n",
    "                if mae + rmse < best_mae + best_rmse:\n",
    "                    best_model = model\n",
    "                    best_mae = mae\n",
    "                    best_rmse = rmse\n",
    "                    best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "                # 결과 추가\n",
    "                temp_results = pd.DataFrame({\n",
    "                    'Actual': y_test,\n",
    "                    'Predicted': y_pred,\n",
    "                    'MAE': mae,\n",
    "                    'RMSE': rmse\n",
    "                })\n",
    "                results_table = pd.concat([results_table, temp_results])\n",
    "\n",
    "# 최적 모델의 결과와 파라미터 출력\n",
    "print(\"Best Model Results:\")\n",
    "print(results_table)\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model_params)\n",
    "\n",
    "# 최적 모델의 결과에서 가장 좋은 MAE와 RMSE 값 찾기\n",
    "best_mae = results_table['MAE'].min()\n",
    "best_rmse = results_table['RMSE'].min()\n",
    "\n",
    "best_mae, best_rmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "0a68feda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Best Model Results:\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "446     1.0   5.729528  2.604843  3.286461\n",
      "447     3.0   7.196689  2.604843  3.286461\n",
      "448     5.0   4.492699  2.604843  3.286461\n",
      "449     4.0   3.077859  2.604843  3.286461\n",
      "450     3.0   3.041644  2.604843  3.286461\n",
      "451     2.0   2.312771  2.604843  3.286461\n",
      "452     2.0   3.361892  2.604843  3.286461\n",
      "453     1.0   2.934568  2.604843  3.286461\n",
      "454     2.0   4.501396  2.604843  3.286461\n",
      "455     4.0   7.205578  2.604843  3.286461\n",
      "456     3.0   2.923303  2.604843  3.286461\n",
      "457     1.0   7.357630  2.604843  3.286461\n",
      "458     5.0   7.050977  2.604843  3.286461\n",
      "459     4.0   1.199522  2.604843  3.286461\n",
      "460     4.0   9.272696  2.604843  3.286461\n",
      "461     2.0   7.405503  2.604843  3.286461\n",
      "446     1.0   6.102600  2.633103  3.140462\n",
      "447     3.0   7.248217  2.633103  3.140462\n",
      "448     5.0   3.707009  2.633103  3.140462\n",
      "449     4.0   4.687681  2.633103  3.140462\n",
      "450     3.0   2.863070  2.633103  3.140462\n",
      "451     2.0   2.698430  2.633103  3.140462\n",
      "452     2.0   4.557558  2.633103  3.140462\n",
      "453     1.0   4.154144  2.633103  3.140462\n",
      "454     2.0   5.389943  2.633103  3.140462\n",
      "455     4.0   4.993482  2.633103  3.140462\n",
      "456     3.0   5.474251  2.633103  3.140462\n",
      "457     1.0   5.761094  2.633103  3.140462\n",
      "458     5.0   2.589949  2.633103  3.140462\n",
      "459     4.0   3.489486  2.633103  3.140462\n",
      "460     4.0   8.658036  2.633103  3.140462\n",
      "461     2.0   7.053732  2.633103  3.140462\n",
      "446     1.0   5.226077  2.555147  3.294859\n",
      "447     3.0   7.203913  2.555147  3.294859\n",
      "448     5.0   4.287894  2.555147  3.294859\n",
      "449     4.0   2.716136  2.555147  3.294859\n",
      "450     3.0   2.685506  2.555147  3.294859\n",
      "451     2.0   2.167585  2.555147  3.294859\n",
      "452     2.0   3.797302  2.555147  3.294859\n",
      "453     1.0   2.574180  2.555147  3.294859\n",
      "454     2.0   4.221438  2.555147  3.294859\n",
      "455     4.0   8.749762  2.555147  3.294859\n",
      "456     3.0   2.898828  2.555147  3.294859\n",
      "457     1.0   6.972468  2.555147  3.294859\n",
      "458     5.0   5.267379  2.555147  3.294859\n",
      "459     4.0   1.884312  2.555147  3.294859\n",
      "460     4.0   9.663431  2.555147  3.294859\n",
      "461     2.0   7.511486  2.555147  3.294859\n",
      "446     1.0   6.534778  2.877500  3.314748\n",
      "447     3.0   7.033356  2.877500  3.314748\n",
      "448     5.0   3.996070  2.877500  3.314748\n",
      "449     4.0   5.070240  2.877500  3.314748\n",
      "450     3.0   1.232348  2.877500  3.314748\n",
      "451     2.0   1.258347  2.877500  3.314748\n",
      "452     2.0   5.468633  2.877500  3.314748\n",
      "453     1.0   4.927811  2.877500  3.314748\n",
      "454     2.0   5.969505  2.877500  3.314748\n",
      "455     4.0   5.709777  2.877500  3.314748\n",
      "456     3.0   5.409948  2.877500  3.314748\n",
      "457     1.0   6.917557  2.877500  3.314748\n",
      "458     5.0   2.569430  2.877500  3.314748\n",
      "459     4.0   4.304353  2.877500  3.314748\n",
      "460     4.0   7.684064  2.877500  3.314748\n",
      "461     2.0   6.066179  2.877500  3.314748\n",
      "446     1.0   4.357573  2.355870  3.522872\n",
      "447     3.0   6.506770  2.355870  3.522872\n",
      "448     5.0   3.885031  2.355870  3.522872\n",
      "449     4.0   2.063189  2.355870  3.522872\n",
      "450     3.0   1.924740  2.355870  3.522872\n",
      "451     2.0   2.001202  2.355870  3.522872\n",
      "452     2.0   2.330486  2.355870  3.522872\n",
      "453     1.0   2.607949  2.355870  3.522872\n",
      "454     2.0   2.367661  2.355870  3.522872\n",
      "455     4.0   6.767381  2.355870  3.522872\n",
      "456     3.0   4.590857  2.355870  3.522872\n",
      "457     1.0   2.644639  2.355870  3.522872\n",
      "458     5.0   4.367442  2.355870  3.522872\n",
      "459     4.0   2.397411  2.355870  3.522872\n",
      "460     4.0   8.945841  2.355870  3.522872\n",
      "461     2.0  13.211377  2.355870  3.522872\n",
      "446     1.0   5.894994  2.884662  3.717399\n",
      "447     3.0   7.986207  2.884662  3.717399\n",
      "448     5.0   4.191463  2.884662  3.717399\n",
      "449     4.0   3.742244  2.884662  3.717399\n",
      "450     3.0   3.552193  2.884662  3.717399\n",
      "451     2.0   2.966721  2.884662  3.717399\n",
      "452     2.0   3.529871  2.884662  3.717399\n",
      "453     1.0   4.689393  2.884662  3.717399\n",
      "454     2.0   4.562417  2.884662  3.717399\n",
      "455     4.0   5.329795  2.884662  3.717399\n",
      "456     3.0   5.847824  2.884662  3.717399\n",
      "457     1.0   6.587578  2.884662  3.717399\n",
      "458     5.0   4.259094  2.884662  3.717399\n",
      "459     4.0   3.093167  2.884662  3.717399\n",
      "460     4.0  10.858642  2.884662  3.717399\n",
      "461     2.0   9.634931  2.884662  3.717399\n",
      "446     1.0   4.940752  2.240962  3.009805\n",
      "447     3.0   6.518624  2.240962  3.009805\n",
      "448     5.0   4.125649  2.240962  3.009805\n",
      "449     4.0   3.025416  2.240962  3.009805\n",
      "450     3.0   2.644444  2.240962  3.009805\n",
      "451     2.0   2.644444  2.240962  3.009805\n",
      "452     2.0   2.819925  2.240962  3.009805\n",
      "453     1.0   3.645528  2.240962  3.009805\n",
      "454     2.0   3.370146  2.240962  3.009805\n",
      "455     4.0   6.080899  2.240962  3.009805\n",
      "456     3.0   3.269155  2.240962  3.009805\n",
      "457     1.0   4.799176  2.240962  3.009805\n",
      "458     5.0   5.322391  2.240962  3.009805\n",
      "459     4.0   2.772332  2.240962  3.009805\n",
      "460     4.0  10.753187  2.240962  3.009805\n",
      "461     2.0   8.259007  2.240962  3.009805\n",
      "446     1.0   4.676037  2.611813  3.181454\n",
      "447     3.0   7.251966  2.611813  3.181454\n",
      "448     5.0   3.846745  2.611813  3.181454\n",
      "449     4.0   5.863105  2.611813  3.181454\n",
      "450     3.0   2.093293  2.611813  3.181454\n",
      "451     2.0   1.980670  2.611813  3.181454\n",
      "452     2.0   5.638899  2.611813  3.181454\n",
      "453     1.0   4.754455  2.611813  3.181454\n",
      "454     2.0   6.039667  2.611813  3.181454\n",
      "455     4.0   4.519336  2.611813  3.181454\n",
      "456     3.0   4.403973  2.611813  3.181454\n",
      "457     1.0   5.805783  2.611813  3.181454\n",
      "458     5.0   4.057963  2.611813  3.181454\n",
      "459     4.0   3.563557  2.611813  3.181454\n",
      "460     4.0   8.553460  2.611813  3.181454\n",
      "461     2.0   7.824562  2.611813  3.181454\n",
      "446     1.0   6.958724  3.144240  4.045271\n",
      "447     3.0   8.339520  3.144240  4.045271\n",
      "448     5.0   4.599050  3.144240  4.045271\n",
      "449     4.0   3.729853  3.144240  4.045271\n",
      "450     3.0   2.770833  3.144240  4.045271\n",
      "451     2.0   2.647808  3.144240  4.045271\n",
      "452     2.0   3.474656  3.144240  4.045271\n",
      "453     1.0   2.874981  3.144240  4.045271\n",
      "454     2.0   3.756742  3.144240  4.045271\n",
      "455     4.0   8.680692  3.144240  4.045271\n",
      "456     3.0   4.049294  3.144240  4.045271\n",
      "457     1.0   7.253853  3.144240  4.045271\n",
      "458     5.0   7.843454  3.144240  4.045271\n",
      "459     4.0   1.383123  3.144240  4.045271\n",
      "460     4.0  11.685736  3.144240  4.045271\n",
      "461     2.0   9.225234  3.144240  4.045271\n",
      "446     1.0   6.475587  2.679580  3.349635\n",
      "447     3.0   8.276908  2.679580  3.349635\n",
      "448     5.0   2.982357  2.679580  3.349635\n",
      "449     4.0   4.037055  2.679580  3.349635\n",
      "450     3.0   2.104316  2.679580  3.349635\n",
      "451     2.0   1.919672  2.679580  3.349635\n",
      "452     2.0   3.836870  2.679580  3.349635\n",
      "453     1.0   4.175609  2.679580  3.349635\n",
      "454     2.0   5.032312  2.679580  3.349635\n",
      "455     4.0   4.767844  2.679580  3.349635\n",
      "456     3.0   6.205831  2.679580  3.349635\n",
      "457     1.0   6.043119  2.679580  3.349635\n",
      "458     5.0   3.837689  2.679580  3.349635\n",
      "459     4.0   3.733985  2.679580  3.349635\n",
      "460     4.0   8.942849  2.679580  3.349635\n",
      "461     2.0   7.657310  2.679580  3.349635\n",
      "446     1.0   6.358254  2.787077  3.680474\n",
      "447     3.0   7.785076  2.787077  3.680474\n",
      "448     5.0   4.863937  2.787077  3.680474\n",
      "449     4.0   2.945652  2.787077  3.680474\n",
      "450     3.0   2.457281  2.787077  3.680474\n",
      "451     2.0   1.986608  2.787077  3.680474\n",
      "452     2.0   2.778119  2.787077  3.680474\n",
      "453     1.0   2.576177  2.787077  3.680474\n",
      "454     2.0   4.291611  2.787077  3.680474\n",
      "455     4.0   8.898119  2.787077  3.680474\n",
      "456     3.0   3.064163  2.787077  3.680474\n",
      "457     1.0   7.167220  2.787077  3.680474\n",
      "458     5.0   6.417514  2.787077  3.680474\n",
      "459     4.0   1.530942  2.787077  3.680474\n",
      "460     4.0  10.825077  2.787077  3.680474\n",
      "461     2.0   8.216326  2.787077  3.680474\n",
      "446     1.0   5.792861  2.906132  3.392112\n",
      "447     3.0   8.046866  2.906132  3.392112\n",
      "448     5.0   3.901861  2.906132  3.392112\n",
      "449     4.0   4.340979  2.906132  3.392112\n",
      "450     3.0   1.269476  2.906132  3.392112\n",
      "451     2.0   1.243452  2.906132  3.392112\n",
      "452     2.0   5.544934  2.906132  3.392112\n",
      "453     1.0   4.391711  2.906132  3.392112\n",
      "454     2.0   5.952830  2.906132  3.392112\n",
      "455     4.0   5.201227  2.906132  3.392112\n",
      "456     3.0   5.880455  2.906132  3.392112\n",
      "457     1.0   6.164657  2.906132  3.392112\n",
      "458     5.0   2.484602  2.906132  3.392112\n",
      "459     4.0   3.744477  2.906132  3.392112\n",
      "460     4.0   8.913510  2.906132  3.392112\n",
      "461     2.0   6.911952  2.906132  3.392112\n",
      "446     1.0   3.270598  2.274430  3.360992\n",
      "447     3.0   4.933193  2.274430  3.360992\n",
      "448     5.0   2.911105  2.274430  3.360992\n",
      "449     4.0   6.552826  2.274430  3.360992\n",
      "450     3.0   1.623797  2.274430  3.360992\n",
      "451     2.0   1.623797  2.274430  3.360992\n",
      "452     2.0   2.231994  2.274430  3.360992\n",
      "453     1.0   2.600088  2.274430  3.360992\n",
      "454     2.0   1.623797  2.274430  3.360992\n",
      "455     4.0   3.799132  2.274430  3.360992\n",
      "456     3.0   1.683583  2.274430  3.360992\n",
      "457     1.0   2.539145  2.274430  3.360992\n",
      "458     5.0   6.356883  2.274430  3.360992\n",
      "459     4.0   1.623797  2.274430  3.360992\n",
      "460     4.0  11.073269  2.274430  3.360992\n",
      "461     2.0  11.721888  2.274430  3.360992\n",
      "446     1.0   6.176043  3.033875  3.662935\n",
      "447     3.0   9.279511  3.033875  3.662935\n",
      "448     5.0   3.829663  3.033875  3.662935\n",
      "449     4.0   4.963174  3.033875  3.662935\n",
      "450     3.0   4.332680  3.033875  3.662935\n",
      "451     2.0   4.231702  3.033875  3.662935\n",
      "452     2.0   5.014159  3.033875  3.662935\n",
      "453     1.0   4.208937  3.033875  3.662935\n",
      "454     2.0   4.338159  3.033875  3.662935\n",
      "455     4.0   4.861459  3.033875  3.662935\n",
      "456     3.0   5.716048  3.033875  3.662935\n",
      "457     1.0   4.238169  3.033875  3.662935\n",
      "458     5.0   6.081390  3.033875  3.662935\n",
      "459     4.0   2.713162  3.033875  3.662935\n",
      "460     4.0  10.972167  3.033875  3.662935\n",
      "461     2.0   8.671226  3.033875  3.662935\n",
      "446     1.0   5.829938  2.159699  2.775434\n",
      "447     3.0   7.835932  2.159699  2.775434\n",
      "448     5.0   2.909455  2.159699  2.775434\n",
      "449     4.0   4.210028  2.159699  2.775434\n",
      "450     3.0   2.061028  2.159699  2.775434\n",
      "451     2.0   2.061028  2.159699  2.775434\n",
      "452     2.0   2.479036  2.159699  2.775434\n",
      "453     1.0   2.851667  2.159699  2.775434\n",
      "454     2.0   2.902378  2.159699  2.775434\n",
      "455     4.0   6.096836  2.159699  2.775434\n",
      "456     3.0   3.536452  2.159699  2.775434\n",
      "457     1.0   3.664924  2.159699  2.775434\n",
      "458     5.0   3.683140  2.159699  2.775434\n",
      "459     4.0   2.086501  2.159699  2.775434\n",
      "460     4.0   8.109201  2.159699  2.775434\n",
      "461     2.0   7.717888  2.159699  2.775434\n",
      "446     1.0   6.376221  3.192163  4.054245\n",
      "447     3.0  10.154729  3.192163  4.054245\n",
      "448     5.0   4.793755  3.192163  4.054245\n",
      "449     4.0   5.290863  3.192163  4.054245\n",
      "450     3.0   2.924707  3.192163  4.054245\n",
      "451     2.0   2.259152  3.192163  4.054245\n",
      "452     2.0   5.099944  3.192163  4.054245\n",
      "453     1.0   5.401728  3.192163  4.054245\n",
      "454     2.0   6.217340  3.192163  4.054245\n",
      "455     4.0   6.235020  3.192163  4.054245\n",
      "456     3.0   5.669738  3.192163  4.054245\n",
      "457     1.0   4.970515  3.192163  4.054245\n",
      "458     5.0   4.143435  3.192163  4.054245\n",
      "459     4.0   3.237312  3.192163  4.054245\n",
      "460     4.0  11.113990  3.192163  4.054245\n",
      "461     2.0   9.384577  3.192163  4.054245\n",
      "\n",
      "Best Model Parameters:\n",
      "{'n_units': 128, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'activation': 'relu'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.159699007868767, 2.7754341290348012)"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "#연도별\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# # 데이터 준비\n",
    "# X = merged_all_comb_copy_model[feature_columns]\n",
    "# y = merged_all_comb_copy_model[target_column]\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2017]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 구축 및 컴파일 함수\n",
    "def build_model(n_units, learning_rate, dropout_rate, activation):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(n_units, activation=activation, input_shape=(X_train.shape[1],)),  # 수정: input_shape를 X_train의 특성 수에 맞게 설정\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "n_units_options = [64, 128]\n",
    "learning_rate_options = [0.001, 0.01]\n",
    "dropout_rate_options = [0.3, 0.5]\n",
    "activation_options = ['relu', 'tanh']\n",
    "\n",
    "best_model = None\n",
    "best_mae = float('inf')\n",
    "best_rmse = float('inf')\n",
    "best_model_params = None\n",
    "results_table = pd.DataFrame()\n",
    "\n",
    "# 하이퍼파라미터 실험 및 모델 평가\n",
    "for n_units in n_units_options:\n",
    "    for learning_rate in learning_rate_options:\n",
    "        for dropout_rate in dropout_rate_options:\n",
    "            for activation in activation_options:\n",
    "                model = build_model(n_units, learning_rate, dropout_rate, activation)\n",
    "                model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "                y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "                y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "                # 평가 지표 계산\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "\n",
    "                # 최적 모델 업데이트\n",
    "                if mae + rmse < best_mae + best_rmse:\n",
    "                    best_model = model\n",
    "                    best_mae = mae\n",
    "                    best_rmse = rmse\n",
    "                    best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "                # 결과 추가\n",
    "                temp_results = pd.DataFrame({\n",
    "                    'Actual': y_test,\n",
    "                    'Predicted': y_pred,\n",
    "                    'MAE': mae,\n",
    "                    'RMSE': rmse\n",
    "                })\n",
    "                results_table = pd.concat([results_table, temp_results])\n",
    "\n",
    "# 최적 모델의 결과와 파라미터 출력\n",
    "print(\"Best Model Results:\")\n",
    "print(results_table)\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model_params)\n",
    "\n",
    "# 최적 모델의 결과에서 가장 좋은 MAE와 RMSE 값 찾기\n",
    "best_mae = results_table['MAE'].min()\n",
    "best_rmse = results_table['RMSE'].min()\n",
    "\n",
    "best_mae, best_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "fc71ef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Best Model Results:\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "448     5.0   5.423403  3.867541  5.197006\n",
      "449     4.0   4.568167  3.867541  5.197006\n",
      "450     3.0   2.185392  3.867541  5.197006\n",
      "451     2.0   1.164544  3.867541  5.197006\n",
      "452     2.0   4.304038  3.867541  5.197006\n",
      "453     1.0   2.509817  3.867541  5.197006\n",
      "454     2.0   6.639870  3.867541  5.197006\n",
      "455     4.0  13.230279  3.867541  5.197006\n",
      "456     3.0   4.099782  3.867541  5.197006\n",
      "457     1.0   7.160971  3.867541  5.197006\n",
      "458     5.0   9.513252  3.867541  5.197006\n",
      "459     4.0   1.839149  3.867541  5.197006\n",
      "460     4.0  14.068777  3.867541  5.197006\n",
      "461     2.0  11.816303  3.867541  5.197006\n",
      "448     5.0   3.636551  2.768906  3.275016\n",
      "449     4.0   4.844739  2.768906  3.275016\n",
      "450     3.0   0.362835  2.768906  3.275016\n",
      "451     2.0   2.768803  2.768906  3.275016\n",
      "452     2.0   6.704338  2.768906  3.275016\n",
      "453     1.0   3.701329  2.768906  3.275016\n",
      "454     2.0   2.882051  2.768906  3.275016\n",
      "455     4.0   8.633760  2.768906  3.275016\n",
      "456     3.0   4.882296  2.768906  3.275016\n",
      "457     1.0   4.982975  2.768906  3.275016\n",
      "458     5.0   2.739050  2.768906  3.275016\n",
      "459     4.0   3.104822  2.768906  3.275016\n",
      "460     4.0   9.948944  2.768906  3.275016\n",
      "461     2.0   7.258702  2.768906  3.275016\n",
      "448     5.0   4.343591  3.421485  4.722701\n",
      "449     4.0   3.933496  3.421485  4.722701\n",
      "450     3.0   1.232475  3.421485  4.722701\n",
      "451     2.0   0.862074  3.421485  4.722701\n",
      "452     2.0   5.312607  3.421485  4.722701\n",
      "453     1.0   2.393478  3.421485  4.722701\n",
      "454     2.0   4.279035  3.421485  4.722701\n",
      "455     4.0  14.049321  3.421485  4.722701\n",
      "456     3.0   3.355179  3.421485  4.722701\n",
      "457     1.0   7.266024  3.421485  4.722701\n",
      "458     5.0   6.499185  3.421485  4.722701\n",
      "459     4.0   1.503644  3.421485  4.722701\n",
      "460     4.0  13.383233  3.421485  4.722701\n",
      "461     2.0   9.238009  3.421485  4.722701\n",
      "448     5.0   4.144471  2.964641  3.412396\n",
      "449     4.0   4.837462  2.964641  3.412396\n",
      "450     3.0   0.000000  2.964641  3.412396\n",
      "451     2.0   0.000000  2.964641  3.412396\n",
      "452     2.0   6.351405  2.964641  3.412396\n",
      "453     1.0   4.408502  2.964641  3.412396\n",
      "454     2.0   4.812498  2.964641  3.412396\n",
      "455     4.0   8.109091  2.964641  3.412396\n",
      "456     3.0   4.793324  2.964641  3.412396\n",
      "457     1.0   7.337813  2.964641  3.412396\n",
      "458     5.0   3.128438  2.964641  3.412396\n",
      "459     4.0   3.404172  2.964641  3.412396\n",
      "460     4.0   8.231716  2.964641  3.412396\n",
      "461     2.0   7.300243  2.964641  3.412396\n",
      "448     5.0   3.320454  3.513827  5.622296\n",
      "449     4.0   4.915582  3.513827  5.622296\n",
      "450     3.0   2.007377  3.513827  5.622296\n",
      "451     2.0   2.007377  3.513827  5.622296\n",
      "452     2.0   4.604891  3.513827  5.622296\n",
      "453     1.0   2.007377  3.513827  5.622296\n",
      "454     2.0   3.262712  3.513827  5.622296\n",
      "455     4.0  19.248121  3.513827  5.622296\n",
      "456     3.0   5.743539  3.513827  5.622296\n",
      "457     1.0   3.068027  3.513827  5.622296\n",
      "458     5.0   4.731756  3.513827  5.622296\n",
      "459     4.0   2.255972  3.513827  5.622296\n",
      "460     4.0  15.215451  3.513827  5.622296\n",
      "461     2.0   9.436056  3.513827  5.622296\n",
      "448     5.0   4.601804  3.030182  4.047720\n",
      "449     4.0   7.424294  3.030182  4.047720\n",
      "450     3.0   2.071563  3.030182  4.047720\n",
      "451     2.0   0.887062  3.030182  4.047720\n",
      "452     2.0   7.072711  3.030182  4.047720\n",
      "453     1.0   2.355206  3.030182  4.047720\n",
      "454     2.0   2.654357  3.030182  4.047720\n",
      "455     4.0   7.578854  3.030182  4.047720\n",
      "456     3.0   3.458792  3.030182  4.047720\n",
      "457     1.0   5.800418  3.030182  4.047720\n",
      "458     5.0   3.425385  3.030182  4.047720\n",
      "459     4.0   1.941170  3.030182  4.047720\n",
      "460     4.0  12.379541  3.030182  4.047720\n",
      "461     2.0  10.625357  3.030182  4.047720\n",
      "448     5.0   4.740443  3.213331  4.966978\n",
      "449     4.0   4.109056  3.213331  4.966978\n",
      "450     3.0   2.202426  3.213331  4.966978\n",
      "451     2.0   2.202426  3.213331  4.966978\n",
      "452     2.0   4.179377  3.213331  4.966978\n",
      "453     1.0   2.665093  3.213331  4.966978\n",
      "454     2.0   2.612640  3.213331  4.966978\n",
      "455     4.0  13.068115  3.213331  4.966978\n",
      "456     3.0   2.738038  3.213331  4.966978\n",
      "457     1.0   5.930804  3.213331  4.966978\n",
      "458     5.0   2.982123  3.213331  4.966978\n",
      "459     4.0   2.229186  3.213331  4.966978\n",
      "460     4.0  14.362976  3.213331  4.966978\n",
      "461     2.0  12.748358  3.213331  4.966978\n",
      "448     5.0   2.846436  2.863729  3.401286\n",
      "449     4.0   5.899230  2.863729  3.401286\n",
      "450     3.0   2.164839  2.863729  3.401286\n",
      "451     2.0   3.065392  2.863729  3.401286\n",
      "452     2.0   7.485048  2.863729  3.401286\n",
      "453     1.0   2.689406  2.863729  3.401286\n",
      "454     2.0   3.009055  2.863729  3.401286\n",
      "455     4.0   9.633241  2.863729  3.401286\n",
      "456     3.0   4.362185  2.863729  3.401286\n",
      "457     1.0   4.796807  2.863729  3.401286\n",
      "458     5.0   1.675617  2.863729  3.401286\n",
      "459     4.0   2.567386  2.863729  3.401286\n",
      "460     4.0  10.359486  2.863729  3.401286\n",
      "461     2.0   6.046638  2.863729  3.401286\n",
      "448     5.0   5.584471  3.794879  5.543192\n",
      "449     4.0   6.078110  3.794879  5.543192\n",
      "450     3.0   1.851014  3.794879  5.543192\n",
      "451     2.0   2.653954  3.794879  5.543192\n",
      "452     2.0   4.721606  3.794879  5.543192\n",
      "453     1.0   1.881971  3.794879  5.543192\n",
      "454     2.0   3.694460  3.794879  5.543192\n",
      "455     4.0  14.400908  3.794879  5.543192\n",
      "456     3.0   2.976917  3.794879  5.543192\n",
      "457     1.0   5.776085  3.794879  5.543192\n",
      "458     5.0   8.039007  3.794879  5.543192\n",
      "459     4.0   1.783555  3.794879  5.543192\n",
      "460     4.0  17.060654  3.794879  5.543192\n",
      "461     2.0  11.848565  3.794879  5.543192\n",
      "448     5.0   4.624904  3.613081  4.194353\n",
      "449     4.0   5.900215  3.613081  4.194353\n",
      "450     3.0   0.000000  3.613081  4.194353\n",
      "451     2.0   0.000000  3.613081  4.194353\n",
      "452     2.0   8.053864  3.613081  4.194353\n",
      "453     1.0   4.192740  3.613081  4.194353\n",
      "454     2.0   3.575236  3.613081  4.194353\n",
      "455     4.0   9.162652  3.613081  4.194353\n",
      "456     3.0   5.673995  3.613081  4.194353\n",
      "457     1.0   6.262204  3.613081  4.194353\n",
      "458     5.0   2.177396  3.613081  4.194353\n",
      "459     4.0   2.061484  3.613081  4.194353\n",
      "460     4.0  11.168725  3.613081  4.194353\n",
      "461     2.0   9.457281  3.613081  4.194353\n",
      "448     5.0   5.542887  3.529975  5.276241\n",
      "449     4.0   3.642959  3.529975  5.276241\n",
      "450     3.0   1.872665  3.529975  5.276241\n",
      "451     2.0   1.559502  3.529975  5.276241\n",
      "452     2.0   4.260994  3.529975  5.276241\n",
      "453     1.0   2.135723  3.529975  5.276241\n",
      "454     2.0   5.471686  3.529975  5.276241\n",
      "455     4.0  15.310150  3.529975  5.276241\n",
      "456     3.0   2.858002  3.529975  5.276241\n",
      "457     1.0   6.198895  3.529975  5.276241\n",
      "458     5.0   6.432139  3.529975  5.276241\n",
      "459     4.0   2.081275  3.529975  5.276241\n",
      "460     4.0  15.920259  3.529975  5.276241\n",
      "461     2.0  10.161318  3.529975  5.276241\n",
      "448     5.0   3.929147  2.957030  3.648948\n",
      "449     4.0   3.871871  2.957030  3.648948\n",
      "450     3.0   2.170207  2.957030  3.648948\n",
      "451     2.0   1.691200  2.957030  3.648948\n",
      "452     2.0   7.267808  2.957030  3.648948\n",
      "453     1.0   3.139419  2.957030  3.648948\n",
      "454     2.0   3.951136  2.957030  3.648948\n",
      "455     4.0   9.129028  2.957030  3.648948\n",
      "456     3.0   5.911865  2.957030  3.648948\n",
      "457     1.0   6.221672  2.957030  3.648948\n",
      "458     5.0   2.764214  2.957030  3.648948\n",
      "459     4.0   2.250363  2.957030  3.648948\n",
      "460     4.0   9.653799  2.957030  3.648948\n",
      "461     2.0   8.800691  2.957030  3.648948\n",
      "448     5.0   3.914510  3.204709  4.901946\n",
      "449     4.0   6.852071  3.204709  4.901946\n",
      "450     3.0   3.507437  3.204709  4.901946\n",
      "451     2.0   1.992124  3.204709  4.901946\n",
      "452     2.0   3.821726  3.204709  4.901946\n",
      "453     1.0   2.380095  3.204709  4.901946\n",
      "454     2.0   1.992124  3.204709  4.901946\n",
      "455     4.0  15.139370  3.204709  4.901946\n",
      "456     3.0   2.100341  3.204709  4.901946\n",
      "457     1.0   4.374025  3.204709  4.901946\n",
      "458     5.0   3.418146  3.204709  4.901946\n",
      "459     4.0   1.992124  3.204709  4.901946\n",
      "460     4.0  15.666437  3.204709  4.901946\n",
      "461     2.0   8.534133  3.204709  4.901946\n",
      "448     5.0   5.024715  3.514413  4.531165\n",
      "449     4.0   7.808817  3.514413  4.531165\n",
      "450     3.0   1.484734  3.514413  4.531165\n",
      "451     2.0   0.265881  3.514413  4.531165\n",
      "452     2.0   5.240746  3.514413  4.531165\n",
      "453     1.0   2.430542  3.514413  4.531165\n",
      "454     2.0   2.713304  3.514413  4.531165\n",
      "455     4.0   8.872262  3.514413  4.531165\n",
      "456     3.0   4.632020  3.514413  4.531165\n",
      "457     1.0   6.463084  3.514413  4.531165\n",
      "458     5.0   0.000000  3.514413  4.531165\n",
      "459     4.0   2.769969  3.514413  4.531165\n",
      "460     4.0  13.228630  3.514413  4.531165\n",
      "461     2.0  11.308246  3.514413  4.531165\n",
      "448     5.0   5.194818  2.825331  4.334833\n",
      "449     4.0   5.974948  2.825331  4.334833\n",
      "450     3.0   2.068871  2.825331  4.334833\n",
      "451     2.0   2.068871  2.825331  4.334833\n",
      "452     2.0   4.320595  2.825331  4.334833\n",
      "453     1.0   2.802743  2.825331  4.334833\n",
      "454     2.0   2.884689  2.825331  4.334833\n",
      "455     4.0  13.110360  2.825331  4.334833\n",
      "456     3.0   2.566133  2.825331  4.334833\n",
      "457     1.0   2.776965  2.825331  4.334833\n",
      "458     5.0   5.387304  2.825331  4.334833\n",
      "459     4.0   2.068871  2.825331  4.334833\n",
      "460     4.0  13.679418  2.825331  4.334833\n",
      "461     2.0  10.057803  2.825331  4.334833\n",
      "448     5.0   5.998434  2.991064  4.013919\n",
      "449     4.0   5.327214  2.991064  4.013919\n",
      "450     3.0   1.489464  2.991064  4.013919\n",
      "451     2.0   1.515489  2.991064  4.013919\n",
      "452     2.0   5.017066  2.991064  4.013919\n",
      "453     1.0   1.603184  2.991064  4.013919\n",
      "454     2.0   3.873287  2.991064  4.013919\n",
      "455     4.0   9.960370  2.991064  4.013919\n",
      "456     3.0   3.811205  2.991064  4.013919\n",
      "457     1.0   4.861413  2.991064  4.013919\n",
      "458     5.0   1.781977  2.991064  4.013919\n",
      "459     4.0   2.617743  2.991064  4.013919\n",
      "460     4.0  11.325216  2.991064  4.013919\n",
      "461     2.0  11.502181  2.991064  4.013919\n",
      "\n",
      "Best Model Parameters:\n",
      "{'n_units': 64, 'learning_rate': 0.001, 'dropout_rate': 0.3, 'activation': 'tanh'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.7689056268760135, 3.2750162818137225)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# # 데이터 준비\n",
    "# X = merged_all_comb_copy_model[feature_columns]\n",
    "# y = merged_all_comb_copy_model[target_column]\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data['Draft_year'] = pd.to_numeric(data['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data[data['Draft_year'] == 2017]\n",
    "train_data = data[data['Draft_year'] != 2017]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 구축 및 컴파일 함수\n",
    "def build_model(n_units, learning_rate, dropout_rate, activation):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(n_units, activation=activation, input_shape=(X_train_scaled.shape[1],)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "n_units_options = [64, 128]\n",
    "learning_rate_options = [0.001, 0.01]\n",
    "dropout_rate_options = [0.3, 0.5]\n",
    "activation_options = ['relu', 'tanh']\n",
    "\n",
    "best_model = None\n",
    "best_mae = float('inf')\n",
    "best_rmse = float('inf')\n",
    "best_model_params = None\n",
    "results_table = pd.DataFrame()\n",
    "\n",
    "# 하이퍼파라미터 실험 및 모델 평가\n",
    "for n_units in n_units_options:\n",
    "    for learning_rate in learning_rate_options:\n",
    "        for dropout_rate in dropout_rate_options:\n",
    "            for activation in activation_options:\n",
    "                model = build_model(n_units, learning_rate, dropout_rate, activation)\n",
    "                model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "                y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "                y_pred = np.maximum(y_pred_raw, 0)    \n",
    "                \n",
    "                # 평가 지표 계산\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "\n",
    "                # 최적 모델 업데이트\n",
    "                if mae + rmse < best_mae + best_rmse:\n",
    "                    best_model = model\n",
    "                    best_mae = mae\n",
    "                    best_rmse = rmse\n",
    "                    best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "                # 결과 추가\n",
    "                temp_results = pd.DataFrame({\n",
    "                    'Actual': y_test,\n",
    "                    'Predicted': y_pred,\n",
    "                    'MAE': mae,\n",
    "                    'RMSE': rmse\n",
    "                })\n",
    "                results_table = pd.concat([results_table, temp_results])\n",
    "\n",
    "                \n",
    "                \n",
    "              \n",
    "                \n",
    "                \n",
    "# 최적 모델의 결과와 파라미터 출력\n",
    "print(\"Best Model Results:\")\n",
    "print(results_table)\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model_params)\n",
    "\n",
    "# 최적 모델의 결과에서 가장 좋은 MAE와 RMSE 값 찾기\n",
    "best_mae = results_table['MAE'].min()\n",
    "best_rmse = results_table['RMSE'].min()\n",
    "\n",
    "best_mae, best_rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "2c68ede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "Best Model Results:\n",
      "     Actual  Predicted       MAE     RMSE\n",
      "415     3.0   2.102698  1.149961  1.55436\n",
      "416     3.0   1.985532  1.149961  1.55436\n",
      "417     1.0   2.456291  1.149961  1.55436\n",
      "419     1.0   1.985532  1.149961  1.55436\n",
      "420     4.0   2.455856  1.149961  1.55436\n",
      "422     3.0   3.569488  1.149961  1.55436\n",
      "423     4.0   2.854258  1.149961  1.55436\n",
      "424     2.0   1.985532  1.149961  1.55436\n",
      "425     3.0   2.268708  1.149961  1.55436\n",
      "426     6.0   1.868635  1.149961  1.55436\n",
      "427     5.0   5.159473  1.149961  1.55436\n",
      "\n",
      "Best Model Parameters:\n",
      "{'n_units': 128, 'learning_rate': 0.01, 'dropout_rate': 0.3, 'activation': 'relu'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.149960528720509, 1.554359963409215)"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "#연도별\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# # 데이터 준비\n",
    "# X = merged_all_comb_copy_model[feature_columns]\n",
    "# y = merged_all_comb_copy_model[target_column]\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "test_data = data_avg[data_avg['Draft_year'] == 2015]\n",
    "train_data = data_avg[data_avg['Draft_year'] != 2015]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 구축 및 컴파일 함수\n",
    "def build_model(n_units, learning_rate, dropout_rate, activation):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(n_units, activation=activation, input_shape=(X_train.shape[1],)),  # 수정: input_shape를 X_train의 특성 수에 맞게 설정\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "n_units_options = [128]\n",
    "learning_rate_options = [0.01]\n",
    "dropout_rate_options = [0.3]\n",
    "activation_options = ['relu']\n",
    "\n",
    "best_model = None\n",
    "best_mae = float('inf')\n",
    "best_rmse = float('inf')\n",
    "best_model_params = None\n",
    "results_table = pd.DataFrame()\n",
    "\n",
    "# 하이퍼파라미터 실험 및 모델 평가\n",
    "for n_units in n_units_options:\n",
    "    for learning_rate in learning_rate_options:\n",
    "        for dropout_rate in dropout_rate_options:\n",
    "            for activation in activation_options:\n",
    "                model = build_model(n_units, learning_rate, dropout_rate, activation)\n",
    "                model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "                y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "                y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "                # 평가 지표 계산\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "\n",
    "                # 최적 모델 업데이트\n",
    "                if mae + rmse < best_mae + best_rmse:\n",
    "                    best_model = model\n",
    "                    best_mae = mae\n",
    "                    best_rmse = rmse\n",
    "                    best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "                # 결과 추가\n",
    "                temp_results = pd.DataFrame({\n",
    "                    'Actual': y_test,\n",
    "                    'Predicted': y_pred,\n",
    "                    'MAE': mae,\n",
    "                    'RMSE': rmse\n",
    "                })\n",
    "                results_table = pd.concat([results_table, temp_results])\n",
    "\n",
    "# 최적 모델의 결과와 파라미터 출력\n",
    "print(\"Best Model Results:\")\n",
    "print(results_table)\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model_params)\n",
    "\n",
    "# 최적 모델의 결과에서 가장 좋은 MAE와 RMSE 값 찾기\n",
    "best_mae = results_table['MAE'].min()\n",
    "best_rmse = results_table['RMSE'].min()\n",
    "\n",
    "best_mae, best_rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "6622e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for Draft Year: 2000\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicting for Draft Year: 2001\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Predicting for Draft Year: 2002\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicting for Draft Year: 2003\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicting for Draft Year: 2004\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2005\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2006\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicting for Draft Year: 2007\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicting for Draft Year: 2008\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicting for Draft Year: 2009\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2010\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2011\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2012\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2013\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2014\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicting for Draft Year: 2015\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2016\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2017\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicting for Draft Year: 2021\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "#4-1\n",
    "#best model로 연도별 test\n",
    "\n",
    "# 'Draft_year'별로 best_model을 사용하여 예측 수행하는 함수를 정의합니다.\n",
    "\n",
    "def predict_per_draft_year_with_best_model(data, feature_columns, target_column, best_model):\n",
    "    results = []\n",
    "\n",
    "    for year in sorted(data['Draft_year'].unique()):\n",
    "        print(f\"Predicting for Draft Year: {year}\")\n",
    "        train_data = data[data['Draft_year'] != year]\n",
    "        test_data = data[data['Draft_year'] == year]\n",
    "\n",
    "        if test_data.empty:\n",
    "            print(f\"No samples for Draft Year {year}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        X_test = test_data[feature_columns]\n",
    "        y_test = test_data[target_column]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(train_data[feature_columns])  # Scaling on the basis of train data\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        y_pred_raw = best_model.predict(X_test_scaled).flatten()\n",
    "        y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        results.append({\n",
    "            'Draft_year': year,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 최적 모델 사용하여 'Draft_year'별 예측 수행\n",
    "# 주의: 'best_model'은 이전에 학습된 최적의 MLP 모델이어야 합니다.\n",
    "draft_year_results = predict_per_draft_year_with_best_model(data_avg, feature_columns, 'Experience', best_model)\n",
    "\n",
    "# 주의: 위의 'draft_year_results' 실행은 실제로 학습된 'best_model'이 필요합니다.\n",
    "# 실제 환경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "5d5e75ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorted by Draft Year:\n",
      "    Draft_year       MAE      RMSE\n",
      "0         2000  1.971642  2.678535\n",
      "1         2001  2.683859  3.923367\n",
      "2         2002  2.254324  3.028953\n",
      "3         2003  4.230106  4.956334\n",
      "4         2004  2.786984  3.649128\n",
      "5         2005  2.590011  3.424740\n",
      "6         2006  2.420432  3.285770\n",
      "7         2007  2.196216  2.854055\n",
      "8         2008  1.759980  2.527698\n",
      "9         2009  2.290029  2.696935\n",
      "10        2010  2.082055  2.863541\n",
      "11        2011  2.078330  2.726981\n",
      "12        2012  1.294896  1.648966\n",
      "13        2013  2.069747  2.612803\n",
      "14        2014  1.029772  1.468981\n",
      "15        2015  1.206397  1.480990\n",
      "16        2016  0.758523  1.062925\n",
      "17        2017  0.668155  0.934139\n",
      "18        2021  0.979664  0.979664\n"
     ]
    }
   ],
   "source": [
    "draft_year_results = pd.DataFrame(draft_year_results)\n",
    "draft_year_results\n",
    "# 'Position'별로 정렬\n",
    "draft_year_results = draft_year_results.sort_values(by=['Draft_year'])\n",
    "\n",
    "\n",
    "# 'Draft_year'별로 정렬\n",
    "draft_year_results = draft_year_results.sort_values(by=['Draft_year'])\n",
    "print(\"\\nSorted by Draft Year:\")\n",
    "print(draft_year_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "a53fcb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draft_year_results.to_csv(\"draft_year_results_mlp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "92fda5c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3475260691.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24596\\3475260691.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    연도별 actual, predicted 값을 모두 출력해서 보자.\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "연도별 actual, predicted 값을 모두 출력해서 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "b7fd1eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for Draft Year: 2000, Position: 1\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicting for Draft Year: 2000, Position: 3\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicting for Draft Year: 2000, Position: 5\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicting for Draft Year: 2001, Position: 1\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicting for Draft Year: 2001, Position: 3\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2001, Position: 5\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicting for Draft Year: 2002, Position: 1\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2002, Position: 3\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicting for Draft Year: 2002, Position: 5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicting for Draft Year: 2003, Position: 1\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicting for Draft Year: 2003, Position: 3\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2003, Position: 5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2004, Position: 1\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2004, Position: 3\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2004, Position: 5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2005, Position: 1\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicting for Draft Year: 2005, Position: 3\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicting for Draft Year: 2005, Position: 5\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicting for Draft Year: 2006, Position: 1\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicting for Draft Year: 2006, Position: 3\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicting for Draft Year: 2006, Position: 5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2007, Position: 1\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicting for Draft Year: 2007, Position: 3\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2007, Position: 5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2008, Position: 1\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicting for Draft Year: 2008, Position: 3\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicting for Draft Year: 2008, Position: 5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicting for Draft Year: 2009, Position: 1\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2009, Position: 3\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2009, Position: 5\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicting for Draft Year: 2010, Position: 1\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicting for Draft Year: 2010, Position: 3\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicting for Draft Year: 2010, Position: 5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2011, Position: 1\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicting for Draft Year: 2011, Position: 3\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicting for Draft Year: 2011, Position: 5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicting for Draft Year: 2012, Position: 1\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicting for Draft Year: 2012, Position: 3\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2012, Position: 5\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicting for Draft Year: 2013, Position: 1\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicting for Draft Year: 2013, Position: 3\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicting for Draft Year: 2013, Position: 5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2014, Position: 1\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicting for Draft Year: 2014, Position: 3\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicting for Draft Year: 2014, Position: 5\n",
      "No samples for Draft Year 2014, Position 5. Skipping.\n",
      "Predicting for Draft Year: 2015, Position: 1\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicting for Draft Year: 2015, Position: 3\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2015, Position: 5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2016, Position: 1\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicting for Draft Year: 2016, Position: 3\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicting for Draft Year: 2016, Position: 5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2017, Position: 1\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2017, Position: 3\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicting for Draft Year: 2017, Position: 5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicting for Draft Year: 2021, Position: 1\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicting for Draft Year: 2021, Position: 3\n",
      "No samples for Draft Year 2021, Position 3. Skipping.\n",
      "Predicting for Draft Year: 2021, Position: 5\n",
      "No samples for Draft Year 2021, Position 5. Skipping.\n"
     ]
    }
   ],
   "source": [
    "#4-2\n",
    "# Draft_year'와 'Pos'별로 best_model을 사용하여 예측 수행하는 함수를 정의합니다.\n",
    "#MAPE 추가\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_mape(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    # 실제 값(y_test)이 0인 경우만 제외하고 MAPE 계산\n",
    "    nonzero_mask = (y_test != 0)\n",
    "    y_test_nonzero = y_test[nonzero_mask]\n",
    "    y_pred_nonzero = y_pred[nonzero_mask]\n",
    "    if len(y_test_nonzero) == 0:\n",
    "        return np.nan  # Avoid division by zero\n",
    "    mape = np.mean(np.abs((y_test_nonzero - y_pred_nonzero) / y_test_nonzero)) * 100\n",
    "    return mape\n",
    "\n",
    "\n",
    "def predict_per_draft_year_and_position_with_best_model(data, feature_columns, target_column, best_model):\n",
    "    results = []\n",
    "\n",
    "    for year in sorted(data['Draft_year'].unique()):\n",
    "        for position in data['Pos'].unique():\n",
    "            print(f\"Predicting for Draft Year: {year}, Position: {position}\")\n",
    "            test_data = data[(data['Draft_year'] == year) & (data['Pos'] == position)]\n",
    "\n",
    "            if test_data.empty:\n",
    "                print(f\"No samples for Draft Year {year}, Position {position}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X_test = test_data[feature_columns]\n",
    "            y_test = test_data[target_column]\n",
    "\n",
    "            X_test_scaled = scaler.transform(X_test)  # 사용된 scaler는 전역 변수이거나 미리 정의된 scaler여야 함\n",
    "            y_pred_raw = best_model.predict(X_test_scaled).flatten()\n",
    "            y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            mape = calculate_mape(y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "            \n",
    "            results.append({\n",
    "                'Draft_year': year,\n",
    "                'Position': position,\n",
    "                'MAE': mae,\n",
    "                'RMSE': rmse,\n",
    "                'MAPE': mape\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 최적 모델을 사용하여 'Draft_year'와 'Pos'별 예측 수행\n",
    "# 주의: 'best_model'은 이전에 학습된 최적의 MLP 모델이어야 합니다. 또한, 'scaler'는 모델 학습에 사용된 StandardScaler의 인스턴스여야 합니다.\n",
    "draft_year_pos_results_mlp = predict_per_draft_year_and_position_with_best_model(data_avg, feature_columns, 'Experience', best_model)\n",
    "\n",
    "# 주의: 위의 'draft_year_pos_results_mlp' 실행은 실제로 학습된 'best_model'과 'scaler'가 필요합니다.\n",
    "# 실제 환경에서 이 코드를 실행하려면 최적의 모델과 scaler를 미리 학습시켜야 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "c8b4c267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by Position:\n",
      "    Draft_year  Position       MAE      RMSE        MAPE\n",
      "0         2000         1  2.782494  3.857322   55.008534\n",
      "3         2001         1  1.613367  3.074081   19.271326\n",
      "6         2002         1  1.145865  1.260050   56.065746\n",
      "9         2003         1  2.635627  3.438617   46.356577\n",
      "12        2004         1  2.403463  2.681609   41.075765\n",
      "15        2005         1  1.782953  2.531697   28.669959\n",
      "18        2006         1  2.589200  3.837471   55.731138\n",
      "21        2007         1  2.516647  3.169710   55.570696\n",
      "24        2008         1  1.838194  2.801762   44.833918\n",
      "27        2009         1  1.857633  2.200123   22.359426\n",
      "30        2010         1  0.990743  1.167673   33.925055\n",
      "33        2011         1  1.463618  1.773501   36.539024\n",
      "36        2012         1  1.113825  1.562179   37.628792\n",
      "39        2013         1  1.552084  2.362680   46.482138\n",
      "42        2014         1  0.836918  1.037330   35.522323\n",
      "44        2015         1  0.947201  0.959402   29.186410\n",
      "47        2016         1  0.568628  0.699367   29.288992\n",
      "50        2017         1  0.986202  1.269915   44.608805\n",
      "53        2021         1  0.985532  0.985532   98.553181\n",
      "1         2000         3  1.461040  1.611617   36.478688\n",
      "4         2001         3  3.112140  4.834143   30.285209\n",
      "7         2002         3  2.049126  2.445897   47.392385\n",
      "10        2003         3  3.393542  4.348469   25.282223\n",
      "13        2004         3  1.333161  2.088025   14.702239\n",
      "16        2005         3  1.926350  2.409097   26.058147\n",
      "19        2006         3  1.750503  2.304700   23.405380\n",
      "22        2007         3  1.553155  1.842072   22.410120\n",
      "25        2008         3  1.677887  1.969878   34.001399\n",
      "28        2009         3  1.622095  1.887633   27.746055\n",
      "31        2010         3  1.324105  1.681081   38.603709\n",
      "34        2011         3  1.431007  1.848050   53.224001\n",
      "37        2012         3  1.322399  1.596990   25.567446\n",
      "40        2013         3  1.623602  1.764334   71.073712\n",
      "43        2014         3  0.971592  1.460450   11.210152\n",
      "45        2015         3  1.312538  1.911513   45.997430\n",
      "48        2016         3  0.811589  1.269316   43.306850\n",
      "51        2017         3  0.704243  0.961273   22.936236\n",
      "2         2000         5  0.794423  0.817087   56.818020\n",
      "5         2001         5  2.048073  2.662993   36.736534\n",
      "8         2002         5  0.850978  1.034778    9.979603\n",
      "11        2003         5  0.957941  0.957941    7.368777\n",
      "14        2004         5  3.330947  3.592402   46.763625\n",
      "17        2005         5  2.080030  2.221992   60.715397\n",
      "20        2006         5  2.298145  2.785218   38.235311\n",
      "23        2007         5  1.876584  2.184303   33.307333\n",
      "26        2008         5  1.485532  1.567420   98.553181\n",
      "29        2009         5  3.014468  3.014468   60.289364\n",
      "32        2010         5  1.177384  1.573117   14.288059\n",
      "35        2011         5  1.045735  1.045735  104.573464\n",
      "38        2012         5  1.276521  1.335130   51.746105\n",
      "41        2013         5  1.751954  1.751954   35.039077\n",
      "46        2015         5  0.985532  0.985532   98.553181\n",
      "49        2016         5  1.305450  1.305450  130.544996\n",
      "52        2017         5  1.427455  1.427455   35.686368\n",
      "\n",
      "Sorted by Draft Year:\n",
      "    Draft_year  Position       MAE      RMSE        MAPE\n",
      "0         2000         1  2.782494  3.857322   55.008534\n",
      "1         2000         3  1.461040  1.611617   36.478688\n",
      "2         2000         5  0.794423  0.817087   56.818020\n",
      "3         2001         1  1.613367  3.074081   19.271326\n",
      "4         2001         3  3.112140  4.834143   30.285209\n",
      "5         2001         5  2.048073  2.662993   36.736534\n",
      "6         2002         1  1.145865  1.260050   56.065746\n",
      "7         2002         3  2.049126  2.445897   47.392385\n",
      "8         2002         5  0.850978  1.034778    9.979603\n",
      "9         2003         1  2.635627  3.438617   46.356577\n",
      "10        2003         3  3.393542  4.348469   25.282223\n",
      "11        2003         5  0.957941  0.957941    7.368777\n",
      "12        2004         1  2.403463  2.681609   41.075765\n",
      "13        2004         3  1.333161  2.088025   14.702239\n",
      "14        2004         5  3.330947  3.592402   46.763625\n",
      "15        2005         1  1.782953  2.531697   28.669959\n",
      "16        2005         3  1.926350  2.409097   26.058147\n",
      "17        2005         5  2.080030  2.221992   60.715397\n",
      "18        2006         1  2.589200  3.837471   55.731138\n",
      "19        2006         3  1.750503  2.304700   23.405380\n",
      "20        2006         5  2.298145  2.785218   38.235311\n",
      "21        2007         1  2.516647  3.169710   55.570696\n",
      "22        2007         3  1.553155  1.842072   22.410120\n",
      "23        2007         5  1.876584  2.184303   33.307333\n",
      "24        2008         1  1.838194  2.801762   44.833918\n",
      "25        2008         3  1.677887  1.969878   34.001399\n",
      "26        2008         5  1.485532  1.567420   98.553181\n",
      "27        2009         1  1.857633  2.200123   22.359426\n",
      "28        2009         3  1.622095  1.887633   27.746055\n",
      "29        2009         5  3.014468  3.014468   60.289364\n",
      "30        2010         1  0.990743  1.167673   33.925055\n",
      "31        2010         3  1.324105  1.681081   38.603709\n",
      "32        2010         5  1.177384  1.573117   14.288059\n",
      "33        2011         1  1.463618  1.773501   36.539024\n",
      "34        2011         3  1.431007  1.848050   53.224001\n",
      "35        2011         5  1.045735  1.045735  104.573464\n",
      "36        2012         1  1.113825  1.562179   37.628792\n",
      "37        2012         3  1.322399  1.596990   25.567446\n",
      "38        2012         5  1.276521  1.335130   51.746105\n",
      "39        2013         1  1.552084  2.362680   46.482138\n",
      "40        2013         3  1.623602  1.764334   71.073712\n",
      "41        2013         5  1.751954  1.751954   35.039077\n",
      "42        2014         1  0.836918  1.037330   35.522323\n",
      "43        2014         3  0.971592  1.460450   11.210152\n",
      "44        2015         1  0.947201  0.959402   29.186410\n",
      "45        2015         3  1.312538  1.911513   45.997430\n",
      "46        2015         5  0.985532  0.985532   98.553181\n",
      "47        2016         1  0.568628  0.699367   29.288992\n",
      "48        2016         3  0.811589  1.269316   43.306850\n",
      "49        2016         5  1.305450  1.305450  130.544996\n",
      "50        2017         1  0.986202  1.269915   44.608805\n",
      "51        2017         3  0.704243  0.961273   22.936236\n",
      "52        2017         5  1.427455  1.427455   35.686368\n",
      "53        2021         1  0.985532  0.985532   98.553181\n"
     ]
    }
   ],
   "source": [
    "draft_year_pos_results_mlp = pd.DataFrame(draft_year_pos_results_mlp)\n",
    "draft_year_pos_results_mlp\n",
    "# 'Position'별로 정렬\n",
    "sorted_by_position = draft_year_pos_results_mlp.sort_values(by=['Position', 'Draft_year'])\n",
    "print(\"Sorted by Position:\")\n",
    "print(sorted_by_position)\n",
    "\n",
    "# 'Draft_year'별로 정렬\n",
    "sorted_by_draft_year = draft_year_pos_results_mlp.sort_values(by=['Draft_year', 'Position'])\n",
    "print(\"\\nSorted by Draft Year:\")\n",
    "print(sorted_by_draft_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "772d98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_year_pos_results_mlp.to_csv(\"draft_year_pos_results_mlp_mlp222.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef30ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4-3\n",
    "#data_avg\n",
    "#연도별 & Pos별 test\n",
    "\n",
    "data_avg = weighted_avg_new.copy()\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data_avg = ... # data_avg 데이터 로드\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 모델 구축 및 컴파일 함수\n",
    "def build_model(n_units, learning_rate, dropout_rate, activation, input_dim):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(n_units, activation=activation, input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "n_units_options = [128]\n",
    "learning_rate_options = [0.01]\n",
    "dropout_rate_options = [0.3]\n",
    "activation_options = ['relu']\n",
    "\n",
    "def evaluate_model_per_draft_year_and_position_mlp(data, feature_columns, target_column, n_units_options, learning_rate_options, dropout_rate_options, activation_options):\n",
    "    results = []\n",
    "\n",
    "    for year in sorted(data_avg['Draft_year'].unique()):\n",
    "        for position in data_avg['Pos'].unique():\n",
    "            print(f\"Evaluating for Draft Year: {year}, Position: {position}\")\n",
    "            train_data = data_avg[(data_avg['Draft_year'] != year) & (data_avg['Pos'] != position)]\n",
    "            test_data = data_avg[(data_avg['Draft_year'] == year) & (data_avg['Pos'] == position)]\n",
    "\n",
    "#             if len(train_data) < 5 or len(test_data) < 5:\n",
    "#                 print(f\"Skipping Draft Year {year}, Position {position} due to insufficient data.\")\n",
    "#                 continue\n",
    "         \n",
    "\n",
    "            X_train = train_data[feature_columns]\n",
    "            y_train = train_data[target_column]\n",
    "            X_test = test_data[feature_columns]\n",
    "            y_test = test_data[target_column]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            best_mae = float('inf')\n",
    "            best_rmse = float('inf')\n",
    "            best_model_params = None\n",
    "\n",
    "            for n_units in n_units_options:\n",
    "                for learning_rate in learning_rate_options:\n",
    "                    for dropout_rate in dropout_rate_options:\n",
    "                        for activation in activation_options:\n",
    "                            model = build_model(n_units, learning_rate, dropout_rate, activation, X_train_scaled.shape[1])\n",
    "                            model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "                            y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "                            y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "                            mae = mean_absolute_error(y_test, y_pred)\n",
    "                            mse = mean_squared_error(y_test, y_pred)\n",
    "                            rmse = np.sqrt(mse)\n",
    "\n",
    "                            if mae + rmse < best_mae + best_rmse:\n",
    "                                best_mae = mae\n",
    "                                best_rmse = rmse\n",
    "                                best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "            results.append({\n",
    "                'Draft_year': year,\n",
    "                'Position': position,\n",
    "                'MAE': best_mae,\n",
    "                'RMSE': best_rmse,\n",
    "                'Best_Params': best_model_params\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 함수 실행\n",
    "# 결과는 실제 데이터셋 'data_avg'와 'feature_columns' 리스트가 필요합니다.\n",
    "# draft_year_pos_results_mlp = evaluate_model_per_draft_year_and_position_mlp(data_avg, feature_columns, 'Experience', n_units_options, learning_rate_options, dropout_rate_options, activation_options)\n",
    "\n",
    "# 주의: 위의 'draft_year_pos_results_mlp' 실행은 실제 데이터셋 'data_avg'와 'feature_columns' 리스트가 필요합니다.\n",
    "# 실제 환경에서 이\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b460e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_year_pos_results_mlp = evaluate_model_per_draft_year_and_position_mlp(data_avg, feature_columns, 'Experience', n_units_options, learning_rate_options, dropout_rate_options, activation_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "6f1dcefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4-4\n",
    "#data_avg\n",
    "#연도별 & Pos별 test\n",
    "#MAPE추가\n",
    "\n",
    "data_avg = weighted_avg_new.copy()\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data_avg = ... # data_avg 데이터 로드\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "\n",
    "# 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "# 모델 구축 및 컴파일 함수\n",
    "def build_model(n_units, learning_rate, dropout_rate, activation, input_dim):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(n_units, activation=activation, input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "n_units_options = [128]\n",
    "learning_rate_options = [0.01]\n",
    "dropout_rate_options = [0.3]\n",
    "activation_options = ['relu']\n",
    "\n",
    "\n",
    "def calculate_mape(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    # 실제 값(y_test)이 0인 경우만 제외하고 MAPE 계산\n",
    "    nonzero_mask = (y_test != 0)\n",
    "    y_test_nonzero = y_test[nonzero_mask]\n",
    "    y_pred_nonzero = y_pred[nonzero_mask]\n",
    "    if len(y_test_nonzero) == 0:\n",
    "        return np.nan  # Avoid division by zero\n",
    "    mape = np.mean(np.abs((y_test_nonzero - y_pred_nonzero) / y_test_nonzero)) * 100\n",
    "    return mape\n",
    "\n",
    "def evaluate_model_per_draft_year_and_position_mlp(data, feature_columns, target_column, n_units_options, learning_rate_options, dropout_rate_options, activation_options):\n",
    "    results = []\n",
    "\n",
    "    for year in sorted(data_avg['Draft_year'].unique()):\n",
    "        for position in data_avg['Pos'].unique():\n",
    "            print(f\"Evaluating for Draft Year: {year}, Position: {position}\")\n",
    "            train_data = data_avg[(data_avg['Draft_year'] != year) & (data_avg['Pos'] != position)]\n",
    "            test_data = data_avg[(data_avg['Draft_year'] == year) & (data_avg['Pos'] == position)]\n",
    "\n",
    "#             if len(train_data) < 5 or len(test_data) < 5:\n",
    "#                 print(f\"Skipping Draft Year {year}, Position {position} due to insufficient data.\")\n",
    "#                 continue\n",
    "         \n",
    "\n",
    "            X_train = train_data[feature_columns]\n",
    "            y_train = train_data[target_column]\n",
    "            X_test = test_data[feature_columns]\n",
    "            y_test = test_data[target_column]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            best_mae = float('inf')\n",
    "            best_rmse = float('inf')\n",
    "            best_model_params = None\n",
    "\n",
    "            for n_units in n_units_options:\n",
    "                for learning_rate in learning_rate_options:\n",
    "                    for dropout_rate in dropout_rate_options:\n",
    "                        for activation in activation_options:\n",
    "                            model = build_model(n_units, learning_rate, dropout_rate, activation, X_train_scaled.shape[1])\n",
    "                            model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "                            y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "                            y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "                            mae = mean_absolute_error(y_test, y_pred)\n",
    "                            mse = mean_squared_error(y_test, y_pred)\n",
    "                            rmse = np.sqrt(mse)\n",
    "                            mape = calculate_mape(y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "                            if mae + rmse < best_mae + best_rmse:\n",
    "                                best_mae = mae\n",
    "                                best_rmse = rmse\n",
    "                                best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "            results.append({\n",
    "                'Draft_year': year,\n",
    "                'Position': position,\n",
    "                'MAE': best_mae,\n",
    "                'RMSE': best_rmse,\n",
    "                'MAPE': mape,\n",
    "                'Best_Params': best_model_params\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 함수 실행\n",
    "# 결과는 실제 데이터셋 'data_avg'와 'feature_columns' 리스트가 필요합니다.\n",
    "# draft_year_pos_results_mlp = evaluate_model_per_draft_year_and_position_mlp(data_avg, feature_columns, 'Experience', n_units_options, learning_rate_options, dropout_rate_options, activation_options)\n",
    "\n",
    "# 주의: 위의 'draft_year_pos_results_mlp' 실행은 실제 데이터셋 'data_avg'와 'feature_columns' 리스트가 필요합니다.\n",
    "# 실제 환경에서 이\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "012b98f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for Draft Year: 2000, Position: 1\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Evaluating for Draft Year: 2000, Position: 3\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "Evaluating for Draft Year: 2000, Position: 5\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Evaluating for Draft Year: 2001, Position: 1\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Evaluating for Draft Year: 2001, Position: 3\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Evaluating for Draft Year: 2001, Position: 5\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Evaluating for Draft Year: 2002, Position: 1\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Evaluating for Draft Year: 2002, Position: 3\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Evaluating for Draft Year: 2002, Position: 5\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Evaluating for Draft Year: 2003, Position: 1\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Evaluating for Draft Year: 2003, Position: 3\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Evaluating for Draft Year: 2003, Position: 5\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Evaluating for Draft Year: 2004, Position: 1\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Evaluating for Draft Year: 2004, Position: 3\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Evaluating for Draft Year: 2004, Position: 5\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Evaluating for Draft Year: 2005, Position: 1\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Evaluating for Draft Year: 2005, Position: 3\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Evaluating for Draft Year: 2005, Position: 5\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Evaluating for Draft Year: 2006, Position: 1\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Evaluating for Draft Year: 2006, Position: 3\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Evaluating for Draft Year: 2006, Position: 5\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Evaluating for Draft Year: 2007, Position: 1\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Evaluating for Draft Year: 2007, Position: 3\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Evaluating for Draft Year: 2007, Position: 5\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Evaluating for Draft Year: 2008, Position: 1\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Evaluating for Draft Year: 2008, Position: 3\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Evaluating for Draft Year: 2008, Position: 5\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Evaluating for Draft Year: 2009, Position: 1\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Evaluating for Draft Year: 2009, Position: 3\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Evaluating for Draft Year: 2009, Position: 5\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Evaluating for Draft Year: 2010, Position: 1\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Evaluating for Draft Year: 2010, Position: 3\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Evaluating for Draft Year: 2010, Position: 5\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Evaluating for Draft Year: 2011, Position: 1\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Evaluating for Draft Year: 2011, Position: 3\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Evaluating for Draft Year: 2011, Position: 5\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Evaluating for Draft Year: 2012, Position: 1\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Evaluating for Draft Year: 2012, Position: 3\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Evaluating for Draft Year: 2012, Position: 5\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Evaluating for Draft Year: 2013, Position: 1\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Evaluating for Draft Year: 2013, Position: 3\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Evaluating for Draft Year: 2013, Position: 5\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Evaluating for Draft Year: 2014, Position: 1\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Evaluating for Draft Year: 2014, Position: 3\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Evaluating for Draft Year: 2014, Position: 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 60)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24596\\3690878534.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdraft_year_pos_results_mlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model_per_draft_year_and_position_mlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Experience'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_units_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_rate_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24596\\835811706.py\u001b[0m in \u001b[0;36mevaluate_model_per_draft_year_and_position_mlp\u001b[1;34m(data, feature_columns, target_column, n_units_options, learning_rate_options, dropout_rate_options, activation_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mX_train_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mX_test_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mbest_mae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Jupyter\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m             \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Jupyter\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Jupyter\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    806\u001b[0m                 \u001b[1;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m                 \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 60)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "draft_year_pos_results_mlp = evaluate_model_per_draft_year_and_position_mlp(data_avg, feature_columns, 'Experience', n_units_options, learning_rate_options, dropout_rate_options, activation_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #4-5\n",
    "# #data\n",
    "# #all options(draft_year & pos 별 test, MAPE)\n",
    "# #grid search\n",
    "\n",
    "\n",
    "\n",
    "# #######이건 아닌거 같다. 테스트하려는 데이터로 최적의 모델을 찾는 꼴이다.\n",
    "\n",
    "\n",
    "\n",
    "# #7\n",
    "# #split\n",
    "# #1차+2차\n",
    "# #data\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# #data\n",
    "\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# import pandas as pd\n",
    "\n",
    "# # 랜덤 시드 설정\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # merged_all_comb_copy_model = ...\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#      \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#      \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # # 데이터 준비\n",
    "# # X = merged_all_comb_copy_model[feature_columns]\n",
    "# # y = merged_all_comb_copy_model[target_column]\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data = data.dropna(subset=feature_columns + [target_column])\n",
    "# X = data[feature_columns]\n",
    "# y = data[target_column]\n",
    "\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 모델 구축 및 컴파일 함수\n",
    "# def build_model(n_units, learning_rate, dropout_rate, activation):\n",
    "#     model = tf.keras.models.Sequential([\n",
    "#         tf.keras.layers.Dense(n_units, activation=activation, input_shape=(X_train_scaled.shape[1],)),\n",
    "#         tf.keras.layers.Dropout(dropout_rate),\n",
    "#         tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "#         tf.keras.layers.Dropout(dropout_rate),\n",
    "#         tf.keras.layers.Dense(1)\n",
    "#     ])\n",
    "#     optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def calculate_mape(y_test, y_pred):\n",
    "#     y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "#     # 실제 값(y_test)이 0인 경우만 제외하고 MAPE 계산\n",
    "#     nonzero_mask = (y_test != 0)\n",
    "#     y_test_nonzero = y_test[nonzero_mask]\n",
    "#     y_pred_nonzero = y_pred[nonzero_mask]\n",
    "#     if len(y_test_nonzero) == 0:\n",
    "#         return np.nan  # Avoid division by zero\n",
    "#     mape = np.mean(np.abs((y_test_nonzero - y_pred_nonzero) / y_test_nonzero)) * 100\n",
    "#     return mape\n",
    "\n",
    "\n",
    "# def predict_per_draft_year_and_position_with_best_model(data, feature_columns, target_column, best_model):\n",
    "#     results = []\n",
    "\n",
    "#     for year in sorted(data['Draft_year'].unique()):\n",
    "#         for position in data['Pos'].unique():\n",
    "#             print(f\"Predicting for Draft Year: {year}, Position: {position}\")\n",
    "#             test_data = data[(data['Draft_year'] == year) & (data['Pos'] == position)]\n",
    "\n",
    "#             if test_data.empty:\n",
    "#                 print(f\"No samples for Draft Year {year}, Position {position}. Skipping.\")\n",
    "#                 continue\n",
    "\n",
    "#             X_test = test_data[feature_columns]\n",
    "#             y_test = test_data[target_column]\n",
    "\n",
    "#             X_test_scaled = scaler.transform(X_test)  # 사용된 scaler는 전역 변수이거나 미리 정의된 scaler여야 함\n",
    "#             y_pred_raw = best_model.predict(X_test_scaled).flatten()\n",
    "#             y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "#             mae = mean_absolute_error(y_test, y_pred)\n",
    "#             rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#             mape = calculate_mape(y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "            \n",
    "#             results.append({\n",
    "#                 'Draft_year': year,\n",
    "#                 'Position': position,\n",
    "#                 'MAE': mae,\n",
    "#                 'RMSE': rmse,\n",
    "#                 'MAPE': mape\n",
    "#             })\n",
    "\n",
    "#     return pd.DataFrame(results)\n",
    "\n",
    "# # 하이퍼파라미터 설정\n",
    "# n_units_options = [64, 128]\n",
    "# learning_rate_options = [0.001, 0.01]\n",
    "# dropout_rate_options = [0.3, 0.5]\n",
    "# activation_options = ['relu', 'tanh']\n",
    "\n",
    "# best_model = None\n",
    "# best_mae = float('inf')\n",
    "# best_rmse = float('inf')\n",
    "# best_model_params = None\n",
    "# results_table = pd.DataFrame()\n",
    "\n",
    "# # 하이퍼파라미터 실험 및 모델 평가\n",
    "# for n_units in n_units_options:\n",
    "#     for learning_rate in learning_rate_options:\n",
    "#         for dropout_rate in dropout_rate_options:\n",
    "#             for activation in activation_options:\n",
    "#                 model = build_model(n_units, learning_rate, dropout_rate, activation)\n",
    "#                 model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "#                 y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "#                 y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "#                 # 평가 지표 계산\n",
    "#                 mae = mean_absolute_error(y_test, y_pred)\n",
    "#                 mse = mean_squared_error(y_test, y_pred)\n",
    "#                 rmse = np.sqrt(mse)\n",
    "\n",
    "#                 # 최적 모델 업데이트\n",
    "#                 if mae + rmse < best_mae + best_rmse:\n",
    "#                     best_model = model\n",
    "#                     best_mae = mae\n",
    "#                     best_rmse = rmse\n",
    "#                     best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "#                 # 결과 추가\n",
    "#                 temp_results = pd.DataFrame({\n",
    "#                     'Actual': y_test,\n",
    "#                     'Predicted': y_pred,\n",
    "#                     'MAE': mae,\n",
    "#                     'RMSE': rmse\n",
    "#                 })\n",
    "#                 results_table = pd.concat([results_table, temp_results])\n",
    "\n",
    "# draft_year_results = predict_per_draft_year_with_best_model(data_avg, feature_columns, 'Experience', best_model)\n",
    "\n",
    "                \n",
    "# # 최적 모델의 결과와 파라미터 출력\n",
    "# print(\"Best Model Results:\")\n",
    "# print(results_table)\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model_params)\n",
    "\n",
    "# # 최적 모델의 결과에서 가장 좋은 MAE와 RMSE 값 찾기\n",
    "# best_mae = results_table['MAE'].min()\n",
    "# best_rmse = results_table['RMSE'].min()\n",
    "\n",
    "# best_mae, best_rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf717e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_year_pos_results_mlp = pd.DataFrame(draft_year_pos_results_mlp)\n",
    "draft_year_pos_results_mlp\n",
    "# 'Position'별로 정렬\n",
    "sorted_by_position = draft_year_pos_results_mlp.sort_values(by=['Position', 'Draft_year'])\n",
    "print(\"Sorted by Position:\")\n",
    "print(sorted_by_position)\n",
    "\n",
    "# 'Draft_year'별로 정렬\n",
    "sorted_by_draft_year = draft_year_pos_results_mlp.sort_values(by=['Draft_year', 'Position'])\n",
    "print(\"\\nSorted by Draft Year:\")\n",
    "print(sorted_by_draft_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f8b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b2b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5059d057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac789d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #4-6\n",
    "# #data_avg\n",
    "# #all options(draft_year & pos 별 test, MAPE)\n",
    "# #grid search\n",
    "\n",
    "\n",
    "# # #######이건 아닌거 같다. 테스트하려는 데이터로 최적의 모델을 찾는 꼴이다.\n",
    "\n",
    "\n",
    "\n",
    "# #4\n",
    "# #연도별\n",
    "# #1차+2차\n",
    "# #data_avg\n",
    "\n",
    "\n",
    "# data = merged_all_comb_copy_grouped.copy()\n",
    "# data_avg = weighted_avg_new.copy()\n",
    "# #data\n",
    "\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# import pandas as pd\n",
    "\n",
    "# # 랜덤 시드 설정\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "\n",
    "# # 데이터 로드 및 전처리\n",
    "# # merged_all_comb_copy_model = ...\n",
    "\n",
    "# # Feature 및 타겟 컬럼 정의\n",
    "# feature_columns = [\n",
    "#     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "#     'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "#     \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "#     \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "#     \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "#     \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "#      \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "#      \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "#     \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "#     \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "#     \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "#     \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "#     \"ORtg_per_poss\"]\n",
    "\n",
    "# # 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# # ORB%_advanced\n",
    "# # DRB%_advanced\n",
    "# # OBPM_advanced\n",
    "# # DBPM_advanced\n",
    "# # BPM_advanced\n",
    "# # DWS_advanced\n",
    "# # WS/40_advanced\n",
    "# # DRtg_per_poss\n",
    "# target_column = 'Experience'\n",
    "\n",
    "# # # 데이터 준비\n",
    "# # X = merged_all_comb_copy_model[feature_columns]\n",
    "# # y = merged_all_comb_copy_model[target_column]\n",
    "\n",
    "# # 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "# data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "# X = data_avg[feature_columns]\n",
    "# y = data_avg[target_column]\n",
    "\n",
    "# # # 데이터 분할 및 정규화\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # 'Draft_year' 컬럼을 숫자형으로 변환\n",
    "# data_avg['Draft_year'] = pd.to_numeric(data_avg['Draft_year'], errors='coerce')\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 모델 구축 및 컴파일 함수\n",
    "# def build_model(n_units, learning_rate, dropout_rate, activation):\n",
    "#     model = tf.keras.models.Sequential([\n",
    "#         tf.keras.layers.Dense(n_units, activation=activation, input_shape=(X_train.shape[1],)),  # 수정: input_shape를 X_train의 특성 수에 맞게 설정\n",
    "#         tf.keras.layers.Dropout(dropout_rate),\n",
    "#         tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "#         tf.keras.layers.Dropout(dropout_rate),\n",
    "#         tf.keras.layers.Dense(1)\n",
    "#     ])\n",
    "#     optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def calculate_mape(y_test, y_pred):\n",
    "#     y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "#     # 실제 값(y_test)이 0인 경우만 제외하고 MAPE 계산\n",
    "#     nonzero_mask = (y_test != 0)\n",
    "#     y_test_nonzero = y_test[nonzero_mask]\n",
    "#     y_pred_nonzero = y_pred[nonzero_mask]\n",
    "#     if len(y_test_nonzero) == 0:\n",
    "#         return np.nan  # Avoid division by zero\n",
    "#     mape = np.mean(np.abs((y_test_nonzero - y_pred_nonzero) / y_test_nonzero)) * 100\n",
    "#     return mape\n",
    "\n",
    "\n",
    "# def predict_per_draft_year_and_position_with_best_model(data, feature_columns, target_column, best_model):\n",
    "#     results = []\n",
    "\n",
    "#     for year in sorted(data['Draft_year'].unique()):\n",
    "#         for position in data['Pos'].unique():\n",
    "#             print(f\"Predicting for Draft Year: {year}, Position: {position}\")\n",
    "#             test_data = data[(data['Draft_year'] == year) & (data['Pos'] == position)]\n",
    "\n",
    "#             if test_data.empty:\n",
    "#                 print(f\"No samples for Draft Year {year}, Position {position}. Skipping.\")\n",
    "#                 continue\n",
    "\n",
    "#             X_test = test_data[feature_columns]\n",
    "#             y_test = test_data[target_column]\n",
    "\n",
    "#             X_test_scaled = scaler.transform(X_test)  # 사용된 scaler는 전역 변수이거나 미리 정의된 scaler여야 함\n",
    "#             y_pred_raw = best_model.predict(X_test_scaled).flatten()\n",
    "#             y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "#             mae = mean_absolute_error(y_test, y_pred)\n",
    "#             rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#             mape = calculate_mape(y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "            \n",
    "#             results.append({\n",
    "#                 'Draft_year': year,\n",
    "#                 'Position': position,\n",
    "#                 'MAE': mae,\n",
    "#                 'RMSE': rmse,\n",
    "#                 'MAPE': mape\n",
    "#             })\n",
    "\n",
    "#     return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "# # 하이퍼파라미터 설정\n",
    "# n_units_options = [64, 128]\n",
    "# learning_rate_options = [0.001, 0.01]\n",
    "# dropout_rate_options = [0.3, 0.5]\n",
    "# activation_options = ['relu', 'tanh']\n",
    "\n",
    "# best_model = None\n",
    "# best_mae = float('inf')\n",
    "# best_rmse = float('inf')\n",
    "# best_model_params = None\n",
    "# results_table = pd.DataFrame()\n",
    "\n",
    "# # 하이퍼파라미터 실험 및 모델 평가\n",
    "# for n_units in n_units_options:\n",
    "#     for learning_rate in learning_rate_options:\n",
    "#         for dropout_rate in dropout_rate_options:\n",
    "#             for activation in activation_options:\n",
    "#                 model = build_model(n_units, learning_rate, dropout_rate, activation)\n",
    "#                 model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "#                 y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "#                 y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "#                 # 평가 지표 계산\n",
    "#                 mae = mean_absolute_error(y_test, y_pred)\n",
    "#                 mse = mean_squared_error(y_test, y_pred)\n",
    "#                 rmse = np.sqrt(mse)\n",
    "\n",
    "#                 # 최적 모델 업데이트\n",
    "#                 if mae + rmse < best_mae + best_rmse:\n",
    "#                     best_model = model\n",
    "#                     best_mae = mae\n",
    "#                     best_rmse = rmse\n",
    "#                     best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "#                 # 결과 추가\n",
    "#                 temp_results = pd.DataFrame({\n",
    "#                     'Actual': y_test,\n",
    "#                     'Predicted': y_pred,\n",
    "#                     'MAE': mae,\n",
    "#                     'RMSE': rmse\n",
    "#                 })\n",
    "#                 results_table = pd.concat([results_table, temp_results])\n",
    "\n",
    "# # 최적 모델의 결과와 파라미터 출력\n",
    "# print(\"Best Model Results:\")\n",
    "# print(results_table)\n",
    "# print(\"\\nBest Model Parameters:\")\n",
    "# print(best_model_params)\n",
    "\n",
    "# # 최적 모델의 결과에서 가장 좋은 MAE와 RMSE 값 찾기\n",
    "# best_mae = results_table['MAE'].min()\n",
    "# best_rmse = results_table['RMSE'].min()\n",
    "\n",
    "# best_mae, best_rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d8e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f9478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc5929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796fa562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6e482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1029b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dea076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8e4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f153e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "991523f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Best Model Results:\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "225     2.0   3.089836  3.620561  4.663400\n",
      "30     11.0   8.762975  3.620561  4.663400\n",
      "39      2.0   4.108375  3.620561  4.663400\n",
      "222     0.0   2.003901  3.620561  4.663400\n",
      "124     1.0   5.322908  3.620561  4.663400\n",
      "203     0.0   3.923831  3.620561  4.663400\n",
      "310     2.0   6.896348  3.620561  4.663400\n",
      "211    11.0   1.606189  3.620561  4.663400\n",
      "457     1.0   6.335377  3.620561  4.663400\n",
      "77     13.0   5.442395  3.620561  4.663400\n",
      "454     2.0   6.049556  3.620561  4.663400\n",
      "398     2.0   2.518882  3.620561  4.663400\n",
      "76      1.0   1.396714  3.620561  4.663400\n",
      "386     3.0   4.294081  3.620561  4.663400\n",
      "278     3.0   2.098212  3.620561  4.663400\n",
      "271    11.0   4.706811  3.620561  4.663400\n",
      "70      4.0   5.984070  3.620561  4.663400\n",
      "93     16.0  12.401191  3.620561  4.663400\n",
      "157    14.0   6.098627  3.620561  4.663400\n",
      "0       3.0   5.483259  3.620561  4.663400\n",
      "388     5.0   1.652067  3.620561  4.663400\n",
      "82      3.0   4.839403  3.620561  4.663400\n",
      "368     2.0   4.877786  3.620561  4.663400\n",
      "357     7.0   3.314530  3.620561  4.663400\n",
      "420     4.0   3.106859  3.620561  4.663400\n",
      "307     3.0   9.662278  3.620561  4.663400\n",
      "172    10.0   2.480785  3.620561  4.663400\n",
      "176     4.0   3.045771  3.620561  4.663400\n",
      "18      7.0   7.416784  3.620561  4.663400\n",
      "9       0.0   1.798321  3.620561  4.663400\n",
      "428     1.0   1.647468  3.620561  4.663400\n",
      "448     5.0   4.649006  3.620561  4.663400\n",
      "73     14.0   1.038642  3.620561  4.663400\n",
      "234     1.0   2.481832  3.620561  4.663400\n",
      "287    10.0  10.235040  3.620561  4.663400\n",
      "408     1.0   3.382787  3.620561  4.663400\n",
      "55     14.0   8.660262  3.620561  4.663400\n",
      "90     13.0   3.843556  3.620561  4.663400\n",
      "364     6.0   7.875299  3.620561  4.663400\n",
      "79      0.0   2.830424  3.620561  4.663400\n",
      "325     1.0   4.536369  3.620561  4.663400\n",
      "450     3.0   2.523067  3.620561  4.663400\n",
      "209     4.0   5.314673  3.620561  4.663400\n",
      "173    16.0   3.793583  3.620561  4.663400\n",
      "185     8.0   2.998355  3.620561  4.663400\n",
      "72      0.0   4.230690  3.620561  4.663400\n",
      "148     8.0   4.186764  3.620561  4.663400\n",
      "78      2.0   2.782446  3.620561  4.663400\n",
      "126    15.0   8.195715  3.620561  4.663400\n",
      "132     0.0   9.475739  3.620561  4.663400\n",
      "458     5.0   6.918827  3.620561  4.663400\n",
      "75     15.0   6.156768  3.620561  4.663400\n",
      "296    10.0   1.761356  3.620561  4.663400\n",
      "195     2.0   4.011393  3.620561  4.663400\n",
      "131     0.0   2.469959  3.620561  4.663400\n",
      "227    11.0   4.635468  3.620561  4.663400\n",
      "365     5.0   2.549781  3.620561  4.663400\n",
      "33     13.0   7.529799  3.620561  4.663400\n",
      "373     0.0   1.699103  3.620561  4.663400\n",
      "320     8.0   2.623771  3.620561  4.663400\n",
      "409     2.0   1.321227  3.620561  4.663400\n",
      "140    13.0   6.466173  3.620561  4.663400\n",
      "11      1.0   7.497026  3.620561  4.663400\n",
      "407     3.0   1.701732  3.620561  4.663400\n",
      "15     12.0   3.878819  3.620561  4.663400\n",
      "421     5.0   4.859873  3.620561  4.663400\n",
      "358     3.0   1.916354  3.620561  4.663400\n",
      "19      3.0   0.677542  3.620561  4.663400\n",
      "297     6.0   2.991041  3.620561  4.663400\n",
      "416     3.0   1.796937  3.620561  4.663400\n",
      "56      1.0   0.984890  3.620561  4.663400\n",
      "196    13.0   6.293678  3.620561  4.663400\n",
      "334     2.0   1.442384  3.620561  4.663400\n",
      "305     1.0   6.685967  3.620561  4.663400\n",
      "113     3.0   6.222108  3.620561  4.663400\n",
      "155    15.0   6.233503  3.620561  4.663400\n",
      "394     0.0   4.099796  3.620561  4.663400\n",
      "25      4.0   2.314835  3.620561  4.663400\n",
      "449     4.0   2.809980  3.620561  4.663400\n",
      "255     5.0   4.088351  3.620561  4.663400\n",
      "180     6.0   2.646604  3.620561  4.663400\n",
      "42      5.0   4.501013  3.620561  4.663400\n",
      "302     2.0   4.280748  3.620561  4.663400\n",
      "101    10.0   1.277769  3.620561  4.663400\n",
      "432     2.0   4.412417  3.620561  4.663400\n",
      "402     3.0   1.891107  3.620561  4.663400\n",
      "137    14.0   9.027395  3.620561  4.663400\n",
      "299     8.0   6.982104  3.620561  4.663400\n",
      "22      3.0   8.935740  3.620561  4.663400\n",
      "301    11.0   6.790279  3.620561  4.663400\n",
      "46      4.0   4.241789  3.620561  4.663400\n",
      "168     1.0   2.059994  3.620561  4.663400\n",
      "460     4.0   9.138687  3.620561  4.663400\n",
      "225     2.0   4.039632  3.745015  4.601783\n",
      "30     11.0   6.652883  3.745015  4.601783\n",
      "39      2.0   5.677669  3.745015  4.601783\n",
      "222     0.0   1.496005  3.745015  4.601783\n",
      "124     1.0   3.769767  3.745015  4.601783\n",
      "203     0.0   5.551211  3.745015  4.601783\n",
      "310     2.0   6.775318  3.745015  4.601783\n",
      "211    11.0   2.862571  3.745015  4.601783\n",
      "457     1.0   6.784340  3.745015  4.601783\n",
      "77     13.0   3.921217  3.745015  4.601783\n",
      "454     2.0   5.381538  3.745015  4.601783\n",
      "398     2.0   3.150760  3.745015  4.601783\n",
      "76      1.0   3.625721  3.745015  4.601783\n",
      "386     3.0   6.427494  3.745015  4.601783\n",
      "278     3.0   2.272208  3.745015  4.601783\n",
      "271    11.0   6.142807  3.745015  4.601783\n",
      "70      4.0   6.328822  3.745015  4.601783\n",
      "93     16.0   9.366149  3.745015  4.601783\n",
      "157    14.0   6.792593  3.745015  4.601783\n",
      "0       3.0   4.691302  3.745015  4.601783\n",
      "388     5.0   0.705637  3.745015  4.601783\n",
      "82      3.0   5.537084  3.745015  4.601783\n",
      "368     2.0   7.111576  3.745015  4.601783\n",
      "357     7.0   4.169626  3.745015  4.601783\n",
      "420     4.0   5.356301  3.745015  4.601783\n",
      "307     3.0   6.402703  3.745015  4.601783\n",
      "172    10.0   5.220237  3.745015  4.601783\n",
      "176     4.0   2.224633  3.745015  4.601783\n",
      "18      7.0   7.058059  3.745015  4.601783\n",
      "9       0.0   4.751292  3.745015  4.601783\n",
      "428     1.0   2.681248  3.745015  4.601783\n",
      "448     5.0   2.739430  3.745015  4.601783\n",
      "73     14.0   2.853061  3.745015  4.601783\n",
      "234     1.0   3.237173  3.745015  4.601783\n",
      "287    10.0   8.773424  3.745015  4.601783\n",
      "408     1.0   4.416904  3.745015  4.601783\n",
      "55     14.0   7.340373  3.745015  4.601783\n",
      "90     13.0   4.850878  3.745015  4.601783\n",
      "364     6.0   7.120481  3.745015  4.601783\n",
      "79      0.0   4.555697  3.745015  4.601783\n",
      "325     1.0   6.541889  3.745015  4.601783\n",
      "450     3.0   1.819731  3.745015  4.601783\n",
      "209     4.0   6.673747  3.745015  4.601783\n",
      "173    16.0   4.042243  3.745015  4.601783\n",
      "185     8.0   3.076198  3.745015  4.601783\n",
      "72      0.0   3.175264  3.745015  4.601783\n",
      "148     8.0   6.372993  3.745015  4.601783\n",
      "78      2.0   2.360791  3.745015  4.601783\n",
      "126    15.0   8.071701  3.745015  4.601783\n",
      "132     0.0   8.780487  3.745015  4.601783\n",
      "458     5.0   3.252388  3.745015  4.601783\n",
      "75     15.0   7.893015  3.745015  4.601783\n",
      "296    10.0   3.021527  3.745015  4.601783\n",
      "195     2.0   2.904659  3.745015  4.601783\n",
      "131     0.0   3.691857  3.745015  4.601783\n",
      "227    11.0   3.658810  3.745015  4.601783\n",
      "365     5.0   4.760791  3.745015  4.601783\n",
      "33     13.0   4.053990  3.745015  4.601783\n",
      "373     0.0   2.180663  3.745015  4.601783\n",
      "320     8.0   2.981733  3.745015  4.601783\n",
      "409     2.0   0.860844  3.745015  4.601783\n",
      "140    13.0   6.287449  3.745015  4.601783\n",
      "11      1.0   7.382057  3.745015  4.601783\n",
      "407     3.0   4.110112  3.745015  4.601783\n",
      "15     12.0   4.711022  3.745015  4.601783\n",
      "421     5.0   4.648925  3.745015  4.601783\n",
      "358     3.0   5.163203  3.745015  4.601783\n",
      "19      3.0   0.000000  3.745015  4.601783\n",
      "297     6.0   3.692356  3.745015  4.601783\n",
      "416     3.0   1.369522  3.745015  4.601783\n",
      "56      1.0   2.323721  3.745015  4.601783\n",
      "196    13.0   8.301319  3.745015  4.601783\n",
      "334     2.0   5.050622  3.745015  4.601783\n",
      "305     1.0   5.592938  3.745015  4.601783\n",
      "113     3.0   6.062227  3.745015  4.601783\n",
      "155    15.0   5.258777  3.745015  4.601783\n",
      "394     0.0   5.377021  3.745015  4.601783\n",
      "25      4.0   3.481741  3.745015  4.601783\n",
      "449     4.0   4.160049  3.745015  4.601783\n",
      "255     5.0   5.429803  3.745015  4.601783\n",
      "180     6.0   5.338284  3.745015  4.601783\n",
      "42      5.0   5.757460  3.745015  4.601783\n",
      "302     2.0   3.829502  3.745015  4.601783\n",
      "101    10.0   4.426668  3.745015  4.601783\n",
      "432     2.0   4.346597  3.745015  4.601783\n",
      "402     3.0   2.360363  3.745015  4.601783\n",
      "137    14.0   7.321007  3.745015  4.601783\n",
      "299     8.0   5.716463  3.745015  4.601783\n",
      "22      3.0   6.066980  3.745015  4.601783\n",
      "301    11.0   6.108227  3.745015  4.601783\n",
      "46      4.0   6.488608  3.745015  4.601783\n",
      "168     1.0   4.183125  3.745015  4.601783\n",
      "460     4.0   6.500755  3.745015  4.601783\n",
      "225     2.0   2.735375  3.516347  4.668851\n",
      "30     11.0   6.950973  3.516347  4.668851\n",
      "39      2.0   3.959887  3.516347  4.668851\n",
      "222     0.0   1.402258  3.516347  4.668851\n",
      "124     1.0   5.061948  3.516347  4.668851\n",
      "203     0.0   3.632762  3.516347  4.668851\n",
      "310     2.0   6.790172  3.516347  4.668851\n",
      "211    11.0   1.728150  3.516347  4.668851\n",
      "457     1.0   7.258677  3.516347  4.668851\n",
      "77     13.0   4.122759  3.516347  4.668851\n",
      "454     2.0   5.405676  3.516347  4.668851\n",
      "398     2.0   2.415576  3.516347  4.668851\n",
      "76      1.0   1.730537  3.516347  4.668851\n",
      "386     3.0   4.856335  3.516347  4.668851\n",
      "278     3.0   1.540499  3.516347  4.668851\n",
      "271    11.0   3.889076  3.516347  4.668851\n",
      "70      4.0   5.820970  3.516347  4.668851\n",
      "93     16.0  11.043737  3.516347  4.668851\n",
      "157    14.0   6.184921  3.516347  4.668851\n",
      "0       3.0   4.166082  3.516347  4.668851\n",
      "388     5.0   1.449175  3.516347  4.668851\n",
      "82      3.0   3.299886  3.516347  4.668851\n",
      "368     2.0   4.371507  3.516347  4.668851\n",
      "357     7.0   3.823011  3.516347  4.668851\n",
      "420     4.0   3.126737  3.516347  4.668851\n",
      "307     3.0   7.101503  3.516347  4.668851\n",
      "172    10.0   3.266956  3.516347  4.668851\n",
      "176     4.0   2.361939  3.516347  4.668851\n",
      "18      7.0   7.199115  3.516347  4.668851\n",
      "9       0.0   1.993155  3.516347  4.668851\n",
      "428     1.0   1.767413  3.516347  4.668851\n",
      "448     5.0   4.286757  3.516347  4.668851\n",
      "73     14.0   1.237235  3.516347  4.668851\n",
      "234     1.0   3.220960  3.516347  4.668851\n",
      "287    10.0   9.642860  3.516347  4.668851\n",
      "408     1.0   2.358419  3.516347  4.668851\n",
      "55     14.0   7.801939  3.516347  4.668851\n",
      "90     13.0   3.608268  3.516347  4.668851\n",
      "364     6.0   5.892772  3.516347  4.668851\n",
      "79      0.0   2.515330  3.516347  4.668851\n",
      "325     1.0   5.304998  3.516347  4.668851\n",
      "450     3.0   1.895469  3.516347  4.668851\n",
      "209     4.0   4.902269  3.516347  4.668851\n",
      "173    16.0   3.458881  3.516347  4.668851\n",
      "185     8.0   3.172758  3.516347  4.668851\n",
      "72      0.0   2.265018  3.516347  4.668851\n",
      "148     8.0   4.154312  3.516347  4.668851\n",
      "78      2.0   2.421219  3.516347  4.668851\n",
      "126    15.0   7.221876  3.516347  4.668851\n",
      "132     0.0   9.763363  3.516347  4.668851\n",
      "458     5.0   4.905347  3.516347  4.668851\n",
      "75     15.0   5.843149  3.516347  4.668851\n",
      "296    10.0   2.334059  3.516347  4.668851\n",
      "195     2.0   3.303093  3.516347  4.668851\n",
      "131     0.0   2.319154  3.516347  4.668851\n",
      "227    11.0   3.950709  3.516347  4.668851\n",
      "365     5.0   2.710660  3.516347  4.668851\n",
      "33     13.0   6.062300  3.516347  4.668851\n",
      "373     0.0   1.633874  3.516347  4.668851\n",
      "320     8.0   2.428291  3.516347  4.668851\n",
      "409     2.0   1.535038  3.516347  4.668851\n",
      "140    13.0   6.854568  3.516347  4.668851\n",
      "11      1.0   6.677106  3.516347  4.668851\n",
      "407     3.0   1.724421  3.516347  4.668851\n",
      "15     12.0   3.647528  3.516347  4.668851\n",
      "421     5.0   3.790537  3.516347  4.668851\n",
      "358     3.0   1.858171  3.516347  4.668851\n",
      "19      3.0   1.288428  3.516347  4.668851\n",
      "297     6.0   3.539688  3.516347  4.668851\n",
      "416     3.0   1.795342  3.516347  4.668851\n",
      "56      1.0   1.091827  3.516347  4.668851\n",
      "196    13.0   5.633290  3.516347  4.668851\n",
      "334     2.0   1.782347  3.516347  4.668851\n",
      "305     1.0   4.945256  3.516347  4.668851\n",
      "113     3.0   5.334441  3.516347  4.668851\n",
      "155    15.0   5.518044  3.516347  4.668851\n",
      "394     0.0   4.119581  3.516347  4.668851\n",
      "25      4.0   2.684273  3.516347  4.668851\n",
      "449     4.0   3.336178  3.516347  4.668851\n",
      "255     5.0   3.895036  3.516347  4.668851\n",
      "180     6.0   2.623531  3.516347  4.668851\n",
      "42      5.0   4.944994  3.516347  4.668851\n",
      "302     2.0   3.258177  3.516347  4.668851\n",
      "101    10.0   1.544342  3.516347  4.668851\n",
      "432     2.0   4.118532  3.516347  4.668851\n",
      "402     3.0   1.966667  3.516347  4.668851\n",
      "137    14.0   8.830979  3.516347  4.668851\n",
      "299     8.0   6.452727  3.516347  4.668851\n",
      "22      3.0   7.077200  3.516347  4.668851\n",
      "301    11.0   7.089575  3.516347  4.668851\n",
      "46      4.0   4.097494  3.516347  4.668851\n",
      "168     1.0   2.209511  3.516347  4.668851\n",
      "460     4.0   9.545928  3.516347  4.668851\n",
      "225     2.0   4.022897  3.785848  4.666477\n",
      "30     11.0   6.431708  3.785848  4.666477\n",
      "39      2.0   5.432404  3.785848  4.666477\n",
      "222     0.0   1.144984  3.785848  4.666477\n",
      "124     1.0   4.805030  3.785848  4.666477\n",
      "203     0.0   5.682687  3.785848  4.666477\n",
      "310     2.0   6.424098  3.785848  4.666477\n",
      "211    11.0   2.867314  3.785848  4.666477\n",
      "457     1.0   5.935935  3.785848  4.666477\n",
      "77     13.0   3.974722  3.785848  4.666477\n",
      "454     2.0   5.790833  3.785848  4.666477\n",
      "398     2.0   3.244720  3.785848  4.666477\n",
      "76      1.0   3.691891  3.785848  4.666477\n",
      "386     3.0   6.120421  3.785848  4.666477\n",
      "278     3.0   1.920164  3.785848  4.666477\n",
      "271    11.0   5.865356  3.785848  4.666477\n",
      "70      4.0   5.903832  3.785848  4.666477\n",
      "93     16.0   7.617855  3.785848  4.666477\n",
      "157    14.0   6.898037  3.785848  4.666477\n",
      "0       3.0   5.223378  3.785848  4.666477\n",
      "388     5.0   1.025061  3.785848  4.666477\n",
      "82      3.0   5.273353  3.785848  4.666477\n",
      "368     2.0   6.138736  3.785848  4.666477\n",
      "357     7.0   3.949568  3.785848  4.666477\n",
      "420     4.0   5.219775  3.785848  4.666477\n",
      "307     3.0   6.159300  3.785848  4.666477\n",
      "172    10.0   5.467724  3.785848  4.666477\n",
      "176     4.0   2.728792  3.785848  4.666477\n",
      "18      7.0   6.601630  3.785848  4.666477\n",
      "9       0.0   5.286980  3.785848  4.666477\n",
      "428     1.0   3.281685  3.785848  4.666477\n",
      "448     5.0   3.395931  3.785848  4.666477\n",
      "73     14.0   2.558583  3.785848  4.666477\n",
      "234     1.0   3.932601  3.785848  4.666477\n",
      "287    10.0   7.479282  3.785848  4.666477\n",
      "408     1.0   4.284116  3.785848  4.666477\n",
      "55     14.0   6.331384  3.785848  4.666477\n",
      "90     13.0   4.335563  3.785848  4.666477\n",
      "364     6.0   6.214260  3.785848  4.666477\n",
      "79      0.0   4.931994  3.785848  4.666477\n",
      "325     1.0   6.424216  3.785848  4.666477\n",
      "450     3.0   1.376533  3.785848  4.666477\n",
      "209     4.0   6.401199  3.785848  4.666477\n",
      "173    16.0   4.499756  3.785848  4.666477\n",
      "185     8.0   3.477996  3.785848  4.666477\n",
      "72      0.0   2.996860  3.785848  4.666477\n",
      "148     8.0   5.723796  3.785848  4.666477\n",
      "78      2.0   2.820340  3.785848  4.666477\n",
      "126    15.0   7.004870  3.785848  4.666477\n",
      "132     0.0   7.630829  3.785848  4.666477\n",
      "458     5.0   1.752130  3.785848  4.666477\n",
      "75     15.0   6.450221  3.785848  4.666477\n",
      "296    10.0   3.097885  3.785848  4.666477\n",
      "195     2.0   2.915500  3.785848  4.666477\n",
      "131     0.0   4.028745  3.785848  4.666477\n",
      "227    11.0   4.795099  3.785848  4.666477\n",
      "365     5.0   4.650465  3.785848  4.666477\n",
      "33     13.0   3.852258  3.785848  4.666477\n",
      "373     0.0   2.120516  3.785848  4.666477\n",
      "320     8.0   2.875184  3.785848  4.666477\n",
      "409     2.0   2.408105  3.785848  4.666477\n",
      "140    13.0   6.380891  3.785848  4.666477\n",
      "11      1.0   6.692253  3.785848  4.666477\n",
      "407     3.0   4.064994  3.785848  4.666477\n",
      "15     12.0   4.855792  3.785848  4.666477\n",
      "421     5.0   5.231332  3.785848  4.666477\n",
      "358     3.0   5.520483  3.785848  4.666477\n",
      "19      3.0   0.000000  3.785848  4.666477\n",
      "297     6.0   4.302754  3.785848  4.666477\n",
      "416     3.0   1.031661  3.785848  4.666477\n",
      "56      1.0   1.729148  3.785848  4.666477\n",
      "196    13.0   6.772165  3.785848  4.666477\n",
      "334     2.0   4.523910  3.785848  4.666477\n",
      "305     1.0   5.541698  3.785848  4.666477\n",
      "113     3.0   5.466015  3.785848  4.666477\n",
      "155    15.0   5.034412  3.785848  4.666477\n",
      "394     0.0   5.198519  3.785848  4.666477\n",
      "25      4.0   3.633632  3.785848  4.666477\n",
      "449     4.0   4.526731  3.785848  4.666477\n",
      "255     5.0   5.062233  3.785848  4.666477\n",
      "180     6.0   4.632808  3.785848  4.666477\n",
      "42      5.0   5.827628  3.785848  4.666477\n",
      "302     2.0   3.044453  3.785848  4.666477\n",
      "101    10.0   4.264227  3.785848  4.666477\n",
      "432     2.0   4.109766  3.785848  4.666477\n",
      "402     3.0   2.854821  3.785848  4.666477\n",
      "137    14.0   7.255697  3.785848  4.666477\n",
      "299     8.0   4.713526  3.785848  4.666477\n",
      "22      3.0   5.601420  3.785848  4.666477\n",
      "301    11.0   6.269082  3.785848  4.666477\n",
      "46      4.0   6.172690  3.785848  4.666477\n",
      "168     1.0   3.875576  3.785848  4.666477\n",
      "460     4.0   7.009113  3.785848  4.666477\n",
      "225     2.0   3.297942  3.688119  4.739607\n",
      "30     11.0   4.984073  3.688119  4.739607\n",
      "39      2.0   3.500016  3.688119  4.739607\n",
      "222     0.0   1.892805  3.688119  4.739607\n",
      "124     1.0   4.115252  3.688119  4.739607\n",
      "203     0.0   2.779298  3.688119  4.739607\n",
      "310     2.0   7.995987  3.688119  4.739607\n",
      "211    11.0   2.209611  3.688119  4.739607\n",
      "457     1.0   4.503213  3.688119  4.739607\n",
      "77     13.0   4.731631  3.688119  4.739607\n",
      "454     2.0   4.139400  3.688119  4.739607\n",
      "398     2.0   4.493244  3.688119  4.739607\n",
      "76      1.0   2.814419  3.688119  4.739607\n",
      "386     3.0   5.305226  3.688119  4.739607\n",
      "278     3.0   3.715726  3.688119  4.739607\n",
      "271    11.0   3.736007  3.688119  4.739607\n",
      "70      4.0   7.133827  3.688119  4.739607\n",
      "93     16.0  13.264359  3.688119  4.739607\n",
      "157    14.0   5.155563  3.688119  4.739607\n",
      "0       3.0   4.286361  3.688119  4.739607\n",
      "388     5.0   2.103778  3.688119  4.739607\n",
      "82      3.0   4.277069  3.688119  4.739607\n",
      "368     2.0   3.917171  3.688119  4.739607\n",
      "357     7.0   3.039158  3.688119  4.739607\n",
      "420     4.0   6.453609  3.688119  4.739607\n",
      "307     3.0   7.585926  3.688119  4.739607\n",
      "172    10.0   2.694442  3.688119  4.739607\n",
      "176     4.0   1.957129  3.688119  4.739607\n",
      "18      7.0   7.950983  3.688119  4.739607\n",
      "9       0.0   2.605103  3.688119  4.739607\n",
      "428     1.0   2.611707  3.688119  4.739607\n",
      "448     5.0   2.418753  3.688119  4.739607\n",
      "73     14.0   4.112879  3.688119  4.739607\n",
      "234     1.0   1.892805  3.688119  4.739607\n",
      "287    10.0  11.234524  3.688119  4.739607\n",
      "408     1.0   5.254849  3.688119  4.739607\n",
      "55     14.0  11.450035  3.688119  4.739607\n",
      "90     13.0   7.104656  3.688119  4.739607\n",
      "364     6.0  10.481908  3.688119  4.739607\n",
      "79      0.0   3.558085  3.688119  4.739607\n",
      "325     1.0   5.287204  3.688119  4.739607\n",
      "450     3.0   1.897574  3.688119  4.739607\n",
      "209     4.0   6.723856  3.688119  4.739607\n",
      "173    16.0   3.044153  3.688119  4.739607\n",
      "185     8.0   1.980376  3.688119  4.739607\n",
      "72      0.0   2.048703  3.688119  4.739607\n",
      "148     8.0   4.653998  3.688119  4.739607\n",
      "78      2.0   1.892805  3.688119  4.739607\n",
      "126    15.0  12.011917  3.688119  4.739607\n",
      "132     0.0  13.027890  3.688119  4.739607\n",
      "458     5.0   2.397691  3.688119  4.739607\n",
      "75     15.0   6.453150  3.688119  4.739607\n",
      "296    10.0   3.633818  3.688119  4.739607\n",
      "195     2.0   2.062324  3.688119  4.739607\n",
      "131     0.0   3.426025  3.688119  4.739607\n",
      "227    11.0   4.222436  3.688119  4.739607\n",
      "365     5.0   8.307127  3.688119  4.739607\n",
      "33     13.0   2.546751  3.688119  4.739607\n",
      "373     0.0   4.156090  3.688119  4.739607\n",
      "320     8.0   2.018811  3.688119  4.739607\n",
      "409     2.0   1.493254  3.688119  4.739607\n",
      "140    13.0   4.927613  3.688119  4.739607\n",
      "11      1.0   7.118793  3.688119  4.739607\n",
      "407     3.0   5.165040  3.688119  4.739607\n",
      "15     12.0   4.666508  3.688119  4.739607\n",
      "421     5.0   3.589392  3.688119  4.739607\n",
      "358     3.0   2.810522  3.688119  4.739607\n",
      "19      3.0   1.956576  3.688119  4.739607\n",
      "297     6.0   4.773397  3.688119  4.739607\n",
      "416     3.0   1.789639  3.688119  4.739607\n",
      "56      1.0   4.615507  3.688119  4.739607\n",
      "196    13.0   9.265009  3.688119  4.739607\n",
      "334     2.0   2.059195  3.688119  4.739607\n",
      "305     1.0   3.316020  3.688119  4.739607\n",
      "113     3.0   8.187034  3.688119  4.739607\n",
      "155    15.0   2.256461  3.688119  4.739607\n",
      "394     0.0   4.512060  3.688119  4.739607\n",
      "25      4.0   1.892805  3.688119  4.739607\n",
      "449     4.0   4.446862  3.688119  4.739607\n",
      "255     5.0   2.849681  3.688119  4.739607\n",
      "180     6.0   6.945980  3.688119  4.739607\n",
      "42      5.0   4.921290  3.688119  4.739607\n",
      "302     2.0   2.242564  3.688119  4.739607\n",
      "101    10.0   2.974278  3.688119  4.739607\n",
      "432     2.0   3.873590  3.688119  4.739607\n",
      "402     3.0   1.710580  3.688119  4.739607\n",
      "137    14.0   9.852117  3.688119  4.739607\n",
      "299     8.0   6.373217  3.688119  4.739607\n",
      "22      3.0   7.268715  3.688119  4.739607\n",
      "301    11.0   7.413752  3.688119  4.739607\n",
      "46      4.0   5.335698  3.688119  4.739607\n",
      "168     1.0   2.295220  3.688119  4.739607\n",
      "460     4.0  10.008723  3.688119  4.739607\n",
      "225     2.0   3.219897  3.979967  4.840991\n",
      "30     11.0   8.094683  3.979967  4.840991\n",
      "39      2.0   5.162037  3.979967  4.840991\n",
      "222     0.0   3.321705  3.979967  4.840991\n",
      "124     1.0   5.354607  3.979967  4.840991\n",
      "203     0.0   5.922736  3.979967  4.840991\n",
      "310     2.0   4.793923  3.979967  4.840991\n",
      "211    11.0   0.050483  3.979967  4.840991\n",
      "457     1.0   5.576847  3.979967  4.840991\n",
      "77     13.0   3.833158  3.979967  4.840991\n",
      "454     2.0   4.288527  3.979967  4.840991\n",
      "398     2.0   4.563281  3.979967  4.840991\n",
      "76      1.0   2.197071  3.979967  4.840991\n",
      "386     3.0   5.678991  3.979967  4.840991\n",
      "278     3.0   1.981842  3.979967  4.840991\n",
      "271    11.0   6.680534  3.979967  4.840991\n",
      "70      4.0   6.240066  3.979967  4.840991\n",
      "93     16.0   9.278111  3.979967  4.840991\n",
      "157    14.0   9.232425  3.979967  4.840991\n",
      "0       3.0   6.130875  3.979967  4.840991\n",
      "388     5.0   0.000000  3.979967  4.840991\n",
      "82      3.0   5.605070  3.979967  4.840991\n",
      "368     2.0   6.875107  3.979967  4.840991\n",
      "357     7.0   1.863810  3.979967  4.840991\n",
      "420     4.0   5.241482  3.979967  4.840991\n",
      "307     3.0   8.706501  3.979967  4.840991\n",
      "172    10.0   4.747981  3.979967  4.840991\n",
      "176     4.0   2.648086  3.979967  4.840991\n",
      "18      7.0   7.670326  3.979967  4.840991\n",
      "9       0.0   5.413759  3.979967  4.840991\n",
      "428     1.0   4.257779  3.979967  4.840991\n",
      "448     5.0   3.967768  3.979967  4.840991\n",
      "73     14.0   4.267016  3.979967  4.840991\n",
      "234     1.0   3.319989  3.979967  4.840991\n",
      "287    10.0  10.324509  3.979967  4.840991\n",
      "408     1.0   2.235439  3.979967  4.840991\n",
      "55     14.0   6.040244  3.979967  4.840991\n",
      "90     13.0   6.428364  3.979967  4.840991\n",
      "364     6.0   8.875036  3.979967  4.840991\n",
      "79      0.0   4.235594  3.979967  4.840991\n",
      "325     1.0   7.255614  3.979967  4.840991\n",
      "450     3.0   2.809902  3.979967  4.840991\n",
      "209     4.0   7.670481  3.979967  4.840991\n",
      "173    16.0   5.421555  3.979967  4.840991\n",
      "185     8.0   2.383795  3.979967  4.840991\n",
      "72      0.0   3.824823  3.979967  4.840991\n",
      "148     8.0   6.341883  3.979967  4.840991\n",
      "78      2.0   3.704548  3.979967  4.840991\n",
      "126    15.0   8.754973  3.979967  4.840991\n",
      "132     0.0   9.680785  3.979967  4.840991\n",
      "458     5.0   3.963706  3.979967  4.840991\n",
      "75     15.0   7.823333  3.979967  4.840991\n",
      "296    10.0   0.064662  3.979967  4.840991\n",
      "195     2.0   4.777305  3.979967  4.840991\n",
      "131     0.0   3.720653  3.979967  4.840991\n",
      "227    11.0   3.120832  3.979967  4.840991\n",
      "365     5.0   5.733220  3.979967  4.840991\n",
      "33     13.0   4.268495  3.979967  4.840991\n",
      "373     0.0   4.162149  3.979967  4.840991\n",
      "320     8.0   3.611946  3.979967  4.840991\n",
      "409     2.0   2.306727  3.979967  4.840991\n",
      "140    13.0   8.471811  3.979967  4.840991\n",
      "11      1.0   6.635109  3.979967  4.840991\n",
      "407     3.0   4.584590  3.979967  4.840991\n",
      "15     12.0   4.588822  3.979967  4.840991\n",
      "421     5.0   6.922635  3.979967  4.840991\n",
      "358     3.0   6.541517  3.979967  4.840991\n",
      "19      3.0   0.000000  3.979967  4.840991\n",
      "297     6.0   2.475424  3.979967  4.840991\n",
      "416     3.0   2.509434  3.979967  4.840991\n",
      "56      1.0   3.287347  3.979967  4.840991\n",
      "196    13.0  11.283840  3.979967  4.840991\n",
      "334     2.0   3.478671  3.979967  4.840991\n",
      "305     1.0   9.961128  3.979967  4.840991\n",
      "113     3.0   7.507734  3.979967  4.840991\n",
      "155    15.0   5.227687  3.979967  4.840991\n",
      "394     0.0   5.737561  3.979967  4.840991\n",
      "25      4.0   4.355684  3.979967  4.840991\n",
      "449     4.0   5.399908  3.979967  4.840991\n",
      "255     5.0   4.534420  3.979967  4.840991\n",
      "180     6.0   3.650558  3.979967  4.840991\n",
      "42      5.0   5.236438  3.979967  4.840991\n",
      "302     2.0   4.090566  3.979967  4.840991\n",
      "101    10.0   1.371933  3.979967  4.840991\n",
      "432     2.0   4.626981  3.979967  4.840991\n",
      "402     3.0   2.655667  3.979967  4.840991\n",
      "137    14.0   9.038869  3.979967  4.840991\n",
      "299     8.0   4.554983  3.979967  4.840991\n",
      "22      3.0   9.703306  3.979967  4.840991\n",
      "301    11.0   8.427923  3.979967  4.840991\n",
      "46      4.0   9.772738  3.979967  4.840991\n",
      "168     1.0   2.942481  3.979967  4.840991\n",
      "460     4.0   7.776068  3.979967  4.840991\n",
      "225     2.0   2.423571  3.532638  4.740503\n",
      "30     11.0   5.599378  3.532638  4.740503\n",
      "39      2.0   2.967698  3.532638  4.740503\n",
      "222     0.0   1.936118  3.532638  4.740503\n",
      "124     1.0   4.075648  3.532638  4.740503\n",
      "203     0.0   3.616412  3.532638  4.740503\n",
      "310     2.0   5.444071  3.532638  4.740503\n",
      "211    11.0   1.915649  3.532638  4.740503\n",
      "457     1.0   4.911893  3.532638  4.740503\n",
      "77     13.0   3.180441  3.532638  4.740503\n",
      "454     2.0   4.510169  3.532638  4.740503\n",
      "398     2.0   2.553075  3.532638  4.740503\n",
      "76      1.0   2.014884  3.532638  4.740503\n",
      "386     3.0   4.749990  3.532638  4.740503\n",
      "278     3.0   2.600449  3.532638  4.740503\n",
      "271    11.0   3.407881  3.532638  4.740503\n",
      "70      4.0   4.829539  3.532638  4.740503\n",
      "93     16.0  10.213986  3.532638  4.740503\n",
      "157    14.0   5.218055  3.532638  4.740503\n",
      "0       3.0   3.020430  3.532638  4.740503\n",
      "388     5.0   2.007139  3.532638  4.740503\n",
      "82      3.0   4.102861  3.532638  4.740503\n",
      "368     2.0   3.824254  3.532638  4.740503\n",
      "357     7.0   2.761170  3.532638  4.740503\n",
      "420     4.0   3.448494  3.532638  4.740503\n",
      "307     3.0   5.706583  3.532638  4.740503\n",
      "172    10.0   2.494619  3.532638  4.740503\n",
      "176     4.0   2.186325  3.532638  4.740503\n",
      "18      7.0   6.538443  3.532638  4.740503\n",
      "9       0.0   2.088451  3.532638  4.740503\n",
      "428     1.0   2.105498  3.532638  4.740503\n",
      "448     5.0   2.257712  3.532638  4.740503\n",
      "73     14.0   2.104391  3.532638  4.740503\n",
      "234     1.0   2.178997  3.532638  4.740503\n",
      "287    10.0  10.003519  3.532638  4.740503\n",
      "408     1.0   3.470649  3.532638  4.740503\n",
      "55     14.0   7.112120  3.532638  4.740503\n",
      "90     13.0   4.223992  3.532638  4.740503\n",
      "364     6.0   8.710234  3.532638  4.740503\n",
      "79      0.0   3.296467  3.532638  4.740503\n",
      "325     1.0   3.152873  3.532638  4.740503\n",
      "450     3.0   1.822902  3.532638  4.740503\n",
      "209     4.0   6.153966  3.532638  4.740503\n",
      "173    16.0   2.841094  3.532638  4.740503\n",
      "185     8.0   4.245237  3.532638  4.740503\n",
      "72      0.0   2.028423  3.532638  4.740503\n",
      "148     8.0   3.048275  3.532638  4.740503\n",
      "78      2.0   2.022314  3.532638  4.740503\n",
      "126    15.0   8.119272  3.532638  4.740503\n",
      "132     0.0  10.096062  3.532638  4.740503\n",
      "458     5.0   5.584760  3.532638  4.740503\n",
      "75     15.0   5.126668  3.532638  4.740503\n",
      "296    10.0   2.155675  3.532638  4.740503\n",
      "195     2.0   2.017941  3.532638  4.740503\n",
      "131     0.0   2.306330  3.532638  4.740503\n",
      "227    11.0   2.987149  3.532638  4.740503\n",
      "365     5.0   3.464761  3.532638  4.740503\n",
      "33     13.0   7.564353  3.532638  4.740503\n",
      "373     0.0   2.265274  3.532638  4.740503\n",
      "320     8.0   2.241274  3.532638  4.740503\n",
      "409     2.0   2.083142  3.532638  4.740503\n",
      "140    13.0   5.399939  3.532638  4.740503\n",
      "11      1.0   4.658134  3.532638  4.740503\n",
      "407     3.0   2.863550  3.532638  4.740503\n",
      "15     12.0   3.871785  3.532638  4.740503\n",
      "421     5.0   4.230997  3.532638  4.740503\n",
      "358     3.0   2.255151  3.532638  4.740503\n",
      "19      3.0   2.049002  3.532638  4.740503\n",
      "297     6.0   2.996207  3.532638  4.740503\n",
      "416     3.0   2.099000  3.532638  4.740503\n",
      "56      1.0   2.049002  3.532638  4.740503\n",
      "196    13.0   7.185044  3.532638  4.740503\n",
      "334     2.0   2.378464  3.532638  4.740503\n",
      "305     1.0   6.131597  3.532638  4.740503\n",
      "113     3.0   7.379513  3.532638  4.740503\n",
      "155    15.0   3.561238  3.532638  4.740503\n",
      "394     0.0   5.023248  3.532638  4.740503\n",
      "25      4.0   2.975616  3.532638  4.740503\n",
      "449     4.0   3.285051  3.532638  4.740503\n",
      "255     5.0   2.165139  3.532638  4.740503\n",
      "180     6.0   3.236962  3.532638  4.740503\n",
      "42      5.0   3.068982  3.532638  4.740503\n",
      "302     2.0   4.296803  3.532638  4.740503\n",
      "101    10.0   2.045215  3.532638  4.740503\n",
      "432     2.0   3.153591  3.532638  4.740503\n",
      "402     3.0   2.013577  3.532638  4.740503\n",
      "137    14.0   7.990561  3.532638  4.740503\n",
      "299     8.0   4.384552  3.532638  4.740503\n",
      "22      3.0   4.540378  3.532638  4.740503\n",
      "301    11.0   5.083111  3.532638  4.740503\n",
      "46      4.0   3.678595  3.532638  4.740503\n",
      "168     1.0   2.287074  3.532638  4.740503\n",
      "460     4.0   5.711584  3.532638  4.740503\n",
      "225     2.0   4.210441  3.821390  4.675107\n",
      "30     11.0   8.472683  3.821390  4.675107\n",
      "39      2.0   5.997223  3.821390  4.675107\n",
      "222     0.0   1.991099  3.821390  4.675107\n",
      "124     1.0   3.374209  3.821390  4.675107\n",
      "203     0.0   5.968797  3.821390  4.675107\n",
      "310     2.0   7.838932  3.821390  4.675107\n",
      "211    11.0   1.756612  3.821390  4.675107\n",
      "457     1.0   5.503044  3.821390  4.675107\n",
      "77     13.0   4.203129  3.821390  4.675107\n",
      "454     2.0   6.488768  3.821390  4.675107\n",
      "398     2.0   4.158388  3.821390  4.675107\n",
      "76      1.0   0.452702  3.821390  4.675107\n",
      "386     3.0   7.188485  3.821390  4.675107\n",
      "278     3.0   2.417140  3.821390  4.675107\n",
      "271    11.0   6.102595  3.821390  4.675107\n",
      "70      4.0   6.506008  3.821390  4.675107\n",
      "93     16.0   8.715202  3.821390  4.675107\n",
      "157    14.0   8.683298  3.821390  4.675107\n",
      "0       3.0   5.665339  3.821390  4.675107\n",
      "388     5.0   2.751402  3.821390  4.675107\n",
      "82      3.0   4.632620  3.821390  4.675107\n",
      "368     2.0   8.134045  3.821390  4.675107\n",
      "357     7.0   4.028190  3.821390  4.675107\n",
      "420     4.0   5.849331  3.821390  4.675107\n",
      "307     3.0   7.895847  3.821390  4.675107\n",
      "172    10.0   5.413998  3.821390  4.675107\n",
      "176     4.0   2.854171  3.821390  4.675107\n",
      "18      7.0   7.338211  3.821390  4.675107\n",
      "9       0.0   4.762930  3.821390  4.675107\n",
      "428     1.0   3.061768  3.821390  4.675107\n",
      "448     5.0   3.856256  3.821390  4.675107\n",
      "73     14.0   2.858176  3.821390  4.675107\n",
      "234     1.0   3.862828  3.821390  4.675107\n",
      "287    10.0   8.737511  3.821390  4.675107\n",
      "408     1.0   3.175992  3.821390  4.675107\n",
      "55     14.0   7.348488  3.821390  4.675107\n",
      "90     13.0   5.925136  3.821390  4.675107\n",
      "364     6.0   8.537653  3.821390  4.675107\n",
      "79      0.0   2.642322  3.821390  4.675107\n",
      "325     1.0   8.548885  3.821390  4.675107\n",
      "450     3.0   1.168895  3.821390  4.675107\n",
      "209     4.0   5.259923  3.821390  4.675107\n",
      "173    16.0   4.229445  3.821390  4.675107\n",
      "185     8.0   4.254577  3.821390  4.675107\n",
      "72      0.0   4.399272  3.821390  4.675107\n",
      "148     8.0   5.700094  3.821390  4.675107\n",
      "78      2.0   2.985409  3.821390  4.675107\n",
      "126    15.0   8.511763  3.821390  4.675107\n",
      "132     0.0   8.798998  3.821390  4.675107\n",
      "458     5.0   3.535460  3.821390  4.675107\n",
      "75     15.0   8.647387  3.821390  4.675107\n",
      "296    10.0   1.579661  3.821390  4.675107\n",
      "195     2.0   2.722886  3.821390  4.675107\n",
      "131     0.0   3.736808  3.821390  4.675107\n",
      "227    11.0   4.371328  3.821390  4.675107\n",
      "365     5.0   3.623958  3.821390  4.675107\n",
      "33     13.0   5.305716  3.821390  4.675107\n",
      "373     0.0   3.000822  3.821390  4.675107\n",
      "320     8.0   3.322654  3.821390  4.675107\n",
      "409     2.0   2.575156  3.821390  4.675107\n",
      "140    13.0   8.762697  3.821390  4.675107\n",
      "11      1.0   8.455761  3.821390  4.675107\n",
      "407     3.0   3.158690  3.821390  4.675107\n",
      "15     12.0   3.255166  3.821390  4.675107\n",
      "421     5.0   6.426790  3.821390  4.675107\n",
      "358     3.0   6.271949  3.821390  4.675107\n",
      "19      3.0   0.696009  3.821390  4.675107\n",
      "297     6.0   3.534581  3.821390  4.675107\n",
      "416     3.0   1.469638  3.821390  4.675107\n",
      "56      1.0   2.254740  3.821390  4.675107\n",
      "196    13.0   8.789564  3.821390  4.675107\n",
      "334     2.0   5.684067  3.821390  4.675107\n",
      "305     1.0   7.004741  3.821390  4.675107\n",
      "113     3.0   7.019572  3.821390  4.675107\n",
      "155    15.0   5.240010  3.821390  4.675107\n",
      "394     0.0   6.352427  3.821390  4.675107\n",
      "25      4.0   5.333699  3.821390  4.675107\n",
      "449     4.0   3.953460  3.821390  4.675107\n",
      "255     5.0   4.022717  3.821390  4.675107\n",
      "180     6.0   5.039758  3.821390  4.675107\n",
      "42      5.0   3.678658  3.821390  4.675107\n",
      "302     2.0   3.990001  3.821390  4.675107\n",
      "101    10.0   2.949540  3.821390  4.675107\n",
      "432     2.0   3.822766  3.821390  4.675107\n",
      "402     3.0   0.852164  3.821390  4.675107\n",
      "137    14.0   5.787393  3.821390  4.675107\n",
      "299     8.0   5.588864  3.821390  4.675107\n",
      "22      3.0   5.296237  3.821390  4.675107\n",
      "301    11.0   8.246857  3.821390  4.675107\n",
      "46      4.0   7.190404  3.821390  4.675107\n",
      "168     1.0   3.615953  3.821390  4.675107\n",
      "460     4.0   7.393729  3.821390  4.675107\n",
      "225     2.0   2.672680  3.678701  4.728448\n",
      "30     11.0  10.439757  3.678701  4.728448\n",
      "39      2.0   5.258542  3.678701  4.728448\n",
      "222     0.0   2.215403  3.678701  4.728448\n",
      "124     1.0   6.358954  3.678701  4.728448\n",
      "203     0.0   4.660452  3.678701  4.728448\n",
      "310     2.0   8.726878  3.678701  4.728448\n",
      "211    11.0   1.326561  3.678701  4.728448\n",
      "457     1.0   8.667213  3.678701  4.728448\n",
      "77     13.0   6.731156  3.678701  4.728448\n",
      "454     2.0   7.057363  3.678701  4.728448\n",
      "398     2.0   2.494197  3.678701  4.728448\n",
      "76      1.0   1.646457  3.678701  4.728448\n",
      "386     3.0   6.020092  3.678701  4.728448\n",
      "278     3.0   2.618800  3.678701  4.728448\n",
      "271    11.0   5.134012  3.678701  4.728448\n",
      "70      4.0   7.038957  3.678701  4.728448\n",
      "93     16.0  13.875636  3.678701  4.728448\n",
      "157    14.0   6.456421  3.678701  4.728448\n",
      "0       3.0   6.058302  3.678701  4.728448\n",
      "388     5.0   1.774349  3.678701  4.728448\n",
      "82      3.0   4.844421  3.678701  4.728448\n",
      "368     2.0   5.992317  3.678701  4.728448\n",
      "357     7.0   5.690771  3.678701  4.728448\n",
      "420     4.0   2.963048  3.678701  4.728448\n",
      "307     3.0  11.590225  3.678701  4.728448\n",
      "172    10.0   2.917177  3.678701  4.728448\n",
      "176     4.0   2.740067  3.678701  4.728448\n",
      "18      7.0   8.463537  3.678701  4.728448\n",
      "9       0.0   2.476467  3.678701  4.728448\n",
      "428     1.0   1.118892  3.678701  4.728448\n",
      "448     5.0   4.909011  3.678701  4.728448\n",
      "73     14.0   1.442595  3.678701  4.728448\n",
      "234     1.0   3.160513  3.678701  4.728448\n",
      "287    10.0  11.758339  3.678701  4.728448\n",
      "408     1.0   3.423600  3.678701  4.728448\n",
      "55     14.0   9.612274  3.678701  4.728448\n",
      "90     13.0   4.096179  3.678701  4.728448\n",
      "364     6.0   9.589575  3.678701  4.728448\n",
      "79      0.0   2.606667  3.678701  4.728448\n",
      "325     1.0   4.976739  3.678701  4.728448\n",
      "450     3.0   2.265783  3.678701  4.728448\n",
      "209     4.0   6.694872  3.678701  4.728448\n",
      "173    16.0   2.635798  3.678701  4.728448\n",
      "185     8.0   3.132177  3.678701  4.728448\n",
      "72      0.0   3.759632  3.678701  4.728448\n",
      "148     8.0   4.524349  3.678701  4.728448\n",
      "78      2.0   3.390061  3.678701  4.728448\n",
      "126    15.0   9.268414  3.678701  4.728448\n",
      "132     0.0  11.090239  3.678701  4.728448\n",
      "458     5.0   7.841917  3.678701  4.728448\n",
      "75     15.0   5.668236  3.678701  4.728448\n",
      "296    10.0   2.124165  3.678701  4.728448\n",
      "195     2.0   5.860269  3.678701  4.728448\n",
      "131     0.0   2.207442  3.678701  4.728448\n",
      "227    11.0   5.998026  3.678701  4.728448\n",
      "365     5.0   4.241266  3.678701  4.728448\n",
      "33     13.0   8.571684  3.678701  4.728448\n",
      "373     0.0   2.158259  3.678701  4.728448\n",
      "320     8.0   2.399511  3.678701  4.728448\n",
      "409     2.0   1.479652  3.678701  4.728448\n",
      "140    13.0   7.201627  3.678701  4.728448\n",
      "11      1.0   8.052713  3.678701  4.728448\n",
      "407     3.0   2.041361  3.678701  4.728448\n",
      "15     12.0   5.079841  3.678701  4.728448\n",
      "421     5.0   4.730792  3.678701  4.728448\n",
      "358     3.0   3.017162  3.678701  4.728448\n",
      "19      3.0   1.061856  3.678701  4.728448\n",
      "297     6.0   3.451040  3.678701  4.728448\n",
      "416     3.0   1.948306  3.678701  4.728448\n",
      "56      1.0   1.054641  3.678701  4.728448\n",
      "196    13.0   8.194612  3.678701  4.728448\n",
      "334     2.0   1.141922  3.678701  4.728448\n",
      "305     1.0   7.222034  3.678701  4.728448\n",
      "113     3.0   7.377725  3.678701  4.728448\n",
      "155    15.0   6.736695  3.678701  4.728448\n",
      "394     0.0   4.857917  3.678701  4.728448\n",
      "25      4.0   3.037080  3.678701  4.728448\n",
      "449     4.0   3.931468  3.678701  4.728448\n",
      "255     5.0   3.940891  3.678701  4.728448\n",
      "180     6.0   4.077908  3.678701  4.728448\n",
      "42      5.0   4.771890  3.678701  4.728448\n",
      "302     2.0   4.809233  3.678701  4.728448\n",
      "101    10.0   1.908260  3.678701  4.728448\n",
      "432     2.0   5.280441  3.678701  4.728448\n",
      "402     3.0   2.069903  3.678701  4.728448\n",
      "137    14.0   9.503019  3.678701  4.728448\n",
      "299     8.0   7.641364  3.678701  4.728448\n",
      "22      3.0   9.037758  3.678701  4.728448\n",
      "301    11.0   7.313920  3.678701  4.728448\n",
      "46      4.0   5.022924  3.678701  4.728448\n",
      "168     1.0   3.156993  3.678701  4.728448\n",
      "460     4.0   8.170837  3.678701  4.728448\n",
      "225     2.0   2.721000  3.904606  4.817520\n",
      "30     11.0   7.937859  3.904606  4.817520\n",
      "39      2.0   5.681180  3.904606  4.817520\n",
      "222     0.0   1.563949  3.904606  4.817520\n",
      "124     1.0   3.380973  3.904606  4.817520\n",
      "203     0.0   4.963297  3.904606  4.817520\n",
      "310     2.0   6.787314  3.904606  4.817520\n",
      "211    11.0   1.407132  3.904606  4.817520\n",
      "457     1.0   5.796061  3.904606  4.817520\n",
      "77     13.0   3.167495  3.904606  4.817520\n",
      "454     2.0   4.589623  3.904606  4.817520\n",
      "398     2.0   3.004000  3.904606  4.817520\n",
      "76      1.0   1.846059  3.904606  4.817520\n",
      "386     3.0   6.722775  3.904606  4.817520\n",
      "278     3.0   1.683185  3.904606  4.817520\n",
      "271    11.0   5.596273  3.904606  4.817520\n",
      "70      4.0   6.534531  3.904606  4.817520\n",
      "93     16.0   9.673225  3.904606  4.817520\n",
      "157    14.0   8.207493  3.904606  4.817520\n",
      "0       3.0   5.561360  3.904606  4.817520\n",
      "388     5.0   0.007123  3.904606  4.817520\n",
      "82      3.0   5.202821  3.904606  4.817520\n",
      "368     2.0   7.250965  3.904606  4.817520\n",
      "357     7.0   1.818680  3.904606  4.817520\n",
      "420     4.0   5.476436  3.904606  4.817520\n",
      "307     3.0   8.165491  3.904606  4.817520\n",
      "172    10.0   5.040351  3.904606  4.817520\n",
      "176     4.0   2.206532  3.904606  4.817520\n",
      "18      7.0   6.146622  3.904606  4.817520\n",
      "9       0.0   5.721491  3.904606  4.817520\n",
      "428     1.0   3.034872  3.904606  4.817520\n",
      "448     5.0   2.192319  3.904606  4.817520\n",
      "73     14.0   2.501337  3.904606  4.817520\n",
      "234     1.0   2.100211  3.904606  4.817520\n",
      "287    10.0   9.602787  3.904606  4.817520\n",
      "408     1.0   4.835987  3.904606  4.817520\n",
      "55     14.0   6.610506  3.904606  4.817520\n",
      "90     13.0   5.481368  3.904606  4.817520\n",
      "364     6.0   8.178137  3.904606  4.817520\n",
      "79      0.0   3.974868  3.904606  4.817520\n",
      "325     1.0   7.852808  3.904606  4.817520\n",
      "450     3.0   1.721915  3.904606  4.817520\n",
      "209     4.0   6.446453  3.904606  4.817520\n",
      "173    16.0   4.081890  3.904606  4.817520\n",
      "185     8.0   1.953450  3.904606  4.817520\n",
      "72      0.0   2.627568  3.904606  4.817520\n",
      "148     8.0   5.597559  3.904606  4.817520\n",
      "78      2.0   3.011161  3.904606  4.817520\n",
      "126    15.0   8.789886  3.904606  4.817520\n",
      "132     0.0  10.654793  3.904606  4.817520\n",
      "458     5.0   2.945252  3.904606  4.817520\n",
      "75     15.0   7.227331  3.904606  4.817520\n",
      "296    10.0   1.541062  3.904606  4.817520\n",
      "195     2.0   2.745231  3.904606  4.817520\n",
      "131     0.0   3.711542  3.904606  4.817520\n",
      "227    11.0   3.910096  3.904606  4.817520\n",
      "365     5.0   3.318117  3.904606  4.817520\n",
      "33     13.0   3.006670  3.904606  4.817520\n",
      "373     0.0   2.723471  3.904606  4.817520\n",
      "320     8.0   2.385355  3.904606  4.817520\n",
      "409     2.0   1.440145  3.904606  4.817520\n",
      "140    13.0   7.763780  3.904606  4.817520\n",
      "11      1.0   8.195831  3.904606  4.817520\n",
      "407     3.0   4.514038  3.904606  4.817520\n",
      "15     12.0   4.732419  3.904606  4.817520\n",
      "421     5.0   4.791458  3.904606  4.817520\n",
      "358     3.0   6.043896  3.904606  4.817520\n",
      "19      3.0   0.000000  3.904606  4.817520\n",
      "297     6.0   3.689386  3.904606  4.817520\n",
      "416     3.0   0.721153  3.904606  4.817520\n",
      "56      1.0   2.211445  3.904606  4.817520\n",
      "196    13.0   9.836166  3.904606  4.817520\n",
      "334     2.0   3.877046  3.904606  4.817520\n",
      "305     1.0   6.467061  3.904606  4.817520\n",
      "113     3.0   6.081935  3.904606  4.817520\n",
      "155    15.0   4.958622  3.904606  4.817520\n",
      "394     0.0   5.749856  3.904606  4.817520\n",
      "25      4.0   3.274432  3.904606  4.817520\n",
      "449     4.0   4.631368  3.904606  4.817520\n",
      "255     5.0   3.784748  3.904606  4.817520\n",
      "180     6.0   4.310968  3.904606  4.817520\n",
      "42      5.0   4.785339  3.904606  4.817520\n",
      "302     2.0   2.826068  3.904606  4.817520\n",
      "101    10.0   3.663991  3.904606  4.817520\n",
      "432     2.0   4.396239  3.904606  4.817520\n",
      "402     3.0   2.390723  3.904606  4.817520\n",
      "137    14.0   6.935739  3.904606  4.817520\n",
      "299     8.0   4.492519  3.904606  4.817520\n",
      "22      3.0   7.606441  3.904606  4.817520\n",
      "301    11.0   7.815511  3.904606  4.817520\n",
      "46      4.0   6.433287  3.904606  4.817520\n",
      "168     1.0   2.653009  3.904606  4.817520\n",
      "460     4.0   7.720387  3.904606  4.817520\n",
      "225     2.0   2.702127  3.635843  4.731581\n",
      "30     11.0   7.316720  3.635843  4.731581\n",
      "39      2.0   4.085654  3.635843  4.731581\n",
      "222     0.0   1.420689  3.635843  4.731581\n",
      "124     1.0   5.963009  3.635843  4.731581\n",
      "203     0.0   3.824283  3.635843  4.731581\n",
      "310     2.0   6.777953  3.635843  4.731581\n",
      "211    11.0   1.227296  3.635843  4.731581\n",
      "457     1.0   6.966962  3.635843  4.731581\n",
      "77     13.0   5.564660  3.635843  4.731581\n",
      "454     2.0   6.279922  3.635843  4.731581\n",
      "398     2.0   2.338156  3.635843  4.731581\n",
      "76      1.0   1.271319  3.635843  4.731581\n",
      "386     3.0   4.348713  3.635843  4.731581\n",
      "278     3.0   2.367457  3.635843  4.731581\n",
      "271    11.0   3.712716  3.635843  4.731581\n",
      "70      4.0   5.483611  3.635843  4.731581\n",
      "93     16.0  10.837027  3.635843  4.731581\n",
      "157    14.0   6.126620  3.635843  4.731581\n",
      "0       3.0   4.216742  3.635843  4.731581\n",
      "388     5.0   1.454817  3.635843  4.731581\n",
      "82      3.0   4.304000  3.635843  4.731581\n",
      "368     2.0   5.603831  3.635843  4.731581\n",
      "357     7.0   3.849153  3.635843  4.731581\n",
      "420     4.0   3.134336  3.635843  4.731581\n",
      "307     3.0   8.163627  3.635843  4.731581\n",
      "172    10.0   2.894728  3.635843  4.731581\n",
      "176     4.0   2.555526  3.635843  4.731581\n",
      "18      7.0   7.269876  3.635843  4.731581\n",
      "9       0.0   1.585300  3.635843  4.731581\n",
      "428     1.0   1.478715  3.635843  4.731581\n",
      "448     5.0   4.284872  3.635843  4.731581\n",
      "73     14.0   1.249710  3.635843  4.731581\n",
      "234     1.0   3.226227  3.635843  4.731581\n",
      "287    10.0  10.881102  3.635843  4.731581\n",
      "408     1.0   2.937809  3.635843  4.731581\n",
      "55     14.0   7.594032  3.635843  4.731581\n",
      "90     13.0   4.163655  3.635843  4.731581\n",
      "364     6.0   6.724751  3.635843  4.731581\n",
      "79      0.0   2.315189  3.635843  4.731581\n",
      "325     1.0   4.313137  3.635843  4.731581\n",
      "450     3.0   1.952464  3.635843  4.731581\n",
      "209     4.0   6.036279  3.635843  4.731581\n",
      "173    16.0   3.304439  3.635843  4.731581\n",
      "185     8.0   2.560786  3.635843  4.731581\n",
      "72      0.0   3.072603  3.635843  4.731581\n",
      "148     8.0   3.544378  3.635843  4.731581\n",
      "78      2.0   1.967567  3.635843  4.731581\n",
      "126    15.0   7.818484  3.635843  4.731581\n",
      "132     0.0  10.547434  3.635843  4.731581\n",
      "458     5.0   6.444179  3.635843  4.731581\n",
      "75     15.0   5.901785  3.635843  4.731581\n",
      "296    10.0   2.074780  3.635843  4.731581\n",
      "195     2.0   4.007085  3.635843  4.731581\n",
      "131     0.0   2.182639  3.635843  4.731581\n",
      "227    11.0   3.720101  3.635843  4.731581\n",
      "365     5.0   2.889290  3.635843  4.731581\n",
      "33     13.0   7.435948  3.635843  4.731581\n",
      "373     0.0   1.443216  3.635843  4.731581\n",
      "320     8.0   2.176275  3.635843  4.731581\n",
      "409     2.0   1.452898  3.635843  4.731581\n",
      "140    13.0   6.187479  3.635843  4.731581\n",
      "11      1.0   6.506250  3.635843  4.731581\n",
      "407     3.0   1.631241  3.635843  4.731581\n",
      "15     12.0   3.213224  3.635843  4.731581\n",
      "421     5.0   3.757925  3.635843  4.731581\n",
      "358     3.0   1.671251  3.635843  4.731581\n",
      "19      3.0   0.721327  3.635843  4.731581\n",
      "297     6.0   3.050359  3.635843  4.731581\n",
      "416     3.0   1.788349  3.635843  4.731581\n",
      "56      1.0   0.806186  3.635843  4.731581\n",
      "196    13.0   7.452293  3.635843  4.731581\n",
      "334     2.0   1.800618  3.635843  4.731581\n",
      "305     1.0   6.134826  3.635843  4.731581\n",
      "113     3.0   6.464399  3.635843  4.731581\n",
      "155    15.0   5.687134  3.635843  4.731581\n",
      "394     0.0   4.262337  3.635843  4.731581\n",
      "25      4.0   2.658830  3.635843  4.731581\n",
      "449     4.0   3.102721  3.635843  4.731581\n",
      "255     5.0   3.966304  3.635843  4.731581\n",
      "180     6.0   3.828681  3.635843  4.731581\n",
      "42      5.0   4.973663  3.635843  4.731581\n",
      "302     2.0   4.275989  3.635843  4.731581\n",
      "101    10.0   1.414719  3.635843  4.731581\n",
      "432     2.0   3.768067  3.635843  4.731581\n",
      "402     3.0   1.539830  3.635843  4.731581\n",
      "137    14.0   8.485161  3.635843  4.731581\n",
      "299     8.0   6.199272  3.635843  4.731581\n",
      "22      3.0   8.410239  3.635843  4.731581\n",
      "301    11.0   6.366414  3.635843  4.731581\n",
      "46      4.0   4.413606  3.635843  4.731581\n",
      "168     1.0   2.514528  3.635843  4.731581\n",
      "460     4.0   8.602545  3.635843  4.731581\n",
      "225     2.0   3.187518  3.802402  4.678270\n",
      "30     11.0   7.245615  3.802402  4.678270\n",
      "39      2.0   5.491704  3.802402  4.678270\n",
      "222     0.0   0.916538  3.802402  4.678270\n",
      "124     1.0   3.933197  3.802402  4.678270\n",
      "203     0.0   5.753832  3.802402  4.678270\n",
      "310     2.0   7.170795  3.802402  4.678270\n",
      "211    11.0   2.336053  3.802402  4.678270\n",
      "457     1.0   6.789649  3.802402  4.678270\n",
      "77     13.0   3.593144  3.802402  4.678270\n",
      "454     2.0   5.431018  3.802402  4.678270\n",
      "398     2.0   2.648762  3.802402  4.678270\n",
      "76      1.0   3.266293  3.802402  4.678270\n",
      "386     3.0   6.792477  3.802402  4.678270\n",
      "278     3.0   2.010919  3.802402  4.678270\n",
      "271    11.0   6.157887  3.802402  4.678270\n",
      "70      4.0   6.295827  3.802402  4.678270\n",
      "93     16.0   9.292600  3.802402  4.678270\n",
      "157    14.0   7.319556  3.802402  4.678270\n",
      "0       3.0   5.152106  3.802402  4.678270\n",
      "388     5.0   0.741178  3.802402  4.678270\n",
      "82      3.0   5.175250  3.802402  4.678270\n",
      "368     2.0   6.849071  3.802402  4.678270\n",
      "357     7.0   2.528953  3.802402  4.678270\n",
      "420     4.0   5.202666  3.802402  4.678270\n",
      "307     3.0   7.039005  3.802402  4.678270\n",
      "172    10.0   5.343439  3.802402  4.678270\n",
      "176     4.0   1.792597  3.802402  4.678270\n",
      "18      7.0   7.194545  3.802402  4.678270\n",
      "9       0.0   5.193424  3.802402  4.678270\n",
      "428     1.0   3.292600  3.802402  4.678270\n",
      "448     5.0   2.837946  3.802402  4.678270\n",
      "73     14.0   2.194231  3.802402  4.678270\n",
      "234     1.0   3.985749  3.802402  4.678270\n",
      "287    10.0   9.123283  3.802402  4.678270\n",
      "408     1.0   4.514432  3.802402  4.678270\n",
      "55     14.0   7.132822  3.802402  4.678270\n",
      "90     13.0   4.844049  3.802402  4.678270\n",
      "364     6.0   7.448765  3.802402  4.678270\n",
      "79      0.0   4.498990  3.802402  4.678270\n",
      "325     1.0   7.101304  3.802402  4.678270\n",
      "450     3.0   1.164488  3.802402  4.678270\n",
      "209     4.0   6.898200  3.802402  4.678270\n",
      "173    16.0   3.986834  3.802402  4.678270\n",
      "185     8.0   2.954575  3.802402  4.678270\n",
      "72      0.0   2.431392  3.802402  4.678270\n",
      "148     8.0   6.572892  3.802402  4.678270\n",
      "78      2.0   2.905238  3.802402  4.678270\n",
      "126    15.0   8.190044  3.802402  4.678270\n",
      "132     0.0   8.945072  3.802402  4.678270\n",
      "458     5.0   0.977412  3.802402  4.678270\n",
      "75     15.0   7.086557  3.802402  4.678270\n",
      "296    10.0   3.107801  3.802402  4.678270\n",
      "195     2.0   3.111731  3.802402  4.678270\n",
      "131     0.0   3.442543  3.802402  4.678270\n",
      "227    11.0   4.200217  3.802402  4.678270\n",
      "365     5.0   3.939025  3.802402  4.678270\n",
      "33     13.0   3.064374  3.802402  4.678270\n",
      "373     0.0   2.286876  3.802402  4.678270\n",
      "320     8.0   2.113177  3.802402  4.678270\n",
      "409     2.0   1.353558  3.802402  4.678270\n",
      "140    13.0   6.979652  3.802402  4.678270\n",
      "11      1.0   7.116035  3.802402  4.678270\n",
      "407     3.0   4.194740  3.802402  4.678270\n",
      "15     12.0   5.225656  3.802402  4.678270\n",
      "421     5.0   5.006520  3.802402  4.678270\n",
      "358     3.0   5.499559  3.802402  4.678270\n",
      "19      3.0   0.000000  3.802402  4.678270\n",
      "297     6.0   4.338824  3.802402  4.678270\n",
      "416     3.0   0.010162  3.802402  4.678270\n",
      "56      1.0   1.525377  3.802402  4.678270\n",
      "196    13.0   7.951837  3.802402  4.678270\n",
      "334     2.0   4.118614  3.802402  4.678270\n",
      "305     1.0   5.205447  3.802402  4.678270\n",
      "113     3.0   5.602896  3.802402  4.678270\n",
      "155    15.0   5.280191  3.802402  4.678270\n",
      "394     0.0   5.397096  3.802402  4.678270\n",
      "25      4.0   3.258888  3.802402  4.678270\n",
      "449     4.0   4.500092  3.802402  4.678270\n",
      "255     5.0   4.348257  3.802402  4.678270\n",
      "180     6.0   4.540129  3.802402  4.678270\n",
      "42      5.0   5.390960  3.802402  4.678270\n",
      "302     2.0   2.508422  3.802402  4.678270\n",
      "101    10.0   4.256219  3.802402  4.678270\n",
      "432     2.0   4.286487  3.802402  4.678270\n",
      "402     3.0   2.966905  3.802402  4.678270\n",
      "137    14.0   8.335943  3.802402  4.678270\n",
      "299     8.0   5.193889  3.802402  4.678270\n",
      "22      3.0   6.403294  3.802402  4.678270\n",
      "301    11.0   7.089674  3.802402  4.678270\n",
      "46      4.0   6.509696  3.802402  4.678270\n",
      "168     1.0   3.089663  3.802402  4.678270\n",
      "460     4.0   7.903397  3.802402  4.678270\n",
      "225     2.0   3.737671  3.829030  4.920742\n",
      "30     11.0   9.466183  3.829030  4.920742\n",
      "39      2.0   4.138257  3.829030  4.920742\n",
      "222     0.0   2.476625  3.829030  4.920742\n",
      "124     1.0   4.279450  3.829030  4.920742\n",
      "203     0.0   4.957149  3.829030  4.920742\n",
      "310     2.0   8.332167  3.829030  4.920742\n",
      "211    11.0   1.896514  3.829030  4.920742\n",
      "457     1.0   3.452749  3.829030  4.920742\n",
      "77     13.0   4.462878  3.829030  4.920742\n",
      "454     2.0   6.652727  3.829030  4.920742\n",
      "398     2.0   4.248670  3.829030  4.920742\n",
      "76      1.0   1.832340  3.829030  4.920742\n",
      "386     3.0   5.794377  3.829030  4.920742\n",
      "278     3.0   2.391027  3.829030  4.920742\n",
      "271    11.0   6.374763  3.829030  4.920742\n",
      "70      4.0   6.369781  3.829030  4.920742\n",
      "93     16.0  14.446496  3.829030  4.920742\n",
      "157    14.0   3.805004  3.829030  4.920742\n",
      "0       3.0   6.611683  3.829030  4.920742\n",
      "388     5.0   2.037703  3.829030  4.920742\n",
      "82      3.0   6.845142  3.829030  4.920742\n",
      "368     2.0   4.531217  3.829030  4.920742\n",
      "357     7.0   2.213301  3.829030  4.920742\n",
      "420     4.0   6.287685  3.829030  4.920742\n",
      "307     3.0   8.105072  3.829030  4.920742\n",
      "172    10.0   2.109125  3.829030  4.920742\n",
      "176     4.0   1.909988  3.829030  4.920742\n",
      "18      7.0  11.340851  3.829030  4.920742\n",
      "9       0.0   2.520616  3.829030  4.920742\n",
      "428     1.0   2.098320  3.829030  4.920742\n",
      "448     5.0   1.304444  3.829030  4.920742\n",
      "73     14.0   1.957951  3.829030  4.920742\n",
      "234     1.0   1.751139  3.829030  4.920742\n",
      "287    10.0  13.318386  3.829030  4.920742\n",
      "408     1.0   3.111873  3.829030  4.920742\n",
      "55     14.0  10.192588  3.829030  4.920742\n",
      "90     13.0   9.829961  3.829030  4.920742\n",
      "364     6.0  12.631853  3.829030  4.920742\n",
      "79      0.0   2.700350  3.829030  4.920742\n",
      "325     1.0   5.118772  3.829030  4.920742\n",
      "450     3.0   2.682067  3.829030  4.920742\n",
      "209     4.0   9.429495  3.829030  4.920742\n",
      "173    16.0   2.489486  3.829030  4.920742\n",
      "185     8.0   1.812964  3.829030  4.920742\n",
      "72      0.0   2.134359  3.829030  4.920742\n",
      "148     8.0   4.225423  3.829030  4.920742\n",
      "78      2.0   3.203407  3.829030  4.920742\n",
      "126    15.0   9.797417  3.829030  4.920742\n",
      "132     0.0  15.823039  3.829030  4.920742\n",
      "458     5.0   6.845189  3.829030  4.920742\n",
      "75     15.0   7.416158  3.829030  4.920742\n",
      "296    10.0   1.835634  3.829030  4.920742\n",
      "195     2.0   3.235036  3.829030  4.920742\n",
      "131     0.0   2.884371  3.829030  4.920742\n",
      "227    11.0   3.230280  3.829030  4.920742\n",
      "365     5.0   4.861872  3.829030  4.920742\n",
      "33     13.0   8.015898  3.829030  4.920742\n",
      "373     0.0   2.920903  3.829030  4.920742\n",
      "320     8.0   2.538715  3.829030  4.920742\n",
      "409     2.0   1.812964  3.829030  4.920742\n",
      "140    13.0   7.321110  3.829030  4.920742\n",
      "11      1.0   5.893188  3.829030  4.920742\n",
      "407     3.0   3.658640  3.829030  4.920742\n",
      "15     12.0   5.381632  3.829030  4.920742\n",
      "421     5.0   9.133906  3.829030  4.920742\n",
      "358     3.0   3.969792  3.829030  4.920742\n",
      "19      3.0   1.812964  3.829030  4.920742\n",
      "297     6.0   2.943553  3.829030  4.920742\n",
      "416     3.0   1.500447  3.829030  4.920742\n",
      "56      1.0   1.881934  3.829030  4.920742\n",
      "196    13.0  12.108396  3.829030  4.920742\n",
      "334     2.0   1.523450  3.829030  4.920742\n",
      "305     1.0   7.128097  3.829030  4.920742\n",
      "113     3.0  10.650111  3.829030  4.920742\n",
      "155    15.0   3.907735  3.829030  4.920742\n",
      "394     0.0   5.767618  3.829030  4.920742\n",
      "25      4.0   5.793178  3.829030  4.920742\n",
      "449     4.0   3.131728  3.829030  4.920742\n",
      "255     5.0   2.475455  3.829030  4.920742\n",
      "180     6.0   3.915246  3.829030  4.920742\n",
      "42      5.0   5.235892  3.829030  4.920742\n",
      "302     2.0   3.922146  3.829030  4.920742\n",
      "101    10.0   2.240778  3.829030  4.920742\n",
      "432     2.0   4.016306  3.829030  4.920742\n",
      "402     3.0   2.025642  3.829030  4.920742\n",
      "137    14.0   8.775846  3.829030  4.920742\n",
      "299     8.0   5.592727  3.829030  4.920742\n",
      "22      3.0   5.077653  3.829030  4.920742\n",
      "301    11.0   3.747560  3.829030  4.920742\n",
      "46      4.0   4.186723  3.829030  4.920742\n",
      "168     1.0   2.047539  3.829030  4.920742\n",
      "460     4.0   5.537381  3.829030  4.920742\n",
      "225     2.0   3.979457  4.337037  5.211542\n",
      "30     11.0   8.593175  4.337037  5.211542\n",
      "39      2.0   6.451313  4.337037  5.211542\n",
      "222     0.0   1.206473  4.337037  5.211542\n",
      "124     1.0   4.751790  4.337037  5.211542\n",
      "203     0.0   7.762245  4.337037  5.211542\n",
      "310     2.0   7.210252  4.337037  5.211542\n",
      "211    11.0   0.521748  4.337037  5.211542\n",
      "457     1.0   6.533557  4.337037  5.211542\n",
      "77     13.0   5.184827  4.337037  5.211542\n",
      "454     2.0   6.170209  4.337037  5.211542\n",
      "398     2.0   5.705904  4.337037  5.211542\n",
      "76      1.0   0.546794  4.337037  5.211542\n",
      "386     3.0   6.896543  4.337037  5.211542\n",
      "278     3.0   1.357736  4.337037  5.211542\n",
      "271    11.0   4.372569  4.337037  5.211542\n",
      "70      4.0   9.532271  4.337037  5.211542\n",
      "93     16.0   9.573954  4.337037  5.211542\n",
      "157    14.0  11.339624  4.337037  5.211542\n",
      "0       3.0   6.299526  4.337037  5.211542\n",
      "388     5.0   2.566827  4.337037  5.211542\n",
      "82      3.0   9.403977  4.337037  5.211542\n",
      "368     2.0   8.502128  4.337037  5.211542\n",
      "357     7.0   4.156294  4.337037  5.211542\n",
      "420     4.0   6.686070  4.337037  5.211542\n",
      "307     3.0   7.925161  4.337037  5.211542\n",
      "172    10.0   3.866548  4.337037  5.211542\n",
      "176     4.0   4.891477  4.337037  5.211542\n",
      "18      7.0   6.707014  4.337037  5.211542\n",
      "9       0.0   4.754523  4.337037  5.211542\n",
      "428     1.0   4.701151  4.337037  5.211542\n",
      "448     5.0   4.584593  4.337037  5.211542\n",
      "73     14.0   5.474585  4.337037  5.211542\n",
      "234     1.0   2.550209  4.337037  5.211542\n",
      "287    10.0  13.122342  4.337037  5.211542\n",
      "408     1.0   4.759805  4.337037  5.211542\n",
      "55     14.0   6.576069  4.337037  5.211542\n",
      "90     13.0   8.487021  4.337037  5.211542\n",
      "364     6.0   8.072406  4.337037  5.211542\n",
      "79      0.0   5.930772  4.337037  5.211542\n",
      "325     1.0   8.412273  4.337037  5.211542\n",
      "450     3.0   0.538574  4.337037  5.211542\n",
      "209     4.0   8.709002  4.337037  5.211542\n",
      "173    16.0   3.905092  4.337037  5.211542\n",
      "185     8.0   3.509861  4.337037  5.211542\n",
      "72      0.0   2.652409  4.337037  5.211542\n",
      "148     8.0   5.645429  4.337037  5.211542\n",
      "78      2.0   1.793899  4.337037  5.211542\n",
      "126    15.0   7.770603  4.337037  5.211542\n",
      "132     0.0  11.239289  4.337037  5.211542\n",
      "458     5.0   3.458337  4.337037  5.211542\n",
      "75     15.0   6.679202  4.337037  5.211542\n",
      "296    10.0   2.683980  4.337037  5.211542\n",
      "195     2.0   2.130948  4.337037  5.211542\n",
      "131     0.0   4.912901  4.337037  5.211542\n",
      "227    11.0   3.044886  4.337037  5.211542\n",
      "365     5.0   6.355490  4.337037  5.211542\n",
      "33     13.0   2.983990  4.337037  5.211542\n",
      "373     0.0   5.642303  4.337037  5.211542\n",
      "320     8.0   2.616374  4.337037  5.211542\n",
      "409     2.0   2.481000  4.337037  5.211542\n",
      "140    13.0   7.225638  4.337037  5.211542\n",
      "11      1.0   7.952176  4.337037  5.211542\n",
      "407     3.0   6.416996  4.337037  5.211542\n",
      "15     12.0   5.093538  4.337037  5.211542\n",
      "421     5.0   8.903831  4.337037  5.211542\n",
      "358     3.0   7.213148  4.337037  5.211542\n",
      "19      3.0   0.000000  4.337037  5.211542\n",
      "297     6.0   2.351170  4.337037  5.211542\n",
      "416     3.0   2.156647  4.337037  5.211542\n",
      "56      1.0   0.000000  4.337037  5.211542\n",
      "196    13.0  13.041642  4.337037  5.211542\n",
      "334     2.0   5.508114  4.337037  5.211542\n",
      "305     1.0   9.800155  4.337037  5.211542\n",
      "113     3.0   8.047351  4.337037  5.211542\n",
      "155    15.0   5.938002  4.337037  5.211542\n",
      "394     0.0   9.157256  4.337037  5.211542\n",
      "25      4.0   4.391133  4.337037  5.211542\n",
      "449     4.0   4.048124  4.337037  5.211542\n",
      "255     5.0   1.589249  4.337037  5.211542\n",
      "180     6.0   4.540589  4.337037  5.211542\n",
      "42      5.0   4.190278  4.337037  5.211542\n",
      "302     2.0   3.242110  4.337037  5.211542\n",
      "101    10.0   1.501367  4.337037  5.211542\n",
      "432     2.0   4.329854  4.337037  5.211542\n",
      "402     3.0   0.829138  4.337037  5.211542\n",
      "137    14.0   6.001431  4.337037  5.211542\n",
      "299     8.0   5.218262  4.337037  5.211542\n",
      "22      3.0  10.204574  4.337037  5.211542\n",
      "301    11.0   8.877389  4.337037  5.211542\n",
      "46      4.0  10.556180  4.337037  5.211542\n",
      "168     1.0   0.828409  4.337037  5.211542\n",
      "460     4.0   9.077374  4.337037  5.211542\n",
      "225     2.0   2.471649  3.564256  4.860291\n",
      "30     11.0   6.616639  3.564256  4.860291\n",
      "39      2.0   2.413232  3.564256  4.860291\n",
      "222     0.0   2.021292  3.564256  4.860291\n",
      "124     1.0   3.227165  3.564256  4.860291\n",
      "203     0.0   3.109984  3.564256  4.860291\n",
      "310     2.0   7.047277  3.564256  4.860291\n",
      "211    11.0   2.086742  3.564256  4.860291\n",
      "457     1.0   4.635818  3.564256  4.860291\n",
      "77     13.0   2.179266  3.564256  4.860291\n",
      "454     2.0   4.171021  3.564256  4.860291\n",
      "398     2.0   2.088127  3.564256  4.860291\n",
      "76      1.0   2.053881  3.564256  4.860291\n",
      "386     3.0   5.864589  3.564256  4.860291\n",
      "278     3.0   2.063181  3.564256  4.860291\n",
      "271    11.0   3.880769  3.564256  4.860291\n",
      "70      4.0   3.631981  3.564256  4.860291\n",
      "93     16.0  12.517817  3.564256  4.860291\n",
      "157    14.0   5.539127  3.564256  4.860291\n",
      "0       3.0   3.831912  3.564256  4.860291\n",
      "388     5.0   2.032137  3.564256  4.860291\n",
      "82      3.0   4.111036  3.564256  4.860291\n",
      "368     2.0   3.095387  3.564256  4.860291\n",
      "357     7.0   2.172659  3.564256  4.860291\n",
      "420     4.0   4.054236  3.564256  4.860291\n",
      "307     3.0   6.469256  3.564256  4.860291\n",
      "172    10.0   2.159718  3.564256  4.860291\n",
      "176     4.0   2.380077  3.564256  4.860291\n",
      "18      7.0   7.803601  3.564256  4.860291\n",
      "9       0.0   2.231455  3.564256  4.860291\n",
      "428     1.0   2.233549  3.564256  4.860291\n",
      "448     5.0   2.021292  3.564256  4.860291\n",
      "73     14.0   2.040315  3.564256  4.860291\n",
      "234     1.0   2.021292  3.564256  4.860291\n",
      "287    10.0  12.559963  3.564256  4.860291\n",
      "408     1.0   2.341625  3.564256  4.860291\n",
      "55     14.0   8.350399  3.564256  4.860291\n",
      "90     13.0   5.854430  3.564256  4.860291\n",
      "364     6.0  10.371176  3.564256  4.860291\n",
      "79      0.0   3.310231  3.564256  4.860291\n",
      "325     1.0   2.293016  3.564256  4.860291\n",
      "450     3.0   2.021292  3.564256  4.860291\n",
      "209     4.0   7.270047  3.564256  4.860291\n",
      "173    16.0   2.021292  3.564256  4.860291\n",
      "185     8.0   2.021292  3.564256  4.860291\n",
      "72      0.0   2.038491  3.564256  4.860291\n",
      "148     8.0   3.524766  3.564256  4.860291\n",
      "78      2.0   2.021292  3.564256  4.860291\n",
      "126    15.0   9.502649  3.564256  4.860291\n",
      "132     0.0  10.517233  3.564256  4.860291\n",
      "458     5.0   4.472019  3.564256  4.860291\n",
      "75     15.0   5.777651  3.564256  4.860291\n",
      "296    10.0   2.270147  3.564256  4.860291\n",
      "195     2.0   2.086716  3.564256  4.860291\n",
      "131     0.0   2.312485  3.564256  4.860291\n",
      "227    11.0   3.195723  3.564256  4.860291\n",
      "365     5.0   3.659048  3.564256  4.860291\n",
      "33     13.0   3.823106  3.564256  4.860291\n",
      "373     0.0   2.021292  3.564256  4.860291\n",
      "320     8.0   2.060810  3.564256  4.860291\n",
      "409     2.0   2.021292  3.564256  4.860291\n",
      "140    13.0   3.100287  3.564256  4.860291\n",
      "11      1.0   6.672554  3.564256  4.860291\n",
      "407     3.0   2.442289  3.564256  4.860291\n",
      "15     12.0   5.655026  3.564256  4.860291\n",
      "421     5.0   5.051639  3.564256  4.860291\n",
      "358     3.0   2.775840  3.564256  4.860291\n",
      "19      3.0   2.021292  3.564256  4.860291\n",
      "297     6.0   2.237278  3.564256  4.860291\n",
      "416     3.0   2.845235  3.564256  4.860291\n",
      "56      1.0   2.021292  3.564256  4.860291\n",
      "196    13.0   9.452673  3.564256  4.860291\n",
      "334     2.0   2.021292  3.564256  4.860291\n",
      "305     1.0   6.079389  3.564256  4.860291\n",
      "113     3.0   7.195331  3.564256  4.860291\n",
      "155    15.0   2.677131  3.564256  4.860291\n",
      "394     0.0   5.248287  3.564256  4.860291\n",
      "25      4.0   2.389175  3.564256  4.860291\n",
      "449     4.0   3.719784  3.564256  4.860291\n",
      "255     5.0   2.028145  3.564256  4.860291\n",
      "180     6.0   3.783114  3.564256  4.860291\n",
      "42      5.0   2.698349  3.564256  4.860291\n",
      "302     2.0   2.368332  3.564256  4.860291\n",
      "101    10.0   2.094312  3.564256  4.860291\n",
      "432     2.0   2.456782  3.564256  4.860291\n",
      "402     3.0   2.021292  3.564256  4.860291\n",
      "137    14.0   7.166373  3.564256  4.860291\n",
      "299     8.0   5.955364  3.564256  4.860291\n",
      "22      3.0   5.796754  3.564256  4.860291\n",
      "301    11.0   3.003016  3.564256  4.860291\n",
      "46      4.0   5.607409  3.564256  4.860291\n",
      "168     1.0   2.123914  3.564256  4.860291\n",
      "460     4.0   4.654554  3.564256  4.860291\n",
      "225     2.0   5.206391  3.915258  4.777598\n",
      "30     11.0   7.043945  3.915258  4.777598\n",
      "39      2.0   4.784177  3.915258  4.777598\n",
      "222     0.0   4.624181  3.915258  4.777598\n",
      "124     1.0   3.151332  3.915258  4.777598\n",
      "203     0.0   4.746693  3.915258  4.777598\n",
      "310     2.0   6.453652  3.915258  4.777598\n",
      "211    11.0   0.880142  3.915258  4.777598\n",
      "457     1.0   4.698252  3.915258  4.777598\n",
      "77     13.0   3.066978  3.915258  4.777598\n",
      "454     2.0   4.402851  3.915258  4.777598\n",
      "398     2.0   5.208886  3.915258  4.777598\n",
      "76      1.0   1.750431  3.915258  4.777598\n",
      "386     3.0   6.449035  3.915258  4.777598\n",
      "278     3.0   3.105805  3.915258  4.777598\n",
      "271    11.0   6.987761  3.915258  4.777598\n",
      "70      4.0   7.059641  3.915258  4.777598\n",
      "93     16.0   8.377133  3.915258  4.777598\n",
      "157    14.0   9.664330  3.915258  4.777598\n",
      "0       3.0   4.550973  3.915258  4.777598\n",
      "388     5.0   1.925669  3.915258  4.777598\n",
      "82      3.0   6.588594  3.915258  4.777598\n",
      "368     2.0   9.131413  3.915258  4.777598\n",
      "357     7.0   3.525924  3.915258  4.777598\n",
      "420     4.0   7.052691  3.915258  4.777598\n",
      "307     3.0   7.817080  3.915258  4.777598\n",
      "172    10.0   3.581771  3.915258  4.777598\n",
      "176     4.0   3.896760  3.915258  4.777598\n",
      "18      7.0   6.261024  3.915258  4.777598\n",
      "9       0.0   4.332244  3.915258  4.777598\n",
      "428     1.0   4.628978  3.915258  4.777598\n",
      "448     5.0   4.450382  3.915258  4.777598\n",
      "73     14.0   4.306659  3.915258  4.777598\n",
      "234     1.0   4.644578  3.915258  4.777598\n",
      "287    10.0   9.770505  3.915258  4.777598\n",
      "408     1.0   3.556643  3.915258  4.777598\n",
      "55     14.0   5.994364  3.915258  4.777598\n",
      "90     13.0   8.515780  3.915258  4.777598\n",
      "364     6.0   6.853927  3.915258  4.777598\n",
      "79      0.0   2.837373  3.915258  4.777598\n",
      "325     1.0   7.829909  3.915258  4.777598\n",
      "450     3.0   3.606205  3.915258  4.777598\n",
      "209     4.0   8.419257  3.915258  4.777598\n",
      "173    16.0   4.837536  3.915258  4.777598\n",
      "185     8.0   3.826015  3.915258  4.777598\n",
      "72      0.0   4.268160  3.915258  4.777598\n",
      "148     8.0   5.129148  3.915258  4.777598\n",
      "78      2.0   3.298975  3.915258  4.777598\n",
      "126    15.0   6.632168  3.915258  4.777598\n",
      "132     0.0  10.593006  3.915258  4.777598\n",
      "458     5.0   3.989984  3.915258  4.777598\n",
      "75     15.0   8.174807  3.915258  4.777598\n",
      "296    10.0   2.404166  3.915258  4.777598\n",
      "195     2.0   3.368104  3.915258  4.777598\n",
      "131     0.0   4.238367  3.915258  4.777598\n",
      "227    11.0   4.147779  3.915258  4.777598\n",
      "365     5.0   4.567923  3.915258  4.777598\n",
      "33     13.0   4.764138  3.915258  4.777598\n",
      "373     0.0   4.369105  3.915258  4.777598\n",
      "320     8.0   4.614522  3.915258  4.777598\n",
      "409     2.0   2.747556  3.915258  4.777598\n",
      "140    13.0   8.691576  3.915258  4.777598\n",
      "11      1.0   7.303067  3.915258  4.777598\n",
      "407     3.0   4.030168  3.915258  4.777598\n",
      "15     12.0   3.563425  3.915258  4.777598\n",
      "421     5.0   5.934623  3.915258  4.777598\n",
      "358     3.0   5.593758  3.915258  4.777598\n",
      "19      3.0   0.215364  3.915258  4.777598\n",
      "297     6.0   4.145082  3.915258  4.777598\n",
      "416     3.0   3.263860  3.915258  4.777598\n",
      "56      1.0   4.031828  3.915258  4.777598\n",
      "196    13.0  10.708558  3.915258  4.777598\n",
      "334     2.0   6.510002  3.915258  4.777598\n",
      "305     1.0   5.949161  3.915258  4.777598\n",
      "113     3.0   7.521724  3.915258  4.777598\n",
      "155    15.0   6.228233  3.915258  4.777598\n",
      "394     0.0   6.982093  3.915258  4.777598\n",
      "25      4.0   4.968674  3.915258  4.777598\n",
      "449     4.0   4.026066  3.915258  4.777598\n",
      "255     5.0   4.018340  3.915258  4.777598\n",
      "180     6.0   5.338419  3.915258  4.777598\n",
      "42      5.0   5.504887  3.915258  4.777598\n",
      "302     2.0   5.250007  3.915258  4.777598\n",
      "101    10.0   2.402272  3.915258  4.777598\n",
      "432     2.0   4.516951  3.915258  4.777598\n",
      "402     3.0   1.039597  3.915258  4.777598\n",
      "137    14.0   5.681678  3.915258  4.777598\n",
      "299     8.0   5.564059  3.915258  4.777598\n",
      "22      3.0   7.258418  3.915258  4.777598\n",
      "301    11.0   8.806211  3.915258  4.777598\n",
      "46      4.0   8.155969  3.915258  4.777598\n",
      "168     1.0   3.584038  3.915258  4.777598\n",
      "460     4.0   9.099340  3.915258  4.777598\n",
      "\n",
      "Best Model Parameters:\n",
      "{'n_units': 64, 'learning_rate': 0.001, 'dropout_rate': 0.5, 'activation': 'relu'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.5163473262581775, 4.601782884634073)"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5\n",
    "#split\n",
    "#1차\n",
    "#data\n",
    "\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# # 데이터 준비\n",
    "# X = merged_all_comb_copy_model[feature_columns]\n",
    "# y = merged_all_comb_copy_model[target_column]\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 구축 및 컴파일 함수\n",
    "def build_model(n_units, learning_rate, dropout_rate, activation):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(n_units, activation=activation, input_shape=(X_train.shape[1],)),  # 수정: input_shape를 X_train의 특성 수에 맞게 설정\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "n_units_options = [64, 128]\n",
    "learning_rate_options = [0.001, 0.01]\n",
    "dropout_rate_options = [0.3, 0.5]\n",
    "activation_options = ['relu', 'tanh']\n",
    "\n",
    "best_model = None\n",
    "best_mae = float('inf')\n",
    "best_rmse = float('inf')\n",
    "best_model_params = None\n",
    "results_table = pd.DataFrame()\n",
    "\n",
    "# 하이퍼파라미터 실험 및 모델 평가\n",
    "for n_units in n_units_options:\n",
    "    for learning_rate in learning_rate_options:\n",
    "        for dropout_rate in dropout_rate_options:\n",
    "            for activation in activation_options:\n",
    "                model = build_model(n_units, learning_rate, dropout_rate, activation)\n",
    "                model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "                y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "                y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "                # 평가 지표 계산\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "\n",
    "                # 최적 모델 업데이트\n",
    "                if mae + rmse < best_mae + best_rmse:\n",
    "                    best_model = model\n",
    "                    best_mae = mae\n",
    "                    best_rmse = rmse\n",
    "                    best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "                # 결과 추가\n",
    "                temp_results = pd.DataFrame({\n",
    "                    'Actual': y_test,\n",
    "                    'Predicted': y_pred,\n",
    "                    'MAE': mae,\n",
    "                    'RMSE': rmse\n",
    "                })\n",
    "                results_table = pd.concat([results_table, temp_results])\n",
    "\n",
    "# 최적 모델의 결과와 파라미터 출력\n",
    "print(\"Best Model Results:\")\n",
    "print(results_table)\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model_params)\n",
    "\n",
    "# 최적 모델의 결과에서 가장 좋은 MAE와 RMSE 값 찾기\n",
    "best_mae = results_table['MAE'].min()\n",
    "best_rmse = results_table['RMSE'].min()\n",
    "\n",
    "best_mae, best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "06b09e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 997us/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Best Model Results:\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "126    15.0   9.028882  2.924383  3.977806\n",
      "30     11.0   7.396214  2.924383  3.977806\n",
      "202    14.0   3.658470  2.924383  3.977806\n",
      "442     1.0   1.788990  2.924383  3.977806\n",
      "157    14.0   5.988822  2.924383  3.977806\n",
      "228     2.0   2.897159  2.924383  3.977806\n",
      "409     2.0   2.520252  2.924383  3.977806\n",
      "299     8.0   7.940459  2.924383  3.977806\n",
      "225     2.0   3.147213  2.924383  3.977806\n",
      "76      1.0   2.571755  2.924383  3.977806\n",
      "454     2.0   5.441133  2.924383  3.977806\n",
      "345     5.0   8.314921  2.924383  3.977806\n",
      "79      0.0   2.183453  2.924383  3.977806\n",
      "335     5.0   7.372680  2.924383  3.977806\n",
      "248    11.0   7.422365  2.924383  3.977806\n",
      "420     4.0   3.106368  2.924383  3.977806\n",
      "213    10.0   6.926157  2.924383  3.977806\n",
      "251     3.0   3.999584  2.924383  3.977806\n",
      "450     3.0   2.980097  2.924383  3.977806\n",
      "0       3.0   4.105131  2.924383  3.977806\n",
      "71      4.0   3.046960  2.924383  3.977806\n",
      "265     4.0   5.815368  2.924383  3.977806\n",
      "439     2.0   6.885375  2.924383  3.977806\n",
      "39      2.0   4.221397  2.924383  3.977806\n",
      "211    11.0   2.763306  2.924383  3.977806\n",
      "308     9.0   4.513801  2.924383  3.977806\n",
      "73     14.0   1.467903  2.924383  3.977806\n",
      "83      1.0   3.802111  2.924383  3.977806\n",
      "128     2.0   2.423590  2.924383  3.977806\n",
      "9       0.0   2.895129  2.924383  3.977806\n",
      "55     14.0   9.396070  2.924383  3.977806\n",
      "234     1.0   3.029239  2.924383  3.977806\n",
      "457     1.0   6.761639  2.924383  3.977806\n",
      "297     6.0   4.223637  2.924383  3.977806\n",
      "383     3.0   4.267180  2.924383  3.977806\n",
      "324     3.0   4.173221  2.924383  3.977806\n",
      "412     1.0   2.548439  2.924383  3.977806\n",
      "252     6.0   4.399518  2.924383  3.977806\n",
      "78      2.0   3.689681  2.924383  3.977806\n",
      "326     6.0   6.470198  2.924383  3.977806\n",
      "432     2.0   4.709245  2.924383  3.977806\n",
      "393     4.0   3.687019  2.924383  3.977806\n",
      "171     2.0   6.224611  2.924383  3.977806\n",
      "80      3.0   3.994031  2.924383  3.977806\n",
      "277     4.0   5.575381  2.924383  3.977806\n",
      "440     3.0   1.754669  2.924383  3.977806\n",
      "77     13.0   4.963890  2.924383  3.977806\n",
      "240     4.0   7.406686  2.924383  3.977806\n",
      "428     1.0   1.770366  2.924383  3.977806\n",
      "74      9.0   7.351839  2.924383  3.977806\n",
      "143    10.0   6.558148  2.924383  3.977806\n",
      "94     14.0   3.160272  2.924383  3.977806\n",
      "437     2.0   1.935599  2.924383  3.977806\n",
      "436     5.0   3.950227  2.924383  3.977806\n",
      "33     13.0   7.346899  2.924383  3.977806\n",
      "212     0.0   3.699662  2.924383  3.977806\n",
      "321     5.0   5.596718  2.924383  3.977806\n",
      "405     3.0   2.672595  2.924383  3.977806\n",
      "140    13.0   8.059592  2.924383  3.977806\n",
      "11      1.0   6.671204  2.924383  3.977806\n",
      "407     3.0   1.638403  2.924383  3.977806\n",
      "15     12.0   4.382801  2.924383  3.977806\n",
      "176     4.0   2.774347  2.924383  3.977806\n",
      "280     1.0   3.051067  2.924383  3.977806\n",
      "359     3.0   3.342811  2.924383  3.977806\n",
      "19      3.0   1.390673  2.924383  3.977806\n",
      "374     2.0   3.058230  2.924383  3.977806\n",
      "307     3.0   9.306211  2.924383  3.977806\n",
      "56      1.0   1.768748  2.924383  3.977806\n",
      "196    13.0   6.506018  2.924383  3.977806\n",
      "389     4.0   4.514817  2.924383  3.977806\n",
      "379     2.0   3.280083  2.924383  3.977806\n",
      "91     15.0   9.196111  2.924383  3.977806\n",
      "115     9.0   5.574762  2.924383  3.977806\n",
      "394     0.0   3.141998  2.924383  3.977806\n",
      "25      4.0   4.534447  2.924383  3.977806\n",
      "198     2.0   2.196005  2.924383  3.977806\n",
      "207    13.0   7.418842  2.924383  3.977806\n",
      "434     3.0   2.363521  2.924383  3.977806\n",
      "42      5.0   4.196829  2.924383  3.977806\n",
      "184     6.0  12.526319  2.924383  3.977806\n",
      "448     5.0   4.391013  2.924383  3.977806\n",
      "453     1.0   2.662808  2.924383  3.977806\n",
      "364     6.0   7.230603  2.924383  3.977806\n",
      "271    11.0   3.773273  2.924383  3.977806\n",
      "300     2.0   6.561765  2.924383  3.977806\n",
      "22      3.0   7.695691  2.924383  3.977806\n",
      "302     2.0   3.234916  2.924383  3.977806\n",
      "46      4.0   3.438932  2.924383  3.977806\n",
      "102    12.0   3.826294  2.924383  3.977806\n",
      "418     3.0   5.996037  2.924383  3.977806\n",
      "160     4.0   4.539555  2.924383  3.977806\n",
      "126    15.0   8.599787  3.350627  4.099108\n",
      "30     11.0   7.855176  3.350627  4.099108\n",
      "202    14.0   4.683836  3.350627  4.099108\n",
      "442     1.0   4.771700  3.350627  4.099108\n",
      "157    14.0   7.999913  3.350627  4.099108\n",
      "228     2.0   5.333791  3.350627  4.099108\n",
      "409     2.0   2.385814  3.350627  4.099108\n",
      "299     8.0   5.393469  3.350627  4.099108\n",
      "225     2.0   3.837048  3.350627  4.099108\n",
      "76      1.0   4.798830  3.350627  4.099108\n",
      "454     2.0   6.305561  3.350627  4.099108\n",
      "345     5.0   7.321960  3.350627  4.099108\n",
      "79      0.0   5.233397  3.350627  4.099108\n",
      "335     5.0   7.696598  3.350627  4.099108\n",
      "248    11.0   6.185699  3.350627  4.099108\n",
      "420     4.0   5.994046  3.350627  4.099108\n",
      "213    10.0   6.013053  3.350627  4.099108\n",
      "251     3.0   6.599598  3.350627  4.099108\n",
      "450     3.0   2.564507  3.350627  4.099108\n",
      "0       3.0   3.891281  3.350627  4.099108\n",
      "71      4.0   3.710431  3.350627  4.099108\n",
      "265     4.0   6.330670  3.350627  4.099108\n",
      "439     2.0   4.735529  3.350627  4.099108\n",
      "39      2.0   6.201194  3.350627  4.099108\n",
      "211    11.0   2.002383  3.350627  4.099108\n",
      "308     9.0   3.527493  3.350627  4.099108\n",
      "73     14.0   3.939177  3.350627  4.099108\n",
      "83      1.0   5.290915  3.350627  4.099108\n",
      "128     2.0   1.470848  3.350627  4.099108\n",
      "9       0.0   5.752103  3.350627  4.099108\n",
      "55     14.0   7.259438  3.350627  4.099108\n",
      "234     1.0   3.630645  3.350627  4.099108\n",
      "457     1.0   6.466165  3.350627  4.099108\n",
      "297     6.0   5.077928  3.350627  4.099108\n",
      "383     3.0   3.750368  3.350627  4.099108\n",
      "324     3.0   4.977850  3.350627  4.099108\n",
      "412     1.0   3.798029  3.350627  4.099108\n",
      "252     6.0   6.504203  3.350627  4.099108\n",
      "78      2.0   2.932084  3.350627  4.099108\n",
      "326     6.0   4.636439  3.350627  4.099108\n",
      "432     2.0   5.940307  3.350627  4.099108\n",
      "393     4.0   6.003053  3.350627  4.099108\n",
      "171     2.0   7.030647  3.350627  4.099108\n",
      "80      3.0   5.733262  3.350627  4.099108\n",
      "277     4.0   6.070210  3.350627  4.099108\n",
      "440     3.0   0.300433  3.350627  4.099108\n",
      "77     13.0   3.518536  3.350627  4.099108\n",
      "240     4.0   7.437328  3.350627  4.099108\n",
      "428     1.0   4.429780  3.350627  4.099108\n",
      "74      9.0   8.332199  3.350627  4.099108\n",
      "143    10.0   5.509928  3.350627  4.099108\n",
      "94     14.0   4.258176  3.350627  4.099108\n",
      "437     2.0   4.480443  3.350627  4.099108\n",
      "436     5.0   5.868865  3.350627  4.099108\n",
      "33     13.0   5.485696  3.350627  4.099108\n",
      "212     0.0   5.170380  3.350627  4.099108\n",
      "321     5.0   4.748098  3.350627  4.099108\n",
      "405     3.0   5.120538  3.350627  4.099108\n",
      "140    13.0   8.816065  3.350627  4.099108\n",
      "11      1.0   7.234527  3.350627  4.099108\n",
      "407     3.0   5.033047  3.350627  4.099108\n",
      "15     12.0   4.361566  3.350627  4.099108\n",
      "176     4.0   3.347268  3.350627  4.099108\n",
      "280     1.0   3.924317  3.350627  4.099108\n",
      "359     3.0   5.055250  3.350627  4.099108\n",
      "19      3.0   0.068395  3.350627  4.099108\n",
      "374     2.0   2.677011  3.350627  4.099108\n",
      "307     3.0   7.138741  3.350627  4.099108\n",
      "56      1.0   2.449454  3.350627  4.099108\n",
      "196    13.0   8.531727  3.350627  4.099108\n",
      "389     4.0   5.157597  3.350627  4.099108\n",
      "379     2.0   4.125896  3.350627  4.099108\n",
      "91     15.0   8.086774  3.350627  4.099108\n",
      "115     9.0   5.637936  3.350627  4.099108\n",
      "394     0.0   5.171782  3.350627  4.099108\n",
      "25      4.0   5.431333  3.350627  4.099108\n",
      "198     2.0   3.315479  3.350627  4.099108\n",
      "207    13.0   8.629722  3.350627  4.099108\n",
      "434     3.0   3.703021  3.350627  4.099108\n",
      "42      5.0   5.960015  3.350627  4.099108\n",
      "184     6.0   8.511546  3.350627  4.099108\n",
      "448     5.0   3.425737  3.350627  4.099108\n",
      "453     1.0   3.690021  3.350627  4.099108\n",
      "364     6.0   6.856563  3.350627  4.099108\n",
      "271    11.0   5.925650  3.350627  4.099108\n",
      "300     2.0   6.492158  3.350627  4.099108\n",
      "22      3.0   6.228568  3.350627  4.099108\n",
      "302     2.0   3.705170  3.350627  4.099108\n",
      "46      4.0   5.010406  3.350627  4.099108\n",
      "102    12.0   5.289471  3.350627  4.099108\n",
      "418     3.0   4.306740  3.350627  4.099108\n",
      "160     4.0   6.447840  3.350627  4.099108\n",
      "126    15.0   7.445109  2.929499  4.088199\n",
      "30     11.0   7.058461  2.929499  4.088199\n",
      "202    14.0   3.736689  2.929499  4.088199\n",
      "442     1.0   2.486603  2.929499  4.088199\n",
      "157    14.0   5.614138  2.929499  4.088199\n",
      "228     2.0   2.520177  2.929499  4.088199\n",
      "409     2.0   1.922183  2.929499  4.088199\n",
      "299     8.0   6.431676  2.929499  4.088199\n",
      "225     2.0   2.267009  2.929499  4.088199\n",
      "76      1.0   2.372323  2.929499  4.088199\n",
      "454     2.0   4.368000  2.929499  4.088199\n",
      "345     5.0   7.382668  2.929499  4.088199\n",
      "79      0.0   2.603071  2.929499  4.088199\n",
      "335     5.0   7.242824  2.929499  4.088199\n",
      "248    11.0   6.571980  2.929499  4.088199\n",
      "420     4.0   3.321188  2.929499  4.088199\n",
      "213    10.0   7.175401  2.929499  4.088199\n",
      "251     3.0   4.204311  2.929499  4.088199\n",
      "450     3.0   1.917786  2.929499  4.088199\n",
      "0       3.0   3.147640  2.929499  4.088199\n",
      "71      4.0   2.524809  2.929499  4.088199\n",
      "265     4.0   4.758971  2.929499  4.088199\n",
      "439     2.0   6.803821  2.929499  4.088199\n",
      "39      2.0   4.176410  2.929499  4.088199\n",
      "211    11.0   2.021598  2.929499  4.088199\n",
      "308     9.0   4.615541  2.929499  4.088199\n",
      "73     14.0   1.275646  2.929499  4.088199\n",
      "83      1.0   3.172856  2.929499  4.088199\n",
      "128     2.0   1.932874  2.929499  4.088199\n",
      "9       0.0   2.548010  2.929499  4.088199\n",
      "55     14.0   7.398562  2.929499  4.088199\n",
      "234     1.0   3.800333  2.929499  4.088199\n",
      "457     1.0   6.525701  2.929499  4.088199\n",
      "297     6.0   3.573811  2.929499  4.088199\n",
      "383     3.0   3.831722  2.929499  4.088199\n",
      "324     3.0   4.147069  2.929499  4.088199\n",
      "412     1.0   2.654058  2.929499  4.088199\n",
      "252     6.0   3.537000  2.929499  4.088199\n",
      "78      2.0   2.791135  2.929499  4.088199\n",
      "326     6.0   5.293983  2.929499  4.088199\n",
      "432     2.0   4.490708  2.929499  4.088199\n",
      "393     4.0   3.389149  2.929499  4.088199\n",
      "171     2.0   6.102258  2.929499  4.088199\n",
      "80      3.0   3.988879  2.929499  4.088199\n",
      "277     4.0   4.915254  2.929499  4.088199\n",
      "440     3.0   1.965106  2.929499  4.088199\n",
      "77     13.0   4.108148  2.929499  4.088199\n",
      "240     4.0   6.835353  2.929499  4.088199\n",
      "428     1.0   2.438941  2.929499  4.088199\n",
      "74      9.0   6.409828  2.929499  4.088199\n",
      "143    10.0   5.821812  2.929499  4.088199\n",
      "94     14.0   2.780172  2.929499  4.088199\n",
      "437     2.0   1.971942  2.929499  4.088199\n",
      "436     5.0   3.646784  2.929499  4.088199\n",
      "33     13.0   6.273632  2.929499  4.088199\n",
      "212     0.0   2.912557  2.929499  4.088199\n",
      "321     5.0   3.524659  2.929499  4.088199\n",
      "405     3.0   2.642650  2.929499  4.088199\n",
      "140    13.0   7.182503  2.929499  4.088199\n",
      "11      1.0   6.179380  2.929499  4.088199\n",
      "407     3.0   1.819645  2.929499  4.088199\n",
      "15     12.0   3.416161  2.929499  4.088199\n",
      "176     4.0   2.147286  2.929499  4.088199\n",
      "280     1.0   2.618755  2.929499  4.088199\n",
      "359     3.0   3.078290  2.929499  4.088199\n",
      "19      3.0   1.490161  2.929499  4.088199\n",
      "374     2.0   2.874643  2.929499  4.088199\n",
      "307     3.0   7.596055  2.929499  4.088199\n",
      "56      1.0   1.980026  2.929499  4.088199\n",
      "196    13.0   5.701209  2.929499  4.088199\n",
      "389     4.0   4.339617  2.929499  4.088199\n",
      "379     2.0   2.648007  2.929499  4.088199\n",
      "91     15.0   7.732892  2.929499  4.088199\n",
      "115     9.0   5.651492  2.929499  4.088199\n",
      "394     0.0   2.881125  2.929499  4.088199\n",
      "25      4.0   4.196929  2.929499  4.088199\n",
      "198     2.0   2.713884  2.929499  4.088199\n",
      "207    13.0   7.669151  2.929499  4.088199\n",
      "434     3.0   2.065594  2.929499  4.088199\n",
      "42      5.0   5.359533  2.929499  4.088199\n",
      "184     6.0  10.375533  2.929499  4.088199\n",
      "448     5.0   4.154168  2.929499  4.088199\n",
      "453     1.0   2.712682  2.929499  4.088199\n",
      "364     6.0   5.933465  2.929499  4.088199\n",
      "271    11.0   3.426032  2.929499  4.088199\n",
      "300     2.0   5.563705  2.929499  4.088199\n",
      "22      3.0   6.584907  2.929499  4.088199\n",
      "302     2.0   2.775060  2.929499  4.088199\n",
      "46      4.0   3.512046  2.929499  4.088199\n",
      "102    12.0   3.628649  2.929499  4.088199\n",
      "418     3.0   4.419092  2.929499  4.088199\n",
      "160     4.0   4.560775  2.929499  4.088199\n",
      "126    15.0   7.262054  3.313890  4.105310\n",
      "30     11.0   6.863322  3.313890  4.105310\n",
      "202    14.0   5.049276  3.313890  4.105310\n",
      "442     1.0   4.288669  3.313890  4.105310\n",
      "157    14.0   6.571491  3.313890  4.105310\n",
      "228     2.0   5.134531  3.313890  4.105310\n",
      "409     2.0   3.375740  3.313890  4.105310\n",
      "299     8.0   4.718406  3.313890  4.105310\n",
      "225     2.0   3.938081  3.313890  4.105310\n",
      "76      1.0   4.718338  3.313890  4.105310\n",
      "454     2.0   6.467741  3.313890  4.105310\n",
      "345     5.0   6.459150  3.313890  4.105310\n",
      "79      0.0   4.730817  3.313890  4.105310\n",
      "335     5.0   7.082825  3.313890  4.105310\n",
      "248    11.0   6.412930  3.313890  4.105310\n",
      "420     4.0   5.615482  3.313890  4.105310\n",
      "213    10.0   6.489658  3.313890  4.105310\n",
      "251     3.0   5.990250  3.313890  4.105310\n",
      "450     3.0   1.646403  3.313890  4.105310\n",
      "0       3.0   3.904062  3.313890  4.105310\n",
      "71      4.0   3.661126  3.313890  4.105310\n",
      "265     4.0   4.576444  3.313890  4.105310\n",
      "439     2.0   5.782751  3.313890  4.105310\n",
      "39      2.0   5.299170  3.313890  4.105310\n",
      "211    11.0   3.159809  3.313890  4.105310\n",
      "308     9.0   3.422705  3.313890  4.105310\n",
      "73     14.0   3.524603  3.313890  4.105310\n",
      "83      1.0   4.800034  3.313890  4.105310\n",
      "128     2.0   2.904113  3.313890  4.105310\n",
      "9       0.0   5.546878  3.313890  4.105310\n",
      "55     14.0   6.465728  3.313890  4.105310\n",
      "234     1.0   3.275316  3.313890  4.105310\n",
      "457     1.0   5.984787  3.313890  4.105310\n",
      "297     6.0   5.209804  3.313890  4.105310\n",
      "383     3.0   4.443814  3.313890  4.105310\n",
      "324     3.0   5.340154  3.313890  4.105310\n",
      "412     1.0   4.210490  3.313890  4.105310\n",
      "252     6.0   5.137879  3.313890  4.105310\n",
      "78      2.0   3.457713  3.313890  4.105310\n",
      "326     6.0   4.726095  3.313890  4.105310\n",
      "432     2.0   3.723670  3.313890  4.105310\n",
      "393     4.0   5.906518  3.313890  4.105310\n",
      "171     2.0   6.696284  3.313890  4.105310\n",
      "80      3.0   5.541455  3.313890  4.105310\n",
      "277     4.0   6.416937  3.313890  4.105310\n",
      "440     3.0   0.371073  3.313890  4.105310\n",
      "77     13.0   3.659498  3.313890  4.105310\n",
      "240     4.0   6.430332  3.313890  4.105310\n",
      "428     1.0   4.515068  3.313890  4.105310\n",
      "74      9.0   7.150868  3.313890  4.105310\n",
      "143    10.0   6.215188  3.313890  4.105310\n",
      "94     14.0   4.467059  3.313890  4.105310\n",
      "437     2.0   4.165403  3.313890  4.105310\n",
      "436     5.0   5.074265  3.313890  4.105310\n",
      "33     13.0   4.754600  3.313890  4.105310\n",
      "212     0.0   5.017006  3.313890  4.105310\n",
      "321     5.0   4.856754  3.313890  4.105310\n",
      "405     3.0   5.469992  3.313890  4.105310\n",
      "140    13.0   7.327789  3.313890  4.105310\n",
      "11      1.0   6.380770  3.313890  4.105310\n",
      "407     3.0   4.229981  3.313890  4.105310\n",
      "15     12.0   4.519521  3.313890  4.105310\n",
      "176     4.0   3.768291  3.313890  4.105310\n",
      "280     1.0   3.947649  3.313890  4.105310\n",
      "359     3.0   4.730020  3.313890  4.105310\n",
      "19      3.0   0.556576  3.313890  4.105310\n",
      "374     2.0   3.524560  3.313890  4.105310\n",
      "307     3.0   5.749030  3.313890  4.105310\n",
      "56      1.0   2.064086  3.313890  4.105310\n",
      "196    13.0   7.192014  3.313890  4.105310\n",
      "389     4.0   5.342328  3.313890  4.105310\n",
      "379     2.0   4.757398  3.313890  4.105310\n",
      "91     15.0   7.086084  3.313890  4.105310\n",
      "115     9.0   5.373992  3.313890  4.105310\n",
      "394     0.0   5.103261  3.313890  4.105310\n",
      "25      4.0   5.737213  3.313890  4.105310\n",
      "198     2.0   4.346543  3.313890  4.105310\n",
      "207    13.0   7.898921  3.313890  4.105310\n",
      "434     3.0   3.778673  3.313890  4.105310\n",
      "42      5.0   5.450613  3.313890  4.105310\n",
      "184     6.0   8.025499  3.313890  4.105310\n",
      "448     5.0   4.236027  3.313890  4.105310\n",
      "453     1.0   4.331240  3.313890  4.105310\n",
      "364     6.0   6.136270  3.313890  4.105310\n",
      "271    11.0   5.843530  3.313890  4.105310\n",
      "300     2.0   5.162757  3.313890  4.105310\n",
      "22      3.0   6.198799  3.313890  4.105310\n",
      "302     2.0   3.909741  3.313890  4.105310\n",
      "46      4.0   5.630474  3.313890  4.105310\n",
      "102    12.0   5.679536  3.313890  4.105310\n",
      "418     3.0   2.838559  3.313890  4.105310\n",
      "160     4.0   6.173843  3.313890  4.105310\n",
      "126    15.0  10.381599  3.236113  4.339417\n",
      "30     11.0   6.193603  3.236113  4.339417\n",
      "202    14.0   4.186046  3.236113  4.339417\n",
      "442     1.0   2.803551  3.236113  4.339417\n",
      "157    14.0   9.557147  3.236113  4.339417\n",
      "228     2.0   3.139787  3.236113  4.339417\n",
      "409     2.0   1.834941  3.236113  4.339417\n",
      "299     8.0   4.326616  3.236113  4.339417\n",
      "225     2.0   3.141383  3.236113  4.339417\n",
      "76      1.0   2.446294  3.236113  4.339417\n",
      "454     2.0   4.824045  3.236113  4.339417\n",
      "345     5.0   9.494178  3.236113  4.339417\n",
      "79      0.0   3.514390  3.236113  4.339417\n",
      "335     5.0   8.832815  3.236113  4.339417\n",
      "248    11.0   3.034834  3.236113  4.339417\n",
      "420     4.0   6.143250  3.236113  4.339417\n",
      "213    10.0   4.110533  3.236113  4.339417\n",
      "251     3.0   2.789268  3.236113  4.339417\n",
      "450     3.0   1.865804  3.236113  4.339417\n",
      "0       3.0   5.801122  3.236113  4.339417\n",
      "71      4.0   2.214205  3.236113  4.339417\n",
      "265     4.0  10.215601  3.236113  4.339417\n",
      "439     2.0   4.635925  3.236113  4.339417\n",
      "39      2.0   2.503463  3.236113  4.339417\n",
      "211    11.0   2.519083  3.236113  4.339417\n",
      "308     9.0   5.012789  3.236113  4.339417\n",
      "73     14.0   2.137314  3.236113  4.339417\n",
      "83      1.0   2.913653  3.236113  4.339417\n",
      "128     2.0   2.153882  3.236113  4.339417\n",
      "9       0.0   3.424509  3.236113  4.339417\n",
      "55     14.0   6.093338  3.236113  4.339417\n",
      "234     1.0   2.272990  3.236113  4.339417\n",
      "457     1.0   3.533447  3.236113  4.339417\n",
      "297     6.0   3.544270  3.236113  4.339417\n",
      "383     3.0   4.601924  3.236113  4.339417\n",
      "324     3.0   3.441643  3.236113  4.339417\n",
      "412     1.0   4.591526  3.236113  4.339417\n",
      "252     6.0   4.357751  3.236113  4.339417\n",
      "78      2.0   2.452457  3.236113  4.339417\n",
      "326     6.0  10.126472  3.236113  4.339417\n",
      "432     2.0   2.769979  3.236113  4.339417\n",
      "393     4.0   2.642317  3.236113  4.339417\n",
      "171     2.0   3.700276  3.236113  4.339417\n",
      "80      3.0   5.766611  3.236113  4.339417\n",
      "277     4.0   7.019454  3.236113  4.339417\n",
      "440     3.0   2.641207  3.236113  4.339417\n",
      "77     13.0   3.600405  3.236113  4.339417\n",
      "240     4.0   9.787992  3.236113  4.339417\n",
      "428     1.0   2.778056  3.236113  4.339417\n",
      "74      9.0  10.644522  3.236113  4.339417\n",
      "143    10.0  11.036179  3.236113  4.339417\n",
      "94     14.0   2.582898  3.236113  4.339417\n",
      "437     2.0   2.442506  3.236113  4.339417\n",
      "436     5.0   5.509255  3.236113  4.339417\n",
      "33     13.0   4.929793  3.236113  4.339417\n",
      "212     0.0   2.985011  3.236113  4.339417\n",
      "321     5.0   4.122629  3.236113  4.339417\n",
      "405     3.0   1.925397  3.236113  4.339417\n",
      "140    13.0  10.105655  3.236113  4.339417\n",
      "11      1.0   4.940207  3.236113  4.339417\n",
      "407     3.0   3.812776  3.236113  4.339417\n",
      "15     12.0   3.212421  3.236113  4.339417\n",
      "176     4.0   2.305211  3.236113  4.339417\n",
      "280     1.0   2.451278  3.236113  4.339417\n",
      "359     3.0   3.314198  3.236113  4.339417\n",
      "19      3.0   1.737918  3.236113  4.339417\n",
      "374     2.0   2.479766  3.236113  4.339417\n",
      "307     3.0  10.612809  3.236113  4.339417\n",
      "56      1.0   2.525157  3.236113  4.339417\n",
      "196    13.0   7.340518  3.236113  4.339417\n",
      "389     4.0   1.791844  3.236113  4.339417\n",
      "379     2.0   2.174234  3.236113  4.339417\n",
      "91     15.0  10.559668  3.236113  4.339417\n",
      "115     9.0   3.420881  3.236113  4.339417\n",
      "394     0.0   4.330605  3.236113  4.339417\n",
      "25      4.0   3.642315  3.236113  4.339417\n",
      "198     2.0   2.935102  3.236113  4.339417\n",
      "207    13.0   7.320367  3.236113  4.339417\n",
      "434     3.0   2.066869  3.236113  4.339417\n",
      "42      5.0   2.840261  3.236113  4.339417\n",
      "184     6.0  17.567387  3.236113  4.339417\n",
      "448     5.0   3.088153  3.236113  4.339417\n",
      "453     1.0   2.622769  3.236113  4.339417\n",
      "364     6.0  10.617646  3.236113  4.339417\n",
      "271    11.0   5.207390  3.236113  4.339417\n",
      "300     2.0   4.527599  3.236113  4.339417\n",
      "22      3.0   4.514579  3.236113  4.339417\n",
      "302     2.0   2.453232  3.236113  4.339417\n",
      "46      4.0   4.652386  3.236113  4.339417\n",
      "102    12.0   2.480847  3.236113  4.339417\n",
      "418     3.0   4.449530  3.236113  4.339417\n",
      "160     4.0   7.017088  3.236113  4.339417\n",
      "126    15.0   9.894737  3.332634  4.259437\n",
      "30     11.0  10.854972  3.332634  4.259437\n",
      "202    14.0   3.278058  3.332634  4.259437\n",
      "442     1.0   5.364090  3.332634  4.259437\n",
      "157    14.0  11.094351  3.332634  4.259437\n",
      "228     2.0   6.014711  3.332634  4.259437\n",
      "409     2.0   2.492512  3.332634  4.259437\n",
      "299     8.0   5.517065  3.332634  4.259437\n",
      "225     2.0   2.505949  3.332634  4.259437\n",
      "76      1.0   2.731676  3.332634  4.259437\n",
      "454     2.0   5.442828  3.332634  4.259437\n",
      "345     5.0   7.871103  3.332634  4.259437\n",
      "79      0.0   4.632828  3.332634  4.259437\n",
      "335     5.0   8.861352  3.332634  4.259437\n",
      "248    11.0   7.927902  3.332634  4.259437\n",
      "420     4.0   7.174205  3.332634  4.259437\n",
      "213    10.0   5.945903  3.332634  4.259437\n",
      "251     3.0   5.539532  3.332634  4.259437\n",
      "450     3.0   3.127737  3.332634  4.259437\n",
      "0       3.0   5.243923  3.332634  4.259437\n",
      "71      4.0   2.656646  3.332634  4.259437\n",
      "265     4.0   6.213381  3.332634  4.259437\n",
      "439     2.0   3.602317  3.332634  4.259437\n",
      "39      2.0   8.191642  3.332634  4.259437\n",
      "211    11.0   2.828450  3.332634  4.259437\n",
      "308     9.0   3.514341  3.332634  4.259437\n",
      "73     14.0   3.584683  3.332634  4.259437\n",
      "83      1.0   4.753979  3.332634  4.259437\n",
      "128     2.0   3.589229  3.332634  4.259437\n",
      "9       0.0   7.807088  3.332634  4.259437\n",
      "55     14.0   6.473703  3.332634  4.259437\n",
      "234     1.0   4.323672  3.332634  4.259437\n",
      "457     1.0   5.555243  3.332634  4.259437\n",
      "297     6.0   4.622238  3.332634  4.259437\n",
      "383     3.0   3.030694  3.332634  4.259437\n",
      "324     3.0   4.668267  3.332634  4.259437\n",
      "412     1.0   4.685530  3.332634  4.259437\n",
      "252     6.0   6.196495  3.332634  4.259437\n",
      "78      2.0   3.938760  3.332634  4.259437\n",
      "326     6.0   4.750550  3.332634  4.259437\n",
      "432     2.0   8.180769  3.332634  4.259437\n",
      "393     4.0   5.110225  3.332634  4.259437\n",
      "171     2.0   7.571733  3.332634  4.259437\n",
      "80      3.0   5.116601  3.332634  4.259437\n",
      "277     4.0   8.218963  3.332634  4.259437\n",
      "440     3.0   3.166838  3.332634  4.259437\n",
      "77     13.0   4.789154  3.332634  4.259437\n",
      "240     4.0   9.272797  3.332634  4.259437\n",
      "428     1.0   4.674283  3.332634  4.259437\n",
      "74      9.0   8.108801  3.332634  4.259437\n",
      "143    10.0   4.082620  3.332634  4.259437\n",
      "94     14.0   3.218517  3.332634  4.259437\n",
      "437     2.0   6.036722  3.332634  4.259437\n",
      "436     5.0   6.787076  3.332634  4.259437\n",
      "33     13.0   4.961118  3.332634  4.259437\n",
      "212     0.0   4.790193  3.332634  4.259437\n",
      "321     5.0   6.153874  3.332634  4.259437\n",
      "405     3.0   5.028372  3.332634  4.259437\n",
      "140    13.0   9.129457  3.332634  4.259437\n",
      "11      1.0   8.880100  3.332634  4.259437\n",
      "407     3.0   5.780894  3.332634  4.259437\n",
      "15     12.0   1.829579  3.332634  4.259437\n",
      "176     4.0   3.365716  3.332634  4.259437\n",
      "280     1.0   3.272228  3.332634  4.259437\n",
      "359     3.0   3.726231  3.332634  4.259437\n",
      "19      3.0   1.601860  3.332634  4.259437\n",
      "374     2.0   2.023913  3.332634  4.259437\n",
      "307     3.0   9.399351  3.332634  4.259437\n",
      "56      1.0   1.845051  3.332634  4.259437\n",
      "196    13.0  11.592942  3.332634  4.259437\n",
      "389     4.0   7.159864  3.332634  4.259437\n",
      "379     2.0   3.013539  3.332634  4.259437\n",
      "91     15.0   9.464887  3.332634  4.259437\n",
      "115     9.0   6.635665  3.332634  4.259437\n",
      "394     0.0   5.505943  3.332634  4.259437\n",
      "25      4.0   3.804880  3.332634  4.259437\n",
      "198     2.0   2.883613  3.332634  4.259437\n",
      "207    13.0  10.019906  3.332634  4.259437\n",
      "434     3.0   3.243315  3.332634  4.259437\n",
      "42      5.0   5.175173  3.332634  4.259437\n",
      "184     6.0   9.653529  3.332634  4.259437\n",
      "448     5.0   3.947052  3.332634  4.259437\n",
      "453     1.0   4.380054  3.332634  4.259437\n",
      "364     6.0   8.656906  3.332634  4.259437\n",
      "271    11.0   5.760934  3.332634  4.259437\n",
      "300     2.0   5.295668  3.332634  4.259437\n",
      "22      3.0   6.595103  3.332634  4.259437\n",
      "302     2.0   2.213093  3.332634  4.259437\n",
      "46      4.0   3.636182  3.332634  4.259437\n",
      "102    12.0   5.349024  3.332634  4.259437\n",
      "418     3.0   4.318342  3.332634  4.259437\n",
      "160     4.0   6.155155  3.332634  4.259437\n",
      "126    15.0  11.159072  2.882364  4.000109\n",
      "30     11.0   8.217569  2.882364  4.000109\n",
      "202    14.0   3.467634  2.882364  4.000109\n",
      "442     1.0   4.696831  2.882364  4.000109\n",
      "157    14.0   8.086012  2.882364  4.000109\n",
      "228     2.0   3.296168  2.882364  4.000109\n",
      "409     2.0   2.251800  2.882364  4.000109\n",
      "299     8.0   5.718992  2.882364  4.000109\n",
      "225     2.0   2.325909  2.882364  4.000109\n",
      "76      1.0   2.385819  2.882364  4.000109\n",
      "454     2.0   3.612087  2.882364  4.000109\n",
      "345     5.0   5.500712  2.882364  4.000109\n",
      "79      0.0   2.846248  2.882364  4.000109\n",
      "335     5.0   6.620432  2.882364  4.000109\n",
      "248    11.0   8.420634  2.882364  4.000109\n",
      "420     4.0   4.162417  2.882364  4.000109\n",
      "213    10.0   5.129181  2.882364  4.000109\n",
      "251     3.0   3.399588  2.882364  4.000109\n",
      "450     3.0   2.525819  2.882364  4.000109\n",
      "0       3.0   2.877667  2.882364  4.000109\n",
      "71      4.0   2.930700  2.882364  4.000109\n",
      "265     4.0   7.371964  2.882364  4.000109\n",
      "439     2.0   5.356303  2.882364  4.000109\n",
      "39      2.0   3.906371  2.882364  4.000109\n",
      "211    11.0   2.525819  2.882364  4.000109\n",
      "308     9.0   3.856766  2.882364  4.000109\n",
      "73     14.0   2.336365  2.882364  4.000109\n",
      "83      1.0   2.558365  2.882364  4.000109\n",
      "128     2.0   2.840408  2.882364  4.000109\n",
      "9       0.0   2.766231  2.882364  4.000109\n",
      "55     14.0   9.447597  2.882364  4.000109\n",
      "234     1.0   2.529011  2.882364  4.000109\n",
      "457     1.0   5.875893  2.882364  4.000109\n",
      "297     6.0   3.985739  2.882364  4.000109\n",
      "383     3.0   3.333993  2.882364  4.000109\n",
      "324     3.0   3.288451  2.882364  4.000109\n",
      "412     1.0   3.111090  2.882364  4.000109\n",
      "252     6.0   4.951560  2.882364  4.000109\n",
      "78      2.0   3.690205  2.882364  4.000109\n",
      "326     6.0   4.942761  2.882364  4.000109\n",
      "432     2.0   3.827009  2.882364  4.000109\n",
      "393     4.0   3.859245  2.882364  4.000109\n",
      "171     2.0   5.376873  2.882364  4.000109\n",
      "80      3.0   5.911755  2.882364  4.000109\n",
      "277     4.0   6.744653  2.882364  4.000109\n",
      "440     3.0   3.035028  2.882364  4.000109\n",
      "77     13.0   4.123910  2.882364  4.000109\n",
      "240     4.0   8.097141  2.882364  4.000109\n",
      "428     1.0   2.868017  2.882364  4.000109\n",
      "74      9.0   7.752992  2.882364  4.000109\n",
      "143    10.0   6.177174  2.882364  4.000109\n",
      "94     14.0   3.826765  2.882364  4.000109\n",
      "437     2.0   2.479154  2.882364  4.000109\n",
      "436     5.0   3.301114  2.882364  4.000109\n",
      "33     13.0   5.014380  2.882364  4.000109\n",
      "212     0.0   3.372357  2.882364  4.000109\n",
      "321     5.0   5.012460  2.882364  4.000109\n",
      "405     3.0   3.455541  2.882364  4.000109\n",
      "140    13.0   7.054805  2.882364  4.000109\n",
      "11      1.0   8.077554  2.882364  4.000109\n",
      "407     3.0   2.690125  2.882364  4.000109\n",
      "15     12.0   3.152538  2.882364  4.000109\n",
      "176     4.0   3.145728  2.882364  4.000109\n",
      "280     1.0   2.774604  2.882364  4.000109\n",
      "359     3.0   3.419614  2.882364  4.000109\n",
      "19      3.0   2.261135  2.882364  4.000109\n",
      "374     2.0   2.888208  2.882364  4.000109\n",
      "307     3.0   6.597118  2.882364  4.000109\n",
      "56      1.0   2.400325  2.882364  4.000109\n",
      "196    13.0   7.771547  2.882364  4.000109\n",
      "389     4.0   5.861996  2.882364  4.000109\n",
      "379     2.0   2.702275  2.882364  4.000109\n",
      "91     15.0   8.516521  2.882364  4.000109\n",
      "115     9.0   7.219461  2.882364  4.000109\n",
      "394     0.0   4.221770  2.882364  4.000109\n",
      "25      4.0   3.949409  2.882364  4.000109\n",
      "198     2.0   3.462070  2.882364  4.000109\n",
      "207    13.0   7.590986  2.882364  4.000109\n",
      "434     3.0   2.758854  2.882364  4.000109\n",
      "42      5.0   2.953725  2.882364  4.000109\n",
      "184     6.0  14.876347  2.882364  4.000109\n",
      "448     5.0   3.368263  2.882364  4.000109\n",
      "453     1.0   3.157244  2.882364  4.000109\n",
      "364     6.0   7.362093  2.882364  4.000109\n",
      "271    11.0   4.076891  2.882364  4.000109\n",
      "300     2.0   3.629737  2.882364  4.000109\n",
      "22      3.0   9.325550  2.882364  4.000109\n",
      "302     2.0   3.739172  2.882364  4.000109\n",
      "46      4.0   3.127805  2.882364  4.000109\n",
      "102    12.0   3.145130  2.882364  4.000109\n",
      "418     3.0   2.536328  2.882364  4.000109\n",
      "160     4.0   4.730260  2.882364  4.000109\n",
      "126    15.0   7.556376  3.285826  4.168054\n",
      "30     11.0   8.661517  3.285826  4.168054\n",
      "202    14.0   4.150390  3.285826  4.168054\n",
      "442     1.0   3.225976  3.285826  4.168054\n",
      "157    14.0   8.653929  3.285826  4.168054\n",
      "228     2.0   3.993560  3.285826  4.168054\n",
      "409     2.0   2.137269  3.285826  4.168054\n",
      "299     8.0   5.366047  3.285826  4.168054\n",
      "225     2.0   3.274596  3.285826  4.168054\n",
      "76      1.0   4.320892  3.285826  4.168054\n",
      "454     2.0   7.130054  3.285826  4.168054\n",
      "345     5.0   7.352519  3.285826  4.168054\n",
      "79      0.0   5.234729  3.285826  4.168054\n",
      "335     5.0   8.943169  3.285826  4.168054\n",
      "248    11.0   7.532017  3.285826  4.168054\n",
      "420     4.0   7.931519  3.285826  4.168054\n",
      "213    10.0   4.950638  3.285826  4.168054\n",
      "251     3.0   8.050523  3.285826  4.168054\n",
      "450     3.0   3.173022  3.285826  4.168054\n",
      "0       3.0   2.782144  3.285826  4.168054\n",
      "71      4.0   3.433530  3.285826  4.168054\n",
      "265     4.0   6.092458  3.285826  4.168054\n",
      "439     2.0   4.673434  3.285826  4.168054\n",
      "39      2.0   6.675624  3.285826  4.168054\n",
      "211    11.0   2.946411  3.285826  4.168054\n",
      "308     9.0   3.224995  3.285826  4.168054\n",
      "73     14.0   3.535789  3.285826  4.168054\n",
      "83      1.0   3.852540  3.285826  4.168054\n",
      "128     2.0   1.287002  3.285826  4.168054\n",
      "9       0.0   4.936377  3.285826  4.168054\n",
      "55     14.0   7.531896  3.285826  4.168054\n",
      "234     1.0   3.115802  3.285826  4.168054\n",
      "457     1.0   5.803483  3.285826  4.168054\n",
      "297     6.0   4.224674  3.285826  4.168054\n",
      "383     3.0   3.697616  3.285826  4.168054\n",
      "324     3.0   5.695622  3.285826  4.168054\n",
      "412     1.0   4.838754  3.285826  4.168054\n",
      "252     6.0   5.848775  3.285826  4.168054\n",
      "78      2.0   3.246439  3.285826  4.168054\n",
      "326     6.0   4.611817  3.285826  4.168054\n",
      "432     2.0   4.811421  3.285826  4.168054\n",
      "393     4.0   4.906360  3.285826  4.168054\n",
      "171     2.0   7.711598  3.285826  4.168054\n",
      "80      3.0   6.506543  3.285826  4.168054\n",
      "277     4.0   7.206227  3.285826  4.168054\n",
      "440     3.0   1.438177  3.285826  4.168054\n",
      "77     13.0   3.710272  3.285826  4.168054\n",
      "240     4.0   7.129112  3.285826  4.168054\n",
      "428     1.0   6.698220  3.285826  4.168054\n",
      "74      9.0   8.750556  3.285826  4.168054\n",
      "143    10.0   4.499733  3.285826  4.168054\n",
      "94     14.0   4.072971  3.285826  4.168054\n",
      "437     2.0   3.006682  3.285826  4.168054\n",
      "436     5.0   5.744262  3.285826  4.168054\n",
      "33     13.0   4.503138  3.285826  4.168054\n",
      "212     0.0   4.395550  3.285826  4.168054\n",
      "321     5.0   4.410181  3.285826  4.168054\n",
      "405     3.0   4.603225  3.285826  4.168054\n",
      "140    13.0   7.800350  3.285826  4.168054\n",
      "11      1.0   8.104002  3.285826  4.168054\n",
      "407     3.0   5.032389  3.285826  4.168054\n",
      "15     12.0   3.629115  3.285826  4.168054\n",
      "176     4.0   2.914619  3.285826  4.168054\n",
      "280     1.0   3.327631  3.285826  4.168054\n",
      "359     3.0   3.466308  3.285826  4.168054\n",
      "19      3.0   1.970217  3.285826  4.168054\n",
      "374     2.0   3.047278  3.285826  4.168054\n",
      "307     3.0   7.295564  3.285826  4.168054\n",
      "56      1.0   3.568593  3.285826  4.168054\n",
      "196    13.0   9.026043  3.285826  4.168054\n",
      "389     4.0   6.422472  3.285826  4.168054\n",
      "379     2.0   2.979268  3.285826  4.168054\n",
      "91     15.0   7.762022  3.285826  4.168054\n",
      "115     9.0   6.747338  3.285826  4.168054\n",
      "394     0.0   5.404643  3.285826  4.168054\n",
      "25      4.0   3.936150  3.285826  4.168054\n",
      "198     2.0   3.801639  3.285826  4.168054\n",
      "207    13.0   8.951324  3.285826  4.168054\n",
      "434     3.0   2.790210  3.285826  4.168054\n",
      "42      5.0   6.533206  3.285826  4.168054\n",
      "184     6.0   8.128494  3.285826  4.168054\n",
      "448     5.0   4.272739  3.285826  4.168054\n",
      "453     1.0   2.926818  3.285826  4.168054\n",
      "364     6.0   6.985995  3.285826  4.168054\n",
      "271    11.0   5.923851  3.285826  4.168054\n",
      "300     2.0   5.289140  3.285826  4.168054\n",
      "22      3.0   6.489629  3.285826  4.168054\n",
      "302     2.0   3.867880  3.285826  4.168054\n",
      "46      4.0   4.850061  3.285826  4.168054\n",
      "102    12.0   4.516947  3.285826  4.168054\n",
      "418     3.0   4.051148  3.285826  4.168054\n",
      "160     4.0   4.532516  3.285826  4.168054\n",
      "126    15.0  10.979220  2.987132  3.985555\n",
      "30     11.0   9.767439  2.987132  3.985555\n",
      "202    14.0   4.133509  2.987132  3.985555\n",
      "442     1.0   3.114292  2.987132  3.985555\n",
      "157    14.0   7.666013  2.987132  3.985555\n",
      "228     2.0   2.579435  2.987132  3.985555\n",
      "409     2.0   3.326849  2.987132  3.985555\n",
      "299     8.0   6.451478  2.987132  3.985555\n",
      "225     2.0   1.946984  2.987132  3.985555\n",
      "76      1.0   1.998028  2.987132  3.985555\n",
      "454     2.0   5.928172  2.987132  3.985555\n",
      "345     5.0   7.970734  2.987132  3.985555\n",
      "79      0.0   3.367635  2.987132  3.985555\n",
      "335     5.0   8.636616  2.987132  3.985555\n",
      "248    11.0   8.258193  2.987132  3.985555\n",
      "420     4.0   4.315649  2.987132  3.985555\n",
      "213    10.0   7.269636  2.987132  3.985555\n",
      "251     3.0   3.295280  2.987132  3.985555\n",
      "450     3.0   1.999160  2.987132  3.985555\n",
      "0       3.0   4.198649  2.987132  3.985555\n",
      "71      4.0   2.780033  2.987132  3.985555\n",
      "265     4.0   7.226733  2.987132  3.985555\n",
      "439     2.0   6.358775  2.987132  3.985555\n",
      "39      2.0   5.159955  2.987132  3.985555\n",
      "211    11.0   2.162674  2.987132  3.985555\n",
      "308     9.0   5.501107  2.987132  3.985555\n",
      "73     14.0   2.188986  2.987132  3.985555\n",
      "83      1.0   4.159721  2.987132  3.985555\n",
      "128     2.0   2.473926  2.987132  3.985555\n",
      "9       0.0   2.937172  2.987132  3.985555\n",
      "55     14.0  10.457077  2.987132  3.985555\n",
      "234     1.0   2.968965  2.987132  3.985555\n",
      "457     1.0   6.429297  2.987132  3.985555\n",
      "297     6.0   4.204697  2.987132  3.985555\n",
      "383     3.0   4.670909  2.987132  3.985555\n",
      "324     3.0   4.018010  2.987132  3.985555\n",
      "412     1.0   3.744964  2.987132  3.985555\n",
      "252     6.0   4.574011  2.987132  3.985555\n",
      "78      2.0   2.459800  2.987132  3.985555\n",
      "326     6.0   8.216084  2.987132  3.985555\n",
      "432     2.0   5.777266  2.987132  3.985555\n",
      "393     4.0   3.068501  2.987132  3.985555\n",
      "171     2.0   4.650969  2.987132  3.985555\n",
      "80      3.0   4.899254  2.987132  3.985555\n",
      "277     4.0   7.131853  2.987132  3.985555\n",
      "440     3.0   3.318510  2.987132  3.985555\n",
      "77     13.0   4.397781  2.987132  3.985555\n",
      "240     4.0   9.094140  2.987132  3.985555\n",
      "428     1.0   1.889902  2.987132  3.985555\n",
      "74      9.0   9.127042  2.987132  3.985555\n",
      "143    10.0   7.530729  2.987132  3.985555\n",
      "94     14.0   3.863271  2.987132  3.985555\n",
      "437     2.0   2.479391  2.987132  3.985555\n",
      "436     5.0   4.620448  2.987132  3.985555\n",
      "33     13.0   7.511676  2.987132  3.985555\n",
      "212     0.0   4.305972  2.987132  3.985555\n",
      "321     5.0   6.401235  2.987132  3.985555\n",
      "405     3.0   2.693704  2.987132  3.985555\n",
      "140    13.0   7.927047  2.987132  3.985555\n",
      "11      1.0   8.197155  2.987132  3.985555\n",
      "407     3.0   2.318102  2.987132  3.985555\n",
      "15     12.0   5.004159  2.987132  3.985555\n",
      "176     4.0   3.817115  2.987132  3.985555\n",
      "280     1.0   2.255878  2.987132  3.985555\n",
      "359     3.0   3.094158  2.987132  3.985555\n",
      "19      3.0   1.282920  2.987132  3.985555\n",
      "374     2.0   2.808860  2.987132  3.985555\n",
      "307     3.0  11.165117  2.987132  3.985555\n",
      "56      1.0   1.668748  2.987132  3.985555\n",
      "196    13.0   8.327341  2.987132  3.985555\n",
      "389     4.0   4.771742  2.987132  3.985555\n",
      "379     2.0   4.171556  2.987132  3.985555\n",
      "91     15.0  10.738306  2.987132  3.985555\n",
      "115     9.0   6.772080  2.987132  3.985555\n",
      "394     0.0   3.244708  2.987132  3.985555\n",
      "25      4.0   4.532924  2.987132  3.985555\n",
      "198     2.0   2.604945  2.987132  3.985555\n",
      "207    13.0   8.379181  2.987132  3.985555\n",
      "434     3.0   1.866813  2.987132  3.985555\n",
      "42      5.0   3.205945  2.987132  3.985555\n",
      "184     6.0  14.752697  2.987132  3.985555\n",
      "448     5.0   4.107853  2.987132  3.985555\n",
      "453     1.0   2.827457  2.987132  3.985555\n",
      "364     6.0   9.943038  2.987132  3.985555\n",
      "271    11.0   5.543992  2.987132  3.985555\n",
      "300     2.0   6.430335  2.987132  3.985555\n",
      "22      3.0  10.142010  2.987132  3.985555\n",
      "302     2.0   3.634988  2.987132  3.985555\n",
      "46      4.0   3.858516  2.987132  3.985555\n",
      "102    12.0   3.311697  2.987132  3.985555\n",
      "418     3.0   5.914443  2.987132  3.985555\n",
      "160     4.0   6.511558  2.987132  3.985555\n",
      "126    15.0   9.532286  3.247394  3.997840\n",
      "30     11.0   8.141636  3.247394  3.997840\n",
      "202    14.0   5.490364  3.247394  3.997840\n",
      "442     1.0   4.852608  3.247394  3.997840\n",
      "157    14.0   8.279752  3.247394  3.997840\n",
      "228     2.0   4.836405  3.247394  3.997840\n",
      "409     2.0   2.895582  3.247394  3.997840\n",
      "299     8.0   5.495002  3.247394  3.997840\n",
      "225     2.0   3.885589  3.247394  3.997840\n",
      "76      1.0   3.876650  3.247394  3.997840\n",
      "454     2.0   6.612303  3.247394  3.997840\n",
      "345     5.0   7.605100  3.247394  3.997840\n",
      "79      0.0   5.483473  3.247394  3.997840\n",
      "335     5.0   7.390762  3.247394  3.997840\n",
      "248    11.0   7.029917  3.247394  3.997840\n",
      "420     4.0   5.815544  3.247394  3.997840\n",
      "213    10.0   5.773100  3.247394  3.997840\n",
      "251     3.0   6.183202  3.247394  3.997840\n",
      "450     3.0   1.616828  3.247394  3.997840\n",
      "0       3.0   4.559825  3.247394  3.997840\n",
      "71      4.0   3.022016  3.247394  3.997840\n",
      "265     4.0   5.063479  3.247394  3.997840\n",
      "439     2.0   5.853342  3.247394  3.997840\n",
      "39      2.0   6.586060  3.247394  3.997840\n",
      "211    11.0   2.126578  3.247394  3.997840\n",
      "308     9.0   4.849251  3.247394  3.997840\n",
      "73     14.0   3.361917  3.247394  3.997840\n",
      "83      1.0   3.853927  3.247394  3.997840\n",
      "128     2.0   2.246831  3.247394  3.997840\n",
      "9       0.0   6.116936  3.247394  3.997840\n",
      "55     14.0   7.700751  3.247394  3.997840\n",
      "234     1.0   3.599271  3.247394  3.997840\n",
      "457     1.0   6.931706  3.247394  3.997840\n",
      "297     6.0   3.988216  3.247394  3.997840\n",
      "383     3.0   3.673744  3.247394  3.997840\n",
      "324     3.0   4.597778  3.247394  3.997840\n",
      "412     1.0   4.019761  3.247394  3.997840\n",
      "252     6.0   5.300118  3.247394  3.997840\n",
      "78      2.0   3.031025  3.247394  3.997840\n",
      "326     6.0   5.692058  3.247394  3.997840\n",
      "432     2.0   4.655444  3.247394  3.997840\n",
      "393     4.0   5.275569  3.247394  3.997840\n",
      "171     2.0   6.881691  3.247394  3.997840\n",
      "80      3.0   4.956266  3.247394  3.997840\n",
      "277     4.0   6.545572  3.247394  3.997840\n",
      "440     3.0   1.876990  3.247394  3.997840\n",
      "77     13.0   4.040009  3.247394  3.997840\n",
      "240     4.0   8.166750  3.247394  3.997840\n",
      "428     1.0   4.118815  3.247394  3.997840\n",
      "74      9.0   8.515941  3.247394  3.997840\n",
      "143    10.0   6.282806  3.247394  3.997840\n",
      "94     14.0   4.660373  3.247394  3.997840\n",
      "437     2.0   4.563252  3.247394  3.997840\n",
      "436     5.0   6.091894  3.247394  3.997840\n",
      "33     13.0   4.476107  3.247394  3.997840\n",
      "212     0.0   5.282486  3.247394  3.997840\n",
      "321     5.0   4.867399  3.247394  3.997840\n",
      "405     3.0   5.565945  3.247394  3.997840\n",
      "140    13.0   8.790718  3.247394  3.997840\n",
      "11      1.0   7.476542  3.247394  3.997840\n",
      "407     3.0   5.107857  3.247394  3.997840\n",
      "15     12.0   4.779654  3.247394  3.997840\n",
      "176     4.0   3.336726  3.247394  3.997840\n",
      "280     1.0   2.901180  3.247394  3.997840\n",
      "359     3.0   4.157767  3.247394  3.997840\n",
      "19      3.0   0.000000  3.247394  3.997840\n",
      "374     2.0   2.234269  3.247394  3.997840\n",
      "307     3.0   7.788123  3.247394  3.997840\n",
      "56      1.0   2.527972  3.247394  3.997840\n",
      "196    13.0   9.372374  3.247394  3.997840\n",
      "389     4.0   6.242741  3.247394  3.997840\n",
      "379     2.0   3.797254  3.247394  3.997840\n",
      "91     15.0   9.093215  3.247394  3.997840\n",
      "115     9.0   5.540254  3.247394  3.997840\n",
      "394     0.0   5.034819  3.247394  3.997840\n",
      "25      4.0   5.443799  3.247394  3.997840\n",
      "198     2.0   4.417215  3.247394  3.997840\n",
      "207    13.0   9.491982  3.247394  3.997840\n",
      "434     3.0   2.399271  3.247394  3.997840\n",
      "42      5.0   4.924190  3.247394  3.997840\n",
      "184     6.0  10.008562  3.247394  3.997840\n",
      "448     5.0   4.283426  3.247394  3.997840\n",
      "453     1.0   3.694017  3.247394  3.997840\n",
      "364     6.0   7.226076  3.247394  3.997840\n",
      "271    11.0   5.643867  3.247394  3.997840\n",
      "300     2.0   6.192038  3.247394  3.997840\n",
      "22      3.0   6.729823  3.247394  3.997840\n",
      "302     2.0   3.403605  3.247394  3.997840\n",
      "46      4.0   4.895352  3.247394  3.997840\n",
      "102    12.0   5.369957  3.247394  3.997840\n",
      "418     3.0   4.739354  3.247394  3.997840\n",
      "160     4.0   6.212300  3.247394  3.997840\n",
      "126    15.0   8.854457  2.857089  3.927252\n",
      "30     11.0   7.447724  2.857089  3.927252\n",
      "202    14.0   3.479959  2.857089  3.927252\n",
      "442     1.0   2.311621  2.857089  3.927252\n",
      "157    14.0   6.069250  2.857089  3.927252\n",
      "228     2.0   2.582232  2.857089  3.927252\n",
      "409     2.0   2.631558  2.857089  3.927252\n",
      "299     8.0   7.423699  2.857089  3.927252\n",
      "225     2.0   2.877634  2.857089  3.927252\n",
      "76      1.0   2.283141  2.857089  3.927252\n",
      "454     2.0   4.802795  2.857089  3.927252\n",
      "345     5.0   7.201810  2.857089  3.927252\n",
      "79      0.0   2.553322  2.857089  3.927252\n",
      "335     5.0   6.943321  2.857089  3.927252\n",
      "248    11.0   7.867450  2.857089  3.927252\n",
      "420     4.0   3.128192  2.857089  3.927252\n",
      "213    10.0   6.358641  2.857089  3.927252\n",
      "251     3.0   3.120468  2.857089  3.927252\n",
      "450     3.0   2.679676  2.857089  3.927252\n",
      "0       3.0   3.727658  2.857089  3.927252\n",
      "71      4.0   2.459544  2.857089  3.927252\n",
      "265     4.0   5.530277  2.857089  3.927252\n",
      "439     2.0   5.406103  2.857089  3.927252\n",
      "39      2.0   4.459424  2.857089  3.927252\n",
      "211    11.0   2.080103  2.857089  3.927252\n",
      "308     9.0   4.170336  2.857089  3.927252\n",
      "73     14.0   1.626133  2.857089  3.927252\n",
      "83      1.0   3.346838  2.857089  3.927252\n",
      "128     2.0   1.814298  2.857089  3.927252\n",
      "9       0.0   2.012697  2.857089  3.927252\n",
      "55     14.0   8.393943  2.857089  3.927252\n",
      "234     1.0   4.062727  2.857089  3.927252\n",
      "457     1.0   6.248081  2.857089  3.927252\n",
      "297     6.0   3.247062  2.857089  3.927252\n",
      "383     3.0   3.383029  2.857089  3.927252\n",
      "324     3.0   3.549252  2.857089  3.927252\n",
      "412     1.0   2.669788  2.857089  3.927252\n",
      "252     6.0   4.126616  2.857089  3.927252\n",
      "78      2.0   3.029133  2.857089  3.927252\n",
      "326     6.0   6.264555  2.857089  3.927252\n",
      "432     2.0   5.026989  2.857089  3.927252\n",
      "393     4.0   3.296979  2.857089  3.927252\n",
      "171     2.0   5.808314  2.857089  3.927252\n",
      "80      3.0   3.834082  2.857089  3.927252\n",
      "277     4.0   5.697604  2.857089  3.927252\n",
      "440     3.0   1.971886  2.857089  3.927252\n",
      "77     13.0   4.912338  2.857089  3.927252\n",
      "240     4.0   8.207528  2.857089  3.927252\n",
      "428     1.0   1.842723  2.857089  3.927252\n",
      "74      9.0   6.765629  2.857089  3.927252\n",
      "143    10.0   6.870622  2.857089  3.927252\n",
      "94     14.0   3.965033  2.857089  3.927252\n",
      "437     2.0   2.126383  2.857089  3.927252\n",
      "436     5.0   3.516204  2.857089  3.927252\n",
      "33     13.0   7.367968  2.857089  3.927252\n",
      "212     0.0   3.363996  2.857089  3.927252\n",
      "321     5.0   4.822145  2.857089  3.927252\n",
      "405     3.0   2.652004  2.857089  3.927252\n",
      "140    13.0   7.242611  2.857089  3.927252\n",
      "11      1.0   6.625287  2.857089  3.927252\n",
      "407     3.0   1.288830  2.857089  3.927252\n",
      "15     12.0   3.610669  2.857089  3.927252\n",
      "176     4.0   2.750916  2.857089  3.927252\n",
      "280     1.0   2.738162  2.857089  3.927252\n",
      "359     3.0   2.813609  2.857089  3.927252\n",
      "19      3.0   1.366101  2.857089  3.927252\n",
      "374     2.0   2.305470  2.857089  3.927252\n",
      "307     3.0   7.736834  2.857089  3.927252\n",
      "56      1.0   1.497070  2.857089  3.927252\n",
      "196    13.0   6.609715  2.857089  3.927252\n",
      "389     4.0   4.923429  2.857089  3.927252\n",
      "379     2.0   3.047279  2.857089  3.927252\n",
      "91     15.0   9.861583  2.857089  3.927252\n",
      "115     9.0   6.325584  2.857089  3.927252\n",
      "394     0.0   3.076223  2.857089  3.927252\n",
      "25      4.0   4.532740  2.857089  3.927252\n",
      "198     2.0   2.600657  2.857089  3.927252\n",
      "207    13.0   7.682187  2.857089  3.927252\n",
      "434     3.0   2.118820  2.857089  3.927252\n",
      "42      5.0   3.680598  2.857089  3.927252\n",
      "184     6.0  12.448997  2.857089  3.927252\n",
      "448     5.0   4.271937  2.857089  3.927252\n",
      "453     1.0   2.389870  2.857089  3.927252\n",
      "364     6.0   7.152587  2.857089  3.927252\n",
      "271    11.0   3.772373  2.857089  3.927252\n",
      "300     2.0   5.484013  2.857089  3.927252\n",
      "22      3.0   6.719479  2.857089  3.927252\n",
      "302     2.0   4.180332  2.857089  3.927252\n",
      "46      4.0   3.721756  2.857089  3.927252\n",
      "102    12.0   3.152976  2.857089  3.927252\n",
      "418     3.0   4.699808  2.857089  3.927252\n",
      "160     4.0   5.427063  2.857089  3.927252\n",
      "126    15.0   8.204784  3.287500  4.063774\n",
      "30     11.0   6.966796  3.287500  4.063774\n",
      "202    14.0   4.858162  3.287500  4.063774\n",
      "442     1.0   4.276169  3.287500  4.063774\n",
      "157    14.0   6.664636  3.287500  4.063774\n",
      "228     2.0   5.184073  3.287500  4.063774\n",
      "409     2.0   3.079453  3.287500  4.063774\n",
      "299     8.0   4.798572  3.287500  4.063774\n",
      "225     2.0   3.802566  3.287500  4.063774\n",
      "76      1.0   4.765853  3.287500  4.063774\n",
      "454     2.0   6.411589  3.287500  4.063774\n",
      "345     5.0   6.119800  3.287500  4.063774\n",
      "79      0.0   5.019622  3.287500  4.063774\n",
      "335     5.0   7.943574  3.287500  4.063774\n",
      "248    11.0   6.476205  3.287500  4.063774\n",
      "420     4.0   5.693768  3.287500  4.063774\n",
      "213    10.0   6.896983  3.287500  4.063774\n",
      "251     3.0   6.546000  3.287500  4.063774\n",
      "450     3.0   2.000315  3.287500  4.063774\n",
      "0       3.0   4.614326  3.287500  4.063774\n",
      "71      4.0   3.891593  3.287500  4.063774\n",
      "265     4.0   4.526430  3.287500  4.063774\n",
      "439     2.0   5.590849  3.287500  4.063774\n",
      "39      2.0   5.381114  3.287500  4.063774\n",
      "211    11.0   2.534054  3.287500  4.063774\n",
      "308     9.0   3.475082  3.287500  4.063774\n",
      "73     14.0   3.134856  3.287500  4.063774\n",
      "83      1.0   3.683204  3.287500  4.063774\n",
      "128     2.0   2.167974  3.287500  4.063774\n",
      "9       0.0   5.398950  3.287500  4.063774\n",
      "55     14.0   6.593198  3.287500  4.063774\n",
      "234     1.0   3.005272  3.287500  4.063774\n",
      "457     1.0   6.018919  3.287500  4.063774\n",
      "297     6.0   5.126370  3.287500  4.063774\n",
      "383     3.0   4.236705  3.287500  4.063774\n",
      "324     3.0   5.489875  3.287500  4.063774\n",
      "412     1.0   3.993746  3.287500  4.063774\n",
      "252     6.0   5.414933  3.287500  4.063774\n",
      "78      2.0   3.257169  3.287500  4.063774\n",
      "326     6.0   4.470315  3.287500  4.063774\n",
      "432     2.0   4.131824  3.287500  4.063774\n",
      "393     4.0   6.053391  3.287500  4.063774\n",
      "171     2.0   7.010286  3.287500  4.063774\n",
      "80      3.0   5.627409  3.287500  4.063774\n",
      "277     4.0   6.225453  3.287500  4.063774\n",
      "440     3.0   0.377843  3.287500  4.063774\n",
      "77     13.0   4.301951  3.287500  4.063774\n",
      "240     4.0   7.197429  3.287500  4.063774\n",
      "428     1.0   4.043983  3.287500  4.063774\n",
      "74      9.0   8.238000  3.287500  4.063774\n",
      "143    10.0   6.252686  3.287500  4.063774\n",
      "94     14.0   4.771119  3.287500  4.063774\n",
      "437     2.0   4.348509  3.287500  4.063774\n",
      "436     5.0   5.192401  3.287500  4.063774\n",
      "33     13.0   4.989021  3.287500  4.063774\n",
      "212     0.0   4.998587  3.287500  4.063774\n",
      "321     5.0   4.977159  3.287500  4.063774\n",
      "405     3.0   5.654868  3.287500  4.063774\n",
      "140    13.0   8.325908  3.287500  4.063774\n",
      "11      1.0   6.719127  3.287500  4.063774\n",
      "407     3.0   4.275437  3.287500  4.063774\n",
      "15     12.0   4.668908  3.287500  4.063774\n",
      "176     4.0   3.716260  3.287500  4.063774\n",
      "280     1.0   3.805441  3.287500  4.063774\n",
      "359     3.0   4.900190  3.287500  4.063774\n",
      "19      3.0   0.055591  3.287500  4.063774\n",
      "374     2.0   2.817465  3.287500  4.063774\n",
      "307     3.0   6.992483  3.287500  4.063774\n",
      "56      1.0   2.389264  3.287500  4.063774\n",
      "196    13.0   8.076784  3.287500  4.063774\n",
      "389     4.0   5.581581  3.287500  4.063774\n",
      "379     2.0   4.137077  3.287500  4.063774\n",
      "91     15.0   7.539961  3.287500  4.063774\n",
      "115     9.0   5.186495  3.287500  4.063774\n",
      "394     0.0   5.441266  3.287500  4.063774\n",
      "25      4.0   5.748169  3.287500  4.063774\n",
      "198     2.0   4.316258  3.287500  4.063774\n",
      "207    13.0   8.976430  3.287500  4.063774\n",
      "434     3.0   3.363688  3.287500  4.063774\n",
      "42      5.0   6.050315  3.287500  4.063774\n",
      "184     6.0   8.995055  3.287500  4.063774\n",
      "448     5.0   4.219359  3.287500  4.063774\n",
      "453     1.0   4.001761  3.287500  4.063774\n",
      "364     6.0   5.986362  3.287500  4.063774\n",
      "271    11.0   5.627246  3.287500  4.063774\n",
      "300     2.0   5.160686  3.287500  4.063774\n",
      "22      3.0   6.629838  3.287500  4.063774\n",
      "302     2.0   3.572091  3.287500  4.063774\n",
      "46      4.0   5.952709  3.287500  4.063774\n",
      "102    12.0   5.595736  3.287500  4.063774\n",
      "418     3.0   4.052766  3.287500  4.063774\n",
      "160     4.0   6.245821  3.287500  4.063774\n",
      "126    15.0   9.231750  3.050616  4.298826\n",
      "30     11.0   7.788892  3.050616  4.298826\n",
      "202    14.0   2.853427  3.050616  4.298826\n",
      "442     1.0   2.828551  3.050616  4.298826\n",
      "157    14.0   6.083880  3.050616  4.298826\n",
      "228     2.0   5.459181  3.050616  4.298826\n",
      "409     2.0   1.498644  3.050616  4.298826\n",
      "299     8.0   4.081149  3.050616  4.298826\n",
      "225     2.0   1.640456  3.050616  4.298826\n",
      "76      1.0   1.849887  3.050616  4.298826\n",
      "454     2.0   4.165485  3.050616  4.298826\n",
      "345     5.0   5.035707  3.050616  4.298826\n",
      "79      0.0   3.651632  3.050616  4.298826\n",
      "335     5.0   5.163136  3.050616  4.298826\n",
      "248    11.0   2.064674  3.050616  4.298826\n",
      "420     4.0   7.253488  3.050616  4.298826\n",
      "213    10.0   5.058981  3.050616  4.298826\n",
      "251     3.0   2.385988  3.050616  4.298826\n",
      "450     3.0   1.859076  3.050616  4.298826\n",
      "0       3.0   2.913953  3.050616  4.298826\n",
      "71      4.0   2.167755  3.050616  4.298826\n",
      "265     4.0   4.308873  3.050616  4.298826\n",
      "439     2.0   4.553043  3.050616  4.298826\n",
      "39      2.0   4.203637  3.050616  4.298826\n",
      "211    11.0   2.760987  3.050616  4.298826\n",
      "308     9.0   3.837637  3.050616  4.298826\n",
      "73     14.0   2.945971  3.050616  4.298826\n",
      "83      1.0   1.700173  3.050616  4.298826\n",
      "128     2.0   1.530350  3.050616  4.298826\n",
      "9       0.0   2.349267  3.050616  4.298826\n",
      "55     14.0   7.972990  3.050616  4.298826\n",
      "234     1.0   1.631271  3.050616  4.298826\n",
      "457     1.0   3.504375  3.050616  4.298826\n",
      "297     6.0   3.143942  3.050616  4.298826\n",
      "383     3.0   4.223809  3.050616  4.298826\n",
      "324     3.0   3.940641  3.050616  4.298826\n",
      "412     1.0   4.535413  3.050616  4.298826\n",
      "252     6.0   4.954984  3.050616  4.298826\n",
      "78      2.0   2.238168  3.050616  4.298826\n",
      "326     6.0   5.707194  3.050616  4.298826\n",
      "432     2.0   4.311073  3.050616  4.298826\n",
      "393     4.0   3.679671  3.050616  4.298826\n",
      "171     2.0   3.651506  3.050616  4.298826\n",
      "80      3.0   2.523885  3.050616  4.298826\n",
      "277     4.0   3.880761  3.050616  4.298826\n",
      "440     3.0   1.712244  3.050616  4.298826\n",
      "77     13.0   1.781991  3.050616  4.298826\n",
      "240     4.0   8.270053  3.050616  4.298826\n",
      "428     1.0   1.602649  3.050616  4.298826\n",
      "74      9.0   9.590065  3.050616  4.298826\n",
      "143    10.0   6.329834  3.050616  4.298826\n",
      "94     14.0   1.923765  3.050616  4.298826\n",
      "437     2.0   1.498644  3.050616  4.298826\n",
      "436     5.0   3.103076  3.050616  4.298826\n",
      "33     13.0   4.336403  3.050616  4.298826\n",
      "212     0.0   4.423629  3.050616  4.298826\n",
      "321     5.0   3.040882  3.050616  4.298826\n",
      "405     3.0   1.806908  3.050616  4.298826\n",
      "140    13.0   4.153634  3.050616  4.298826\n",
      "11      1.0   6.059327  3.050616  4.298826\n",
      "407     3.0   5.083230  3.050616  4.298826\n",
      "15     12.0   2.462327  3.050616  4.298826\n",
      "176     4.0   2.513187  3.050616  4.298826\n",
      "280     1.0   2.575160  3.050616  4.298826\n",
      "359     3.0   5.418658  3.050616  4.298826\n",
      "19      3.0   1.850035  3.050616  4.298826\n",
      "374     2.0   1.823317  3.050616  4.298826\n",
      "307     3.0   4.565077  3.050616  4.298826\n",
      "56      1.0   2.614765  3.050616  4.298826\n",
      "196    13.0   8.406619  3.050616  4.298826\n",
      "389     4.0   1.539863  3.050616  4.298826\n",
      "379     2.0   2.032696  3.050616  4.298826\n",
      "91     15.0  11.532946  3.050616  4.298826\n",
      "115     9.0   2.200518  3.050616  4.298826\n",
      "394     0.0   2.113856  3.050616  4.298826\n",
      "25      4.0   3.231298  3.050616  4.298826\n",
      "198     2.0   1.751467  3.050616  4.298826\n",
      "207    13.0   9.464239  3.050616  4.298826\n",
      "434     3.0   1.498644  3.050616  4.298826\n",
      "42      5.0   2.591888  3.050616  4.298826\n",
      "184     6.0   9.409374  3.050616  4.298826\n",
      "448     5.0   2.444976  3.050616  4.298826\n",
      "453     1.0   1.720660  3.050616  4.298826\n",
      "364     6.0   7.380306  3.050616  4.298826\n",
      "271    11.0   3.736259  3.050616  4.298826\n",
      "300     2.0   3.256888  3.050616  4.298826\n",
      "22      3.0   8.370508  3.050616  4.298826\n",
      "302     2.0   2.670115  3.050616  4.298826\n",
      "46      4.0   2.095246  3.050616  4.298826\n",
      "102    12.0   1.584030  3.050616  4.298826\n",
      "418     3.0   3.924319  3.050616  4.298826\n",
      "160     4.0   9.998262  3.050616  4.298826\n",
      "126    15.0   9.282499  3.665239  4.422014\n",
      "30     11.0   7.592354  3.665239  4.422014\n",
      "202    14.0   2.898790  3.665239  4.422014\n",
      "442     1.0   6.661070  3.665239  4.422014\n",
      "157    14.0   9.773168  3.665239  4.422014\n",
      "228     2.0   6.878994  3.665239  4.422014\n",
      "409     2.0   3.293458  3.665239  4.422014\n",
      "299     8.0   4.699785  3.665239  4.422014\n",
      "225     2.0   1.414982  3.665239  4.422014\n",
      "76      1.0   5.415627  3.665239  4.422014\n",
      "454     2.0   5.062814  3.665239  4.422014\n",
      "345     5.0   7.975543  3.665239  4.422014\n",
      "79      0.0   3.935771  3.665239  4.422014\n",
      "335     5.0  10.554406  3.665239  4.422014\n",
      "248    11.0   6.944872  3.665239  4.422014\n",
      "420     4.0   6.345488  3.665239  4.422014\n",
      "213    10.0   6.784470  3.665239  4.422014\n",
      "251     3.0   6.579315  3.665239  4.422014\n",
      "450     3.0   2.028900  3.665239  4.422014\n",
      "0       3.0   5.239896  3.665239  4.422014\n",
      "71      4.0   1.874012  3.665239  4.422014\n",
      "265     4.0   6.318836  3.665239  4.422014\n",
      "439     2.0   4.138430  3.665239  4.422014\n",
      "39      2.0   5.822859  3.665239  4.422014\n",
      "211    11.0   2.548616  3.665239  4.422014\n",
      "308     9.0   7.407372  3.665239  4.422014\n",
      "73     14.0   3.296324  3.665239  4.422014\n",
      "83      1.0   5.410896  3.665239  4.422014\n",
      "128     2.0   2.826536  3.665239  4.422014\n",
      "9       0.0   7.414082  3.665239  4.422014\n",
      "55     14.0   7.651760  3.665239  4.422014\n",
      "234     1.0   4.042433  3.665239  4.422014\n",
      "457     1.0   4.523481  3.665239  4.422014\n",
      "297     6.0   2.889390  3.665239  4.422014\n",
      "383     3.0   4.313784  3.665239  4.422014\n",
      "324     3.0   4.216361  3.665239  4.422014\n",
      "412     1.0   4.128332  3.665239  4.422014\n",
      "252     6.0   8.397176  3.665239  4.422014\n",
      "78      2.0   1.563256  3.665239  4.422014\n",
      "326     6.0   7.700716  3.665239  4.422014\n",
      "432     2.0   6.899926  3.665239  4.422014\n",
      "393     4.0   4.278278  3.665239  4.422014\n",
      "171     2.0   7.093081  3.665239  4.422014\n",
      "80      3.0   6.725641  3.665239  4.422014\n",
      "277     4.0  10.077876  3.665239  4.422014\n",
      "440     3.0   2.055143  3.665239  4.422014\n",
      "77     13.0   4.878226  3.665239  4.422014\n",
      "240     4.0   9.300231  3.665239  4.422014\n",
      "428     1.0   7.957715  3.665239  4.422014\n",
      "74      9.0   8.242105  3.665239  4.422014\n",
      "143    10.0   5.720114  3.665239  4.422014\n",
      "94     14.0   4.779396  3.665239  4.422014\n",
      "437     2.0   5.116451  3.665239  4.422014\n",
      "436     5.0   7.488101  3.665239  4.422014\n",
      "33     13.0   4.421134  3.665239  4.422014\n",
      "212     0.0   5.136642  3.665239  4.422014\n",
      "321     5.0   4.362842  3.665239  4.422014\n",
      "405     3.0   6.498473  3.665239  4.422014\n",
      "140    13.0   8.418698  3.665239  4.422014\n",
      "11      1.0   8.175227  3.665239  4.422014\n",
      "407     3.0   6.060352  3.665239  4.422014\n",
      "15     12.0   6.219386  3.665239  4.422014\n",
      "176     4.0   4.078525  3.665239  4.422014\n",
      "280     1.0   2.144413  3.665239  4.422014\n",
      "359     3.0   2.952580  3.665239  4.422014\n",
      "19      3.0   1.171039  3.665239  4.422014\n",
      "374     2.0   2.113820  3.665239  4.422014\n",
      "307     3.0   9.539529  3.665239  4.422014\n",
      "56      1.0   3.942110  3.665239  4.422014\n",
      "196    13.0  11.601472  3.665239  4.422014\n",
      "389     4.0   8.434873  3.665239  4.422014\n",
      "379     2.0   5.185488  3.665239  4.422014\n",
      "91     15.0   8.140311  3.665239  4.422014\n",
      "115     9.0   7.152225  3.665239  4.422014\n",
      "394     0.0   5.084368  3.665239  4.422014\n",
      "25      4.0   5.427758  3.665239  4.422014\n",
      "198     2.0   4.860820  3.665239  4.422014\n",
      "207    13.0   9.827971  3.665239  4.422014\n",
      "434     3.0   2.827078  3.665239  4.422014\n",
      "42      5.0   3.438308  3.665239  4.422014\n",
      "184     6.0   9.192062  3.665239  4.422014\n",
      "448     5.0   3.832405  3.665239  4.422014\n",
      "453     1.0   1.982002  3.665239  4.422014\n",
      "364     6.0  10.394599  3.665239  4.422014\n",
      "271    11.0   5.404705  3.665239  4.422014\n",
      "300     2.0   9.561717  3.665239  4.422014\n",
      "22      3.0   8.073580  3.665239  4.422014\n",
      "302     2.0   4.572647  3.665239  4.422014\n",
      "46      4.0   6.242095  3.665239  4.422014\n",
      "102    12.0   3.437863  3.665239  4.422014\n",
      "418     3.0   4.546185  3.665239  4.422014\n",
      "160     4.0   7.354678  3.665239  4.422014\n",
      "126    15.0   9.742389  2.952623  3.994726\n",
      "30     11.0   8.834796  2.952623  3.994726\n",
      "202    14.0   4.808948  2.952623  3.994726\n",
      "442     1.0   2.884454  2.952623  3.994726\n",
      "157    14.0   7.760238  2.952623  3.994726\n",
      "228     2.0   2.616906  2.952623  3.994726\n",
      "409     2.0   2.298736  2.952623  3.994726\n",
      "299     8.0   5.372723  2.952623  3.994726\n",
      "225     2.0   2.271223  2.952623  3.994726\n",
      "76      1.0   2.230164  2.952623  3.994726\n",
      "454     2.0   3.423119  2.952623  3.994726\n",
      "345     5.0   8.376803  2.952623  3.994726\n",
      "79      0.0   2.859894  2.952623  3.994726\n",
      "335     5.0   9.683517  2.952623  3.994726\n",
      "248    11.0   4.801353  2.952623  3.994726\n",
      "420     4.0   6.902592  2.952623  3.994726\n",
      "213    10.0   8.093100  2.952623  3.994726\n",
      "251     3.0   3.117156  2.952623  3.994726\n",
      "450     3.0   2.271223  2.952623  3.994726\n",
      "0       3.0   3.715651  2.952623  3.994726\n",
      "71      4.0   2.961203  2.952623  3.994726\n",
      "265     4.0   7.220615  2.952623  3.994726\n",
      "439     2.0   4.618381  2.952623  3.994726\n",
      "39      2.0   3.922106  2.952623  3.994726\n",
      "211    11.0   2.396463  2.952623  3.994726\n",
      "308     9.0   3.825918  2.952623  3.994726\n",
      "73     14.0   2.417228  2.952623  3.994726\n",
      "83      1.0   2.504181  2.952623  3.994726\n",
      "128     2.0   2.491193  2.952623  3.994726\n",
      "9       0.0   2.849277  2.952623  3.994726\n",
      "55     14.0   8.459598  2.952623  3.994726\n",
      "234     1.0   3.385152  2.952623  3.994726\n",
      "457     1.0   3.491646  2.952623  3.994726\n",
      "297     6.0   3.188854  2.952623  3.994726\n",
      "383     3.0   3.154224  2.952623  3.994726\n",
      "324     3.0   2.306153  2.952623  3.994726\n",
      "412     1.0   3.020148  2.952623  3.994726\n",
      "252     6.0   5.161937  2.952623  3.994726\n",
      "78      2.0   4.376866  2.952623  3.994726\n",
      "326     6.0   4.833764  2.952623  3.994726\n",
      "432     2.0   3.997039  2.952623  3.994726\n",
      "393     4.0   3.398602  2.952623  3.994726\n",
      "171     2.0   5.480487  2.952623  3.994726\n",
      "80      3.0   3.804615  2.952623  3.994726\n",
      "277     4.0   6.254308  2.952623  3.994726\n",
      "440     3.0   2.271223  2.952623  3.994726\n",
      "77     13.0   3.551751  2.952623  3.994726\n",
      "240     4.0   8.762809  2.952623  3.994726\n",
      "428     1.0   2.397179  2.952623  3.994726\n",
      "74      9.0  12.511315  2.952623  3.994726\n",
      "143    10.0   6.316979  2.952623  3.994726\n",
      "94     14.0   3.443177  2.952623  3.994726\n",
      "437     2.0   2.271223  2.952623  3.994726\n",
      "436     5.0   4.149651  2.952623  3.994726\n",
      "33     13.0   6.661574  2.952623  3.994726\n",
      "212     0.0   2.966525  2.952623  3.994726\n",
      "321     5.0   3.021357  2.952623  3.994726\n",
      "405     3.0   2.406439  2.952623  3.994726\n",
      "140    13.0   8.575774  2.952623  3.994726\n",
      "11      1.0   3.796612  2.952623  3.994726\n",
      "407     3.0   2.855561  2.952623  3.994726\n",
      "15     12.0   3.918271  2.952623  3.994726\n",
      "176     4.0   2.715940  2.952623  3.994726\n",
      "280     1.0   3.056635  2.952623  3.994726\n",
      "359     3.0   3.991168  2.952623  3.994726\n",
      "19      3.0   2.271223  2.952623  3.994726\n",
      "374     2.0   2.677826  2.952623  3.994726\n",
      "307     3.0   5.635753  2.952623  3.994726\n",
      "56      1.0   2.303298  2.952623  3.994726\n",
      "196    13.0   6.962816  2.952623  3.994726\n",
      "389     4.0   2.468003  2.952623  3.994726\n",
      "379     2.0   2.858201  2.952623  3.994726\n",
      "91     15.0  13.282664  2.952623  3.994726\n",
      "115     9.0   3.102746  2.952623  3.994726\n",
      "394     0.0   2.985172  2.952623  3.994726\n",
      "25      4.0   4.009737  2.952623  3.994726\n",
      "198     2.0   2.333193  2.952623  3.994726\n",
      "207    13.0   9.341133  2.952623  3.994726\n",
      "434     3.0   2.653738  2.952623  3.994726\n",
      "42      5.0   2.882790  2.952623  3.994726\n",
      "184     6.0  17.272333  2.952623  3.994726\n",
      "448     5.0   2.271223  2.952623  3.994726\n",
      "453     1.0   3.698002  2.952623  3.994726\n",
      "364     6.0   9.702290  2.952623  3.994726\n",
      "271    11.0   5.523050  2.952623  3.994726\n",
      "300     2.0   5.950312  2.952623  3.994726\n",
      "22      3.0   7.824455  2.952623  3.994726\n",
      "302     2.0   3.499530  2.952623  3.994726\n",
      "46      4.0   3.103442  2.952623  3.994726\n",
      "102    12.0   2.324075  2.952623  3.994726\n",
      "418     3.0   3.487832  2.952623  3.994726\n",
      "160     4.0   7.408575  2.952623  3.994726\n",
      "126    15.0  11.040551  3.189854  4.078272\n",
      "30     11.0   8.800250  3.189854  4.078272\n",
      "202    14.0   4.550959  3.189854  4.078272\n",
      "442     1.0   3.805378  3.189854  4.078272\n",
      "157    14.0   9.708767  3.189854  4.078272\n",
      "228     2.0   5.032805  3.189854  4.078272\n",
      "409     2.0   3.433348  3.189854  4.078272\n",
      "299     8.0   4.998867  3.189854  4.078272\n",
      "225     2.0   3.078528  3.189854  4.078272\n",
      "76      1.0   3.709287  3.189854  4.078272\n",
      "454     2.0   4.949794  3.189854  4.078272\n",
      "345     5.0   7.476753  3.189854  4.078272\n",
      "79      0.0   8.576247  3.189854  4.078272\n",
      "335     5.0   9.327412  3.189854  4.078272\n",
      "248    11.0   5.823680  3.189854  4.078272\n",
      "420     4.0   9.068800  3.189854  4.078272\n",
      "213    10.0   5.375088  3.189854  4.078272\n",
      "251     3.0   6.213615  3.189854  4.078272\n",
      "450     3.0   2.374225  3.189854  4.078272\n",
      "0       3.0   4.399188  3.189854  4.078272\n",
      "71      4.0   2.297820  3.189854  4.078272\n",
      "265     4.0   5.770665  3.189854  4.078272\n",
      "439     2.0   4.027043  3.189854  4.078272\n",
      "39      2.0   5.782141  3.189854  4.078272\n",
      "211    11.0   2.564010  3.189854  4.078272\n",
      "308     9.0   3.520013  3.189854  4.078272\n",
      "73     14.0   4.079327  3.189854  4.078272\n",
      "83      1.0   3.547012  3.189854  4.078272\n",
      "128     2.0   2.027209  3.189854  4.078272\n",
      "9       0.0   5.075920  3.189854  4.078272\n",
      "55     14.0   7.282720  3.189854  4.078272\n",
      "234     1.0   5.110332  3.189854  4.078272\n",
      "457     1.0   5.016265  3.189854  4.078272\n",
      "297     6.0   3.752503  3.189854  4.078272\n",
      "383     3.0   3.629003  3.189854  4.078272\n",
      "324     3.0   3.071153  3.189854  4.078272\n",
      "412     1.0   3.625674  3.189854  4.078272\n",
      "252     6.0   5.525664  3.189854  4.078272\n",
      "78      2.0   1.641983  3.189854  4.078272\n",
      "326     6.0   5.071704  3.189854  4.078272\n",
      "432     2.0   4.677640  3.189854  4.078272\n",
      "393     4.0   4.874230  3.189854  4.078272\n",
      "171     2.0   6.732269  3.189854  4.078272\n",
      "80      3.0   5.168281  3.189854  4.078272\n",
      "277     4.0   9.412157  3.189854  4.078272\n",
      "440     3.0   1.365989  3.189854  4.078272\n",
      "77     13.0   4.249185  3.189854  4.078272\n",
      "240     4.0   7.426407  3.189854  4.078272\n",
      "428     1.0   5.931285  3.189854  4.078272\n",
      "74      9.0   8.874330  3.189854  4.078272\n",
      "143    10.0   4.120445  3.189854  4.078272\n",
      "94     14.0   3.912386  3.189854  4.078272\n",
      "437     2.0   3.377166  3.189854  4.078272\n",
      "436     5.0   7.704910  3.189854  4.078272\n",
      "33     13.0   4.112031  3.189854  4.078272\n",
      "212     0.0   4.711084  3.189854  4.078272\n",
      "321     5.0   5.259316  3.189854  4.078272\n",
      "405     3.0   4.871940  3.189854  4.078272\n",
      "140    13.0  10.041224  3.189854  4.078272\n",
      "11      1.0   7.797959  3.189854  4.078272\n",
      "407     3.0   3.685969  3.189854  4.078272\n",
      "15     12.0   4.117011  3.189854  4.078272\n",
      "176     4.0   4.486329  3.189854  4.078272\n",
      "280     1.0   2.554746  3.189854  4.078272\n",
      "359     3.0   4.073668  3.189854  4.078272\n",
      "19      3.0   1.861421  3.189854  4.078272\n",
      "374     2.0   2.510401  3.189854  4.078272\n",
      "307     3.0   8.041509  3.189854  4.078272\n",
      "56      1.0   3.462864  3.189854  4.078272\n",
      "196    13.0  10.533303  3.189854  4.078272\n",
      "389     4.0   4.895596  3.189854  4.078272\n",
      "379     2.0   3.211669  3.189854  4.078272\n",
      "91     15.0   8.059632  3.189854  4.078272\n",
      "115     9.0   7.561938  3.189854  4.078272\n",
      "394     0.0   5.081878  3.189854  4.078272\n",
      "25      4.0   4.667392  3.189854  4.078272\n",
      "198     2.0   3.727872  3.189854  4.078272\n",
      "207    13.0   9.697218  3.189854  4.078272\n",
      "434     3.0   2.665297  3.189854  4.078272\n",
      "42      5.0   4.847158  3.189854  4.078272\n",
      "184     6.0  10.409203  3.189854  4.078272\n",
      "448     5.0   4.442622  3.189854  4.078272\n",
      "453     1.0   4.887236  3.189854  4.078272\n",
      "364     6.0   7.700372  3.189854  4.078272\n",
      "271    11.0   8.943295  3.189854  4.078272\n",
      "300     2.0   5.272356  3.189854  4.078272\n",
      "22      3.0   8.255118  3.189854  4.078272\n",
      "302     2.0   2.737769  3.189854  4.078272\n",
      "46      4.0   3.553093  3.189854  4.078272\n",
      "102    12.0   4.704851  3.189854  4.078272\n",
      "418     3.0   3.862870  3.189854  4.078272\n",
      "160     4.0   6.314052  3.189854  4.078272\n",
      "\n",
      "Best Model Parameters:\n",
      "{'n_units': 128, 'learning_rate': 0.001, 'dropout_rate': 0.5, 'activation': 'relu'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.857089383446652, 3.927251699311607)"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6\n",
    "#split\n",
    "#1차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     ]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# # 데이터 준비\n",
    "# X = merged_all_comb_copy_model[feature_columns]\n",
    "# y = merged_all_comb_copy_model[target_column]\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# # 데이터 분할 및 정규화\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 구축 및 컴파일 함수\n",
    "def build_model(n_units, learning_rate, dropout_rate, activation):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(n_units, activation=activation, input_shape=(X_train.shape[1],)),  # 수정: input_shape를 X_train의 특성 수에 맞게 설정\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "n_units_options = [64, 128]\n",
    "learning_rate_options = [0.001, 0.01]\n",
    "dropout_rate_options = [0.3, 0.5]\n",
    "activation_options = ['relu', 'tanh']\n",
    "\n",
    "best_model = None\n",
    "best_mae = float('inf')\n",
    "best_rmse = float('inf')\n",
    "best_model_params = None\n",
    "results_table = pd.DataFrame()\n",
    "\n",
    "# 하이퍼파라미터 실험 및 모델 평가\n",
    "for n_units in n_units_options:\n",
    "    for learning_rate in learning_rate_options:\n",
    "        for dropout_rate in dropout_rate_options:\n",
    "            for activation in activation_options:\n",
    "                model = build_model(n_units, learning_rate, dropout_rate, activation)\n",
    "                model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "                y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "                y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "                # 평가 지표 계산\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "\n",
    "                # 최적 모델 업데이트\n",
    "                if mae + rmse < best_mae + best_rmse:\n",
    "                    best_model = model\n",
    "                    best_mae = mae\n",
    "                    best_rmse = rmse\n",
    "                    best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "                # 결과 추가\n",
    "                temp_results = pd.DataFrame({\n",
    "                    'Actual': y_test,\n",
    "                    'Predicted': y_pred,\n",
    "                    'MAE': mae,\n",
    "                    'RMSE': rmse\n",
    "                })\n",
    "                results_table = pd.concat([results_table, temp_results])\n",
    "\n",
    "# 최적 모델의 결과와 파라미터 출력\n",
    "print(\"Best Model Results:\")\n",
    "print(results_table)\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model_params)\n",
    "\n",
    "# 최적 모델의 결과에서 가장 좋은 MAE와 RMSE 값 찾기\n",
    "best_mae = results_table['MAE'].min()\n",
    "best_rmse = results_table['RMSE'].min()\n",
    "\n",
    "best_mae, best_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "7a03e3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Best Model Results:\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "350     1.0   2.508691  3.228714  4.357641\n",
      "354     3.0   5.975865  3.228714  4.357641\n",
      "428     1.0   2.385356  3.228714  4.357641\n",
      "60      4.0   3.872035  3.228714  4.357641\n",
      "169     0.0   3.884308  3.228714  4.357641\n",
      "33     13.0   9.295695  3.228714  4.357641\n",
      "76      1.0   1.545720  3.228714  4.357641\n",
      "88     13.0   7.276449  3.228714  4.357641\n",
      "278     3.0   1.049098  3.228714  4.357641\n",
      "461     2.0   8.053267  3.228714  4.357641\n",
      "11      1.0   6.957409  3.228714  4.357641\n",
      "431     2.0   3.323273  3.228714  4.357641\n",
      "116     8.0   4.916768  3.228714  4.357641\n",
      "459     4.0   2.563857  3.228714  4.357641\n",
      "458     5.0   4.553110  3.228714  4.357641\n",
      "42      5.0   6.377014  3.228714  4.357641\n",
      "457     1.0   8.261977  3.228714  4.357641\n",
      "416     3.0   2.499314  3.228714  4.357641\n",
      "59      2.0   4.738655  3.228714  4.357641\n",
      "451     2.0   1.330296  3.228714  4.357641\n",
      "427     5.0   6.524454  3.228714  4.357641\n",
      "265     4.0   6.575042  3.228714  4.357641\n",
      "454     2.0   4.206944  3.228714  4.357641\n",
      "196    13.0   6.693534  3.228714  4.357641\n",
      "243     6.0   2.069313  3.228714  4.357641\n",
      "125     4.0   6.987683  3.228714  4.357641\n",
      "402     3.0   2.770791  3.228714  4.357641\n",
      "164     2.0   1.688084  3.228714  4.357641\n",
      "368     2.0   2.634211  3.228714  4.357641\n",
      "84      1.0   2.602744  3.228714  4.357641\n",
      "227    11.0   3.450735  3.228714  4.357641\n",
      "405     3.0   0.993653  3.228714  4.357641\n",
      "157    14.0   7.664242  3.228714  4.357641\n",
      "100    12.0   4.234711  3.228714  4.357641\n",
      "240     4.0  10.590824  3.228714  4.357641\n",
      "220     3.0   3.299664  3.228714  4.357641\n",
      "85      2.0   4.235939  3.228714  4.357641\n",
      "327     3.0   0.556567  3.228714  4.357641\n",
      "268     7.0  11.941770  3.228714  4.357641\n",
      "80      3.0   3.128309  3.228714  4.357641\n",
      "74      9.0   7.957660  3.228714  4.357641\n",
      "36     18.0   4.020925  3.228714  4.357641\n",
      "122     4.0   1.367104  3.228714  4.357641\n",
      "316    10.0   4.929610  3.228714  4.357641\n",
      "77     13.0   3.586475  3.228714  4.357641\n",
      "281     3.0   6.750643  3.228714  4.357641\n",
      "403     2.0  10.281694  3.228714  4.357641\n",
      "17      0.0   8.019648  3.228714  4.357641\n",
      "83      1.0   2.059279  3.228714  4.357641\n",
      "310     2.0   5.784156  3.228714  4.357641\n",
      "0       3.0   4.535769  3.228714  4.357641\n",
      "21     10.0   4.037943  3.228714  4.357641\n",
      "291    10.0   5.525518  3.228714  4.357641\n",
      "433     3.0   3.066942  3.228714  4.357641\n",
      "407     3.0   1.313572  3.228714  4.357641\n",
      "299     8.0   9.099146  3.228714  4.357641\n",
      "82      3.0   3.459883  3.228714  4.357641\n",
      "153     2.0   8.073465  3.228714  4.357641\n",
      "390     9.0   5.932858  3.228714  4.357641\n",
      "438     2.0   5.231325  3.228714  4.357641\n",
      "27      5.0   3.959618  3.228714  4.357641\n",
      "415     3.0   3.439201  3.228714  4.357641\n",
      "184     6.0   9.733509  3.228714  4.357641\n",
      "301    11.0   6.489311  3.228714  4.357641\n",
      "191     4.0   3.681608  3.228714  4.357641\n",
      "386     3.0   3.369895  3.228714  4.357641\n",
      "45     17.0   4.836406  3.228714  4.357641\n",
      "171     2.0   9.068492  3.228714  4.357641\n",
      "361     3.0   4.833316  3.228714  4.357641\n",
      "449     4.0   4.483281  3.228714  4.357641\n",
      "343     3.0   1.531429  3.228714  4.357641\n",
      "302     2.0   1.952485  3.228714  4.357641\n",
      "372     1.0   1.883914  3.228714  4.357641\n",
      "24     11.0   7.786336  3.228714  4.357641\n",
      "49     13.0  10.457519  3.228714  4.357641\n",
      "414     0.0   1.410829  3.228714  4.357641\n",
      "366     4.0   8.290211  3.228714  4.357641\n",
      "97     11.0   2.412540  3.228714  4.357641\n",
      "181     5.0   2.573612  3.228714  4.357641\n",
      "61      8.0   9.851065  3.228714  4.357641\n",
      "139     2.0   1.399593  3.228714  4.357641\n",
      "26     13.0   3.938502  3.228714  4.357641\n",
      "19      3.0   1.384542  3.228714  4.357641\n",
      "70      4.0   5.300601  3.228714  4.357641\n",
      "350     1.0   3.664513  3.324642  4.146797\n",
      "354     3.0   6.117657  3.324642  4.146797\n",
      "428     1.0   5.108795  3.324642  4.146797\n",
      "60      4.0   4.077512  3.324642  4.146797\n",
      "169     0.0   3.365488  3.324642  4.146797\n",
      "33     13.0   6.952908  3.324642  4.146797\n",
      "76      1.0   1.458426  3.324642  4.146797\n",
      "88     13.0   7.634380  3.324642  4.146797\n",
      "278     3.0   0.964796  3.324642  4.146797\n",
      "461     2.0   6.809988  3.324642  4.146797\n",
      "11      1.0   6.443518  3.324642  4.146797\n",
      "431     2.0   3.831178  3.324642  4.146797\n",
      "116     8.0   7.668011  3.324642  4.146797\n",
      "459     4.0   1.585250  3.324642  4.146797\n",
      "458     5.0   2.653655  3.324642  4.146797\n",
      "42      5.0   7.401131  3.324642  4.146797\n",
      "457     1.0   7.750753  3.324642  4.146797\n",
      "416     3.0   2.586582  3.324642  4.146797\n",
      "59      2.0   3.427692  3.324642  4.146797\n",
      "451     2.0   1.150910  3.324642  4.146797\n",
      "427     5.0   6.615849  3.324642  4.146797\n",
      "265     4.0   6.494161  3.324642  4.146797\n",
      "454     2.0   5.492273  3.324642  4.146797\n",
      "196    13.0   8.374901  3.324642  4.146797\n",
      "243     6.0   5.009313  3.324642  4.146797\n",
      "125     4.0   8.116359  3.324642  4.146797\n",
      "402     3.0   3.833998  3.324642  4.146797\n",
      "164     2.0   5.847422  3.324642  4.146797\n",
      "368     2.0   6.671368  3.324642  4.146797\n",
      "84      1.0   5.132045  3.324642  4.146797\n",
      "227    11.0   4.237861  3.324642  4.146797\n",
      "405     3.0   0.328202  3.324642  4.146797\n",
      "157    14.0   8.693749  3.324642  4.146797\n",
      "100    12.0   5.673058  3.324642  4.146797\n",
      "240     4.0   8.456211  3.324642  4.146797\n",
      "220     3.0   4.445054  3.324642  4.146797\n",
      "85      2.0   7.253826  3.324642  4.146797\n",
      "327     3.0   1.665845  3.324642  4.146797\n",
      "268     7.0   9.343498  3.324642  4.146797\n",
      "80      3.0   4.266188  3.324642  4.146797\n",
      "74      9.0   8.698389  3.324642  4.146797\n",
      "36     18.0   4.523555  3.324642  4.146797\n",
      "122     4.0   2.307146  3.324642  4.146797\n",
      "316    10.0   6.197032  3.324642  4.146797\n",
      "77     13.0   2.707611  3.324642  4.146797\n",
      "281     3.0   4.792137  3.324642  4.146797\n",
      "403     2.0   5.653869  3.324642  4.146797\n",
      "17      0.0   7.948659  3.324642  4.146797\n",
      "83      1.0   3.887609  3.324642  4.146797\n",
      "310     2.0   8.407324  3.324642  4.146797\n",
      "0       3.0   5.437313  3.324642  4.146797\n",
      "21     10.0   5.915722  3.324642  4.146797\n",
      "291    10.0   5.214030  3.324642  4.146797\n",
      "433     3.0   4.747746  3.324642  4.146797\n",
      "407     3.0   0.000000  3.324642  4.146797\n",
      "299     8.0   7.744018  3.324642  4.146797\n",
      "82      3.0   5.292251  3.324642  4.146797\n",
      "153     2.0   7.603335  3.324642  4.146797\n",
      "390     9.0   8.482421  3.324642  4.146797\n",
      "438     2.0   6.058074  3.324642  4.146797\n",
      "27      5.0   6.153444  3.324642  4.146797\n",
      "415     3.0   3.302446  3.324642  4.146797\n",
      "184     6.0   9.019705  3.324642  4.146797\n",
      "301    11.0   6.991436  3.324642  4.146797\n",
      "191     4.0   7.826057  3.324642  4.146797\n",
      "386     3.0   5.854891  3.324642  4.146797\n",
      "45     17.0   5.272623  3.324642  4.146797\n",
      "171     2.0   7.266637  3.324642  4.146797\n",
      "361     3.0   6.264103  3.324642  4.146797\n",
      "449     4.0   3.721729  3.324642  4.146797\n",
      "343     3.0   1.182243  3.324642  4.146797\n",
      "302     2.0   0.600435  3.324642  4.146797\n",
      "372     1.0   3.728626  3.324642  4.146797\n",
      "24     11.0   8.398616  3.324642  4.146797\n",
      "49     13.0   8.607985  3.324642  4.146797\n",
      "414     0.0   0.554685  3.324642  4.146797\n",
      "366     4.0   7.777509  3.324642  4.146797\n",
      "97     11.0   4.718917  3.324642  4.146797\n",
      "181     5.0   2.381592  3.324642  4.146797\n",
      "61      8.0   8.757815  3.324642  4.146797\n",
      "139     2.0   1.008792  3.324642  4.146797\n",
      "26     13.0   7.564258  3.324642  4.146797\n",
      "19      3.0   0.199450  3.324642  4.146797\n",
      "70      4.0   6.128219  3.324642  4.146797\n",
      "350     1.0   1.842723  3.172550  4.395085\n",
      "354     3.0   5.579486  3.172550  4.395085\n",
      "428     1.0   2.389920  3.172550  4.395085\n",
      "60      4.0   4.411279  3.172550  4.395085\n",
      "169     0.0   2.210383  3.172550  4.395085\n",
      "33     13.0   6.792767  3.172550  4.395085\n",
      "76      1.0   1.921164  3.172550  4.395085\n",
      "88     13.0   8.167534  3.172550  4.395085\n",
      "278     3.0   1.118729  3.172550  4.395085\n",
      "461     2.0   5.922938  3.172550  4.395085\n",
      "11      1.0   6.302783  3.172550  4.395085\n",
      "431     2.0   3.419111  3.172550  4.395085\n",
      "116     8.0   4.596599  3.172550  4.395085\n",
      "459     4.0   1.939124  3.172550  4.395085\n",
      "458     5.0   5.279096  3.172550  4.395085\n",
      "42      5.0   6.183514  3.172550  4.395085\n",
      "457     1.0   7.031386  3.172550  4.395085\n",
      "416     3.0   1.422846  3.172550  4.395085\n",
      "59      2.0   3.503648  3.172550  4.395085\n",
      "451     2.0   1.480774  3.172550  4.395085\n",
      "427     5.0   5.685429  3.172550  4.395085\n",
      "265     4.0   4.343636  3.172550  4.395085\n",
      "454     2.0   4.580182  3.172550  4.395085\n",
      "196    13.0   6.139082  3.172550  4.395085\n",
      "243     6.0   2.929796  3.172550  4.395085\n",
      "125     4.0   7.300752  3.172550  4.395085\n",
      "402     3.0   3.284561  3.172550  4.395085\n",
      "164     2.0   1.600650  3.172550  4.395085\n",
      "368     2.0   3.154723  3.172550  4.395085\n",
      "84      1.0   2.820500  3.172550  4.395085\n",
      "227    11.0   3.604857  3.172550  4.395085\n",
      "405     3.0   0.911887  3.172550  4.395085\n",
      "157    14.0   7.442215  3.172550  4.395085\n",
      "100    12.0   3.973106  3.172550  4.395085\n",
      "240     4.0   8.829668  3.172550  4.395085\n",
      "220     3.0   2.870654  3.172550  4.395085\n",
      "85      2.0   5.081100  3.172550  4.395085\n",
      "327     3.0   1.109940  3.172550  4.395085\n",
      "268     7.0  12.948632  3.172550  4.395085\n",
      "80      3.0   2.674928  3.172550  4.395085\n",
      "74      9.0   7.710610  3.172550  4.395085\n",
      "36     18.0   3.116325  3.172550  4.395085\n",
      "122     4.0   1.310228  3.172550  4.395085\n",
      "316    10.0   3.785080  3.172550  4.395085\n",
      "77     13.0   2.894769  3.172550  4.395085\n",
      "281     3.0   5.175264  3.172550  4.395085\n",
      "403     2.0   7.413881  3.172550  4.395085\n",
      "17      0.0   8.240427  3.172550  4.395085\n",
      "83      1.0   1.845394  3.172550  4.395085\n",
      "310     2.0   5.822196  3.172550  4.395085\n",
      "0       3.0   3.356535  3.172550  4.395085\n",
      "21     10.0   2.537651  3.172550  4.395085\n",
      "291    10.0   5.441626  3.172550  4.395085\n",
      "433     3.0   2.235136  3.172550  4.395085\n",
      "407     3.0   1.231432  3.172550  4.395085\n",
      "299     8.0   9.291665  3.172550  4.395085\n",
      "82      3.0   3.232942  3.172550  4.395085\n",
      "153     2.0   7.737225  3.172550  4.395085\n",
      "390     9.0   4.928666  3.172550  4.395085\n",
      "438     2.0   6.122795  3.172550  4.395085\n",
      "27      5.0   4.629959  3.172550  4.395085\n",
      "415     3.0   2.943424  3.172550  4.395085\n",
      "184     6.0   9.546732  3.172550  4.395085\n",
      "301    11.0   7.078071  3.172550  4.395085\n",
      "191     4.0   2.852675  3.172550  4.395085\n",
      "386     3.0   3.914927  3.172550  4.395085\n",
      "45     17.0   3.532743  3.172550  4.395085\n",
      "171     2.0   9.142403  3.172550  4.395085\n",
      "361     3.0   4.311855  3.172550  4.395085\n",
      "449     4.0   4.023382  3.172550  4.395085\n",
      "343     3.0   1.041709  3.172550  4.395085\n",
      "302     2.0   1.925211  3.172550  4.395085\n",
      "372     1.0   1.639568  3.172550  4.395085\n",
      "24     11.0   7.141194  3.172550  4.395085\n",
      "49     13.0   9.388920  3.172550  4.395085\n",
      "414     0.0   0.902809  3.172550  4.395085\n",
      "366     4.0   6.766687  3.172550  4.395085\n",
      "97     11.0   1.951406  3.172550  4.395085\n",
      "181     5.0   2.456053  3.172550  4.395085\n",
      "61      8.0   8.783060  3.172550  4.395085\n",
      "139     2.0   1.340513  3.172550  4.395085\n",
      "26     13.0   3.905363  3.172550  4.395085\n",
      "19      3.0   1.035080  3.172550  4.395085\n",
      "70      4.0   5.387146  3.172550  4.395085\n",
      "350     1.0   3.619266  3.354931  4.180418\n",
      "354     3.0   5.340631  3.354931  4.180418\n",
      "428     1.0   5.530043  3.354931  4.180418\n",
      "60      4.0   2.993061  3.354931  4.180418\n",
      "169     0.0   4.339357  3.354931  4.180418\n",
      "33     13.0   4.761034  3.354931  4.180418\n",
      "76      1.0   3.040995  3.354931  4.180418\n",
      "88     13.0   8.080144  3.354931  4.180418\n",
      "278     3.0   1.872813  3.354931  4.180418\n",
      "461     2.0   6.900143  3.354931  4.180418\n",
      "11      1.0   6.704518  3.354931  4.180418\n",
      "431     2.0   5.615861  3.354931  4.180418\n",
      "116     8.0   7.076383  3.354931  4.180418\n",
      "459     4.0   3.031044  3.354931  4.180418\n",
      "458     5.0   4.264985  3.354931  4.180418\n",
      "42      5.0   7.855882  3.354931  4.180418\n",
      "457     1.0   7.975320  3.354931  4.180418\n",
      "416     3.0   3.680991  3.354931  4.180418\n",
      "59      2.0   5.365059  3.354931  4.180418\n",
      "451     2.0   1.755947  3.354931  4.180418\n",
      "427     5.0   7.038651  3.354931  4.180418\n",
      "265     4.0   6.703327  3.354931  4.180418\n",
      "454     2.0   6.510468  3.354931  4.180418\n",
      "196    13.0   7.160257  3.354931  4.180418\n",
      "243     6.0   5.517166  3.354931  4.180418\n",
      "125     4.0   8.397985  3.354931  4.180418\n",
      "402     3.0   5.837861  3.354931  4.180418\n",
      "164     2.0   5.317664  3.354931  4.180418\n",
      "368     2.0   5.267509  3.354931  4.180418\n",
      "84      1.0   7.089636  3.354931  4.180418\n",
      "227    11.0   4.477530  3.354931  4.180418\n",
      "405     3.0   2.221350  3.354931  4.180418\n",
      "157    14.0   7.563541  3.354931  4.180418\n",
      "100    12.0   5.861365  3.354931  4.180418\n",
      "240     4.0   7.303592  3.354931  4.180418\n",
      "220     3.0   4.937018  3.354931  4.180418\n",
      "85      2.0   7.743151  3.354931  4.180418\n",
      "327     3.0   2.400442  3.354931  4.180418\n",
      "268     7.0   8.119533  3.354931  4.180418\n",
      "80      3.0   5.368128  3.354931  4.180418\n",
      "74      9.0   7.324648  3.354931  4.180418\n",
      "36     18.0   6.134873  3.354931  4.180418\n",
      "122     4.0   4.045753  3.354931  4.180418\n",
      "316    10.0   5.973528  3.354931  4.180418\n",
      "77     13.0   4.150578  3.354931  4.180418\n",
      "281     3.0   6.041441  3.354931  4.180418\n",
      "403     2.0   5.533279  3.354931  4.180418\n",
      "17      0.0   8.229718  3.354931  4.180418\n",
      "83      1.0   4.389825  3.354931  4.180418\n",
      "310     2.0   7.395185  3.354931  4.180418\n",
      "0       3.0   4.677466  3.354931  4.180418\n",
      "21     10.0   6.082315  3.354931  4.180418\n",
      "291    10.0   5.595265  3.354931  4.180418\n",
      "433     3.0   5.454722  3.354931  4.180418\n",
      "407     3.0   1.754296  3.354931  4.180418\n",
      "299     8.0   7.554151  3.354931  4.180418\n",
      "82      3.0   5.519905  3.354931  4.180418\n",
      "153     2.0   7.699875  3.354931  4.180418\n",
      "390     9.0   7.598330  3.354931  4.180418\n",
      "438     2.0   6.474030  3.354931  4.180418\n",
      "27      5.0   6.242790  3.354931  4.180418\n",
      "415     3.0   2.545232  3.354931  4.180418\n",
      "184     6.0   8.128810  3.354931  4.180418\n",
      "301    11.0   7.504294  3.354931  4.180418\n",
      "191     4.0   6.598472  3.354931  4.180418\n",
      "386     3.0   7.448293  3.354931  4.180418\n",
      "45     17.0   5.422645  3.354931  4.180418\n",
      "171     2.0   7.711612  3.354931  4.180418\n",
      "361     3.0   6.103417  3.354931  4.180418\n",
      "449     4.0   5.045264  3.354931  4.180418\n",
      "343     3.0   1.702410  3.354931  4.180418\n",
      "302     2.0   1.597386  3.354931  4.180418\n",
      "372     1.0   3.426064  3.354931  4.180418\n",
      "24     11.0   7.543910  3.354931  4.180418\n",
      "49     13.0   8.381174  3.354931  4.180418\n",
      "414     0.0   0.122400  3.354931  4.180418\n",
      "366     4.0   6.207075  3.354931  4.180418\n",
      "97     11.0   4.989372  3.354931  4.180418\n",
      "181     5.0   5.302469  3.354931  4.180418\n",
      "61      8.0   7.646263  3.354931  4.180418\n",
      "139     2.0   2.548966  3.354931  4.180418\n",
      "26     13.0   6.176046  3.354931  4.180418\n",
      "19      3.0   0.016455  3.354931  4.180418\n",
      "70      4.0   7.595029  3.354931  4.180418\n",
      "350     1.0   2.211993  3.350600  4.515183\n",
      "354     3.0   7.565015  3.350600  4.515183\n",
      "428     1.0   1.892442  3.350600  4.515183\n",
      "60      4.0   8.697445  3.350600  4.515183\n",
      "169     0.0   2.740391  3.350600  4.515183\n",
      "33     13.0   4.381427  3.350600  4.515183\n",
      "76      1.0   1.892442  3.350600  4.515183\n",
      "88     13.0   5.715666  3.350600  4.515183\n",
      "278     3.0   1.892442  3.350600  4.515183\n",
      "461     2.0   8.668852  3.350600  4.515183\n",
      "11      1.0   8.612192  3.350600  4.515183\n",
      "431     2.0   1.993375  3.350600  4.515183\n",
      "116     8.0   5.716111  3.350600  4.515183\n",
      "459     4.0   1.931934  3.350600  4.515183\n",
      "458     5.0   2.862051  3.350600  4.515183\n",
      "42      5.0   2.172583  3.350600  4.515183\n",
      "457     1.0   4.655950  3.350600  4.515183\n",
      "416     3.0   2.412595  3.350600  4.515183\n",
      "59      2.0   3.966495  3.350600  4.515183\n",
      "451     2.0   1.892442  3.350600  4.515183\n",
      "427     5.0   6.263947  3.350600  4.515183\n",
      "265     4.0   8.389862  3.350600  4.515183\n",
      "454     2.0   2.112628  3.350600  4.515183\n",
      "196    13.0   7.886833  3.350600  4.515183\n",
      "243     6.0   2.261239  3.350600  4.515183\n",
      "125     4.0   7.404943  3.350600  4.515183\n",
      "402     3.0   1.547479  3.350600  4.515183\n",
      "164     2.0   2.142561  3.350600  4.515183\n",
      "368     2.0   4.090878  3.350600  4.515183\n",
      "84      1.0   2.223111  3.350600  4.515183\n",
      "227    11.0   2.758307  3.350600  4.515183\n",
      "405     3.0   1.607088  3.350600  4.515183\n",
      "157    14.0   8.227698  3.350600  4.515183\n",
      "100    12.0   5.345345  3.350600  4.515183\n",
      "240     4.0   8.544248  3.350600  4.515183\n",
      "220     3.0   1.892442  3.350600  4.515183\n",
      "85      2.0   2.827003  3.350600  4.515183\n",
      "327     3.0   1.892442  3.350600  4.515183\n",
      "268     7.0   8.927129  3.350600  4.515183\n",
      "80      3.0   3.342838  3.350600  4.515183\n",
      "74      9.0   5.824794  3.350600  4.515183\n",
      "36     18.0   2.210903  3.350600  4.515183\n",
      "122     4.0   2.229806  3.350600  4.515183\n",
      "316    10.0   7.174170  3.350600  4.515183\n",
      "77     13.0   3.640882  3.350600  4.515183\n",
      "281     3.0   4.511535  3.350600  4.515183\n",
      "403     2.0   8.466493  3.350600  4.515183\n",
      "17      0.0   9.420722  3.350600  4.515183\n",
      "83      1.0   2.234834  3.350600  4.515183\n",
      "310     2.0   6.887786  3.350600  4.515183\n",
      "0       3.0   4.744270  3.350600  4.515183\n",
      "21     10.0   4.355330  3.350600  4.515183\n",
      "291    10.0   3.541263  3.350600  4.515183\n",
      "433     3.0   2.218611  3.350600  4.515183\n",
      "407     3.0   1.892442  3.350600  4.515183\n",
      "299     8.0   3.992029  3.350600  4.515183\n",
      "82      3.0   3.982730  3.350600  4.515183\n",
      "153     2.0   8.348559  3.350600  4.515183\n",
      "390     9.0   5.418216  3.350600  4.515183\n",
      "438     2.0   5.981784  3.350600  4.515183\n",
      "27      5.0   2.957481  3.350600  4.515183\n",
      "415     3.0   2.027276  3.350600  4.515183\n",
      "184     6.0  11.029792  3.350600  4.515183\n",
      "301    11.0   4.694375  3.350600  4.515183\n",
      "191     4.0   5.499896  3.350600  4.515183\n",
      "386     3.0   3.137799  3.350600  4.515183\n",
      "45     17.0   3.000353  3.350600  4.515183\n",
      "171     2.0   6.624969  3.350600  4.515183\n",
      "361     3.0   3.301287  3.350600  4.515183\n",
      "449     4.0   8.677762  3.350600  4.515183\n",
      "343     3.0   1.892442  3.350600  4.515183\n",
      "302     2.0   1.892442  3.350600  4.515183\n",
      "372     1.0   2.533272  3.350600  4.515183\n",
      "24     11.0   5.582429  3.350600  4.515183\n",
      "49     13.0  13.719465  3.350600  4.515183\n",
      "414     0.0   1.892442  3.350600  4.515183\n",
      "366     4.0   6.367340  3.350600  4.515183\n",
      "97     11.0   4.441307  3.350600  4.515183\n",
      "181     5.0   2.527216  3.350600  4.515183\n",
      "61      8.0  10.498803  3.350600  4.515183\n",
      "139     2.0   2.759542  3.350600  4.515183\n",
      "26     13.0   6.775649  3.350600  4.515183\n",
      "19      3.0   1.892442  3.350600  4.515183\n",
      "70      4.0   5.228293  3.350600  4.515183\n",
      "350     1.0   2.433283  3.310379  4.305473\n",
      "354     3.0   4.563632  3.310379  4.305473\n",
      "428     1.0   4.739238  3.310379  4.305473\n",
      "60      4.0   4.214273  3.310379  4.305473\n",
      "169     0.0   2.523183  3.310379  4.305473\n",
      "33     13.0  10.154799  3.310379  4.305473\n",
      "76      1.0   1.656297  3.310379  4.305473\n",
      "88     13.0   8.218573  3.310379  4.305473\n",
      "278     3.0   3.839966  3.310379  4.305473\n",
      "461     2.0   9.013004  3.310379  4.305473\n",
      "11      1.0   7.122938  3.310379  4.305473\n",
      "431     2.0   4.699189  3.310379  4.305473\n",
      "116     8.0   7.458365  3.310379  4.305473\n",
      "459     4.0   2.052115  3.310379  4.305473\n",
      "458     5.0   4.982774  3.310379  4.305473\n",
      "42      5.0   8.906721  3.310379  4.305473\n",
      "457     1.0   5.078223  3.310379  4.305473\n",
      "416     3.0   3.021616  3.310379  4.305473\n",
      "59      2.0   5.350121  3.310379  4.305473\n",
      "451     2.0   1.568280  3.310379  4.305473\n",
      "427     5.0   6.134297  3.310379  4.305473\n",
      "265     4.0   6.672770  3.310379  4.305473\n",
      "454     2.0   5.607551  3.310379  4.305473\n",
      "196    13.0   8.335892  3.310379  4.305473\n",
      "243     6.0   5.530313  3.310379  4.305473\n",
      "125     4.0   5.783397  3.310379  4.305473\n",
      "402     3.0   2.276778  3.310379  4.305473\n",
      "164     2.0   4.406867  3.310379  4.305473\n",
      "368     2.0   5.635287  3.310379  4.305473\n",
      "84      1.0   7.453938  3.310379  4.305473\n",
      "227    11.0   3.030641  3.310379  4.305473\n",
      "405     3.0   1.857349  3.310379  4.305473\n",
      "157    14.0   8.417206  3.310379  4.305473\n",
      "100    12.0   4.104099  3.310379  4.305473\n",
      "240     4.0   8.851118  3.310379  4.305473\n",
      "220     3.0   5.348372  3.310379  4.305473\n",
      "85      2.0   8.082027  3.310379  4.305473\n",
      "327     3.0   1.556752  3.310379  4.305473\n",
      "268     7.0   8.778119  3.310379  4.305473\n",
      "80      3.0   4.139779  3.310379  4.305473\n",
      "74      9.0  10.130058  3.310379  4.305473\n",
      "36     18.0   5.579622  3.310379  4.305473\n",
      "122     4.0   1.254539  3.310379  4.305473\n",
      "316    10.0   5.742847  3.310379  4.305473\n",
      "77     13.0   3.712754  3.310379  4.305473\n",
      "281     3.0   7.007111  3.310379  4.305473\n",
      "403     2.0   5.664853  3.310379  4.305473\n",
      "17      0.0   9.503257  3.310379  4.305473\n",
      "83      1.0   3.955385  3.310379  4.305473\n",
      "310     2.0   7.482375  3.310379  4.305473\n",
      "0       3.0   3.355168  3.310379  4.305473\n",
      "21     10.0   6.089105  3.310379  4.305473\n",
      "291    10.0   4.079461  3.310379  4.305473\n",
      "433     3.0   4.567642  3.310379  4.305473\n",
      "407     3.0   1.065875  3.310379  4.305473\n",
      "299     8.0   7.733420  3.310379  4.305473\n",
      "82      3.0   2.947280  3.310379  4.305473\n",
      "153     2.0   6.809531  3.310379  4.305473\n",
      "390     9.0   4.997969  3.310379  4.305473\n",
      "438     2.0   4.843491  3.310379  4.305473\n",
      "27      5.0   2.286548  3.310379  4.305473\n",
      "415     3.0   2.331193  3.310379  4.305473\n",
      "184     6.0   9.953732  3.310379  4.305473\n",
      "301    11.0   4.164679  3.310379  4.305473\n",
      "191     4.0   7.537026  3.310379  4.305473\n",
      "386     3.0   5.662704  3.310379  4.305473\n",
      "45     17.0   4.391397  3.310379  4.305473\n",
      "171     2.0   6.959816  3.310379  4.305473\n",
      "361     3.0   9.298235  3.310379  4.305473\n",
      "449     4.0   6.278981  3.310379  4.305473\n",
      "343     3.0   2.428981  3.310379  4.305473\n",
      "302     2.0   2.408106  3.310379  4.305473\n",
      "372     1.0   2.821476  3.310379  4.305473\n",
      "24     11.0   8.183533  3.310379  4.305473\n",
      "49     13.0  10.456268  3.310379  4.305473\n",
      "414     0.0   0.451779  3.310379  4.305473\n",
      "366     4.0   6.741334  3.310379  4.305473\n",
      "97     11.0   2.123545  3.310379  4.305473\n",
      "181     5.0   2.463510  3.310379  4.305473\n",
      "61      8.0  10.676437  3.310379  4.305473\n",
      "139     2.0   1.236789  3.310379  4.305473\n",
      "26     13.0   5.730887  3.310379  4.305473\n",
      "19      3.0   2.831830  3.310379  4.305473\n",
      "70      4.0   3.715906  3.310379  4.305473\n",
      "350     1.0   2.078920  3.201108  4.553743\n",
      "354     3.0   4.587838  3.201108  4.553743\n",
      "428     1.0   2.327409  3.201108  4.553743\n",
      "60      4.0   3.308193  3.201108  4.553743\n",
      "169     0.0   2.124775  3.201108  4.553743\n",
      "33     13.0   6.530262  3.201108  4.553743\n",
      "76      1.0   2.078920  3.201108  4.553743\n",
      "88     13.0   7.763740  3.201108  4.553743\n",
      "278     3.0   2.078920  3.201108  4.553743\n",
      "461     2.0   7.240432  3.201108  4.553743\n",
      "11      1.0   5.247381  3.201108  4.553743\n",
      "431     2.0   2.078920  3.201108  4.553743\n",
      "116     8.0   3.538293  3.201108  4.553743\n",
      "459     4.0   2.259249  3.201108  4.553743\n",
      "458     5.0   5.348489  3.201108  4.553743\n",
      "42      5.0   6.123259  3.201108  4.553743\n",
      "457     1.0   5.148102  3.201108  4.553743\n",
      "416     3.0   2.237876  3.201108  4.553743\n",
      "59      2.0   3.009574  3.201108  4.553743\n",
      "451     2.0   2.078920  3.201108  4.553743\n",
      "427     5.0   6.224561  3.201108  4.553743\n",
      "265     4.0   3.579164  3.201108  4.553743\n",
      "454     2.0   3.214449  3.201108  4.553743\n",
      "196    13.0   6.233716  3.201108  4.553743\n",
      "243     6.0   2.078920  3.201108  4.553743\n",
      "125     4.0   7.053957  3.201108  4.553743\n",
      "402     3.0   4.431077  3.201108  4.553743\n",
      "164     2.0   2.883457  3.201108  4.553743\n",
      "368     2.0   2.530852  3.201108  4.553743\n",
      "84      1.0   2.407695  3.201108  4.553743\n",
      "227    11.0   2.229624  3.201108  4.553743\n",
      "405     3.0   2.078920  3.201108  4.553743\n",
      "157    14.0   4.699164  3.201108  4.553743\n",
      "100    12.0   3.531244  3.201108  4.553743\n",
      "240     4.0   7.017172  3.201108  4.553743\n",
      "220     3.0   3.204519  3.201108  4.553743\n",
      "85      2.0   4.452344  3.201108  4.553743\n",
      "327     3.0   2.078920  3.201108  4.553743\n",
      "268     7.0   7.390430  3.201108  4.553743\n",
      "80      3.0   4.451809  3.201108  4.553743\n",
      "74      9.0   7.103815  3.201108  4.553743\n",
      "36     18.0   2.094682  3.201108  4.553743\n",
      "122     4.0   2.078920  3.201108  4.553743\n",
      "316    10.0   2.220418  3.201108  4.553743\n",
      "77     13.0   3.196111  3.201108  4.553743\n",
      "281     3.0   5.804558  3.201108  4.553743\n",
      "403     2.0   6.341255  3.201108  4.553743\n",
      "17      0.0   7.174420  3.201108  4.553743\n",
      "83      1.0   2.078920  3.201108  4.553743\n",
      "310     2.0   4.705453  3.201108  4.553743\n",
      "0       3.0   2.574441  3.201108  4.553743\n",
      "21     10.0   4.038913  3.201108  4.553743\n",
      "291    10.0   4.635625  3.201108  4.553743\n",
      "433     3.0   2.078920  3.201108  4.553743\n",
      "407     3.0   2.078920  3.201108  4.553743\n",
      "299     8.0   5.147371  3.201108  4.553743\n",
      "82      3.0   2.499428  3.201108  4.553743\n",
      "153     2.0   7.128861  3.201108  4.553743\n",
      "390     9.0   4.525022  3.201108  4.553743\n",
      "438     2.0   5.822046  3.201108  4.553743\n",
      "27      5.0   4.379980  3.201108  4.553743\n",
      "415     3.0   2.636135  3.201108  4.553743\n",
      "184     6.0  10.847010  3.201108  4.553743\n",
      "301    11.0   3.922554  3.201108  4.553743\n",
      "191     4.0   2.830282  3.201108  4.553743\n",
      "386     3.0   3.268606  3.201108  4.553743\n",
      "45     17.0   3.099402  3.201108  4.553743\n",
      "171     2.0   9.963470  3.201108  4.553743\n",
      "361     3.0   3.749553  3.201108  4.553743\n",
      "449     4.0   5.756626  3.201108  4.553743\n",
      "343     3.0   2.078920  3.201108  4.553743\n",
      "302     2.0   2.078920  3.201108  4.553743\n",
      "372     1.0   2.078920  3.201108  4.553743\n",
      "24     11.0   5.201315  3.201108  4.553743\n",
      "49     13.0   7.906277  3.201108  4.553743\n",
      "414     0.0   2.078920  3.201108  4.553743\n",
      "366     4.0   6.268872  3.201108  4.553743\n",
      "97     11.0   2.850077  3.201108  4.553743\n",
      "181     5.0   2.276871  3.201108  4.553743\n",
      "61      8.0  10.008400  3.201108  4.553743\n",
      "139     2.0   2.078920  3.201108  4.553743\n",
      "26     13.0   2.573265  3.201108  4.553743\n",
      "19      3.0   2.078920  3.201108  4.553743\n",
      "70      4.0   6.256861  3.201108  4.553743\n",
      "350     1.0   3.722902  3.486018  4.338920\n",
      "354     3.0   5.400812  3.486018  4.338920\n",
      "428     1.0   3.910263  3.486018  4.338920\n",
      "60      4.0   5.242021  3.486018  4.338920\n",
      "169     0.0   3.392380  3.486018  4.338920\n",
      "33     13.0   5.432997  3.486018  4.338920\n",
      "76      1.0   2.523390  3.486018  4.338920\n",
      "88     13.0   9.195061  3.486018  4.338920\n",
      "278     3.0   1.357030  3.486018  4.338920\n",
      "461     2.0   6.748011  3.486018  4.338920\n",
      "11      1.0   7.022696  3.486018  4.338920\n",
      "431     2.0   4.725801  3.486018  4.338920\n",
      "116     8.0   9.262313  3.486018  4.338920\n",
      "459     4.0   3.634490  3.486018  4.338920\n",
      "458     5.0   2.084671  3.486018  4.338920\n",
      "42      5.0   9.253944  3.486018  4.338920\n",
      "457     1.0   8.632238  3.486018  4.338920\n",
      "416     3.0   1.983872  3.486018  4.338920\n",
      "59      2.0   5.304212  3.486018  4.338920\n",
      "451     2.0   1.502413  3.486018  4.338920\n",
      "427     5.0   4.189357  3.486018  4.338920\n",
      "265     4.0   6.189422  3.486018  4.338920\n",
      "454     2.0   6.115220  3.486018  4.338920\n",
      "196    13.0   9.499546  3.486018  4.338920\n",
      "243     6.0   5.956108  3.486018  4.338920\n",
      "125     4.0   9.503250  3.486018  4.338920\n",
      "402     3.0   2.251682  3.486018  4.338920\n",
      "164     2.0   5.222080  3.486018  4.338920\n",
      "368     2.0   4.750344  3.486018  4.338920\n",
      "84      1.0   4.671018  3.486018  4.338920\n",
      "227    11.0   5.328380  3.486018  4.338920\n",
      "405     3.0   0.429253  3.486018  4.338920\n",
      "157    14.0   8.202155  3.486018  4.338920\n",
      "100    12.0   6.585595  3.486018  4.338920\n",
      "240     4.0   9.717562  3.486018  4.338920\n",
      "220     3.0   4.662810  3.486018  4.338920\n",
      "85      2.0   8.794733  3.486018  4.338920\n",
      "327     3.0   0.502462  3.486018  4.338920\n",
      "268     7.0   9.197197  3.486018  4.338920\n",
      "80      3.0   2.588371  3.486018  4.338920\n",
      "74      9.0   8.661782  3.486018  4.338920\n",
      "36     18.0   4.334992  3.486018  4.338920\n",
      "122     4.0   1.430534  3.486018  4.338920\n",
      "316    10.0   4.607787  3.486018  4.338920\n",
      "77     13.0   4.925971  3.486018  4.338920\n",
      "281     3.0   7.291536  3.486018  4.338920\n",
      "403     2.0   7.124925  3.486018  4.338920\n",
      "17      0.0   8.875194  3.486018  4.338920\n",
      "83      1.0   4.079295  3.486018  4.338920\n",
      "310     2.0   8.721289  3.486018  4.338920\n",
      "0       3.0   5.112031  3.486018  4.338920\n",
      "21     10.0   6.890846  3.486018  4.338920\n",
      "291    10.0   5.952207  3.486018  4.338920\n",
      "433     3.0   4.155467  3.486018  4.338920\n",
      "407     3.0   0.000000  3.486018  4.338920\n",
      "299     8.0   9.317553  3.486018  4.338920\n",
      "82      3.0   5.169664  3.486018  4.338920\n",
      "153     2.0   9.780373  3.486018  4.338920\n",
      "390     9.0   7.727147  3.486018  4.338920\n",
      "438     2.0   3.442376  3.486018  4.338920\n",
      "27      5.0   7.130040  3.486018  4.338920\n",
      "415     3.0   4.459957  3.486018  4.338920\n",
      "184     6.0   9.416014  3.486018  4.338920\n",
      "301    11.0   7.392319  3.486018  4.338920\n",
      "191     4.0   5.982114  3.486018  4.338920\n",
      "386     3.0   8.270573  3.486018  4.338920\n",
      "45     17.0   5.399514  3.486018  4.338920\n",
      "171     2.0   6.046968  3.486018  4.338920\n",
      "361     3.0   7.104178  3.486018  4.338920\n",
      "449     4.0   5.019165  3.486018  4.338920\n",
      "343     3.0   1.682035  3.486018  4.338920\n",
      "302     2.0   2.638053  3.486018  4.338920\n",
      "372     1.0   0.492497  3.486018  4.338920\n",
      "24     11.0   9.568556  3.486018  4.338920\n",
      "49     13.0   7.630494  3.486018  4.338920\n",
      "414     0.0   1.685755  3.486018  4.338920\n",
      "366     4.0   5.332976  3.486018  4.338920\n",
      "97     11.0   2.445606  3.486018  4.338920\n",
      "181     5.0   2.112953  3.486018  4.338920\n",
      "61      8.0   9.751515  3.486018  4.338920\n",
      "139     2.0   3.453698  3.486018  4.338920\n",
      "26     13.0   5.721727  3.486018  4.338920\n",
      "19      3.0   0.000000  3.486018  4.338920\n",
      "70      4.0   8.200561  3.486018  4.338920\n",
      "350     1.0   1.344941  3.488360  4.660905\n",
      "354     3.0   7.922465  3.488360  4.660905\n",
      "428     1.0   2.300823  3.488360  4.660905\n",
      "60      4.0   6.407465  3.488360  4.660905\n",
      "169     0.0   4.074055  3.488360  4.660905\n",
      "33     13.0  11.271113  3.488360  4.660905\n",
      "76      1.0   1.553901  3.488360  4.660905\n",
      "88     13.0   8.633328  3.488360  4.660905\n",
      "278     3.0   0.910948  3.488360  4.660905\n",
      "461     2.0   7.004263  3.488360  4.660905\n",
      "11      1.0   7.090982  3.488360  4.660905\n",
      "431     2.0   1.404859  3.488360  4.660905\n",
      "116     8.0   5.165895  3.488360  4.660905\n",
      "459     4.0   2.501855  3.488360  4.660905\n",
      "458     5.0   9.825414  3.488360  4.660905\n",
      "42      5.0   6.099987  3.488360  4.660905\n",
      "457     1.0   5.994946  3.488360  4.660905\n",
      "416     3.0   2.390679  3.488360  4.660905\n",
      "59      2.0   5.521183  3.488360  4.660905\n",
      "451     2.0   1.690904  3.488360  4.660905\n",
      "427     5.0   8.236897  3.488360  4.660905\n",
      "265     4.0   5.769746  3.488360  4.660905\n",
      "454     2.0   2.940023  3.488360  4.660905\n",
      "196    13.0   6.705935  3.488360  4.660905\n",
      "243     6.0   2.318811  3.488360  4.660905\n",
      "125     4.0   9.618978  3.488360  4.660905\n",
      "402     3.0   3.963838  3.488360  4.660905\n",
      "164     2.0   3.151021  3.488360  4.660905\n",
      "368     2.0   2.271094  3.488360  4.660905\n",
      "84      1.0   2.247956  3.488360  4.660905\n",
      "227    11.0   4.834625  3.488360  4.660905\n",
      "405     3.0   0.650688  3.488360  4.660905\n",
      "157    14.0   6.582390  3.488360  4.660905\n",
      "100    12.0   4.564451  3.488360  4.660905\n",
      "240     4.0  10.180808  3.488360  4.660905\n",
      "220     3.0   3.161597  3.488360  4.660905\n",
      "85      2.0   5.229587  3.488360  4.660905\n",
      "327     3.0   1.107880  3.488360  4.660905\n",
      "268     7.0  14.424402  3.488360  4.660905\n",
      "80      3.0   3.860004  3.488360  4.660905\n",
      "74      9.0   9.863787  3.488360  4.660905\n",
      "36     18.0   2.838503  3.488360  4.660905\n",
      "122     4.0   2.045187  3.488360  4.660905\n",
      "316    10.0   2.853961  3.488360  4.660905\n",
      "77     13.0   4.210814  3.488360  4.660905\n",
      "281     3.0   6.851370  3.488360  4.660905\n",
      "403     2.0   9.983572  3.488360  4.660905\n",
      "17      0.0   8.115617  3.488360  4.660905\n",
      "83      1.0   1.533409  3.488360  4.660905\n",
      "310     2.0   8.913110  3.488360  4.660905\n",
      "0       3.0   3.478264  3.488360  4.660905\n",
      "21     10.0   4.996869  3.488360  4.660905\n",
      "291    10.0   4.708281  3.488360  4.660905\n",
      "433     3.0   3.226291  3.488360  4.660905\n",
      "407     3.0   1.889067  3.488360  4.660905\n",
      "299     8.0   9.933518  3.488360  4.660905\n",
      "82      3.0   2.609327  3.488360  4.660905\n",
      "153     2.0   8.171020  3.488360  4.660905\n",
      "390     9.0   6.187431  3.488360  4.660905\n",
      "438     2.0   6.102973  3.488360  4.660905\n",
      "27      5.0   4.858719  3.488360  4.660905\n",
      "415     3.0   3.757018  3.488360  4.660905\n",
      "184     6.0  14.381536  3.488360  4.660905\n",
      "301    11.0   7.075033  3.488360  4.660905\n",
      "191     4.0   2.650290  3.488360  4.660905\n",
      "386     3.0   6.000593  3.488360  4.660905\n",
      "45     17.0   3.055559  3.488360  4.660905\n",
      "171     2.0   9.443892  3.488360  4.660905\n",
      "361     3.0   4.167520  3.488360  4.660905\n",
      "449     4.0   6.722480  3.488360  4.660905\n",
      "343     3.0   1.215364  3.488360  4.660905\n",
      "302     2.0   1.480077  3.488360  4.660905\n",
      "372     1.0   1.759057  3.488360  4.660905\n",
      "24     11.0   6.249002  3.488360  4.660905\n",
      "49     13.0  12.008714  3.488360  4.660905\n",
      "414     0.0   0.000000  3.488360  4.660905\n",
      "366     4.0   6.223022  3.488360  4.660905\n",
      "97     11.0   3.522966  3.488360  4.660905\n",
      "181     5.0   2.301893  3.488360  4.660905\n",
      "61      8.0  10.368904  3.488360  4.660905\n",
      "139     2.0   2.608568  3.488360  4.660905\n",
      "26     13.0   3.066256  3.488360  4.660905\n",
      "19      3.0   0.436231  3.488360  4.660905\n",
      "70      4.0   7.214223  3.488360  4.660905\n",
      "350     1.0   3.962798  3.494046  4.350358\n",
      "354     3.0   4.931322  3.494046  4.350358\n",
      "428     1.0   4.911197  3.494046  4.350358\n",
      "60      4.0   4.202726  3.494046  4.350358\n",
      "169     0.0   4.122988  3.494046  4.350358\n",
      "33     13.0   6.638542  3.494046  4.350358\n",
      "76      1.0   0.556165  3.494046  4.350358\n",
      "88     13.0  10.080184  3.494046  4.350358\n",
      "278     3.0   0.469809  3.494046  4.350358\n",
      "461     2.0   7.547667  3.494046  4.350358\n",
      "11      1.0   6.503543  3.494046  4.350358\n",
      "431     2.0   3.929789  3.494046  4.350358\n",
      "116     8.0   8.187284  3.494046  4.350358\n",
      "459     4.0   1.878396  3.494046  4.350358\n",
      "458     5.0   2.943918  3.494046  4.350358\n",
      "42      5.0   8.674458  3.494046  4.350358\n",
      "457     1.0   6.725622  3.494046  4.350358\n",
      "416     3.0   2.878139  3.494046  4.350358\n",
      "59      2.0   4.257143  3.494046  4.350358\n",
      "451     2.0   0.027204  3.494046  4.350358\n",
      "427     5.0   6.187055  3.494046  4.350358\n",
      "265     4.0   7.586822  3.494046  4.350358\n",
      "454     2.0   3.547739  3.494046  4.350358\n",
      "196    13.0   8.575483  3.494046  4.350358\n",
      "243     6.0   5.165488  3.494046  4.350358\n",
      "125     4.0   9.972538  3.494046  4.350358\n",
      "402     3.0   5.473816  3.494046  4.350358\n",
      "164     2.0   3.844900  3.494046  4.350358\n",
      "368     2.0   5.953300  3.494046  4.350358\n",
      "84      1.0   6.076804  3.494046  4.350358\n",
      "227    11.0   3.244646  3.494046  4.350358\n",
      "405     3.0   0.236811  3.494046  4.350358\n",
      "157    14.0   9.465463  3.494046  4.350358\n",
      "100    12.0   5.162269  3.494046  4.350358\n",
      "240     4.0   7.880069  3.494046  4.350358\n",
      "220     3.0   2.727491  3.494046  4.350358\n",
      "85      2.0   7.338392  3.494046  4.350358\n",
      "327     3.0   0.388135  3.494046  4.350358\n",
      "268     7.0  10.834932  3.494046  4.350358\n",
      "80      3.0   3.819588  3.494046  4.350358\n",
      "74      9.0   9.787643  3.494046  4.350358\n",
      "36     18.0   3.991606  3.494046  4.350358\n",
      "122     4.0   1.694135  3.494046  4.350358\n",
      "316    10.0   5.414104  3.494046  4.350358\n",
      "77     13.0   3.477499  3.494046  4.350358\n",
      "281     3.0   6.856885  3.494046  4.350358\n",
      "403     2.0   6.397769  3.494046  4.350358\n",
      "17      0.0   7.251438  3.494046  4.350358\n",
      "83      1.0   2.803677  3.494046  4.350358\n",
      "310     2.0   8.503062  3.494046  4.350358\n",
      "0       3.0   5.272583  3.494046  4.350358\n",
      "21     10.0   6.816562  3.494046  4.350358\n",
      "291    10.0   3.582451  3.494046  4.350358\n",
      "433     3.0   4.453182  3.494046  4.350358\n",
      "407     3.0   1.268684  3.494046  4.350358\n",
      "299     8.0   8.573133  3.494046  4.350358\n",
      "82      3.0   4.632958  3.494046  4.350358\n",
      "153     2.0   7.946545  3.494046  4.350358\n",
      "390     9.0   6.024961  3.494046  4.350358\n",
      "438     2.0   5.055755  3.494046  4.350358\n",
      "27      5.0   5.571081  3.494046  4.350358\n",
      "415     3.0   2.081561  3.494046  4.350358\n",
      "184     6.0  11.327169  3.494046  4.350358\n",
      "301    11.0   5.959904  3.494046  4.350358\n",
      "191     4.0   6.749543  3.494046  4.350358\n",
      "386     3.0   6.432866  3.494046  4.350358\n",
      "45     17.0   3.992929  3.494046  4.350358\n",
      "171     2.0   6.488070  3.494046  4.350358\n",
      "361     3.0   8.632328  3.494046  4.350358\n",
      "449     4.0   6.398798  3.494046  4.350358\n",
      "343     3.0   0.000000  3.494046  4.350358\n",
      "302     2.0   0.797546  3.494046  4.350358\n",
      "372     1.0   2.271244  3.494046  4.350358\n",
      "24     11.0   8.624914  3.494046  4.350358\n",
      "49     13.0   9.068122  3.494046  4.350358\n",
      "414     0.0   0.000000  3.494046  4.350358\n",
      "366     4.0   7.132710  3.494046  4.350358\n",
      "97     11.0   3.577368  3.494046  4.350358\n",
      "181     5.0   1.760499  3.494046  4.350358\n",
      "61      8.0   9.712099  3.494046  4.350358\n",
      "139     2.0   2.149359  3.494046  4.350358\n",
      "26     13.0   6.435756  3.494046  4.350358\n",
      "19      3.0   0.000000  3.494046  4.350358\n",
      "70      4.0   6.634249  3.494046  4.350358\n",
      "350     1.0   2.011318  3.217842  4.449732\n",
      "354     3.0   5.707380  3.217842  4.449732\n",
      "428     1.0   1.797436  3.217842  4.449732\n",
      "60      4.0   4.096380  3.217842  4.449732\n",
      "169     0.0   2.954900  3.217842  4.449732\n",
      "33     13.0   6.561747  3.217842  4.449732\n",
      "76      1.0   0.622981  3.217842  4.449732\n",
      "88     13.0   8.118481  3.217842  4.449732\n",
      "278     3.0   0.926404  3.217842  4.449732\n",
      "461     2.0   6.874978  3.217842  4.449732\n",
      "11      1.0   5.015924  3.217842  4.449732\n",
      "431     2.0   3.392374  3.217842  4.449732\n",
      "116     8.0   4.049478  3.217842  4.449732\n",
      "459     4.0   1.593213  3.217842  4.449732\n",
      "458     5.0   3.263956  3.217842  4.449732\n",
      "42      5.0   4.392157  3.217842  4.449732\n",
      "457     1.0   6.400556  3.217842  4.449732\n",
      "416     3.0   1.917290  3.217842  4.449732\n",
      "59      2.0   3.511955  3.217842  4.449732\n",
      "451     2.0   1.446726  3.217842  4.449732\n",
      "427     5.0   4.711698  3.217842  4.449732\n",
      "265     4.0   4.159961  3.217842  4.449732\n",
      "454     2.0   2.264884  3.217842  4.449732\n",
      "196    13.0   7.445241  3.217842  4.449732\n",
      "243     6.0   2.346276  3.217842  4.449732\n",
      "125     4.0   6.908073  3.217842  4.449732\n",
      "402     3.0   3.132063  3.217842  4.449732\n",
      "164     2.0   1.261264  3.217842  4.449732\n",
      "368     2.0   2.395453  3.217842  4.449732\n",
      "84      1.0   2.299793  3.217842  4.449732\n",
      "227    11.0   2.771203  3.217842  4.449732\n",
      "405     3.0   0.507574  3.217842  4.449732\n",
      "157    14.0   7.215208  3.217842  4.449732\n",
      "100    12.0   3.664885  3.217842  4.449732\n",
      "240     4.0   9.879557  3.217842  4.449732\n",
      "220     3.0   2.550420  3.217842  4.449732\n",
      "85      2.0   4.449351  3.217842  4.449732\n",
      "327     3.0   1.206728  3.217842  4.449732\n",
      "268     7.0  11.915916  3.217842  4.449732\n",
      "80      3.0   2.455660  3.217842  4.449732\n",
      "74      9.0   7.988250  3.217842  4.449732\n",
      "36     18.0   2.448563  3.217842  4.449732\n",
      "122     4.0   1.304605  3.217842  4.449732\n",
      "316    10.0   3.869177  3.217842  4.449732\n",
      "77     13.0   3.214268  3.217842  4.449732\n",
      "281     3.0   5.788675  3.217842  4.449732\n",
      "403     2.0   9.589202  3.217842  4.449732\n",
      "17      0.0   7.684488  3.217842  4.449732\n",
      "83      1.0   1.277912  3.217842  4.449732\n",
      "310     2.0   6.925756  3.217842  4.449732\n",
      "0       3.0   4.510775  3.217842  4.449732\n",
      "21     10.0   4.147716  3.217842  4.449732\n",
      "291    10.0   4.311343  3.217842  4.449732\n",
      "433     3.0   2.617151  3.217842  4.449732\n",
      "407     3.0   1.250204  3.217842  4.449732\n",
      "299     8.0   7.825797  3.217842  4.449732\n",
      "82      3.0   2.468367  3.217842  4.449732\n",
      "153     2.0   8.125383  3.217842  4.449732\n",
      "390     9.0   5.420093  3.217842  4.449732\n",
      "438     2.0   5.910620  3.217842  4.449732\n",
      "27      5.0   3.909665  3.217842  4.449732\n",
      "415     3.0   2.347814  3.217842  4.449732\n",
      "184     6.0  10.992640  3.217842  4.449732\n",
      "301    11.0   4.931790  3.217842  4.449732\n",
      "191     4.0   2.711260  3.217842  4.449732\n",
      "386     3.0   3.730339  3.217842  4.449732\n",
      "45     17.0   4.437753  3.217842  4.449732\n",
      "171     2.0   8.110334  3.217842  4.449732\n",
      "361     3.0   5.040164  3.217842  4.449732\n",
      "449     4.0   3.937612  3.217842  4.449732\n",
      "343     3.0   1.494150  3.217842  4.449732\n",
      "302     2.0   0.793435  3.217842  4.449732\n",
      "372     1.0   1.964913  3.217842  4.449732\n",
      "24     11.0   7.597843  3.217842  4.449732\n",
      "49     13.0   9.075249  3.217842  4.449732\n",
      "414     0.0   0.938865  3.217842  4.449732\n",
      "366     4.0   6.151743  3.217842  4.449732\n",
      "97     11.0   2.034723  3.217842  4.449732\n",
      "181     5.0   2.954593  3.217842  4.449732\n",
      "61      8.0  10.577564  3.217842  4.449732\n",
      "139     2.0   1.316792  3.217842  4.449732\n",
      "26     13.0   3.263559  3.217842  4.449732\n",
      "19      3.0   0.984617  3.217842  4.449732\n",
      "70      4.0   4.496075  3.217842  4.449732\n",
      "350     1.0   4.536618  3.263314  4.020700\n",
      "354     3.0   4.429450  3.263314  4.020700\n",
      "428     1.0   5.403291  3.263314  4.020700\n",
      "60      4.0   2.681422  3.263314  4.020700\n",
      "169     0.0   4.403723  3.263314  4.020700\n",
      "33     13.0   5.814469  3.263314  4.020700\n",
      "76      1.0   2.280799  3.263314  4.020700\n",
      "88     13.0   8.411600  3.263314  4.020700\n",
      "278     3.0   3.171404  3.263314  4.020700\n",
      "461     2.0   7.601133  3.263314  4.020700\n",
      "11      1.0   5.683495  3.263314  4.020700\n",
      "431     2.0   4.305771  3.263314  4.020700\n",
      "116     8.0   7.848592  3.263314  4.020700\n",
      "459     4.0   2.336008  3.263314  4.020700\n",
      "458     5.0   2.845933  3.263314  4.020700\n",
      "42      5.0   7.849972  3.263314  4.020700\n",
      "457     1.0   7.678127  3.263314  4.020700\n",
      "416     3.0   3.520440  3.263314  4.020700\n",
      "59      2.0   5.413437  3.263314  4.020700\n",
      "451     2.0   2.333783  3.263314  4.020700\n",
      "427     5.0   7.158115  3.263314  4.020700\n",
      "265     4.0   7.037882  3.263314  4.020700\n",
      "454     2.0   4.408125  3.263314  4.020700\n",
      "196    13.0   9.041903  3.263314  4.020700\n",
      "243     6.0   6.202443  3.263314  4.020700\n",
      "125     4.0   8.925100  3.263314  4.020700\n",
      "402     3.0   4.711050  3.263314  4.020700\n",
      "164     2.0   5.641304  3.263314  4.020700\n",
      "368     2.0   6.473111  3.263314  4.020700\n",
      "84      1.0   7.092053  3.263314  4.020700\n",
      "227    11.0   4.035261  3.263314  4.020700\n",
      "405     3.0   1.169195  3.263314  4.020700\n",
      "157    14.0   8.578823  3.263314  4.020700\n",
      "100    12.0   5.807209  3.263314  4.020700\n",
      "240     4.0   7.958901  3.263314  4.020700\n",
      "220     3.0   5.332615  3.263314  4.020700\n",
      "85      2.0   6.573775  3.263314  4.020700\n",
      "327     3.0   1.949411  3.263314  4.020700\n",
      "268     7.0   8.980179  3.263314  4.020700\n",
      "80      3.0   4.736903  3.263314  4.020700\n",
      "74      9.0   8.650435  3.263314  4.020700\n",
      "36     18.0   6.519057  3.263314  4.020700\n",
      "122     4.0   2.918283  3.263314  4.020700\n",
      "316    10.0   6.298585  3.263314  4.020700\n",
      "77     13.0   3.906647  3.263314  4.020700\n",
      "281     3.0   6.050665  3.263314  4.020700\n",
      "403     2.0   5.484503  3.263314  4.020700\n",
      "17      0.0   7.959680  3.263314  4.020700\n",
      "83      1.0   3.032443  3.263314  4.020700\n",
      "310     2.0   7.356356  3.263314  4.020700\n",
      "0       3.0   4.431098  3.263314  4.020700\n",
      "21     10.0   6.338282  3.263314  4.020700\n",
      "291    10.0   5.383693  3.263314  4.020700\n",
      "433     3.0   5.271712  3.263314  4.020700\n",
      "407     3.0   1.186763  3.263314  4.020700\n",
      "299     8.0   8.436979  3.263314  4.020700\n",
      "82      3.0   5.652913  3.263314  4.020700\n",
      "153     2.0   7.471064  3.263314  4.020700\n",
      "390     9.0   7.844522  3.263314  4.020700\n",
      "438     2.0   5.455687  3.263314  4.020700\n",
      "27      5.0   7.423664  3.263314  4.020700\n",
      "415     3.0   2.290704  3.263314  4.020700\n",
      "184     6.0   9.378061  3.263314  4.020700\n",
      "301    11.0   7.628748  3.263314  4.020700\n",
      "191     4.0   6.871033  3.263314  4.020700\n",
      "386     3.0   7.023248  3.263314  4.020700\n",
      "45     17.0   6.629160  3.263314  4.020700\n",
      "171     2.0   7.289645  3.263314  4.020700\n",
      "361     3.0   7.138700  3.263314  4.020700\n",
      "449     4.0   5.051082  3.263314  4.020700\n",
      "343     3.0   1.949028  3.263314  4.020700\n",
      "302     2.0   2.431392  3.263314  4.020700\n",
      "372     1.0   3.949877  3.263314  4.020700\n",
      "24     11.0   8.039523  3.263314  4.020700\n",
      "49     13.0   9.437758  3.263314  4.020700\n",
      "414     0.0   0.741832  3.263314  4.020700\n",
      "366     4.0   5.423434  3.263314  4.020700\n",
      "97     11.0   4.363533  3.263314  4.020700\n",
      "181     5.0   3.823995  3.263314  4.020700\n",
      "61      8.0   8.358231  3.263314  4.020700\n",
      "139     2.0   2.142930  3.263314  4.020700\n",
      "26     13.0   6.400745  3.263314  4.020700\n",
      "19      3.0   0.000000  3.263314  4.020700\n",
      "70      4.0   7.578440  3.263314  4.020700\n",
      "350     1.0   3.018898  3.862696  5.188746\n",
      "354     3.0   5.386351  3.862696  5.188746\n",
      "428     1.0   1.886097  3.862696  5.188746\n",
      "60      4.0   9.496595  3.862696  5.188746\n",
      "169     0.0  10.932441  3.862696  5.188746\n",
      "33     13.0   2.939591  3.862696  5.188746\n",
      "76      1.0   1.687135  3.862696  5.188746\n",
      "88     13.0   6.602529  3.862696  5.188746\n",
      "278     3.0   1.687135  3.862696  5.188746\n",
      "461     2.0   5.218644  3.862696  5.188746\n",
      "11      1.0   9.137840  3.862696  5.188746\n",
      "431     2.0   1.687135  3.862696  5.188746\n",
      "116     8.0   4.419894  3.862696  5.188746\n",
      "459     4.0   1.947843  3.862696  5.188746\n",
      "458     5.0   3.844027  3.862696  5.188746\n",
      "42      5.0   2.176801  3.862696  5.188746\n",
      "457     1.0   7.486126  3.862696  5.188746\n",
      "416     3.0   1.850005  3.862696  5.188746\n",
      "59      2.0   1.687135  3.862696  5.188746\n",
      "451     2.0   1.687135  3.862696  5.188746\n",
      "427     5.0   4.685534  3.862696  5.188746\n",
      "265     4.0   4.261160  3.862696  5.188746\n",
      "454     2.0   4.587831  3.862696  5.188746\n",
      "196    13.0   5.236540  3.862696  5.188746\n",
      "243     6.0   1.888543  3.862696  5.188746\n",
      "125     4.0   7.005637  3.862696  5.188746\n",
      "402     3.0   1.953703  3.862696  5.188746\n",
      "164     2.0   1.741691  3.862696  5.188746\n",
      "368     2.0   3.872023  3.862696  5.188746\n",
      "84      1.0   1.986889  3.862696  5.188746\n",
      "227    11.0   3.189959  3.862696  5.188746\n",
      "405     3.0   1.687135  3.862696  5.188746\n",
      "157    14.0   5.487641  3.862696  5.188746\n",
      "100    12.0   5.592291  3.862696  5.188746\n",
      "240     4.0  13.864596  3.862696  5.188746\n",
      "220     3.0   1.906605  3.862696  5.188746\n",
      "85      2.0   5.094381  3.862696  5.188746\n",
      "327     3.0   1.687135  3.862696  5.188746\n",
      "268     7.0  18.235260  3.862696  5.188746\n",
      "80      3.0   1.687135  3.862696  5.188746\n",
      "74      9.0  11.797675  3.862696  5.188746\n",
      "36     18.0   1.687135  3.862696  5.188746\n",
      "122     4.0   2.100506  3.862696  5.188746\n",
      "316    10.0   1.875050  3.862696  5.188746\n",
      "77     13.0   5.198300  3.862696  5.188746\n",
      "281     3.0   4.323681  3.862696  5.188746\n",
      "403     2.0  11.803609  3.862696  5.188746\n",
      "17      0.0   8.298417  3.862696  5.188746\n",
      "83      1.0   1.687135  3.862696  5.188746\n",
      "310     2.0  11.046420  3.862696  5.188746\n",
      "0       3.0   4.095512  3.862696  5.188746\n",
      "21     10.0   3.206070  3.862696  5.188746\n",
      "291    10.0   2.902961  3.862696  5.188746\n",
      "433     3.0   4.020085  3.862696  5.188746\n",
      "407     3.0   1.687135  3.862696  5.188746\n",
      "299     8.0   8.533763  3.862696  5.188746\n",
      "82      3.0   3.358286  3.862696  5.188746\n",
      "153     2.0  11.327948  3.862696  5.188746\n",
      "390     9.0   3.178687  3.862696  5.188746\n",
      "438     2.0   4.771689  3.862696  5.188746\n",
      "27      5.0   2.649613  3.862696  5.188746\n",
      "415     3.0   1.981018  3.862696  5.188746\n",
      "184     6.0  10.834573  3.862696  5.188746\n",
      "301    11.0   8.105191  3.862696  5.188746\n",
      "191     4.0   8.002157  3.862696  5.188746\n",
      "386     3.0   5.150704  3.862696  5.188746\n",
      "45     17.0  10.022103  3.862696  5.188746\n",
      "171     2.0   3.897211  3.862696  5.188746\n",
      "361     3.0   3.581493  3.862696  5.188746\n",
      "449     4.0   9.026402  3.862696  5.188746\n",
      "343     3.0   1.687135  3.862696  5.188746\n",
      "302     2.0   1.687135  3.862696  5.188746\n",
      "372     1.0   1.687135  3.862696  5.188746\n",
      "24     11.0   5.058449  3.862696  5.188746\n",
      "49     13.0  11.651689  3.862696  5.188746\n",
      "414     0.0   1.687135  3.862696  5.188746\n",
      "366     4.0   5.358702  3.862696  5.188746\n",
      "97     11.0   3.542848  3.862696  5.188746\n",
      "181     5.0   4.069144  3.862696  5.188746\n",
      "61      8.0  13.421164  3.862696  5.188746\n",
      "139     2.0   4.973615  3.862696  5.188746\n",
      "26     13.0   2.689316  3.862696  5.188746\n",
      "19      3.0   1.687135  3.862696  5.188746\n",
      "70      4.0   9.563773  3.862696  5.188746\n",
      "350     1.0   2.784653  3.501504  4.476115\n",
      "354     3.0   5.129920  3.501504  4.476115\n",
      "428     1.0   7.247088  3.501504  4.476115\n",
      "60      4.0   4.097467  3.501504  4.476115\n",
      "169     0.0   2.782004  3.501504  4.476115\n",
      "33     13.0   3.953829  3.501504  4.476115\n",
      "76      1.0   2.628747  3.501504  4.476115\n",
      "88     13.0  11.731638  3.501504  4.476115\n",
      "278     3.0   2.851728  3.501504  4.476115\n",
      "461     2.0   6.384640  3.501504  4.476115\n",
      "11      1.0   6.496214  3.501504  4.476115\n",
      "431     2.0   4.251795  3.501504  4.476115\n",
      "116     8.0   7.980133  3.501504  4.476115\n",
      "459     4.0   2.635340  3.501504  4.476115\n",
      "458     5.0   2.832117  3.501504  4.476115\n",
      "42      5.0   7.587408  3.501504  4.476115\n",
      "457     1.0   6.704340  3.501504  4.476115\n",
      "416     3.0   1.299875  3.501504  4.476115\n",
      "59      2.0   3.562887  3.501504  4.476115\n",
      "451     2.0   2.040933  3.501504  4.476115\n",
      "427     5.0   4.308400  3.501504  4.476115\n",
      "265     4.0   6.173707  3.501504  4.476115\n",
      "454     2.0   5.548502  3.501504  4.476115\n",
      "196    13.0   8.390527  3.501504  4.476115\n",
      "243     6.0   7.027575  3.501504  4.476115\n",
      "125     4.0   7.523382  3.501504  4.476115\n",
      "402     3.0   3.214816  3.501504  4.476115\n",
      "164     2.0   2.354213  3.501504  4.476115\n",
      "368     2.0   5.611076  3.501504  4.476115\n",
      "84      1.0   4.448490  3.501504  4.476115\n",
      "227    11.0   7.280579  3.501504  4.476115\n",
      "405     3.0   0.000000  3.501504  4.476115\n",
      "157    14.0  10.991062  3.501504  4.476115\n",
      "100    12.0   3.552956  3.501504  4.476115\n",
      "240     4.0  10.809170  3.501504  4.476115\n",
      "220     3.0   1.888583  3.501504  4.476115\n",
      "85      2.0   7.880326  3.501504  4.476115\n",
      "327     3.0   0.000000  3.501504  4.476115\n",
      "268     7.0   8.650244  3.501504  4.476115\n",
      "80      3.0   4.191617  3.501504  4.476115\n",
      "74      9.0  11.250998  3.501504  4.476115\n",
      "36     18.0   5.983810  3.501504  4.476115\n",
      "122     4.0   1.616562  3.501504  4.476115\n",
      "316    10.0   5.125601  3.501504  4.476115\n",
      "77     13.0   3.292278  3.501504  4.476115\n",
      "281     3.0   7.094939  3.501504  4.476115\n",
      "403     2.0   7.128234  3.501504  4.476115\n",
      "17      0.0   8.933863  3.501504  4.476115\n",
      "83      1.0   2.698722  3.501504  4.476115\n",
      "310     2.0   9.888256  3.501504  4.476115\n",
      "0       3.0   5.558107  3.501504  4.476115\n",
      "21     10.0   4.810026  3.501504  4.476115\n",
      "291    10.0   2.491346  3.501504  4.476115\n",
      "433     3.0   3.733736  3.501504  4.476115\n",
      "407     3.0   0.000000  3.501504  4.476115\n",
      "299     8.0  10.112536  3.501504  4.476115\n",
      "82      3.0   4.756792  3.501504  4.476115\n",
      "153     2.0  10.258613  3.501504  4.476115\n",
      "390     9.0   6.122887  3.501504  4.476115\n",
      "438     2.0   3.937989  3.501504  4.476115\n",
      "27      5.0   4.729424  3.501504  4.476115\n",
      "415     3.0   0.776965  3.501504  4.476115\n",
      "184     6.0  11.338772  3.501504  4.476115\n",
      "301    11.0   7.477905  3.501504  4.476115\n",
      "191     4.0   7.290979  3.501504  4.476115\n",
      "386     3.0   9.737528  3.501504  4.476115\n",
      "45     17.0   3.906467  3.501504  4.476115\n",
      "171     2.0   6.506115  3.501504  4.476115\n",
      "361     3.0   2.907116  3.501504  4.476115\n",
      "449     4.0   5.899569  3.501504  4.476115\n",
      "343     3.0   1.225440  3.501504  4.476115\n",
      "302     2.0   0.000000  3.501504  4.476115\n",
      "372     1.0   2.536079  3.501504  4.476115\n",
      "24     11.0   7.703397  3.501504  4.476115\n",
      "49     13.0   7.652536  3.501504  4.476115\n",
      "414     0.0   0.173476  3.501504  4.476115\n",
      "366     4.0   9.243383  3.501504  4.476115\n",
      "97     11.0   4.227344  3.501504  4.476115\n",
      "181     5.0   1.278734  3.501504  4.476115\n",
      "61      8.0  10.462318  3.501504  4.476115\n",
      "139     2.0   3.267335  3.501504  4.476115\n",
      "26     13.0   4.980765  3.501504  4.476115\n",
      "19      3.0   0.550346  3.501504  4.476115\n",
      "70      4.0   4.742480  3.501504  4.476115\n",
      "350     1.0   2.025293  3.275294  4.758720\n",
      "354     3.0   3.358297  3.275294  4.758720\n",
      "428     1.0   2.446033  3.275294  4.758720\n",
      "60      4.0   5.850859  3.275294  4.758720\n",
      "169     0.0   2.025293  3.275294  4.758720\n",
      "33     13.0   6.319893  3.275294  4.758720\n",
      "76      1.0   2.025293  3.275294  4.758720\n",
      "88     13.0   7.987098  3.275294  4.758720\n",
      "278     3.0   2.025293  3.275294  4.758720\n",
      "461     2.0   3.086999  3.275294  4.758720\n",
      "11      1.0   3.829977  3.275294  4.758720\n",
      "431     2.0   2.025293  3.275294  4.758720\n",
      "116     8.0   3.062342  3.275294  4.758720\n",
      "459     4.0   2.025293  3.275294  4.758720\n",
      "458     5.0   4.588948  3.275294  4.758720\n",
      "42      5.0   3.927441  3.275294  4.758720\n",
      "457     1.0   3.704193  3.275294  4.758720\n",
      "416     3.0   2.025293  3.275294  4.758720\n",
      "59      2.0   2.025293  3.275294  4.758720\n",
      "451     2.0   2.025293  3.275294  4.758720\n",
      "427     5.0   3.551837  3.275294  4.758720\n",
      "265     4.0   3.294795  3.275294  4.758720\n",
      "454     2.0   2.054739  3.275294  4.758720\n",
      "196    13.0   5.278318  3.275294  4.758720\n",
      "243     6.0   2.190735  3.275294  4.758720\n",
      "125     4.0   7.657413  3.275294  4.758720\n",
      "402     3.0   3.099315  3.275294  4.758720\n",
      "164     2.0   2.884444  3.275294  4.758720\n",
      "368     2.0   2.050029  3.275294  4.758720\n",
      "84      1.0   2.025293  3.275294  4.758720\n",
      "227    11.0   3.059222  3.275294  4.758720\n",
      "405     3.0   2.025293  3.275294  4.758720\n",
      "157    14.0   3.911602  3.275294  4.758720\n",
      "100    12.0   2.279412  3.275294  4.758720\n",
      "240     4.0   7.813217  3.275294  4.758720\n",
      "220     3.0   2.756818  3.275294  4.758720\n",
      "85      2.0   3.398181  3.275294  4.758720\n",
      "327     3.0   2.025293  3.275294  4.758720\n",
      "268     7.0  12.336645  3.275294  4.758720\n",
      "80      3.0   2.205549  3.275294  4.758720\n",
      "74      9.0   6.842505  3.275294  4.758720\n",
      "36     18.0   2.025293  3.275294  4.758720\n",
      "122     4.0   2.218587  3.275294  4.758720\n",
      "316    10.0   2.238220  3.275294  4.758720\n",
      "77     13.0   2.025293  3.275294  4.758720\n",
      "281     3.0   3.253457  3.275294  4.758720\n",
      "403     2.0   6.263663  3.275294  4.758720\n",
      "17      0.0   7.761982  3.275294  4.758720\n",
      "83      1.0   2.025293  3.275294  4.758720\n",
      "310     2.0   5.120478  3.275294  4.758720\n",
      "0       3.0   2.544831  3.275294  4.758720\n",
      "21     10.0   3.404087  3.275294  4.758720\n",
      "291    10.0   2.385473  3.275294  4.758720\n",
      "433     3.0   2.130789  3.275294  4.758720\n",
      "407     3.0   2.025293  3.275294  4.758720\n",
      "299     8.0   6.647284  3.275294  4.758720\n",
      "82      3.0   2.724472  3.275294  4.758720\n",
      "153     2.0   8.657368  3.275294  4.758720\n",
      "390     9.0   2.687428  3.275294  4.758720\n",
      "438     2.0   5.783848  3.275294  4.758720\n",
      "27      5.0   3.055422  3.275294  4.758720\n",
      "415     3.0   2.092655  3.275294  4.758720\n",
      "184     6.0  13.964875  3.275294  4.758720\n",
      "301    11.0   5.243894  3.275294  4.758720\n",
      "191     4.0   2.834341  3.275294  4.758720\n",
      "386     3.0   4.725033  3.275294  4.758720\n",
      "45     17.0   2.745402  3.275294  4.758720\n",
      "171     2.0   5.487752  3.275294  4.758720\n",
      "361     3.0   2.476252  3.275294  4.758720\n",
      "449     4.0   5.098725  3.275294  4.758720\n",
      "343     3.0   2.025293  3.275294  4.758720\n",
      "302     2.0   2.025293  3.275294  4.758720\n",
      "372     1.0   2.025293  3.275294  4.758720\n",
      "24     11.0   4.559854  3.275294  4.758720\n",
      "49     13.0   7.361681  3.275294  4.758720\n",
      "414     0.0   2.025293  3.275294  4.758720\n",
      "366     4.0   6.778197  3.275294  4.758720\n",
      "97     11.0   2.575288  3.275294  4.758720\n",
      "181     5.0   2.275057  3.275294  4.758720\n",
      "61      8.0  12.999094  3.275294  4.758720\n",
      "139     2.0   2.025293  3.275294  4.758720\n",
      "26     13.0   2.117321  3.275294  4.758720\n",
      "19      3.0   2.025293  3.275294  4.758720\n",
      "70      4.0   6.184125  3.275294  4.758720\n",
      "350     1.0   4.220318  3.450295  4.292084\n",
      "354     3.0   4.964116  3.450295  4.292084\n",
      "428     1.0   3.965595  3.450295  4.292084\n",
      "60      4.0   5.784883  3.450295  4.292084\n",
      "169     0.0   4.310940  3.450295  4.292084\n",
      "33     13.0   5.984773  3.450295  4.292084\n",
      "76      1.0   1.161589  3.450295  4.292084\n",
      "88     13.0  11.005641  3.450295  4.292084\n",
      "278     3.0   2.425127  3.450295  4.292084\n",
      "461     2.0   7.298203  3.450295  4.292084\n",
      "11      1.0   6.152826  3.450295  4.292084\n",
      "431     2.0   4.694133  3.450295  4.292084\n",
      "116     8.0   8.463523  3.450295  4.292084\n",
      "459     4.0   3.066012  3.450295  4.292084\n",
      "458     5.0   5.213112  3.450295  4.292084\n",
      "42      5.0   7.996249  3.450295  4.292084\n",
      "457     1.0   6.341406  3.450295  4.292084\n",
      "416     3.0   2.190259  3.450295  4.292084\n",
      "59      2.0   4.787702  3.450295  4.292084\n",
      "451     2.0   1.176197  3.450295  4.292084\n",
      "427     5.0   5.941863  3.450295  4.292084\n",
      "265     4.0   5.430275  3.450295  4.292084\n",
      "454     2.0   6.761756  3.450295  4.292084\n",
      "196    13.0   7.891234  3.450295  4.292084\n",
      "243     6.0   5.642626  3.450295  4.292084\n",
      "125     4.0   7.712478  3.450295  4.292084\n",
      "402     3.0   2.978565  3.450295  4.292084\n",
      "164     2.0   4.321066  3.450295  4.292084\n",
      "368     2.0   7.047143  3.450295  4.292084\n",
      "84      1.0   6.462844  3.450295  4.292084\n",
      "227    11.0   4.647635  3.450295  4.292084\n",
      "405     3.0   4.473924  3.450295  4.292084\n",
      "157    14.0   7.700943  3.450295  4.292084\n",
      "100    12.0   4.088644  3.450295  4.292084\n",
      "240     4.0   8.166626  3.450295  4.292084\n",
      "220     3.0   4.068466  3.450295  4.292084\n",
      "85      2.0  10.076582  3.450295  4.292084\n",
      "327     3.0   0.922825  3.450295  4.292084\n",
      "268     7.0  10.074212  3.450295  4.292084\n",
      "80      3.0   2.976349  3.450295  4.292084\n",
      "74      9.0   9.587880  3.450295  4.292084\n",
      "36     18.0   7.000432  3.450295  4.292084\n",
      "122     4.0   3.110832  3.450295  4.292084\n",
      "316    10.0   6.234076  3.450295  4.292084\n",
      "77     13.0   4.396867  3.450295  4.292084\n",
      "281     3.0   6.708161  3.450295  4.292084\n",
      "403     2.0   4.565903  3.450295  4.292084\n",
      "17      0.0   9.054264  3.450295  4.292084\n",
      "83      1.0   3.852710  3.450295  4.292084\n",
      "310     2.0   9.439057  3.450295  4.292084\n",
      "0       3.0   6.206289  3.450295  4.292084\n",
      "21     10.0   5.802173  3.450295  4.292084\n",
      "291    10.0   2.436900  3.450295  4.292084\n",
      "433     3.0   4.786157  3.450295  4.292084\n",
      "407     3.0   0.000000  3.450295  4.292084\n",
      "299     8.0   9.910275  3.450295  4.292084\n",
      "82      3.0   6.085956  3.450295  4.292084\n",
      "153     2.0  10.531728  3.450295  4.292084\n",
      "390     9.0   6.883324  3.450295  4.292084\n",
      "438     2.0   3.707451  3.450295  4.292084\n",
      "27      5.0   3.938213  3.450295  4.292084\n",
      "415     3.0   2.446106  3.450295  4.292084\n",
      "184     6.0  11.095568  3.450295  4.292084\n",
      "301    11.0   6.824645  3.450295  4.292084\n",
      "191     4.0   6.793008  3.450295  4.292084\n",
      "386     3.0   8.268085  3.450295  4.292084\n",
      "45     17.0   5.599657  3.450295  4.292084\n",
      "171     2.0   4.978946  3.450295  4.292084\n",
      "361     3.0   7.244969  3.450295  4.292084\n",
      "449     4.0   6.736568  3.450295  4.292084\n",
      "343     3.0   1.177080  3.450295  4.292084\n",
      "302     2.0   0.000000  3.450295  4.292084\n",
      "372     1.0   3.725341  3.450295  4.292084\n",
      "24     11.0   9.575926  3.450295  4.292084\n",
      "49     13.0   8.915966  3.450295  4.292084\n",
      "414     0.0   0.583404  3.450295  4.292084\n",
      "366     4.0   7.360528  3.450295  4.292084\n",
      "97     11.0   4.154851  3.450295  4.292084\n",
      "181     5.0   2.317770  3.450295  4.292084\n",
      "61      8.0  11.184667  3.450295  4.292084\n",
      "139     2.0   4.109072  3.450295  4.292084\n",
      "26     13.0   6.848221  3.450295  4.292084\n",
      "19      3.0   0.539199  3.450295  4.292084\n",
      "70      4.0   5.316004  3.450295  4.292084\n",
      "\n",
      "Best Model Parameters:\n",
      "{'n_units': 128, 'learning_rate': 0.001, 'dropout_rate': 0.5, 'activation': 'tanh'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.1725497259980155, 4.020699754026451)"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7\n",
    "#split\n",
    "#1차+2차\n",
    "#data\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "    'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\", \n",
    "    \"2P_totals\", \"2PA_totals\", \"2P%_totals\", \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \n",
    "    \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\", \n",
    "    \"AST_totals\", \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",  \n",
    "     \"TS%_advanced\", \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",  \n",
    "     \"TRB%_advanced\", \"AST%_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\", \"USG%_advanced\", \n",
    "    \"OWS_advanced\",  \"WS_advanced\", \"PER_advanced\", \n",
    "    \"FG_per_poss\", \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\", \n",
    "    \"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \"AST_per_poss\", \n",
    "    \"STL_per_poss\", \"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \n",
    "    \"ORtg_per_poss\"]\n",
    "\n",
    "# 결측치 추정에서 낮은 결정계수를 보였던 피처들\n",
    "# ORB%_advanced\n",
    "# DRB%_advanced\n",
    "# OBPM_advanced\n",
    "# DBPM_advanced\n",
    "# BPM_advanced\n",
    "# DWS_advanced\n",
    "# WS/40_advanced\n",
    "# DRtg_per_poss\n",
    "target_column = 'Experience'\n",
    "\n",
    "# # 데이터 준비\n",
    "# X = merged_all_comb_copy_model[feature_columns]\n",
    "# y = merged_all_comb_copy_model[target_column]\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 구축 및 컴파일 함수\n",
    "def build_model(n_units, learning_rate, dropout_rate, activation):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(n_units, activation=activation, input_shape=(X_train_scaled.shape[1],)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "n_units_options = [64, 128]\n",
    "learning_rate_options = [0.001, 0.01]\n",
    "dropout_rate_options = [0.3, 0.5]\n",
    "activation_options = ['relu', 'tanh']\n",
    "\n",
    "best_model = None\n",
    "best_mae = float('inf')\n",
    "best_rmse = float('inf')\n",
    "best_model_params = None\n",
    "results_table = pd.DataFrame()\n",
    "\n",
    "# 하이퍼파라미터 실험 및 모델 평가\n",
    "for n_units in n_units_options:\n",
    "    for learning_rate in learning_rate_options:\n",
    "        for dropout_rate in dropout_rate_options:\n",
    "            for activation in activation_options:\n",
    "                model = build_model(n_units, learning_rate, dropout_rate, activation)\n",
    "                model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "                y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "                y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "                # 평가 지표 계산\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "\n",
    "                # 최적 모델 업데이트\n",
    "                if mae + rmse < best_mae + best_rmse:\n",
    "                    best_model = model\n",
    "                    best_mae = mae\n",
    "                    best_rmse = rmse\n",
    "                    best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "                # 결과 추가\n",
    "                temp_results = pd.DataFrame({\n",
    "                    'Actual': y_test,\n",
    "                    'Predicted': y_pred,\n",
    "                    'MAE': mae,\n",
    "                    'RMSE': rmse\n",
    "                })\n",
    "                results_table = pd.concat([results_table, temp_results])\n",
    "\n",
    "# 최적 모델의 결과와 파라미터 출력\n",
    "print(\"Best Model Results:\")\n",
    "print(results_table)\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model_params)\n",
    "\n",
    "# 최적 모델의 결과에서 가장 좋은 MAE와 RMSE 값 찾기\n",
    "best_mae = results_table['MAE'].min()\n",
    "best_rmse = results_table['RMSE'].min()\n",
    "\n",
    "best_mae, best_rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "b02a29b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Best Model Results:\n",
      "     Actual  Predicted       MAE      RMSE\n",
      "170     6.0   2.246661  4.120540  5.322806\n",
      "322     1.0   2.336194  4.120540  5.322806\n",
      "457     1.0   4.464988  4.120540  5.322806\n",
      "104    14.0   8.192533  4.120540  5.322806\n",
      "75     15.0   3.482856  4.120540  5.322806\n",
      "441     1.0   2.601148  4.120540  5.322806\n",
      "408     1.0   2.000909  4.120540  5.322806\n",
      "239     0.0  10.758185  4.120540  5.322806\n",
      "42      5.0   5.209866  4.120540  5.322806\n",
      "60      4.0   4.759368  4.120540  5.322806\n",
      "280     1.0   1.456398  4.120540  5.322806\n",
      "461     2.0   5.700718  4.120540  5.322806\n",
      "327     3.0   2.184870  4.120540  5.322806\n",
      "33     13.0   6.258420  4.120540  5.322806\n",
      "449     4.0   8.679972  4.120540  5.322806\n",
      "314     7.0   6.472609  4.120540  5.322806\n",
      "123    13.0   5.574131  4.120540  5.322806\n",
      "242     6.0   3.210855  4.120540  5.322806\n",
      "354     3.0   7.107264  4.120540  5.322806\n",
      "77     13.0   9.654684  4.120540  5.322806\n",
      "91     15.0   8.638810  4.120540  5.322806\n",
      "438     2.0   5.270238  4.120540  5.322806\n",
      "433     3.0   7.494299  4.120540  5.322806\n",
      "357     7.0   6.212989  4.120540  5.322806\n",
      "339     6.0   2.320063  4.120540  5.322806\n",
      "98     13.0   9.388872  4.120540  5.322806\n",
      "11      1.0  10.563088  4.120540  5.322806\n",
      "117    15.0   2.156644  4.120540  5.322806\n",
      "382     5.0   4.743574  4.120540  5.322806\n",
      "83      1.0   3.297942  4.120540  5.322806\n",
      "202    14.0   3.286225  4.120540  5.322806\n",
      "84      1.0   3.109910  4.120540  5.322806\n",
      "61      8.0  10.616630  4.120540  5.322806\n",
      "229     1.0   9.303867  4.120540  5.322806\n",
      "454     2.0   4.048304  4.120540  5.322806\n",
      "381     5.0   6.843301  4.120540  5.322806\n",
      "78      2.0   2.256495  4.120540  5.322806\n",
      "267     9.0  11.153662  4.120540  5.322806\n",
      "36     18.0   3.348509  4.120540  5.322806\n",
      "459     4.0   2.223261  4.120540  5.322806\n",
      "343     3.0   1.372317  4.120540  5.322806\n",
      "458     5.0   2.572704  4.120540  5.322806\n",
      "247    10.0   5.011209  4.120540  5.322806\n",
      "416     3.0   1.557687  4.120540  5.322806\n",
      "17      0.0   3.314433  4.120540  5.322806\n",
      "141    11.0   4.532133  4.120540  5.322806\n",
      "126    15.0   6.641645  4.120540  5.322806\n",
      "0       3.0   2.258870  4.120540  5.322806\n",
      "21     10.0   2.718197  4.120540  5.322806\n",
      "291    10.0   5.609403  4.120540  5.322806\n",
      "300     2.0   6.606970  4.120540  5.322806\n",
      "183     7.0   6.181640  4.120540  5.322806\n",
      "406     2.0   1.494880  4.120540  5.322806\n",
      "163     3.0   7.174809  4.120540  5.322806\n",
      "86      9.0   4.420794  4.120540  5.322806\n",
      "390     9.0   3.821512  4.120540  5.322806\n",
      "158     1.0   2.587594  4.120540  5.322806\n",
      "27      5.0   6.522611  4.120540  5.322806\n",
      "415     3.0   2.760592  4.120540  5.322806\n",
      "194     9.0   5.292659  4.120540  5.322806\n",
      "301    11.0   4.392646  4.120540  5.322806\n",
      "419     1.0   2.555762  4.120540  5.322806\n",
      "259     2.0   5.383621  4.120540  5.322806\n",
      "85      2.0   3.218479  4.120540  5.322806\n",
      "45     17.0   2.573941  4.120540  5.322806\n",
      "270    13.0   5.172853  4.120540  5.322806\n",
      "89     13.0   6.105114  4.120540  5.322806\n",
      "397     2.0   3.473035  4.120540  5.322806\n",
      "319     0.0   4.608526  4.120540  5.322806\n",
      "159    10.0   3.807465  4.120540  5.322806\n",
      "293     2.0   3.317404  4.120540  5.322806\n",
      "24     11.0   7.250298  4.120540  5.322806\n",
      "49     13.0   6.742011  4.120540  5.322806\n",
      "304     8.0   3.180162  4.120540  5.322806\n",
      "405     3.0   1.910532  4.120540  5.322806\n",
      "451     2.0   2.212116  4.120540  5.322806\n",
      "269    10.0   7.216287  4.120540  5.322806\n",
      "62     14.0   5.676723  4.120540  5.322806\n",
      "139     2.0   2.397983  4.120540  5.322806\n",
      "26     13.0   4.699579  4.120540  5.322806\n",
      "19      3.0   0.716204  4.120540  5.322806\n",
      "71      4.0   1.927923  4.120540  5.322806\n",
      "186    11.0  18.335249  4.120540  5.322806\n",
      "34     13.0   6.401453  4.120540  5.322806\n",
      "170     6.0   1.703367  3.938445  4.936259\n",
      "322     1.0   3.408864  3.938445  4.936259\n",
      "457     1.0   6.408386  3.938445  4.936259\n",
      "104    14.0   7.721548  3.938445  4.936259\n",
      "75     15.0  10.056231  3.938445  4.936259\n",
      "441     1.0   2.986539  3.938445  4.936259\n",
      "408     1.0   5.950266  3.938445  4.936259\n",
      "239     0.0   8.991076  3.938445  4.936259\n",
      "42      5.0   5.501713  3.938445  4.936259\n",
      "60      4.0   6.497742  3.938445  4.936259\n",
      "280     1.0   0.000000  3.938445  4.936259\n",
      "461     2.0   5.161563  3.938445  4.936259\n",
      "327     3.0   0.000000  3.938445  4.936259\n",
      "33     13.0   4.515649  3.938445  4.936259\n",
      "449     4.0   6.506231  3.938445  4.936259\n",
      "314     7.0   7.343084  3.938445  4.936259\n",
      "123    13.0   5.030812  3.938445  4.936259\n",
      "242     6.0   4.462236  3.938445  4.936259\n",
      "354     3.0   3.803193  3.938445  4.936259\n",
      "77     13.0   4.797069  3.938445  4.936259\n",
      "91     15.0   7.760365  3.938445  4.936259\n",
      "438     2.0   4.153745  3.938445  4.936259\n",
      "433     3.0   3.883221  3.938445  4.936259\n",
      "357     7.0   3.721195  3.938445  4.936259\n",
      "339     6.0   2.542739  3.938445  4.936259\n",
      "98     13.0   9.740445  3.938445  4.936259\n",
      "11      1.0   6.708892  3.938445  4.936259\n",
      "117    15.0   2.863857  3.938445  4.936259\n",
      "382     5.0   5.420628  3.938445  4.936259\n",
      "83      1.0   3.709612  3.938445  4.936259\n",
      "202    14.0   3.599844  3.938445  4.936259\n",
      "84      1.0   8.742796  3.938445  4.936259\n",
      "61      8.0   7.338323  3.938445  4.936259\n",
      "229     1.0   2.796282  3.938445  4.936259\n",
      "454     2.0   4.594209  3.938445  4.936259\n",
      "381     5.0   6.014464  3.938445  4.936259\n",
      "78      2.0   0.904199  3.938445  4.936259\n",
      "267     9.0   8.155441  3.938445  4.936259\n",
      "36     18.0   7.452505  3.938445  4.936259\n",
      "459     4.0   1.407857  3.938445  4.936259\n",
      "343     3.0   2.051526  3.938445  4.936259\n",
      "458     5.0   1.367868  3.938445  4.936259\n",
      "247    10.0   4.137363  3.938445  4.936259\n",
      "416     3.0   1.002473  3.938445  4.936259\n",
      "17      0.0   4.870624  3.938445  4.936259\n",
      "141    11.0   4.673329  3.938445  4.936259\n",
      "126    15.0   9.471960  3.938445  4.936259\n",
      "0       3.0   4.933616  3.938445  4.936259\n",
      "21     10.0   4.910019  3.938445  4.936259\n",
      "291    10.0   4.595452  3.938445  4.936259\n",
      "300     2.0   5.371088  3.938445  4.936259\n",
      "183     7.0   5.260307  3.938445  4.936259\n",
      "406     2.0   3.185477  3.938445  4.936259\n",
      "163     3.0   5.002779  3.938445  4.936259\n",
      "86      9.0   7.089678  3.938445  4.936259\n",
      "390     9.0   5.866052  3.938445  4.936259\n",
      "158     1.0   0.000000  3.938445  4.936259\n",
      "27      5.0   4.466148  3.938445  4.936259\n",
      "415     3.0   2.343072  3.938445  4.936259\n",
      "194     9.0   4.087131  3.938445  4.936259\n",
      "301    11.0   4.867970  3.938445  4.936259\n",
      "419     1.0   2.285925  3.938445  4.936259\n",
      "259     2.0   5.417150  3.938445  4.936259\n",
      "85      2.0   5.851087  3.938445  4.936259\n",
      "45     17.0   3.596745  3.938445  4.936259\n",
      "270    13.0   8.550055  3.938445  4.936259\n",
      "89     13.0   5.073476  3.938445  4.936259\n",
      "397     2.0   6.117916  3.938445  4.936259\n",
      "319     0.0   7.125943  3.938445  4.936259\n",
      "159    10.0   4.270272  3.938445  4.936259\n",
      "293     2.0   4.096796  3.938445  4.936259\n",
      "24     11.0   6.437308  3.938445  4.936259\n",
      "49     13.0   6.690546  3.938445  4.936259\n",
      "304     8.0   9.630593  3.938445  4.936259\n",
      "405     3.0   5.653629  3.938445  4.936259\n",
      "451     2.0   0.136345  3.938445  4.936259\n",
      "269    10.0   7.253703  3.938445  4.936259\n",
      "62     14.0   4.807333  3.938445  4.936259\n",
      "139     2.0   2.660092  3.938445  4.936259\n",
      "26     13.0   7.998270  3.938445  4.936259\n",
      "19      3.0   1.877667  3.938445  4.936259\n",
      "71      4.0   1.440714  3.938445  4.936259\n",
      "186    11.0  10.150002  3.938445  4.936259\n",
      "34     13.0   2.709397  3.938445  4.936259\n",
      "170     6.0   1.220727  4.351525  5.553676\n",
      "322     1.0   4.158093  4.351525  5.553676\n",
      "457     1.0   5.883695  4.351525  5.553676\n",
      "104    14.0   4.638981  4.351525  5.553676\n",
      "75     15.0   4.798858  4.351525  5.553676\n",
      "441     1.0   3.806360  4.351525  5.553676\n",
      "408     1.0   3.225323  4.351525  5.553676\n",
      "239     0.0  10.885801  4.351525  5.553676\n",
      "42      5.0   3.376647  4.351525  5.553676\n",
      "60      4.0   8.844968  4.351525  5.553676\n",
      "280     1.0   1.290051  4.351525  5.553676\n",
      "461     2.0   6.421929  4.351525  5.553676\n",
      "327     3.0   1.257172  4.351525  5.553676\n",
      "33     13.0   7.078346  4.351525  5.553676\n",
      "449     4.0   5.769743  4.351525  5.553676\n",
      "314     7.0   5.047565  4.351525  5.553676\n",
      "123    13.0   3.252074  4.351525  5.553676\n",
      "242     6.0   1.672872  4.351525  5.553676\n",
      "354     3.0   4.120786  4.351525  5.553676\n",
      "77     13.0   7.005970  4.351525  5.553676\n",
      "91     15.0   4.831311  4.351525  5.553676\n",
      "438     2.0   4.797578  4.351525  5.553676\n",
      "433     3.0   3.431141  4.351525  5.553676\n",
      "357     7.0   3.423294  4.351525  5.553676\n",
      "339     6.0   1.763844  4.351525  5.553676\n",
      "98     13.0   6.628659  4.351525  5.553676\n",
      "11      1.0  10.807411  4.351525  5.553676\n",
      "117    15.0   3.641276  4.351525  5.553676\n",
      "382     5.0   3.742505  4.351525  5.553676\n",
      "83      1.0   2.708525  4.351525  5.553676\n",
      "202    14.0   2.622399  4.351525  5.553676\n",
      "84      1.0   3.789893  4.351525  5.553676\n",
      "61      8.0   7.739867  4.351525  5.553676\n",
      "229     1.0   3.680184  4.351525  5.553676\n",
      "454     2.0   5.142386  4.351525  5.553676\n",
      "381     5.0   4.078147  4.351525  5.553676\n",
      "78      2.0   1.831060  4.351525  5.553676\n",
      "267     9.0   9.924141  4.351525  5.553676\n",
      "36     18.0   7.566297  4.351525  5.553676\n",
      "459     4.0   2.653637  4.351525  5.553676\n",
      "343     3.0   1.107121  4.351525  5.553676\n",
      "458     5.0   6.655781  4.351525  5.553676\n",
      "247    10.0   6.109843  4.351525  5.553676\n",
      "416     3.0   0.823033  4.351525  5.553676\n",
      "17      0.0   6.109252  4.351525  5.553676\n",
      "141    11.0   3.215631  4.351525  5.553676\n",
      "126    15.0   6.252160  4.351525  5.553676\n",
      "0       3.0   2.078861  4.351525  5.553676\n",
      "21     10.0   4.059189  4.351525  5.553676\n",
      "291    10.0   4.014993  4.351525  5.553676\n",
      "300     2.0   5.091692  4.351525  5.553676\n",
      "183     7.0   7.402798  4.351525  5.553676\n",
      "406     2.0   1.273322  4.351525  5.553676\n",
      "163     3.0   8.097743  4.351525  5.553676\n",
      "86      9.0   5.543871  4.351525  5.553676\n",
      "390     9.0   5.194168  4.351525  5.553676\n",
      "158     1.0   1.941125  4.351525  5.553676\n",
      "27      5.0   3.610688  4.351525  5.553676\n",
      "415     3.0   4.755834  4.351525  5.553676\n",
      "194     9.0   2.669371  4.351525  5.553676\n",
      "301    11.0   3.664536  4.351525  5.553676\n",
      "419     1.0   1.790251  4.351525  5.553676\n",
      "259     2.0   7.897242  4.351525  5.553676\n",
      "85      2.0   2.474941  4.351525  5.553676\n",
      "45     17.0   2.384355  4.351525  5.553676\n",
      "270    13.0   4.547253  4.351525  5.553676\n",
      "89     13.0   3.250890  4.351525  5.553676\n",
      "397     2.0   5.599274  4.351525  5.553676\n",
      "319     0.0   3.269544  4.351525  5.553676\n",
      "159    10.0   3.366694  4.351525  5.553676\n",
      "293     2.0   2.158010  4.351525  5.553676\n",
      "24     11.0   6.921161  4.351525  5.553676\n",
      "49     13.0   7.808399  4.351525  5.553676\n",
      "304     8.0   2.060142  4.351525  5.553676\n",
      "405     3.0   3.007971  4.351525  5.553676\n",
      "451     2.0   1.579873  4.351525  5.553676\n",
      "269    10.0   5.513202  4.351525  5.553676\n",
      "62     14.0   3.222095  4.351525  5.553676\n",
      "139     2.0   1.674073  4.351525  5.553676\n",
      "26     13.0   3.617688  4.351525  5.553676\n",
      "19      3.0   1.540540  4.351525  5.553676\n",
      "71      4.0   1.635123  4.351525  5.553676\n",
      "186    11.0  14.032278  4.351525  5.553676\n",
      "34     13.0   5.833868  4.351525  5.553676\n",
      "170     6.0   1.726467  3.981484  5.049163\n",
      "322     1.0   2.540989  3.981484  5.049163\n",
      "457     1.0   9.636731  3.981484  5.049163\n",
      "104    14.0   7.189744  3.981484  5.049163\n",
      "75     15.0   9.467470  3.981484  5.049163\n",
      "441     1.0   3.921633  3.981484  5.049163\n",
      "408     1.0   6.320467  3.981484  5.049163\n",
      "239     0.0   8.119096  3.981484  5.049163\n",
      "42      5.0   5.492058  3.981484  5.049163\n",
      "60      4.0   6.036557  3.981484  5.049163\n",
      "280     1.0   2.016335  3.981484  5.049163\n",
      "461     2.0   4.137936  3.981484  5.049163\n",
      "327     3.0   0.216760  3.981484  5.049163\n",
      "33     13.0   4.798925  3.981484  5.049163\n",
      "449     4.0   7.127340  3.981484  5.049163\n",
      "314     7.0   6.057221  3.981484  5.049163\n",
      "123    13.0   5.187251  3.981484  5.049163\n",
      "242     6.0   3.783768  3.981484  5.049163\n",
      "354     3.0   4.918881  3.981484  5.049163\n",
      "77     13.0   4.427949  3.981484  5.049163\n",
      "91     15.0   6.578485  3.981484  5.049163\n",
      "438     2.0   3.929973  3.981484  5.049163\n",
      "433     3.0   2.984114  3.981484  5.049163\n",
      "357     7.0   2.116591  3.981484  5.049163\n",
      "339     6.0   2.750437  3.981484  5.049163\n",
      "98     13.0   9.136503  3.981484  5.049163\n",
      "11      1.0   6.329621  3.981484  5.049163\n",
      "117    15.0   3.519310  3.981484  5.049163\n",
      "382     5.0   5.058866  3.981484  5.049163\n",
      "83      1.0   3.700585  3.981484  5.049163\n",
      "202    14.0   3.255583  3.981484  5.049163\n",
      "84      1.0   8.063056  3.981484  5.049163\n",
      "61      8.0   6.788811  3.981484  5.049163\n",
      "229     1.0   2.398356  3.981484  5.049163\n",
      "454     2.0   6.261889  3.981484  5.049163\n",
      "381     5.0   3.041954  3.981484  5.049163\n",
      "78      2.0   3.471553  3.981484  5.049163\n",
      "267     9.0   7.004265  3.981484  5.049163\n",
      "36     18.0   5.716163  3.981484  5.049163\n",
      "459     4.0   3.371226  3.981484  5.049163\n",
      "343     3.0   0.002603  3.981484  5.049163\n",
      "458     5.0   1.872401  3.981484  5.049163\n",
      "247    10.0   5.611051  3.981484  5.049163\n",
      "416     3.0   0.000000  3.981484  5.049163\n",
      "17      0.0   5.055286  3.981484  5.049163\n",
      "141    11.0   4.161540  3.981484  5.049163\n",
      "126    15.0   8.705301  3.981484  5.049163\n",
      "0       3.0   2.713516  3.981484  5.049163\n",
      "21     10.0   3.923389  3.981484  5.049163\n",
      "291    10.0   6.121058  3.981484  5.049163\n",
      "300     2.0   7.582736  3.981484  5.049163\n",
      "183     7.0   6.569605  3.981484  5.049163\n",
      "406     2.0   3.736300  3.981484  5.049163\n",
      "163     3.0   7.360142  3.981484  5.049163\n",
      "86      9.0   8.778620  3.981484  5.049163\n",
      "390     9.0   7.547709  3.981484  5.049163\n",
      "158     1.0   0.479160  3.981484  5.049163\n",
      "27      5.0   7.351787  3.981484  5.049163\n",
      "415     3.0   1.185474  3.981484  5.049163\n",
      "194     9.0   4.533056  3.981484  5.049163\n",
      "301    11.0   6.306832  3.981484  5.049163\n",
      "419     1.0   0.000000  3.981484  5.049163\n",
      "259     2.0   3.261449  3.981484  5.049163\n",
      "85      2.0   5.393585  3.981484  5.049163\n",
      "45     17.0   3.041432  3.981484  5.049163\n",
      "270    13.0   9.412210  3.981484  5.049163\n",
      "89     13.0   5.505005  3.981484  5.049163\n",
      "397     2.0   6.793372  3.981484  5.049163\n",
      "319     0.0   3.506953  3.981484  5.049163\n",
      "159    10.0   2.775043  3.981484  5.049163\n",
      "293     2.0   4.342302  3.981484  5.049163\n",
      "24     11.0   5.263144  3.981484  5.049163\n",
      "49     13.0   6.461791  3.981484  5.049163\n",
      "304     8.0   8.590816  3.981484  5.049163\n",
      "405     3.0   2.991171  3.981484  5.049163\n",
      "451     2.0   0.768051  3.981484  5.049163\n",
      "269    10.0   7.836441  3.981484  5.049163\n",
      "62     14.0   6.256911  3.981484  5.049163\n",
      "139     2.0   2.222878  3.981484  5.049163\n",
      "26     13.0   6.493461  3.981484  5.049163\n",
      "19      3.0   0.000000  3.981484  5.049163\n",
      "71      4.0   2.963110  3.981484  5.049163\n",
      "186    11.0   8.847467  3.981484  5.049163\n",
      "34     13.0   2.989346  3.981484  5.049163\n",
      "170     6.0   1.991280  4.251169  5.645417\n",
      "322     1.0   2.529428  4.251169  5.645417\n",
      "457     1.0   6.138141  4.251169  5.645417\n",
      "104    14.0   7.563178  4.251169  5.645417\n",
      "75     15.0   7.090814  4.251169  5.645417\n",
      "441     1.0   2.924716  4.251169  5.645417\n",
      "408     1.0   4.021443  4.251169  5.645417\n",
      "239     0.0   9.214370  4.251169  5.645417\n",
      "42      5.0   6.136304  4.251169  5.645417\n",
      "60      4.0   2.880185  4.251169  5.645417\n",
      "280     1.0   1.991280  4.251169  5.645417\n",
      "461     2.0   6.634693  4.251169  5.645417\n",
      "327     3.0   1.991280  4.251169  5.645417\n",
      "33     13.0   1.991280  4.251169  5.645417\n",
      "449     4.0   5.949170  4.251169  5.645417\n",
      "314     7.0   2.948315  4.251169  5.645417\n",
      "123    13.0   1.991280  4.251169  5.645417\n",
      "242     6.0   1.687816  4.251169  5.645417\n",
      "354     3.0   1.991280  4.251169  5.645417\n",
      "77     13.0   4.883015  4.251169  5.645417\n",
      "91     15.0   2.407586  4.251169  5.645417\n",
      "438     2.0   1.991280  4.251169  5.645417\n",
      "433     3.0   2.477116  4.251169  5.645417\n",
      "357     7.0   1.991280  4.251169  5.645417\n",
      "339     6.0   1.991280  4.251169  5.645417\n",
      "98     13.0   5.118667  4.251169  5.645417\n",
      "11      1.0   3.851456  4.251169  5.645417\n",
      "117    15.0   2.178119  4.251169  5.645417\n",
      "382     5.0   3.452431  4.251169  5.645417\n",
      "83      1.0   1.991280  4.251169  5.645417\n",
      "202    14.0   1.767264  4.251169  5.645417\n",
      "84      1.0   5.381599  4.251169  5.645417\n",
      "61      8.0  10.574505  4.251169  5.645417\n",
      "229     1.0   1.974032  4.251169  5.645417\n",
      "454     2.0   3.163013  4.251169  5.645417\n",
      "381     5.0   6.723696  4.251169  5.645417\n",
      "78      2.0   1.991280  4.251169  5.645417\n",
      "267     9.0   8.313637  4.251169  5.645417\n",
      "36     18.0   5.074485  4.251169  5.645417\n",
      "459     4.0   1.913765  4.251169  5.645417\n",
      "343     3.0   1.991280  4.251169  5.645417\n",
      "458     5.0   1.991280  4.251169  5.645417\n",
      "247    10.0   5.531301  4.251169  5.645417\n",
      "416     3.0   1.991280  4.251169  5.645417\n",
      "17      0.0   1.991280  4.251169  5.645417\n",
      "141    11.0   1.854874  4.251169  5.645417\n",
      "126    15.0   6.897652  4.251169  5.645417\n",
      "0       3.0   2.113108  4.251169  5.645417\n",
      "21     10.0   1.991280  4.251169  5.645417\n",
      "291    10.0   4.888667  4.251169  5.645417\n",
      "300     2.0   4.796287  4.251169  5.645417\n",
      "183     7.0   6.701547  4.251169  5.645417\n",
      "406     2.0   4.284250  4.251169  5.645417\n",
      "163     3.0   4.613137  4.251169  5.645417\n",
      "86      9.0   5.290793  4.251169  5.645417\n",
      "390     9.0   4.315226  4.251169  5.645417\n",
      "158     1.0   1.991280  4.251169  5.645417\n",
      "27      5.0   3.003241  4.251169  5.645417\n",
      "415     3.0   1.991280  4.251169  5.645417\n",
      "194     9.0   2.810631  4.251169  5.645417\n",
      "301    11.0   3.245853  4.251169  5.645417\n",
      "419     1.0   1.991280  4.251169  5.645417\n",
      "259     2.0   4.414420  4.251169  5.645417\n",
      "85      2.0   1.991280  4.251169  5.645417\n",
      "45     17.0   2.922011  4.251169  5.645417\n",
      "270    13.0   5.674269  4.251169  5.645417\n",
      "89     13.0   3.046640  4.251169  5.645417\n",
      "397     2.0   4.195192  4.251169  5.645417\n",
      "319     0.0   2.491165  4.251169  5.645417\n",
      "159    10.0   1.991280  4.251169  5.645417\n",
      "293     2.0   3.027058  4.251169  5.645417\n",
      "24     11.0   4.356584  4.251169  5.645417\n",
      "49     13.0   7.041053  4.251169  5.645417\n",
      "304     8.0   3.979853  4.251169  5.645417\n",
      "405     3.0   1.991280  4.251169  5.645417\n",
      "451     2.0   1.991280  4.251169  5.645417\n",
      "269    10.0   6.448953  4.251169  5.645417\n",
      "62     14.0   3.200777  4.251169  5.645417\n",
      "139     2.0   1.991280  4.251169  5.645417\n",
      "26     13.0   2.766809  4.251169  5.645417\n",
      "19      3.0   1.991280  4.251169  5.645417\n",
      "71      4.0   1.991280  4.251169  5.645417\n",
      "186    11.0   7.470090  4.251169  5.645417\n",
      "34     13.0   5.763108  4.251169  5.645417\n",
      "170     6.0   2.906201  3.727499  4.716379\n",
      "322     1.0   1.743255  3.727499  4.716379\n",
      "457     1.0   3.975398  3.727499  4.716379\n",
      "104    14.0  11.842947  3.727499  4.716379\n",
      "75     15.0   7.171765  3.727499  4.716379\n",
      "441     1.0   5.043796  3.727499  4.716379\n",
      "408     1.0   4.575593  3.727499  4.716379\n",
      "239     0.0   7.014071  3.727499  4.716379\n",
      "42      5.0   8.229319  3.727499  4.716379\n",
      "60      4.0   4.422348  3.727499  4.716379\n",
      "280     1.0   2.707021  3.727499  4.716379\n",
      "461     2.0   5.564970  3.727499  4.716379\n",
      "327     3.0   0.000000  3.727499  4.716379\n",
      "33     13.0   5.931441  3.727499  4.716379\n",
      "449     4.0   7.219111  3.727499  4.716379\n",
      "314     7.0   9.521431  3.727499  4.716379\n",
      "123    13.0   5.342001  3.727499  4.716379\n",
      "242     6.0   3.601367  3.727499  4.716379\n",
      "354     3.0   2.329723  3.727499  4.716379\n",
      "77     13.0   5.531817  3.727499  4.716379\n",
      "91     15.0   9.141494  3.727499  4.716379\n",
      "438     2.0   5.068948  3.727499  4.716379\n",
      "433     3.0   7.484094  3.727499  4.716379\n",
      "357     7.0   3.048892  3.727499  4.716379\n",
      "339     6.0   2.243485  3.727499  4.716379\n",
      "98     13.0   8.975310  3.727499  4.716379\n",
      "11      1.0   6.431779  3.727499  4.716379\n",
      "117    15.0   4.809181  3.727499  4.716379\n",
      "382     5.0   7.144482  3.727499  4.716379\n",
      "83      1.0   2.584785  3.727499  4.716379\n",
      "202    14.0   6.720963  3.727499  4.716379\n",
      "84      1.0   9.445240  3.727499  4.716379\n",
      "61      8.0   6.329223  3.727499  4.716379\n",
      "229     1.0   1.104548  3.727499  4.716379\n",
      "454     2.0   5.547945  3.727499  4.716379\n",
      "381     5.0   7.735620  3.727499  4.716379\n",
      "78      2.0   1.912897  3.727499  4.716379\n",
      "267     9.0   8.434349  3.727499  4.716379\n",
      "36     18.0   9.521097  3.727499  4.716379\n",
      "459     4.0   3.031180  3.727499  4.716379\n",
      "343     3.0   3.491338  3.727499  4.716379\n",
      "458     5.0   3.503731  3.727499  4.716379\n",
      "247    10.0   4.293698  3.727499  4.716379\n",
      "416     3.0   0.768117  3.727499  4.716379\n",
      "17      0.0   6.630738  3.727499  4.716379\n",
      "141    11.0   3.069508  3.727499  4.716379\n",
      "126    15.0   8.933621  3.727499  4.716379\n",
      "0       3.0   2.144249  3.727499  4.716379\n",
      "21     10.0   3.958035  3.727499  4.716379\n",
      "291    10.0   3.368658  3.727499  4.716379\n",
      "300     2.0   4.996772  3.727499  4.716379\n",
      "183     7.0   7.812604  3.727499  4.716379\n",
      "406     2.0   1.366209  3.727499  4.716379\n",
      "163     3.0   5.326719  3.727499  4.716379\n",
      "86      9.0   5.287227  3.727499  4.716379\n",
      "390     9.0   5.255829  3.727499  4.716379\n",
      "158     1.0   0.857912  3.727499  4.716379\n",
      "27      5.0   3.844977  3.727499  4.716379\n",
      "415     3.0   3.099281  3.727499  4.716379\n",
      "194     9.0   5.032954  3.727499  4.716379\n",
      "301    11.0   3.121549  3.727499  4.716379\n",
      "419     1.0   2.810976  3.727499  4.716379\n",
      "259     2.0   4.771115  3.727499  4.716379\n",
      "85      2.0   5.006968  3.727499  4.716379\n",
      "45     17.0   0.686369  3.727499  4.716379\n",
      "270    13.0   6.584215  3.727499  4.716379\n",
      "89     13.0   7.639956  3.727499  4.716379\n",
      "397     2.0   4.282894  3.727499  4.716379\n",
      "319     0.0   1.840895  3.727499  4.716379\n",
      "159    10.0   2.679533  3.727499  4.716379\n",
      "293     2.0   4.902699  3.727499  4.716379\n",
      "24     11.0   8.607461  3.727499  4.716379\n",
      "49     13.0   7.022905  3.727499  4.716379\n",
      "304     8.0   6.095149  3.727499  4.716379\n",
      "405     3.0   3.958708  3.727499  4.716379\n",
      "451     2.0   1.688132  3.727499  4.716379\n",
      "269    10.0  10.522334  3.727499  4.716379\n",
      "62     14.0  10.450826  3.727499  4.716379\n",
      "139     2.0   1.611783  3.727499  4.716379\n",
      "26     13.0   9.270918  3.727499  4.716379\n",
      "19      3.0   1.650697  3.727499  4.716379\n",
      "71      4.0   1.301184  3.727499  4.716379\n",
      "186    11.0   4.791987  3.727499  4.716379\n",
      "34     13.0   4.195175  3.727499  4.716379\n",
      "170     6.0   2.005871  4.285632  5.716708\n",
      "322     1.0   2.005871  4.285632  5.716708\n",
      "457     1.0   6.714356  4.285632  5.716708\n",
      "104    14.0   4.674767  4.285632  5.716708\n",
      "75     15.0   7.497430  4.285632  5.716708\n",
      "441     1.0   2.481995  4.285632  5.716708\n",
      "408     1.0   2.389040  4.285632  5.716708\n",
      "239     0.0   7.815688  4.285632  5.716708\n",
      "42      5.0   3.593657  4.285632  5.716708\n",
      "60      4.0   3.470681  4.285632  5.716708\n",
      "280     1.0   2.005871  4.285632  5.716708\n",
      "461     2.0   4.966021  4.285632  5.716708\n",
      "327     3.0   2.005871  4.285632  5.716708\n",
      "33     13.0   2.005871  4.285632  5.716708\n",
      "449     4.0   5.211623  4.285632  5.716708\n",
      "314     7.0   4.590991  4.285632  5.716708\n",
      "123    13.0   2.005871  4.285632  5.716708\n",
      "242     6.0   2.005871  4.285632  5.716708\n",
      "354     3.0   2.005871  4.285632  5.716708\n",
      "77     13.0   5.182674  4.285632  5.716708\n",
      "91     15.0   6.839341  4.285632  5.716708\n",
      "438     2.0   1.900194  4.285632  5.716708\n",
      "433     3.0   2.465371  4.285632  5.716708\n",
      "357     7.0   2.005871  4.285632  5.716708\n",
      "339     6.0   2.005871  4.285632  5.716708\n",
      "98     13.0   8.235050  4.285632  5.716708\n",
      "11      1.0   2.739584  4.285632  5.716708\n",
      "117    15.0   2.005871  4.285632  5.716708\n",
      "382     5.0   2.117033  4.285632  5.716708\n",
      "83      1.0   2.005871  4.285632  5.716708\n",
      "202    14.0   1.883779  4.285632  5.716708\n",
      "84      1.0   6.759728  4.285632  5.716708\n",
      "61      8.0   2.448727  4.285632  5.716708\n",
      "229     1.0   2.005871  4.285632  5.716708\n",
      "454     2.0   2.262741  4.285632  5.716708\n",
      "381     5.0   2.005871  4.285632  5.716708\n",
      "78      2.0   2.005871  4.285632  5.716708\n",
      "267     9.0   5.833189  4.285632  5.716708\n",
      "36     18.0   2.005871  4.285632  5.716708\n",
      "459     4.0   2.005871  4.285632  5.716708\n",
      "343     3.0   2.005871  4.285632  5.716708\n",
      "458     5.0   2.187954  4.285632  5.716708\n",
      "247    10.0   5.034587  4.285632  5.716708\n",
      "416     3.0   2.005871  4.285632  5.716708\n",
      "17      0.0   2.076936  4.285632  5.716708\n",
      "141    11.0   2.005871  4.285632  5.716708\n",
      "126    15.0   7.319453  4.285632  5.716708\n",
      "0       3.0   2.005871  4.285632  5.716708\n",
      "21     10.0   2.567041  4.285632  5.716708\n",
      "291    10.0   2.350959  4.285632  5.716708\n",
      "300     2.0   4.455623  4.285632  5.716708\n",
      "183     7.0   2.122003  4.285632  5.716708\n",
      "406     2.0   2.005871  4.285632  5.716708\n",
      "163     3.0   3.389356  4.285632  5.716708\n",
      "86      9.0   2.005871  4.285632  5.716708\n",
      "390     9.0   3.717576  4.285632  5.716708\n",
      "158     1.0   2.005871  4.285632  5.716708\n",
      "27      5.0   5.567187  4.285632  5.716708\n",
      "415     3.0   2.005871  4.285632  5.716708\n",
      "194     9.0   2.005871  4.285632  5.716708\n",
      "301    11.0   3.960407  4.285632  5.716708\n",
      "419     1.0   2.005871  4.285632  5.716708\n",
      "259     2.0   4.816185  4.285632  5.716708\n",
      "85      2.0   2.005871  4.285632  5.716708\n",
      "45     17.0   2.005871  4.285632  5.716708\n",
      "270    13.0   6.714356  4.285632  5.716708\n",
      "89     13.0   5.902364  4.285632  5.716708\n",
      "397     2.0   5.985710  4.285632  5.716708\n",
      "319     0.0   2.951702  4.285632  5.716708\n",
      "159    10.0   2.005871  4.285632  5.716708\n",
      "293     2.0   2.005224  4.285632  5.716708\n",
      "24     11.0   5.269944  4.285632  5.716708\n",
      "49     13.0   4.959631  4.285632  5.716708\n",
      "304     8.0   2.813294  4.285632  5.716708\n",
      "405     3.0   2.005871  4.285632  5.716708\n",
      "451     2.0   2.005871  4.285632  5.716708\n",
      "269    10.0   8.232828  4.285632  5.716708\n",
      "62     14.0   6.214280  4.285632  5.716708\n",
      "139     2.0   2.005871  4.285632  5.716708\n",
      "26     13.0   2.073764  4.285632  5.716708\n",
      "19      3.0   2.005871  4.285632  5.716708\n",
      "71      4.0   2.005871  4.285632  5.716708\n",
      "186    11.0   5.972594  4.285632  5.716708\n",
      "34     13.0   3.373383  4.285632  5.716708\n",
      "170     6.0   1.541045  3.988267  5.094913\n",
      "322     1.0   0.874700  3.988267  5.094913\n",
      "457     1.0   9.905070  3.988267  5.094913\n",
      "104    14.0  10.035925  3.988267  5.094913\n",
      "75     15.0   9.348856  3.988267  5.094913\n",
      "441     1.0   4.549798  3.988267  5.094913\n",
      "408     1.0   6.617802  3.988267  5.094913\n",
      "239     0.0   7.313112  3.988267  5.094913\n",
      "42      5.0   9.116779  3.988267  5.094913\n",
      "60      4.0   4.594211  3.988267  5.094913\n",
      "280     1.0   2.001654  3.988267  5.094913\n",
      "461     2.0   4.404807  3.988267  5.094913\n",
      "327     3.0   0.050768  3.988267  5.094913\n",
      "33     13.0   4.153158  3.988267  5.094913\n",
      "449     4.0   4.822348  3.988267  5.094913\n",
      "314     7.0   4.942664  3.988267  5.094913\n",
      "123    13.0   4.346553  3.988267  5.094913\n",
      "242     6.0   3.614594  3.988267  5.094913\n",
      "354     3.0   2.469830  3.988267  5.094913\n",
      "77     13.0   3.952121  3.988267  5.094913\n",
      "91     15.0   5.890631  3.988267  5.094913\n",
      "438     2.0   6.528672  3.988267  5.094913\n",
      "433     3.0   4.366263  3.988267  5.094913\n",
      "357     7.0   2.304358  3.988267  5.094913\n",
      "339     6.0   3.158264  3.988267  5.094913\n",
      "98     13.0  10.766070  3.988267  5.094913\n",
      "11      1.0   7.247446  3.988267  5.094913\n",
      "117    15.0   3.730615  3.988267  5.094913\n",
      "382     5.0   6.613172  3.988267  5.094913\n",
      "83      1.0   5.081387  3.988267  5.094913\n",
      "202    14.0   5.605905  3.988267  5.094913\n",
      "84      1.0   5.077173  3.988267  5.094913\n",
      "61      8.0   9.844694  3.988267  5.094913\n",
      "229     1.0   0.102614  3.988267  5.094913\n",
      "454     2.0   7.537683  3.988267  5.094913\n",
      "381     5.0   4.659186  3.988267  5.094913\n",
      "78      2.0   0.861526  3.988267  5.094913\n",
      "267     9.0  10.400309  3.988267  5.094913\n",
      "36     18.0   5.231333  3.988267  5.094913\n",
      "459     4.0   2.814042  3.988267  5.094913\n",
      "343     3.0   1.071939  3.988267  5.094913\n",
      "458     5.0   1.608848  3.988267  5.094913\n",
      "247    10.0   5.047756  3.988267  5.094913\n",
      "416     3.0   0.727767  3.988267  5.094913\n",
      "17      0.0   8.187881  3.988267  5.094913\n",
      "141    11.0   6.095495  3.988267  5.094913\n",
      "126    15.0   7.610518  3.988267  5.094913\n",
      "0       3.0   3.411701  3.988267  5.094913\n",
      "21     10.0   6.265261  3.988267  5.094913\n",
      "291    10.0   5.739122  3.988267  5.094913\n",
      "300     2.0   6.591482  3.988267  5.094913\n",
      "183     7.0   6.656248  3.988267  5.094913\n",
      "406     2.0   6.923226  3.988267  5.094913\n",
      "163     3.0   5.635766  3.988267  5.094913\n",
      "86      9.0   8.690700  3.988267  5.094913\n",
      "390     9.0   2.761141  3.988267  5.094913\n",
      "158     1.0   1.107986  3.988267  5.094913\n",
      "27      5.0   4.864337  3.988267  5.094913\n",
      "415     3.0   1.397747  3.988267  5.094913\n",
      "194     9.0   6.208793  3.988267  5.094913\n",
      "301    11.0   4.256078  3.988267  5.094913\n",
      "419     1.0   4.067087  3.988267  5.094913\n",
      "259     2.0   4.897079  3.988267  5.094913\n",
      "85      2.0   6.032970  3.988267  5.094913\n",
      "45     17.0   2.427716  3.988267  5.094913\n",
      "270    13.0   4.709610  3.988267  5.094913\n",
      "89     13.0   9.434948  3.988267  5.094913\n",
      "397     2.0   3.096937  3.988267  5.094913\n",
      "319     0.0   6.048564  3.988267  5.094913\n",
      "159    10.0   2.944280  3.988267  5.094913\n",
      "293     2.0   6.478451  3.988267  5.094913\n",
      "24     11.0   6.999532  3.988267  5.094913\n",
      "49     13.0   8.075586  3.988267  5.094913\n",
      "304     8.0   7.909280  3.988267  5.094913\n",
      "405     3.0   2.639426  3.988267  5.094913\n",
      "451     2.0   1.605140  3.988267  5.094913\n",
      "269    10.0  10.149869  3.988267  5.094913\n",
      "62     14.0   9.042019  3.988267  5.094913\n",
      "139     2.0   3.131002  3.988267  5.094913\n",
      "26     13.0   5.740963  3.988267  5.094913\n",
      "19      3.0   1.488925  3.988267  5.094913\n",
      "71      4.0   2.380383  3.988267  5.094913\n",
      "186    11.0   8.095856  3.988267  5.094913\n",
      "34     13.0   2.817795  3.988267  5.094913\n",
      "170     6.0   2.132594  3.869059  5.179731\n",
      "322     1.0   2.942894  3.869059  5.179731\n",
      "457     1.0   5.097774  3.869059  5.179731\n",
      "104    14.0   6.643352  3.869059  5.179731\n",
      "75     15.0   7.932735  3.869059  5.179731\n",
      "441     1.0   2.425113  3.869059  5.179731\n",
      "408     1.0   3.535111  3.869059  5.179731\n",
      "239     0.0  10.667631  3.869059  5.179731\n",
      "42      5.0   3.947850  3.869059  5.179731\n",
      "60      4.0   6.189118  3.869059  5.179731\n",
      "280     1.0   0.396952  3.869059  5.179731\n",
      "461     2.0   4.929375  3.869059  5.179731\n",
      "327     3.0   1.154179  3.869059  5.179731\n",
      "33     13.0   3.812944  3.869059  5.179731\n",
      "449     4.0   5.370621  3.869059  5.179731\n",
      "314     7.0   7.267332  3.869059  5.179731\n",
      "123    13.0   2.986090  3.869059  5.179731\n",
      "242     6.0   0.904273  3.869059  5.179731\n",
      "354     3.0   5.068554  3.869059  5.179731\n",
      "77     13.0   7.591452  3.869059  5.179731\n",
      "91     15.0  10.853989  3.869059  5.179731\n",
      "438     2.0   5.324546  3.869059  5.179731\n",
      "433     3.0   2.968300  3.869059  5.179731\n",
      "357     7.0   6.056019  3.869059  5.179731\n",
      "339     6.0   1.870056  3.869059  5.179731\n",
      "98     13.0  11.747866  3.869059  5.179731\n",
      "11      1.0   4.281883  3.869059  5.179731\n",
      "117    15.0   1.804042  3.869059  5.179731\n",
      "382     5.0   5.461917  3.869059  5.179731\n",
      "83      1.0   2.415257  3.869059  5.179731\n",
      "202    14.0   2.641040  3.869059  5.179731\n",
      "84      1.0   5.685782  3.869059  5.179731\n",
      "61      8.0   7.213735  3.869059  5.179731\n",
      "229     1.0   3.410371  3.869059  5.179731\n",
      "454     2.0   3.376154  3.869059  5.179731\n",
      "381     5.0   7.100318  3.869059  5.179731\n",
      "78      2.0   2.250572  3.869059  5.179731\n",
      "267     9.0   6.986117  3.869059  5.179731\n",
      "36     18.0   4.374138  3.869059  5.179731\n",
      "459     4.0   2.610191  3.869059  5.179731\n",
      "343     3.0   1.316033  3.869059  5.179731\n",
      "458     5.0   1.188753  3.869059  5.179731\n",
      "247    10.0   7.188375  3.869059  5.179731\n",
      "416     3.0   1.800564  3.869059  5.179731\n",
      "17      0.0   2.791138  3.869059  5.179731\n",
      "141    11.0   4.237154  3.869059  5.179731\n",
      "126    15.0   7.442825  3.869059  5.179731\n",
      "0       3.0   1.994417  3.869059  5.179731\n",
      "21     10.0   2.476886  3.869059  5.179731\n",
      "291    10.0   4.495518  3.869059  5.179731\n",
      "300     2.0   4.859691  3.869059  5.179731\n",
      "183     7.0   4.730727  3.869059  5.179731\n",
      "406     2.0   1.735393  3.869059  5.179731\n",
      "163     3.0   4.808925  3.869059  5.179731\n",
      "86      9.0   5.255870  3.869059  5.179731\n",
      "390     9.0   4.367044  3.869059  5.179731\n",
      "158     1.0   0.959723  3.869059  5.179731\n",
      "27      5.0   4.760558  3.869059  5.179731\n",
      "415     3.0   2.606480  3.869059  5.179731\n",
      "194     9.0   7.960543  3.869059  5.179731\n",
      "301    11.0   4.127114  3.869059  5.179731\n",
      "419     1.0   2.738117  3.869059  5.179731\n",
      "259     2.0   6.543126  3.869059  5.179731\n",
      "85      2.0   3.544027  3.869059  5.179731\n",
      "45     17.0   3.849842  3.869059  5.179731\n",
      "270    13.0   4.565558  3.869059  5.179731\n",
      "89     13.0   5.383268  3.869059  5.179731\n",
      "397     2.0   4.026597  3.869059  5.179731\n",
      "319     0.0   5.616191  3.869059  5.179731\n",
      "159    10.0   3.217951  3.869059  5.179731\n",
      "293     2.0   3.077466  3.869059  5.179731\n",
      "24     11.0   5.458712  3.869059  5.179731\n",
      "49     13.0   6.449215  3.869059  5.179731\n",
      "304     8.0   3.526590  3.869059  5.179731\n",
      "405     3.0   2.219205  3.869059  5.179731\n",
      "451     2.0   2.071819  3.869059  5.179731\n",
      "269    10.0   5.501178  3.869059  5.179731\n",
      "62     14.0   3.485543  3.869059  5.179731\n",
      "139     2.0   2.011227  3.869059  5.179731\n",
      "26     13.0   4.157465  3.869059  5.179731\n",
      "19      3.0   1.460495  3.869059  5.179731\n",
      "71      4.0   1.893847  3.869059  5.179731\n",
      "186    11.0  11.053036  3.869059  5.179731\n",
      "34     13.0   3.499973  3.869059  5.179731\n",
      "170     6.0   2.571496  3.743159  4.928312\n",
      "322     1.0   1.563356  3.743159  4.928312\n",
      "457     1.0   6.425467  3.743159  4.928312\n",
      "104    14.0  10.253456  3.743159  4.928312\n",
      "75     15.0   9.119630  3.743159  4.928312\n",
      "441     1.0   4.359822  3.743159  4.928312\n",
      "408     1.0   5.176293  3.743159  4.928312\n",
      "239     0.0   9.304399  3.743159  4.928312\n",
      "42      5.0   7.441909  3.743159  4.928312\n",
      "60      4.0   5.190511  3.743159  4.928312\n",
      "280     1.0   1.504040  3.743159  4.928312\n",
      "461     2.0   3.016436  3.743159  4.928312\n",
      "327     3.0   0.000000  3.743159  4.928312\n",
      "33     13.0   3.527877  3.743159  4.928312\n",
      "449     4.0   7.377728  3.743159  4.928312\n",
      "314     7.0   5.783121  3.743159  4.928312\n",
      "123    13.0   5.294158  3.743159  4.928312\n",
      "242     6.0   2.799609  3.743159  4.928312\n",
      "354     3.0   3.698051  3.743159  4.928312\n",
      "77     13.0   4.704040  3.743159  4.928312\n",
      "91     15.0   8.630242  3.743159  4.928312\n",
      "438     2.0   3.774608  3.743159  4.928312\n",
      "433     3.0   2.346612  3.743159  4.928312\n",
      "357     7.0   2.708991  3.743159  4.928312\n",
      "339     6.0   3.107352  3.743159  4.928312\n",
      "98     13.0  10.839762  3.743159  4.928312\n",
      "11      1.0   7.649187  3.743159  4.928312\n",
      "117    15.0   2.915158  3.743159  4.928312\n",
      "382     5.0   5.713961  3.743159  4.928312\n",
      "83      1.0   5.199851  3.743159  4.928312\n",
      "202    14.0   4.231589  3.743159  4.928312\n",
      "84      1.0   9.705320  3.743159  4.928312\n",
      "61      8.0   4.663537  3.743159  4.928312\n",
      "229     1.0   1.069298  3.743159  4.928312\n",
      "454     2.0   6.346518  3.743159  4.928312\n",
      "381     5.0   3.794347  3.743159  4.928312\n",
      "78      2.0   2.028263  3.743159  4.928312\n",
      "267     9.0   8.734798  3.743159  4.928312\n",
      "36     18.0   5.639175  3.743159  4.928312\n",
      "459     4.0   4.145534  3.743159  4.928312\n",
      "343     3.0   1.679734  3.743159  4.928312\n",
      "458     5.0   2.402560  3.743159  4.928312\n",
      "247    10.0   4.511984  3.743159  4.928312\n",
      "416     3.0   0.000000  3.743159  4.928312\n",
      "17      0.0   3.189199  3.743159  4.928312\n",
      "141    11.0   2.941982  3.743159  4.928312\n",
      "126    15.0   8.914451  3.743159  4.928312\n",
      "0       3.0   2.549259  3.743159  4.928312\n",
      "21     10.0   8.101871  3.743159  4.928312\n",
      "291    10.0   4.317109  3.743159  4.928312\n",
      "300     2.0   5.597485  3.743159  4.928312\n",
      "183     7.0   6.438794  3.743159  4.928312\n",
      "406     2.0   4.870406  3.743159  4.928312\n",
      "163     3.0   4.506385  3.743159  4.928312\n",
      "86      9.0   6.078665  3.743159  4.928312\n",
      "390     9.0   6.010193  3.743159  4.928312\n",
      "158     1.0   0.215825  3.743159  4.928312\n",
      "27      5.0   5.469262  3.743159  4.928312\n",
      "415     3.0   2.440997  3.743159  4.928312\n",
      "194     9.0   4.227616  3.743159  4.928312\n",
      "301    11.0   3.557825  3.743159  4.928312\n",
      "419     1.0   0.000000  3.743159  4.928312\n",
      "259     2.0   3.861343  3.743159  4.928312\n",
      "85      2.0   3.994920  3.743159  4.928312\n",
      "45     17.0   2.390920  3.743159  4.928312\n",
      "270    13.0   9.119541  3.743159  4.928312\n",
      "89     13.0   4.877140  3.743159  4.928312\n",
      "397     2.0   4.278958  3.743159  4.928312\n",
      "319     0.0   4.554429  3.743159  4.928312\n",
      "159    10.0   5.834909  3.743159  4.928312\n",
      "293     2.0   4.147410  3.743159  4.928312\n",
      "24     11.0   5.925079  3.743159  4.928312\n",
      "49     13.0   4.054148  3.743159  4.928312\n",
      "304     8.0   6.506659  3.743159  4.928312\n",
      "405     3.0   4.880827  3.743159  4.928312\n",
      "451     2.0   0.911368  3.743159  4.928312\n",
      "269    10.0   9.394565  3.743159  4.928312\n",
      "62     14.0   6.081625  3.743159  4.928312\n",
      "139     2.0   2.132916  3.743159  4.928312\n",
      "26     13.0   9.391905  3.743159  4.928312\n",
      "19      3.0   0.057670  3.743159  4.928312\n",
      "71      4.0   3.681535  3.743159  4.928312\n",
      "186    11.0   9.824312  3.743159  4.928312\n",
      "34     13.0   4.643520  3.743159  4.928312\n",
      "170     6.0   2.443229  4.008067  5.341751\n",
      "322     1.0   3.463227  4.008067  5.341751\n",
      "457     1.0   3.978460  4.008067  5.341751\n",
      "104    14.0   5.269288  4.008067  5.341751\n",
      "75     15.0   6.852971  4.008067  5.341751\n",
      "441     1.0   3.489109  4.008067  5.341751\n",
      "408     1.0   2.352277  4.008067  5.341751\n",
      "239     0.0  10.150749  4.008067  5.341751\n",
      "42      5.0   4.207905  4.008067  5.341751\n",
      "60      4.0   5.384212  4.008067  5.341751\n",
      "280     1.0   1.945613  4.008067  5.341751\n",
      "461     2.0   3.962289  4.008067  5.341751\n",
      "327     3.0   1.583346  4.008067  5.341751\n",
      "33     13.0   2.730509  4.008067  5.341751\n",
      "449     4.0   6.885142  4.008067  5.341751\n",
      "314     7.0   5.627708  4.008067  5.341751\n",
      "123    13.0   3.116227  4.008067  5.341751\n",
      "242     6.0   3.097998  4.008067  5.341751\n",
      "354     3.0   6.266598  4.008067  5.341751\n",
      "77     13.0   6.471307  4.008067  5.341751\n",
      "91     15.0  10.364529  4.008067  5.341751\n",
      "438     2.0   4.868714  4.008067  5.341751\n",
      "433     3.0   2.026620  4.008067  5.341751\n",
      "357     7.0   3.235113  4.008067  5.341751\n",
      "339     6.0   2.032135  4.008067  5.341751\n",
      "98     13.0   6.541847  4.008067  5.341751\n",
      "11      1.0   2.325330  4.008067  5.341751\n",
      "117    15.0   1.878760  4.008067  5.341751\n",
      "382     5.0   3.794199  4.008067  5.341751\n",
      "83      1.0   2.995043  4.008067  5.341751\n",
      "202    14.0   2.528604  4.008067  5.341751\n",
      "84      1.0   4.776613  4.008067  5.341751\n",
      "61      8.0   6.285534  4.008067  5.341751\n",
      "229     1.0   6.275640  4.008067  5.341751\n",
      "454     2.0   4.907077  4.008067  5.341751\n",
      "381     5.0   4.116110  4.008067  5.341751\n",
      "78      2.0   2.069197  4.008067  5.341751\n",
      "267     9.0   8.218907  4.008067  5.341751\n",
      "36     18.0   2.717314  4.008067  5.341751\n",
      "459     4.0   2.097008  4.008067  5.341751\n",
      "343     3.0   2.109200  4.008067  5.341751\n",
      "458     5.0   1.874081  4.008067  5.341751\n",
      "247    10.0   4.790720  4.008067  5.341751\n",
      "416     3.0   1.495904  4.008067  5.341751\n",
      "17      0.0   3.806889  4.008067  5.341751\n",
      "141    11.0   3.020139  4.008067  5.341751\n",
      "126    15.0   6.606102  4.008067  5.341751\n",
      "0       3.0   1.659013  4.008067  5.341751\n",
      "21     10.0   4.658219  4.008067  5.341751\n",
      "291    10.0   6.904176  4.008067  5.341751\n",
      "300     2.0   3.189689  4.008067  5.341751\n",
      "183     7.0   3.455955  4.008067  5.341751\n",
      "406     2.0   1.865287  4.008067  5.341751\n",
      "163     3.0   5.494054  4.008067  5.341751\n",
      "86      9.0   4.963795  4.008067  5.341751\n",
      "390     9.0   6.752454  4.008067  5.341751\n",
      "158     1.0   2.016321  4.008067  5.341751\n",
      "27      5.0   5.689217  4.008067  5.341751\n",
      "415     3.0   2.528599  4.008067  5.341751\n",
      "194     9.0   2.511752  4.008067  5.341751\n",
      "301    11.0   4.207361  4.008067  5.341751\n",
      "419     1.0   2.265688  4.008067  5.341751\n",
      "259     2.0   4.260033  4.008067  5.341751\n",
      "85      2.0   3.023893  4.008067  5.341751\n",
      "45     17.0   3.141054  4.008067  5.341751\n",
      "270    13.0   4.880676  4.008067  5.341751\n",
      "89     13.0   4.454152  4.008067  5.341751\n",
      "397     2.0   2.757496  4.008067  5.341751\n",
      "319     0.0   4.593732  4.008067  5.341751\n",
      "159    10.0   3.555281  4.008067  5.341751\n",
      "293     2.0   2.847864  4.008067  5.341751\n",
      "24     11.0   7.719447  4.008067  5.341751\n",
      "49     13.0   5.381911  4.008067  5.341751\n",
      "304     8.0   3.002223  4.008067  5.341751\n",
      "405     3.0   2.057969  4.008067  5.341751\n",
      "451     2.0   2.165019  4.008067  5.341751\n",
      "269    10.0   7.941053  4.008067  5.341751\n",
      "62     14.0   3.811488  4.008067  5.341751\n",
      "139     2.0   1.896731  4.008067  5.341751\n",
      "26     13.0   4.094719  4.008067  5.341751\n",
      "19      3.0   1.862527  4.008067  5.341751\n",
      "71      4.0   2.060848  4.008067  5.341751\n",
      "186    11.0  12.354258  4.008067  5.341751\n",
      "34     13.0   4.381852  4.008067  5.341751\n",
      "170     6.0   1.100058  3.911504  4.926573\n",
      "322     1.0   1.377270  3.911504  4.926573\n",
      "457     1.0   7.297743  3.911504  4.926573\n",
      "104    14.0   9.446831  3.911504  4.926573\n",
      "75     15.0   8.499056  3.911504  4.926573\n",
      "441     1.0   4.766588  3.911504  4.926573\n",
      "408     1.0   6.084936  3.911504  4.926573\n",
      "239     0.0   8.023755  3.911504  4.926573\n",
      "42      5.0   6.593329  3.911504  4.926573\n",
      "60      4.0   3.634982  3.911504  4.926573\n",
      "280     1.0   2.223380  3.911504  4.926573\n",
      "461     2.0   6.179936  3.911504  4.926573\n",
      "327     3.0   0.000000  3.911504  4.926573\n",
      "33     13.0   3.683616  3.911504  4.926573\n",
      "449     4.0   7.688175  3.911504  4.926573\n",
      "314     7.0   5.946874  3.911504  4.926573\n",
      "123    13.0   3.606244  3.911504  4.926573\n",
      "242     6.0   2.320019  3.911504  4.926573\n",
      "354     3.0   5.168630  3.911504  4.926573\n",
      "77     13.0   7.712757  3.911504  4.926573\n",
      "91     15.0   7.655524  3.911504  4.926573\n",
      "438     2.0   1.909847  3.911504  4.926573\n",
      "433     3.0   3.373296  3.911504  4.926573\n",
      "357     7.0   2.471857  3.911504  4.926573\n",
      "339     6.0   2.820678  3.911504  4.926573\n",
      "98     13.0   9.615953  3.911504  4.926573\n",
      "11      1.0   6.265903  3.911504  4.926573\n",
      "117    15.0   3.757954  3.911504  4.926573\n",
      "382     5.0   6.447888  3.911504  4.926573\n",
      "83      1.0   4.033368  3.911504  4.926573\n",
      "202    14.0   4.671938  3.911504  4.926573\n",
      "84      1.0  10.500589  3.911504  4.926573\n",
      "61      8.0   6.161371  3.911504  4.926573\n",
      "229     1.0   1.235588  3.911504  4.926573\n",
      "454     2.0   5.249551  3.911504  4.926573\n",
      "381     5.0   4.261794  3.911504  4.926573\n",
      "78      2.0   2.059681  3.911504  4.926573\n",
      "267     9.0   8.121539  3.911504  4.926573\n",
      "36     18.0   6.171848  3.911504  4.926573\n",
      "459     4.0   1.529172  3.911504  4.926573\n",
      "343     3.0   0.493493  3.911504  4.926573\n",
      "458     5.0   1.418814  3.911504  4.926573\n",
      "247    10.0   5.766870  3.911504  4.926573\n",
      "416     3.0   0.000000  3.911504  4.926573\n",
      "17      0.0   3.772267  3.911504  4.926573\n",
      "141    11.0   4.328215  3.911504  4.926573\n",
      "126    15.0   8.605881  3.911504  4.926573\n",
      "0       3.0   2.102301  3.911504  4.926573\n",
      "21     10.0   8.253472  3.911504  4.926573\n",
      "291    10.0   6.029198  3.911504  4.926573\n",
      "300     2.0   6.656269  3.911504  4.926573\n",
      "183     7.0   5.170572  3.911504  4.926573\n",
      "406     2.0   3.674544  3.911504  4.926573\n",
      "163     3.0   5.701890  3.911504  4.926573\n",
      "86      9.0   8.149170  3.911504  4.926573\n",
      "390     9.0   7.186712  3.911504  4.926573\n",
      "158     1.0   0.000000  3.911504  4.926573\n",
      "27      5.0   7.550503  3.911504  4.926573\n",
      "415     3.0   2.037783  3.911504  4.926573\n",
      "194     9.0   3.763848  3.911504  4.926573\n",
      "301    11.0   4.214782  3.911504  4.926573\n",
      "419     1.0   0.000000  3.911504  4.926573\n",
      "259     2.0   3.947309  3.911504  4.926573\n",
      "85      2.0   3.867907  3.911504  4.926573\n",
      "45     17.0   3.862026  3.911504  4.926573\n",
      "270    13.0   6.431722  3.911504  4.926573\n",
      "89     13.0   4.574222  3.911504  4.926573\n",
      "397     2.0   6.091220  3.911504  4.926573\n",
      "319     0.0   5.054271  3.911504  4.926573\n",
      "159    10.0   2.969560  3.911504  4.926573\n",
      "293     2.0   4.538581  3.911504  4.926573\n",
      "24     11.0   5.969230  3.911504  4.926573\n",
      "49     13.0   8.620750  3.911504  4.926573\n",
      "304     8.0   5.393067  3.911504  4.926573\n",
      "405     3.0   3.983219  3.911504  4.926573\n",
      "451     2.0   1.013574  3.911504  4.926573\n",
      "269    10.0   8.533545  3.911504  4.926573\n",
      "62     14.0   6.128688  3.911504  4.926573\n",
      "139     2.0   2.632827  3.911504  4.926573\n",
      "26     13.0   8.613823  3.911504  4.926573\n",
      "19      3.0   0.000000  3.911504  4.926573\n",
      "71      4.0   1.658999  3.911504  4.926573\n",
      "186    11.0   9.449569  3.911504  4.926573\n",
      "34     13.0   2.634292  3.911504  4.926573\n",
      "170     6.0   2.001104  4.165474  5.593451\n",
      "322     1.0   2.001104  4.165474  5.593451\n",
      "457     1.0   5.576642  4.165474  5.593451\n",
      "104    14.0   5.958061  4.165474  5.593451\n",
      "75     15.0   5.171013  4.165474  5.593451\n",
      "441     1.0   3.196204  4.165474  5.593451\n",
      "408     1.0   2.635659  4.165474  5.593451\n",
      "239     0.0   9.823844  4.165474  5.593451\n",
      "42      5.0   3.119120  4.165474  5.593451\n",
      "60      4.0   2.001104  4.165474  5.593451\n",
      "280     1.0   2.001104  4.165474  5.593451\n",
      "461     2.0   7.564558  4.165474  5.593451\n",
      "327     3.0   1.804169  4.165474  5.593451\n",
      "33     13.0   2.001104  4.165474  5.593451\n",
      "449     4.0   6.335014  4.165474  5.593451\n",
      "314     7.0   4.841072  4.165474  5.593451\n",
      "123    13.0   3.009805  4.165474  5.593451\n",
      "242     6.0   1.752052  4.165474  5.593451\n",
      "354     3.0   2.073106  4.165474  5.593451\n",
      "77     13.0   7.031233  4.165474  5.593451\n",
      "91     15.0   6.321871  4.165474  5.593451\n",
      "438     2.0   3.159637  4.165474  5.593451\n",
      "433     3.0   2.327584  4.165474  5.593451\n",
      "357     7.0   2.001104  4.165474  5.593451\n",
      "339     6.0   2.001104  4.165474  5.593451\n",
      "98     13.0  12.171572  4.165474  5.593451\n",
      "11      1.0   6.399508  4.165474  5.593451\n",
      "117    15.0   3.070224  4.165474  5.593451\n",
      "382     5.0   2.885820  4.165474  5.593451\n",
      "83      1.0   2.001104  4.165474  5.593451\n",
      "202    14.0   1.916818  4.165474  5.593451\n",
      "84      1.0   4.735449  4.165474  5.593451\n",
      "61      8.0   8.118705  4.165474  5.593451\n",
      "229     1.0   2.439047  4.165474  5.593451\n",
      "454     2.0   3.257191  4.165474  5.593451\n",
      "381     5.0   5.517791  4.165474  5.593451\n",
      "78      2.0   2.001104  4.165474  5.593451\n",
      "267     9.0   9.670052  4.165474  5.593451\n",
      "36     18.0   2.049018  4.165474  5.593451\n",
      "459     4.0   2.001104  4.165474  5.593451\n",
      "343     3.0   2.001104  4.165474  5.593451\n",
      "458     5.0   2.001104  4.165474  5.593451\n",
      "247    10.0   3.960812  4.165474  5.593451\n",
      "416     3.0   2.001104  4.165474  5.593451\n",
      "17      0.0   2.057232  4.165474  5.593451\n",
      "141    11.0   2.842081  4.165474  5.593451\n",
      "126    15.0   6.080320  4.165474  5.593451\n",
      "0       3.0   2.148677  4.165474  5.593451\n",
      "21     10.0   3.225413  4.165474  5.593451\n",
      "291    10.0   4.721147  4.165474  5.593451\n",
      "300     2.0   4.025472  4.165474  5.593451\n",
      "183     7.0   3.374424  4.165474  5.593451\n",
      "406     2.0   2.001104  4.165474  5.593451\n",
      "163     3.0   4.460641  4.165474  5.593451\n",
      "86      9.0   5.166100  4.165474  5.593451\n",
      "390     9.0   6.210589  4.165474  5.593451\n",
      "158     1.0   2.001104  4.165474  5.593451\n",
      "27      5.0   3.021677  4.165474  5.593451\n",
      "415     3.0   2.001104  4.165474  5.593451\n",
      "194     9.0   2.636016  4.165474  5.593451\n",
      "301    11.0   3.500510  4.165474  5.593451\n",
      "419     1.0   2.001104  4.165474  5.593451\n",
      "259     2.0   3.442699  4.165474  5.593451\n",
      "85      2.0   2.179151  4.165474  5.593451\n",
      "45     17.0   2.001104  4.165474  5.593451\n",
      "270    13.0   6.966379  4.165474  5.593451\n",
      "89     13.0   5.011568  4.165474  5.593451\n",
      "397     2.0   2.296779  4.165474  5.593451\n",
      "319     0.0   4.350985  4.165474  5.593451\n",
      "159    10.0   2.525341  4.165474  5.593451\n",
      "293     2.0   4.837888  4.165474  5.593451\n",
      "24     11.0   3.605122  4.165474  5.593451\n",
      "49     13.0   4.253204  4.165474  5.593451\n",
      "304     8.0   3.233946  4.165474  5.593451\n",
      "405     3.0   2.001104  4.165474  5.593451\n",
      "451     2.0   2.001104  4.165474  5.593451\n",
      "269    10.0   4.879339  4.165474  5.593451\n",
      "62     14.0   4.423393  4.165474  5.593451\n",
      "139     2.0   2.028577  4.165474  5.593451\n",
      "26     13.0   3.716787  4.165474  5.593451\n",
      "19      3.0   2.001104  4.165474  5.593451\n",
      "71      4.0   2.001104  4.165474  5.593451\n",
      "186    11.0   8.122911  4.165474  5.593451\n",
      "34     13.0   4.074008  4.165474  5.593451\n",
      "170     6.0   2.994375  3.960225  4.958155\n",
      "322     1.0   0.056681  3.960225  4.958155\n",
      "457     1.0   6.066135  3.960225  4.958155\n",
      "104    14.0  11.217484  3.960225  4.958155\n",
      "75     15.0   8.761463  3.960225  4.958155\n",
      "441     1.0   6.073039  3.960225  4.958155\n",
      "408     1.0   5.248654  3.960225  4.958155\n",
      "239     0.0   7.807738  3.960225  4.958155\n",
      "42      5.0  10.991156  3.960225  4.958155\n",
      "60      4.0   3.458396  3.960225  4.958155\n",
      "280     1.0   1.120857  3.960225  4.958155\n",
      "461     2.0   4.320340  3.960225  4.958155\n",
      "327     3.0   0.000000  3.960225  4.958155\n",
      "33     13.0   5.494531  3.960225  4.958155\n",
      "449     4.0   4.931515  3.960225  4.958155\n",
      "314     7.0   5.553892  3.960225  4.958155\n",
      "123    13.0   5.336929  3.960225  4.958155\n",
      "242     6.0   2.657741  3.960225  4.958155\n",
      "354     3.0   3.211342  3.960225  4.958155\n",
      "77     13.0   4.767570  3.960225  4.958155\n",
      "91     15.0   8.568989  3.960225  4.958155\n",
      "438     2.0   8.436785  3.960225  4.958155\n",
      "433     3.0   5.661921  3.960225  4.958155\n",
      "357     7.0   3.467023  3.960225  4.958155\n",
      "339     6.0   3.127832  3.960225  4.958155\n",
      "98     13.0   9.371127  3.960225  4.958155\n",
      "11      1.0   6.986683  3.960225  4.958155\n",
      "117    15.0   5.062700  3.960225  4.958155\n",
      "382     5.0   3.977544  3.960225  4.958155\n",
      "83      1.0   2.450865  3.960225  4.958155\n",
      "202    14.0   8.263851  3.960225  4.958155\n",
      "84      1.0   5.117085  3.960225  4.958155\n",
      "61      8.0   8.867064  3.960225  4.958155\n",
      "229     1.0   1.135705  3.960225  4.958155\n",
      "454     2.0   4.899136  3.960225  4.958155\n",
      "381     5.0   8.445194  3.960225  4.958155\n",
      "78      2.0   2.682912  3.960225  4.958155\n",
      "267     9.0   9.239951  3.960225  4.958155\n",
      "36     18.0   5.276001  3.960225  4.958155\n",
      "459     4.0   2.302469  3.960225  4.958155\n",
      "343     3.0   0.181197  3.960225  4.958155\n",
      "458     5.0   3.311019  3.960225  4.958155\n",
      "247    10.0   4.953010  3.960225  4.958155\n",
      "416     3.0   1.098005  3.960225  4.958155\n",
      "17      0.0   9.262304  3.960225  4.958155\n",
      "141    11.0   2.762035  3.960225  4.958155\n",
      "126    15.0   7.511703  3.960225  4.958155\n",
      "0       3.0   2.700260  3.960225  4.958155\n",
      "21     10.0   7.097401  3.960225  4.958155\n",
      "291    10.0   2.797968  3.960225  4.958155\n",
      "300     2.0   8.223015  3.960225  4.958155\n",
      "183     7.0   6.539661  3.960225  4.958155\n",
      "406     2.0   6.426712  3.960225  4.958155\n",
      "163     3.0   5.746490  3.960225  4.958155\n",
      "86      9.0   6.346866  3.960225  4.958155\n",
      "390     9.0   4.795391  3.960225  4.958155\n",
      "158     1.0   0.005236  3.960225  4.958155\n",
      "27      5.0   3.278919  3.960225  4.958155\n",
      "415     3.0   4.809358  3.960225  4.958155\n",
      "194     9.0   3.230036  3.960225  4.958155\n",
      "301    11.0   4.918334  3.960225  4.958155\n",
      "419     1.0   2.686991  3.960225  4.958155\n",
      "259     2.0   5.985952  3.960225  4.958155\n",
      "85      2.0   4.891375  3.960225  4.958155\n",
      "45     17.0   2.363629  3.960225  4.958155\n",
      "270    13.0   6.882574  3.960225  4.958155\n",
      "89     13.0   8.916437  3.960225  4.958155\n",
      "397     2.0   4.833597  3.960225  4.958155\n",
      "319     0.0   6.030060  3.960225  4.958155\n",
      "159    10.0   3.432137  3.960225  4.958155\n",
      "293     2.0   7.771472  3.960225  4.958155\n",
      "24     11.0   5.967220  3.960225  4.958155\n",
      "49     13.0   6.685385  3.960225  4.958155\n",
      "304     8.0   7.982989  3.960225  4.958155\n",
      "405     3.0   4.323801  3.960225  4.958155\n",
      "451     2.0   1.486453  3.960225  4.958155\n",
      "269    10.0  10.276722  3.960225  4.958155\n",
      "62     14.0   8.155262  3.960225  4.958155\n",
      "139     2.0   3.388395  3.960225  4.958155\n",
      "26     13.0   5.914753  3.960225  4.958155\n",
      "19      3.0   0.596323  3.960225  4.958155\n",
      "71      4.0   4.079723  3.960225  4.958155\n",
      "186    11.0   8.722157  3.960225  4.958155\n",
      "34     13.0   4.422217  3.960225  4.958155\n",
      "170     6.0   2.001671  4.082823  5.615723\n",
      "322     1.0   2.001671  4.082823  5.615723\n",
      "457     1.0   7.103406  4.082823  5.615723\n",
      "104    14.0   8.322077  4.082823  5.615723\n",
      "75     15.0   6.827254  4.082823  5.615723\n",
      "441     1.0   2.046427  4.082823  5.615723\n",
      "408     1.0   2.014195  4.082823  5.615723\n",
      "239     0.0   5.242492  4.082823  5.615723\n",
      "42      5.0   2.853613  4.082823  5.615723\n",
      "60      4.0   4.903968  4.082823  5.615723\n",
      "280     1.0   2.001671  4.082823  5.615723\n",
      "461     2.0   4.901449  4.082823  5.615723\n",
      "327     3.0   2.001671  4.082823  5.615723\n",
      "33     13.0   2.001671  4.082823  5.615723\n",
      "449     4.0   5.859296  4.082823  5.615723\n",
      "314     7.0   4.915634  4.082823  5.615723\n",
      "123    13.0   2.001671  4.082823  5.615723\n",
      "242     6.0   2.001671  4.082823  5.615723\n",
      "354     3.0   2.001671  4.082823  5.615723\n",
      "77     13.0   2.081704  4.082823  5.615723\n",
      "91     15.0   4.628185  4.082823  5.615723\n",
      "438     2.0   2.266566  4.082823  5.615723\n",
      "433     3.0   2.001671  4.082823  5.615723\n",
      "357     7.0   2.001671  4.082823  5.615723\n",
      "339     6.0   2.001671  4.082823  5.615723\n",
      "98     13.0   6.439781  4.082823  5.615723\n",
      "11      1.0   4.179948  4.082823  5.615723\n",
      "117    15.0   2.001671  4.082823  5.615723\n",
      "382     5.0   2.983140  4.082823  5.615723\n",
      "83      1.0   2.001671  4.082823  5.615723\n",
      "202    14.0   2.001671  4.082823  5.615723\n",
      "84      1.0   3.323647  4.082823  5.615723\n",
      "61      8.0   9.627593  4.082823  5.615723\n",
      "229     1.0   2.001671  4.082823  5.615723\n",
      "454     2.0   2.001671  4.082823  5.615723\n",
      "381     5.0   3.110051  4.082823  5.615723\n",
      "78      2.0   2.001671  4.082823  5.615723\n",
      "267     9.0   6.506114  4.082823  5.615723\n",
      "36     18.0   3.821128  4.082823  5.615723\n",
      "459     4.0   2.001671  4.082823  5.615723\n",
      "343     3.0   2.001671  4.082823  5.615723\n",
      "458     5.0   2.001671  4.082823  5.615723\n",
      "247    10.0   2.111607  4.082823  5.615723\n",
      "416     3.0   2.001671  4.082823  5.615723\n",
      "17      0.0   2.374340  4.082823  5.615723\n",
      "141    11.0   2.001671  4.082823  5.615723\n",
      "126    15.0   7.686450  4.082823  5.615723\n",
      "0       3.0   2.001671  4.082823  5.615723\n",
      "21     10.0   2.001671  4.082823  5.615723\n",
      "291    10.0   2.804316  4.082823  5.615723\n",
      "300     2.0   3.230855  4.082823  5.615723\n",
      "183     7.0   6.518156  4.082823  5.615723\n",
      "406     2.0   2.001671  4.082823  5.615723\n",
      "163     3.0   3.470588  4.082823  5.615723\n",
      "86      9.0   6.474970  4.082823  5.615723\n",
      "390     9.0   2.629317  4.082823  5.615723\n",
      "158     1.0   2.001671  4.082823  5.615723\n",
      "27      5.0   3.144428  4.082823  5.615723\n",
      "415     3.0   2.001671  4.082823  5.615723\n",
      "194     9.0   2.001671  4.082823  5.615723\n",
      "301    11.0   7.679743  4.082823  5.615723\n",
      "419     1.0   2.001671  4.082823  5.615723\n",
      "259     2.0   3.415910  4.082823  5.615723\n",
      "85      2.0   2.049459  4.082823  5.615723\n",
      "45     17.0   2.001671  4.082823  5.615723\n",
      "270    13.0   4.792375  4.082823  5.615723\n",
      "89     13.0   4.814189  4.082823  5.615723\n",
      "397     2.0   3.192845  4.082823  5.615723\n",
      "319     0.0   2.001671  4.082823  5.615723\n",
      "159    10.0   2.001671  4.082823  5.615723\n",
      "293     2.0   2.147445  4.082823  5.615723\n",
      "24     11.0   7.123932  4.082823  5.615723\n",
      "49     13.0   5.552190  4.082823  5.615723\n",
      "304     8.0   5.253636  4.082823  5.615723\n",
      "405     3.0   2.001671  4.082823  5.615723\n",
      "451     2.0   2.001671  4.082823  5.615723\n",
      "269    10.0   5.779558  4.082823  5.615723\n",
      "62     14.0   6.864874  4.082823  5.615723\n",
      "139     2.0   2.001671  4.082823  5.615723\n",
      "26     13.0   2.001671  4.082823  5.615723\n",
      "19      3.0   2.001671  4.082823  5.615723\n",
      "71      4.0   2.001671  4.082823  5.615723\n",
      "186    11.0   2.707754  4.082823  5.615723\n",
      "34     13.0   2.943737  4.082823  5.615723\n",
      "170     6.0   2.160307  3.853485  4.763557\n",
      "322     1.0   0.709252  3.853485  4.763557\n",
      "457     1.0   8.526511  3.853485  4.763557\n",
      "104    14.0  10.601946  3.853485  4.763557\n",
      "75     15.0   8.040174  3.853485  4.763557\n",
      "441     1.0   5.341578  3.853485  4.763557\n",
      "408     1.0   5.463775  3.853485  4.763557\n",
      "239     0.0   4.732365  3.853485  4.763557\n",
      "42      5.0   9.513855  3.853485  4.763557\n",
      "60      4.0   6.080164  3.853485  4.763557\n",
      "280     1.0   1.469018  3.853485  4.763557\n",
      "461     2.0   3.582964  3.853485  4.763557\n",
      "327     3.0   0.000000  3.853485  4.763557\n",
      "33     13.0   6.087837  3.853485  4.763557\n",
      "449     4.0   5.462339  3.853485  4.763557\n",
      "314     7.0   6.688647  3.853485  4.763557\n",
      "123    13.0   6.312645  3.853485  4.763557\n",
      "242     6.0   1.809452  3.853485  4.763557\n",
      "354     3.0   3.141158  3.853485  4.763557\n",
      "77     13.0   5.644191  3.853485  4.763557\n",
      "91     15.0   7.663949  3.853485  4.763557\n",
      "438     2.0   7.267946  3.853485  4.763557\n",
      "433     3.0   2.984624  3.853485  4.763557\n",
      "357     7.0   2.955918  3.853485  4.763557\n",
      "339     6.0   1.883163  3.853485  4.763557\n",
      "98     13.0   7.606559  3.853485  4.763557\n",
      "11      1.0   6.300449  3.853485  4.763557\n",
      "117    15.0   5.841580  3.853485  4.763557\n",
      "382     5.0   4.622970  3.853485  4.763557\n",
      "83      1.0   3.498981  3.853485  4.763557\n",
      "202    14.0   6.967511  3.853485  4.763557\n",
      "84      1.0   6.109452  3.853485  4.763557\n",
      "61      8.0   7.280569  3.853485  4.763557\n",
      "229     1.0   1.401632  3.853485  4.763557\n",
      "454     2.0   6.719808  3.853485  4.763557\n",
      "381     5.0   3.344852  3.853485  4.763557\n",
      "78      2.0   2.566779  3.853485  4.763557\n",
      "267     9.0   7.213241  3.853485  4.763557\n",
      "36     18.0   6.729440  3.853485  4.763557\n",
      "459     4.0   2.450008  3.853485  4.763557\n",
      "343     3.0   1.264029  3.853485  4.763557\n",
      "458     5.0   0.296185  3.853485  4.763557\n",
      "247    10.0   5.591794  3.853485  4.763557\n",
      "416     3.0   0.000000  3.853485  4.763557\n",
      "17      0.0   6.975579  3.853485  4.763557\n",
      "141    11.0   3.827952  3.853485  4.763557\n",
      "126    15.0   6.027035  3.853485  4.763557\n",
      "0       3.0   4.494719  3.853485  4.763557\n",
      "21     10.0   6.249624  3.853485  4.763557\n",
      "291    10.0   3.352658  3.853485  4.763557\n",
      "300     2.0   9.320244  3.853485  4.763557\n",
      "183     7.0   7.834438  3.853485  4.763557\n",
      "406     2.0   1.184792  3.853485  4.763557\n",
      "163     3.0   8.277000  3.853485  4.763557\n",
      "86      9.0   7.174831  3.853485  4.763557\n",
      "390     9.0   4.266819  3.853485  4.763557\n",
      "158     1.0   2.348379  3.853485  4.763557\n",
      "27      5.0   5.297265  3.853485  4.763557\n",
      "415     3.0   1.503450  3.853485  4.763557\n",
      "194     9.0   6.643707  3.853485  4.763557\n",
      "301    11.0   5.758860  3.853485  4.763557\n",
      "419     1.0   1.999865  3.853485  4.763557\n",
      "259     2.0   5.579326  3.853485  4.763557\n",
      "85      2.0   7.552297  3.853485  4.763557\n",
      "45     17.0   5.341060  3.853485  4.763557\n",
      "270    13.0   7.094176  3.853485  4.763557\n",
      "89     13.0   8.996041  3.853485  4.763557\n",
      "397     2.0   4.666550  3.853485  4.763557\n",
      "319     0.0   4.910382  3.853485  4.763557\n",
      "159    10.0   4.386373  3.853485  4.763557\n",
      "293     2.0   5.896089  3.853485  4.763557\n",
      "24     11.0   8.200897  3.853485  4.763557\n",
      "49     13.0   6.877928  3.853485  4.763557\n",
      "304     8.0  10.110059  3.853485  4.763557\n",
      "405     3.0   3.529256  3.853485  4.763557\n",
      "451     2.0   1.765775  3.853485  4.763557\n",
      "269    10.0   9.101196  3.853485  4.763557\n",
      "62     14.0  10.466536  3.853485  4.763557\n",
      "139     2.0   2.513783  3.853485  4.763557\n",
      "26     13.0   7.750022  3.853485  4.763557\n",
      "19      3.0   1.926649  3.853485  4.763557\n",
      "71      4.0   2.819874  3.853485  4.763557\n",
      "186    11.0   4.839598  3.853485  4.763557\n",
      "34     13.0   1.484549  3.853485  4.763557\n",
      "\n",
      "Best Model Parameters:\n",
      "{'n_units': 64, 'learning_rate': 0.01, 'dropout_rate': 0.3, 'activation': 'tanh'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.727498792466663, 4.716379267547573)"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8\n",
    "#split\n",
    "#1차+2차\n",
    "#data_avg\n",
    "\n",
    "\n",
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data_avg\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# merged_all_comb_copy_model = ...\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\",\"2P_totals\", \"2PA_totals\", \"2P%_totals\",\n",
    "    \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\",\"AST_totals\",\n",
    "    \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",\n",
    "    \"FG_per_min\", \"FGA_per_min\", \"2P_per_min\", \"2PA_per_min\", \"3P_per_min\", \"3PA_per_min\",\"FT_per_min\", \"FTA_per_min\",\n",
    "    \"TRB_per_min\", \"AST_per_min\", \"STL_per_min\", \"BLK_per_min\",\"TOV_per_min\", \"PF_per_min\", \"PTS_per_min\",\"TS%_advanced\",\n",
    "    \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",\"ORB%_advanced\", \"DRB%_advanced\", \"TRB%_advanced\",\n",
    "    \"AST%_advanced\", \"OBPM_advanced\",\"DBPM_advanced\", \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\",\n",
    "    \"USG%_advanced\", \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\",\"FG_per_poss\", \n",
    "    \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\",\"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \n",
    "    \"AST_per_poss\", \"STL_per_poss\",\"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \"ORtg_per_poss\", \"DRtg_per_poss\"\n",
    "]\n",
    "\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# # 데이터 준비\n",
    "# X = merged_all_comb_copy_model[feature_columns]\n",
    "# y = merged_all_comb_copy_model[target_column]\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 데이터 분할 및 정규화\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 구축 및 컴파일 함수\n",
    "def build_model(n_units, learning_rate, dropout_rate, activation):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(n_units, activation=activation, input_shape=(X_train_scaled.shape[1],)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_units // 2, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "n_units_options = [64, 128]\n",
    "learning_rate_options = [0.001, 0.01]\n",
    "dropout_rate_options = [0.3, 0.5]\n",
    "activation_options = ['relu', 'tanh']\n",
    "\n",
    "best_model = None\n",
    "best_mae = float('inf')\n",
    "best_rmse = float('inf')\n",
    "best_model_params = None\n",
    "results_table = pd.DataFrame()\n",
    "\n",
    "# 하이퍼파라미터 실험 및 모델 평가\n",
    "for n_units in n_units_options:\n",
    "    for learning_rate in learning_rate_options:\n",
    "        for dropout_rate in dropout_rate_options:\n",
    "            for activation in activation_options:\n",
    "                model = build_model(n_units, learning_rate, dropout_rate, activation)\n",
    "                model.fit(X_train_scaled, y_train, epochs=1000, batch_size=32, verbose=0)\n",
    "                y_pred_raw = model.predict(X_test_scaled).flatten()\n",
    "                y_pred = np.maximum(y_pred_raw, 0)\n",
    "\n",
    "                # 평가 지표 계산\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "\n",
    "                # 최적 모델 업데이트\n",
    "                if mae + rmse < best_mae + best_rmse:\n",
    "                    best_model = model\n",
    "                    best_mae = mae\n",
    "                    best_rmse = rmse\n",
    "                    best_model_params = {'n_units': n_units, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "\n",
    "                # 결과 추가\n",
    "                temp_results = pd.DataFrame({\n",
    "                    'Actual': y_test,\n",
    "                    'Predicted': y_pred,\n",
    "                    'MAE': mae,\n",
    "                    'RMSE': rmse\n",
    "                })\n",
    "                results_table = pd.concat([results_table, temp_results])\n",
    "\n",
    "# 최적 모델의 결과와 파라미터 출력\n",
    "print(\"Best Model Results:\")\n",
    "print(results_table)\n",
    "print(\"\\nBest Model Parameters:\")\n",
    "print(best_model_params)\n",
    "\n",
    "# 최적 모델의 결과에서 가장 좋은 MAE와 RMSE 값 찾기\n",
    "best_mae = results_table['MAE'].min()\n",
    "best_rmse = results_table['RMSE'].min()\n",
    "\n",
    "best_mae, best_rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b33f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4bc21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49c4022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e004de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347410ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6bcda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6921e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fde0745",
   "metadata": {},
   "source": [
    "<h3>ANN<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "1022f968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: keras-tuner in c:\\jupyter\\anaconda3\\lib\\site-packages (1.4.6)\n",
      "Requirement already satisfied: keras in c:\\jupyter\\anaconda3\\lib\\site-packages (from keras-tuner) (2.15.0)\n",
      "Requirement already satisfied: packaging in c:\\jupyter\\anaconda3\\lib\\site-packages (from keras-tuner) (21.3)\n",
      "Requirement already satisfied: requests in c:\\jupyter\\anaconda3\\lib\\site-packages (from keras-tuner) (2.30.0)\n",
      "Requirement already satisfied: kt-legacy in c:\\jupyter\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\jupyter\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\jupyter\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\jupyter\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\jupyter\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\jupyter\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "e1123663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\ann_tuning\\tuner0.json\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Mean Absolute Error (MAE): 3.2807352173896063\n",
      "Root Mean Squared Error (RMSE): 4.469016241456608\n",
      "Best Model Hyperparameters: {'units': 480, 'dropout': 0.0}\n"
     ]
    }
   ],
   "source": [
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow 및 NumPy의 랜덤 시드 고정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "feature_columns = [\n",
    "     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\",\"2P_totals\", \"2PA_totals\", \"2P%_totals\",\n",
    "    \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\",\"AST_totals\",\n",
    "    \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",\n",
    "    \"FG_per_min\", \"FGA_per_min\", \"2P_per_min\", \"2PA_per_min\", \"3P_per_min\", \"3PA_per_min\",\"FT_per_min\", \"FTA_per_min\",\n",
    "    \"TRB_per_min\", \"AST_per_min\", \"STL_per_min\", \"BLK_per_min\",\"TOV_per_min\", \"PF_per_min\", \"PTS_per_min\",\"TS%_advanced\",\n",
    "    \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",\"ORB%_advanced\", \"DRB%_advanced\", \"TRB%_advanced\",\n",
    "    \"AST%_advanced\", \"OBPM_advanced\",\"DBPM_advanced\", \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\",\n",
    "    \"USG%_advanced\", \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\",\"FG_per_poss\", \n",
    "    \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\",\"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \n",
    "    \"AST_per_poss\", \"STL_per_poss\",\"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \"ORtg_per_poss\", \"DRtg_per_poss\"\n",
    "]\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 데이터 분할 및 정규화\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼모델 정의\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "                    activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='ann_tuning',\n",
    "    seed=42  # 랜덤 시드 고정\n",
    ")\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "# 최적 하이퍼파라미터로 모델 훈련\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Best Model Hyperparameters: {tuner.get_best_hyperparameters(num_trials=1)[0].values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "2c0bd8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\ann_tuning\\tuner0.json\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "Mean Absolute Error (MAE): 4.446753276245935\n",
      "Root Mean Squared Error (RMSE): 5.564460623870958\n",
      "Best Model Hyperparameters: {'units': 480, 'dropout': 0.0}\n"
     ]
    }
   ],
   "source": [
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data_avg\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow 및 NumPy의 랜덤 시드 고정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "feature_columns = [\n",
    "     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\",\"2P_totals\", \"2PA_totals\", \"2P%_totals\",\n",
    "    \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\",\"AST_totals\",\n",
    "    \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",\n",
    "    \"FG_per_min\", \"FGA_per_min\", \"2P_per_min\", \"2PA_per_min\", \"3P_per_min\", \"3PA_per_min\",\"FT_per_min\", \"FTA_per_min\",\n",
    "    \"TRB_per_min\", \"AST_per_min\", \"STL_per_min\", \"BLK_per_min\",\"TOV_per_min\", \"PF_per_min\", \"PTS_per_min\",\"TS%_advanced\",\n",
    "    \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",\"ORB%_advanced\", \"DRB%_advanced\", \"TRB%_advanced\",\n",
    "    \"AST%_advanced\", \"OBPM_advanced\",\"DBPM_advanced\", \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\",\n",
    "    \"USG%_advanced\", \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\",\"FG_per_poss\", \n",
    "    \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\",\"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \n",
    "    \"AST_per_poss\", \"STL_per_poss\",\"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \"ORtg_per_poss\", \"DRtg_per_poss\"\n",
    "]\n",
    "\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 데이터 분할 및 정규화\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 하이퍼모델 정의\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "                    activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='ann_tuning',\n",
    "    seed=42  # 랜덤 시드 고정\n",
    ")\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "# 최적 하이퍼파라미터로 모델 훈련\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적화된 모델로 데이터 예측 및 평가\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Best Model Hyperparameters: {tuner.get_best_hyperparameters(num_trials=1)[0].values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba1fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc0555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3678975",
   "metadata": {},
   "source": [
    "<h3>RNN<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "976216aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\rnn_tuning\\tuner0.json\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Mean Absolute Error (MAE): 3.278646409511566\n",
      "Root Mean Squared Error (RMSE): 4.276832459386783\n",
      "Best Model Hyperparameters: {'units': 60, 'dropout': 0.2, 'learning_rate': 0.0006752863927347823}\n"
     ]
    }
   ],
   "source": [
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from kerastuner import HyperModel, RandomSearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow의 랜덤 시드 고정\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "feature_columns = [\n",
    "     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\",\"2P_totals\", \"2PA_totals\", \"2P%_totals\",\n",
    "    \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\",\"AST_totals\",\n",
    "    \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",\n",
    "    \"FG_per_min\", \"FGA_per_min\", \"2P_per_min\", \"2PA_per_min\", \"3P_per_min\", \"3PA_per_min\",\"FT_per_min\", \"FTA_per_min\",\n",
    "    \"TRB_per_min\", \"AST_per_min\", \"STL_per_min\", \"BLK_per_min\",\"TOV_per_min\", \"PF_per_min\", \"PTS_per_min\",\"TS%_advanced\",\n",
    "    \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",\"ORB%_advanced\", \"DRB%_advanced\", \"TRB%_advanced\",\n",
    "    \"AST%_advanced\", \"OBPM_advanced\",\"DBPM_advanced\", \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\",\n",
    "    \"USG%_advanced\", \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\",\"FG_per_poss\", \n",
    "    \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\",\"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \n",
    "    \"AST_per_poss\", \"STL_per_poss\",\"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \"ORtg_per_poss\", \"DRtg_per_poss\"\n",
    "]\n",
    "target_column = 'Experience'\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 데이터 형태 변환 및 정규화 (시계열 데이터에 맞게 조정 필요)\n",
    "# 예시에서는 간단히 데이터를 3차원으로 변환합니다\n",
    "X = X.values.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 하이퍼모델 정의\n",
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(SimpleRNN(\n",
    "            units=hp.Int('units', min_value=20, max_value=100, step=20),\n",
    "            activation='relu',\n",
    "            input_shape=self.input_shape\n",
    "        ))\n",
    "        model.add(Dropout(rate=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(\n",
    "            optimizer=Adam(\n",
    "                hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "            ),\n",
    "            loss='mean_squared_error'\n",
    "        )\n",
    "        return model\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "hypermodel = MyHyperModel(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='rnn_tuning',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=10, validation_split=0.2, verbose=2)\n",
    "\n",
    "# 최적 하이퍼파라미터로 모델 훈련\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Best Model Hyperparameters: {tuner.get_best_hyperparameters(num_trials=1)[0].values}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "cdf541f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\rnn_tuning\\tuner0.json\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "Mean Absolute Error (MAE): 4.2504095775740485\n",
      "Root Mean Squared Error (RMSE): 5.109946240479343\n",
      "Best Model Hyperparameters: {'units': 60, 'dropout': 0.2, 'learning_rate': 0.0006752863927347823}\n"
     ]
    }
   ],
   "source": [
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data_avg\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from kerastuner import HyperModel, RandomSearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow의 랜덤 시드 고정\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "feature_columns = [\n",
    "     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\",\"2P_totals\", \"2PA_totals\", \"2P%_totals\",\n",
    "    \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\",\"AST_totals\",\n",
    "    \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",\n",
    "    \"FG_per_min\", \"FGA_per_min\", \"2P_per_min\", \"2PA_per_min\", \"3P_per_min\", \"3PA_per_min\",\"FT_per_min\", \"FTA_per_min\",\n",
    "    \"TRB_per_min\", \"AST_per_min\", \"STL_per_min\", \"BLK_per_min\",\"TOV_per_min\", \"PF_per_min\", \"PTS_per_min\",\"TS%_advanced\",\n",
    "    \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",\"ORB%_advanced\", \"DRB%_advanced\", \"TRB%_advanced\",\n",
    "    \"AST%_advanced\", \"OBPM_advanced\",\"DBPM_advanced\", \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\",\n",
    "    \"USG%_advanced\", \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\",\"FG_per_poss\", \n",
    "    \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\",\"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \n",
    "    \"AST_per_poss\", \"STL_per_poss\",\"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \"ORtg_per_poss\", \"DRtg_per_poss\"\n",
    "]\n",
    "target_column = 'Experience'\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 데이터 형태 변환 및 정규화 (시계열 데이터에 맞게 조정 필요)\n",
    "# 예시에서는 간단히 데이터를 3차원으로 변환합니다\n",
    "X = X.values.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 하이퍼모델 정의\n",
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(SimpleRNN(\n",
    "            units=hp.Int('units', min_value=20, max_value=100, step=20),\n",
    "            activation='relu',\n",
    "            input_shape=self.input_shape\n",
    "        ))\n",
    "        model.add(Dropout(rate=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(\n",
    "            optimizer=Adam(\n",
    "                hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "            ),\n",
    "            loss='mean_squared_error'\n",
    "        )\n",
    "        return model\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "hypermodel = MyHyperModel(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='rnn_tuning',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=10, validation_split=0.2, verbose=2)\n",
    "\n",
    "# 최적 하이퍼파라미터로 모델 훈련\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Best Model Hyperparameters: {tuner.get_best_hyperparameters(num_trials=1)[0].values}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f441547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff93f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178903e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5c83d22",
   "metadata": {},
   "source": [
    "<h3>1D 컨볼루전 신경망<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ab81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "b3943eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\1d_cnn_tuning\\tuner0.json\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "Mean Absolute Error (MAE): 3.4880457548868087\n",
      "Root Mean Squared Error (RMSE): 4.372451209774623\n",
      "Best Model Hyperparameters: {'filters': 32, 'kernel_size': 2, 'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005509513888645584}\n"
     ]
    }
   ],
   "source": [
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from kerastuner import HyperModel, RandomSearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow의 랜덤 시드 고정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\",\"2P_totals\", \"2PA_totals\", \"2P%_totals\",\n",
    "    \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\",\"AST_totals\",\n",
    "    \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",\n",
    "    \"FG_per_min\", \"FGA_per_min\", \"2P_per_min\", \"2PA_per_min\", \"3P_per_min\", \"3PA_per_min\",\"FT_per_min\", \"FTA_per_min\",\n",
    "    \"TRB_per_min\", \"AST_per_min\", \"STL_per_min\", \"BLK_per_min\",\"TOV_per_min\", \"PF_per_min\", \"PTS_per_min\",\"TS%_advanced\",\n",
    "    \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",\"ORB%_advanced\", \"DRB%_advanced\", \"TRB%_advanced\",\n",
    "    \"AST%_advanced\", \"OBPM_advanced\",\"DBPM_advanced\", \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\",\n",
    "    \"USG%_advanced\", \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\",\"FG_per_poss\", \n",
    "    \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\",\"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \n",
    "    \"AST_per_poss\", \"STL_per_poss\",\"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \"ORtg_per_poss\", \"DRtg_per_poss\"\n",
    "]\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data = data.dropna(subset=feature_columns + [target_column])\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# 데이터 형태 변환 및 정규화\n",
    "X = X.values.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 하이퍼모델 정의\n",
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(\n",
    "            filters=hp.Int('filters', min_value=32, max_value=128, step=32),\n",
    "            kernel_size=hp.Choice('kernel_size', values=[2, 3, 5]),\n",
    "            activation='relu',\n",
    "            input_shape=self.input_shape\n",
    "        ))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(\n",
    "            units=hp.Int('units', min_value=32, max_value=128, step=32),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(Dropout(rate=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(\n",
    "            optimizer=Adam(\n",
    "                hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "            ),\n",
    "            loss='mean_squared_error'\n",
    "        )\n",
    "        return model\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "hypermodel = MyHyperModel(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='1d_cnn_tuning',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=10, validation_split=0.2, verbose=2)\n",
    "\n",
    "# 최적 하이퍼파라미터로 모델 훈련\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Best Model Hyperparameters: {tuner.get_best_hyperparameters(num_trials=1)[0].values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "6247a5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\1d_cnn_tuning\\tuner0.json\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "Mean Absolute Error (MAE): 4.355038807505653\n",
      "Root Mean Squared Error (RMSE): 5.091043011419902\n",
      "Best Model Hyperparameters: {'filters': 32, 'kernel_size': 2, 'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005509513888645584}\n"
     ]
    }
   ],
   "source": [
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#data_avg\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from kerastuner import HyperModel, RandomSearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow의 랜덤 시드 고정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Feature 및 타겟 컬럼 정의\n",
    "feature_columns = [\n",
    "     'Pos', 'Height_cm', 'Weight_kg', 'Standing_Reach_inch', 'Wingspan_inch', \n",
    "    'LANE_AGILITY_sec', 'THREE_QUATER_SPRINT', 'STANDING_VERTICAL_LEAP_inch', 'MAX_VERTICAL_LEAP_inch',\n",
    "    \"G_totals\", \"MP_totals\", \"FG_totals\", \"FGA_totals\", \"FG%_totals\",\"2P_totals\", \"2PA_totals\", \"2P%_totals\",\n",
    "    \"3P_totals\", \"3PA_totals\", \"3P%_totals\", \"FT_totals\", \"FTA_totals\", \"FT%_totals\", \"TRB_totals\",\"AST_totals\",\n",
    "    \"STL_totals\", \"BLK_totals\", \"TOV_totals\", \"PF_totals\", \"PTS_totals\",\n",
    "    \"FG_per_min\", \"FGA_per_min\", \"2P_per_min\", \"2PA_per_min\", \"3P_per_min\", \"3PA_per_min\",\"FT_per_min\", \"FTA_per_min\",\n",
    "    \"TRB_per_min\", \"AST_per_min\", \"STL_per_min\", \"BLK_per_min\",\"TOV_per_min\", \"PF_per_min\", \"PTS_per_min\",\"TS%_advanced\",\n",
    "    \"eFG%_advanced\", \"3PAr_advanced\", \"FTr_advanced\", \"PProd_advanced\",\"ORB%_advanced\", \"DRB%_advanced\", \"TRB%_advanced\",\n",
    "    \"AST%_advanced\", \"OBPM_advanced\",\"DBPM_advanced\", \"BPM_advanced\", \"STL%_advanced\", \"BLK%_advanced\", \"TOV%_advanced\",\n",
    "    \"USG%_advanced\", \"OWS_advanced\", \"DWS_advanced\", \"WS_advanced\", \"WS/40_advanced\", \"PER_advanced\",\"FG_per_poss\", \n",
    "    \"FGA_per_poss\", \"2P_per_poss\", \"2PA_per_poss\", \"3P_per_poss\",\"3PA_per_poss\", \"FT_per_poss\", \"FTA_per_poss\", \"TRB_per_poss\", \n",
    "    \"AST_per_poss\", \"STL_per_poss\",\"BLK_per_poss\", \"TOV_per_poss\", \"PF_per_poss\", \"PTS_per_poss\", \"ORtg_per_poss\", \"DRtg_per_poss\"\n",
    "]\n",
    "target_column = 'Experience'\n",
    "\n",
    "# 결측치가 있는 샘플 제거 및 데이터 준비\n",
    "data_avg = data_avg.dropna(subset=feature_columns + [target_column])\n",
    "X = data_avg[feature_columns]\n",
    "y = data_avg[target_column]\n",
    "\n",
    "# 데이터 형태 변환 및 정규화\n",
    "X = X.values.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 하이퍼모델 정의\n",
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(\n",
    "            filters=hp.Int('filters', min_value=32, max_value=128, step=32),\n",
    "            kernel_size=hp.Choice('kernel_size', values=[2, 3, 5]),\n",
    "            activation='relu',\n",
    "            input_shape=self.input_shape\n",
    "        ))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(\n",
    "            units=hp.Int('units', min_value=32, max_value=128, step=32),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(Dropout(rate=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(\n",
    "            optimizer=Adam(\n",
    "                hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "            ),\n",
    "            loss='mean_squared_error'\n",
    "        )\n",
    "        return model\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "hypermodel = MyHyperModel(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='1d_cnn_tuning',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=10, validation_split=0.2, verbose=2)\n",
    "\n",
    "# 최적 하이퍼파라미터로 모델 훈련\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Best Model Hyperparameters: {tuner.get_best_hyperparameters(num_trials=1)[0].values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c8067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302a469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "c028abe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24596\\427244873.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# 데이터 형태 변환 (예: X.shape -> (샘플 수, 시계열 길이, 특성 수))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# 데이터 분할\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "data = merged_all_comb_copy_grouped.copy()\n",
    "data_avg = weighted_avg_new.copy()\n",
    "#CNN\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# ...\n",
    "\n",
    "# 데이터 형태 변환 (예: X.shape -> (샘플 수, 시계열 길이, 특성 수))\n",
    "X = X.values.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1D CNN 모델 구축\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일 및 훈련\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d3f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb830f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d128174a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e76c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d0c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
